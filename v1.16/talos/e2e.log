I1007 17:41:25.123089      19 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-832208514
I1007 17:41:25.123213      19 e2e.go:92] Starting e2e run "d0fe5200-588e-46e6-a22f-38b042e15d06" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1570470083 - Will randomize all specs
Will run 276 of 4897 specs

Oct  7 17:41:25.151: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:41:25.154: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Oct  7 17:41:25.171: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Oct  7 17:41:25.204: INFO: 26 / 26 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Oct  7 17:41:25.204: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Oct  7 17:41:25.204: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Oct  7 17:41:25.214: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Oct  7 17:41:25.214: INFO: 6 / 6 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Oct  7 17:41:25.214: INFO: e2e test version: v1.16.0
Oct  7 17:41:25.215: INFO: kube-apiserver version: v1.16.0
Oct  7 17:41:25.215: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:41:25.220: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:41:25.221: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
Oct  7 17:41:25.317: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Oct  7 17:41:25.329: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9587
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a0663277-6d84-4dae-9909-9c25f743f680
STEP: Creating a pod to test consume configMaps
Oct  7 17:41:25.458: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122" in namespace "projected-9587" to be "success or failure"
Oct  7 17:41:25.461: INFO: Pod "pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122": Phase="Pending", Reason="", readiness=false. Elapsed: 2.749805ms
Oct  7 17:41:27.469: INFO: Pod "pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010438346s
STEP: Saw pod success
Oct  7 17:41:27.469: INFO: Pod "pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122" satisfied condition "success or failure"
Oct  7 17:41:27.472: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 17:41:27.510: INFO: Waiting for pod pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122 to disappear
Oct  7 17:41:27.514: INFO: Pod pod-projected-configmaps-c5dfdefb-dbb4-4243-8621-0b83a2b19122 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:41:27.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9587" for this suite.
Oct  7 17:41:33.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:41:33.596: INFO: namespace projected-9587 deletion completed in 6.078241332s

• [SLOW TEST:8.375 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:41:33.596: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-3bd29ea6-3a7b-47ed-bf3d-e805eaa9d040
STEP: Creating a pod to test consume configMaps
Oct  7 17:41:33.769: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928" in namespace "projected-7978" to be "success or failure"
Oct  7 17:41:33.772: INFO: Pod "pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928": Phase="Pending", Reason="", readiness=false. Elapsed: 2.343816ms
Oct  7 17:41:35.776: INFO: Pod "pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006216034s
STEP: Saw pod success
Oct  7 17:41:35.776: INFO: Pod "pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928" satisfied condition "success or failure"
Oct  7 17:41:35.778: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 17:41:35.797: INFO: Waiting for pod pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928 to disappear
Oct  7 17:41:35.800: INFO: Pod pod-projected-configmaps-ef4fcf7b-7c20-4d5d-a413-626b25fb2928 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:41:35.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7978" for this suite.
Oct  7 17:41:41.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:41:41.875: INFO: namespace projected-7978 deletion completed in 6.072291058s

• [SLOW TEST:8.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:41:41.875: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8640
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-7bc769d6-4821-4158-ae78-a274c5785d30
STEP: Creating configMap with name cm-test-opt-upd-defc00b4-557c-4e47-a835-3e6f1420a910
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7bc769d6-4821-4158-ae78-a274c5785d30
STEP: Updating configmap cm-test-opt-upd-defc00b4-557c-4e47-a835-3e6f1420a910
STEP: Creating configMap with name cm-test-opt-create-f2ef15e6-3b0e-42fa-bedf-a6e63b3d9c7c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:43:00.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8640" for this suite.
Oct  7 17:43:12.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:43:12.473: INFO: namespace projected-8640 deletion completed in 12.082405823s

• [SLOW TEST:90.597 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:43:12.473: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-333
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  7 17:43:20.688: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  7 17:43:20.691: INFO: Pod pod-with-poststart-http-hook still exists
Oct  7 17:43:22.691: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  7 17:43:22.695: INFO: Pod pod-with-poststart-http-hook still exists
Oct  7 17:43:24.691: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Oct  7 17:43:24.695: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:43:24.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-333" for this suite.
Oct  7 17:43:36.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:43:36.777: INFO: namespace container-lifecycle-hook-333 deletion completed in 12.07810731s

• [SLOW TEST:24.304 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:43:36.778: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-knm5
STEP: Creating a pod to test atomic-volume-subpath
Oct  7 17:43:36.966: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-knm5" in namespace "subpath-6699" to be "success or failure"
Oct  7 17:43:36.969: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.339511ms
Oct  7 17:43:38.973: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 2.006460378s
Oct  7 17:43:40.976: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 4.0096683s
Oct  7 17:43:42.990: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 6.023797231s
Oct  7 17:43:44.994: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 8.027414725s
Oct  7 17:43:46.998: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 10.031612892s
Oct  7 17:43:49.002: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 12.035466271s
Oct  7 17:43:51.005: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 14.038884595s
Oct  7 17:43:53.009: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 16.04256069s
Oct  7 17:43:55.012: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 18.04594741s
Oct  7 17:43:57.016: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Running", Reason="", readiness=true. Elapsed: 20.049743441s
Oct  7 17:43:59.020: INFO: Pod "pod-subpath-test-secret-knm5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.053352373s
STEP: Saw pod success
Oct  7 17:43:59.020: INFO: Pod "pod-subpath-test-secret-knm5" satisfied condition "success or failure"
Oct  7 17:43:59.023: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod pod-subpath-test-secret-knm5 container test-container-subpath-secret-knm5: <nil>
STEP: delete the pod
Oct  7 17:43:59.041: INFO: Waiting for pod pod-subpath-test-secret-knm5 to disappear
Oct  7 17:43:59.044: INFO: Pod pod-subpath-test-secret-knm5 no longer exists
STEP: Deleting pod pod-subpath-test-secret-knm5
Oct  7 17:43:59.044: INFO: Deleting pod "pod-subpath-test-secret-knm5" in namespace "subpath-6699"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:43:59.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6699" for this suite.
Oct  7 17:44:05.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:44:05.129: INFO: namespace subpath-6699 deletion completed in 6.078765708s

• [SLOW TEST:28.351 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:44:05.129: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 17:44:05.295: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253" in namespace "projected-442" to be "success or failure"
Oct  7 17:44:05.297: INFO: Pod "downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253": Phase="Pending", Reason="", readiness=false. Elapsed: 2.41164ms
Oct  7 17:44:07.311: INFO: Pod "downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016257049s
Oct  7 17:44:09.314: INFO: Pod "downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019642401s
STEP: Saw pod success
Oct  7 17:44:09.314: INFO: Pod "downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253" satisfied condition "success or failure"
Oct  7 17:44:09.317: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253 container client-container: <nil>
STEP: delete the pod
Oct  7 17:44:09.350: INFO: Waiting for pod downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253 to disappear
Oct  7 17:44:09.352: INFO: Pod downwardapi-volume-cea5cbf4-458a-47d4-b729-67302da79253 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:44:09.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-442" for this suite.
Oct  7 17:44:15.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:44:15.432: INFO: namespace projected-442 deletion completed in 6.075873378s

• [SLOW TEST:10.303 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:44:15.432: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3821
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  7 17:44:15.598: INFO: Waiting up to 5m0s for pod "downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331" in namespace "downward-api-3821" to be "success or failure"
Oct  7 17:44:15.601: INFO: Pod "downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331": Phase="Pending", Reason="", readiness=false. Elapsed: 2.788611ms
Oct  7 17:44:17.605: INFO: Pod "downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006964511s
Oct  7 17:44:19.609: INFO: Pod "downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010710441s
STEP: Saw pod success
Oct  7 17:44:19.609: INFO: Pod "downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331" satisfied condition "success or failure"
Oct  7 17:44:19.612: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331 container dapi-container: <nil>
STEP: delete the pod
Oct  7 17:44:19.632: INFO: Waiting for pod downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331 to disappear
Oct  7 17:44:19.635: INFO: Pod downward-api-fe54c56b-7733-4917-a3f1-a8b9c0dea331 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:44:19.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3821" for this suite.
Oct  7 17:44:25.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:44:25.717: INFO: namespace downward-api-3821 deletion completed in 6.079469849s

• [SLOW TEST:10.285 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:44:25.719: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5034
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:44:42.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5034" for this suite.
Oct  7 17:44:48.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:44:48.125: INFO: namespace resourcequota-5034 deletion completed in 6.094585401s

• [SLOW TEST:22.406 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:44:48.125: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4790
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Oct  7 17:45:01.333: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:45:02.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4790" for this suite.
Oct  7 17:45:30.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:45:30.425: INFO: namespace replicaset-4790 deletion completed in 28.072836027s

• [SLOW TEST:42.300 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:45:30.425: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:45:30.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9852" for this suite.
Oct  7 17:45:42.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:45:42.749: INFO: namespace pods-9852 deletion completed in 12.150625485s

• [SLOW TEST:12.324 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:45:42.750: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2601
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Oct  7 17:45:42.905: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-832208514 proxy --unix-socket=/tmp/kubectl-proxy-unix232528889/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:45:42.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2601" for this suite.
Oct  7 17:45:48.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:45:49.064: INFO: namespace kubectl-2601 deletion completed in 6.08874749s

• [SLOW TEST:6.314 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:45:49.065: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7585
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:46:14.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7585" for this suite.
Oct  7 17:46:20.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:46:20.603: INFO: namespace container-runtime-7585 deletion completed in 6.079027947s

• [SLOW TEST:31.539 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:46:20.604: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:46:33.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5075" for this suite.
Oct  7 17:46:39.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:46:39.899: INFO: namespace resourcequota-5075 deletion completed in 6.073839352s

• [SLOW TEST:19.295 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:46:39.899: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-6d1fe365-ce01-47d9-8b9d-52e110c14745
STEP: Creating a pod to test consume configMaps
Oct  7 17:46:40.095: INFO: Waiting up to 5m0s for pod "pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521" in namespace "configmap-6517" to be "success or failure"
Oct  7 17:46:40.098: INFO: Pod "pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521": Phase="Pending", Reason="", readiness=false. Elapsed: 3.180202ms
Oct  7 17:46:42.102: INFO: Pod "pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007180638s
STEP: Saw pod success
Oct  7 17:46:42.102: INFO: Pod "pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521" satisfied condition "success or failure"
Oct  7 17:46:42.105: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 17:46:42.134: INFO: Waiting for pod pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521 to disappear
Oct  7 17:46:42.137: INFO: Pod pod-configmaps-1fb9b727-2812-46e6-a8cf-ce41daa0f521 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:46:42.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6517" for this suite.
Oct  7 17:46:48.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:46:48.214: INFO: namespace configmap-6517 deletion completed in 6.073364818s

• [SLOW TEST:8.314 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:46:48.215: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1201
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-c9f4b142-93ae-4afb-84a6-da00b613d22b
STEP: Creating a pod to test consume configMaps
Oct  7 17:46:48.383: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5" in namespace "projected-1201" to be "success or failure"
Oct  7 17:46:48.386: INFO: Pod "pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.715434ms
Oct  7 17:46:50.390: INFO: Pod "pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006179023s
STEP: Saw pod success
Oct  7 17:46:50.390: INFO: Pod "pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5" satisfied condition "success or failure"
Oct  7 17:46:50.392: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 17:46:50.414: INFO: Waiting for pod pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5 to disappear
Oct  7 17:46:50.417: INFO: Pod pod-projected-configmaps-eeb713cd-b2ce-48b5-8404-613ce72cdcb5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:46:50.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1201" for this suite.
Oct  7 17:46:56.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:46:56.493: INFO: namespace projected-1201 deletion completed in 6.073184972s

• [SLOW TEST:8.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:46:56.494: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-68ec9f45-1533-481c-b006-52eda5ea49be
STEP: Creating a pod to test consume configMaps
Oct  7 17:46:56.691: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb" in namespace "configmap-6264" to be "success or failure"
Oct  7 17:46:56.694: INFO: Pod "pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.807617ms
Oct  7 17:46:58.697: INFO: Pod "pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006015566s
STEP: Saw pod success
Oct  7 17:46:58.697: INFO: Pod "pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb" satisfied condition "success or failure"
Oct  7 17:46:58.700: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 17:46:58.734: INFO: Waiting for pod pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb to disappear
Oct  7 17:46:58.736: INFO: Pod pod-configmaps-7d8224c8-03eb-4f23-b454-0e48498d55fb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:46:58.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6264" for this suite.
Oct  7 17:47:04.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:47:04.815: INFO: namespace configmap-6264 deletion completed in 6.075140714s

• [SLOW TEST:8.322 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:47:04.818: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9142
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  7 17:47:04.988: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  7 17:47:31.101: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.12:8080/dial?request=hostName&protocol=http&host=10.244.4.5&port=8080&tries=1'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:47:31.101: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:47:31.275: INFO: Waiting for endpoints: map[]
Oct  7 17:47:31.279: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.12:8080/dial?request=hostName&protocol=http&host=10.244.3.11&port=8080&tries=1'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:47:31.279: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:47:31.456: INFO: Waiting for endpoints: map[]
Oct  7 17:47:31.459: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.12:8080/dial?request=hostName&protocol=http&host=10.244.1.18&port=8080&tries=1'] Namespace:pod-network-test-9142 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:47:31.459: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:47:31.634: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:47:31.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9142" for this suite.
Oct  7 17:47:43.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:47:43.713: INFO: namespace pod-network-test-9142 deletion completed in 12.074698069s

• [SLOW TEST:38.895 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:47:43.714: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-310cfb2e-764d-4ddb-af15-f13268a57881
STEP: Creating a pod to test consume secrets
Oct  7 17:47:43.898: INFO: Waiting up to 5m0s for pod "pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45" in namespace "secrets-1000" to be "success or failure"
Oct  7 17:47:43.901: INFO: Pod "pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45": Phase="Pending", Reason="", readiness=false. Elapsed: 2.478275ms
Oct  7 17:47:45.904: INFO: Pod "pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006270553s
STEP: Saw pod success
Oct  7 17:47:45.904: INFO: Pod "pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45" satisfied condition "success or failure"
Oct  7 17:47:45.907: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 17:47:45.925: INFO: Waiting for pod pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45 to disappear
Oct  7 17:47:45.928: INFO: Pod pod-secrets-b10c4aef-7bc0-4f81-a101-3dace1642f45 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:47:45.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1000" for this suite.
Oct  7 17:47:51.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:47:52.006: INFO: namespace secrets-1000 deletion completed in 6.075785423s

• [SLOW TEST:8.292 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:47:52.007: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct  7 17:47:52.160: INFO: namespace kubectl-1955
Oct  7 17:47:52.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-1955'
Oct  7 17:47:52.635: INFO: stderr: ""
Oct  7 17:47:52.635: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  7 17:47:53.640: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:53.640: INFO: Found 0 / 1
Oct  7 17:47:54.639: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:54.639: INFO: Found 0 / 1
Oct  7 17:47:55.639: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:55.639: INFO: Found 0 / 1
Oct  7 17:47:56.640: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:56.640: INFO: Found 0 / 1
Oct  7 17:47:57.640: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:57.640: INFO: Found 0 / 1
Oct  7 17:47:58.639: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:58.640: INFO: Found 1 / 1
Oct  7 17:47:58.640: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  7 17:47:58.642: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 17:47:58.642: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  7 17:47:58.642: INFO: wait on redis-master startup in kubectl-1955 
Oct  7 17:47:58.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs redis-master-ldbf7 redis-master --namespace=kubectl-1955'
Oct  7 17:47:58.749: INFO: stderr: ""
Oct  7 17:47:58.749: INFO: stdout: "1:C 07 Oct 2019 17:47:57.217 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 07 Oct 2019 17:47:57.218 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 07 Oct 2019 17:47:57.218 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 07 Oct 2019 17:47:57.220 # You requested maxclients of 10000 requiring at least 10032 max file descriptors.\n1:M 07 Oct 2019 17:47:57.220 # Server can't set maximum open files to 10032 because of OS error: Operation not permitted.\n1:M 07 Oct 2019 17:47:57.220 # Current maximum open files is 4096. maxclients has been reduced to 4064 to compensate for low ulimit. If you need higher maxclients increase 'ulimit -n'.\n1:M 07 Oct 2019 17:47:57.221 * Running mode=standalone, port=6379.\n1:M 07 Oct 2019 17:47:57.221 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 07 Oct 2019 17:47:57.221 # Server initialized\n1:M 07 Oct 2019 17:47:57.221 * Ready to accept connections\n"
STEP: exposing RC
Oct  7 17:47:58.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1955'
Oct  7 17:47:58.884: INFO: stderr: ""
Oct  7 17:47:58.884: INFO: stdout: "service/rm2 exposed\n"
Oct  7 17:47:58.889: INFO: Service rm2 in namespace kubectl-1955 found.
STEP: exposing service
Oct  7 17:48:00.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1955'
Oct  7 17:48:01.010: INFO: stderr: ""
Oct  7 17:48:01.010: INFO: stdout: "service/rm3 exposed\n"
Oct  7 17:48:01.013: INFO: Service rm3 in namespace kubectl-1955 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:48:03.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1955" for this suite.
Oct  7 17:48:15.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:48:15.096: INFO: namespace kubectl-1955 deletion completed in 12.071158641s

• [SLOW TEST:23.089 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:48:15.097: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9821
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9821
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  7 17:48:15.258: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  7 17:48:35.423: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.19 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9821 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:48:35.423: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:48:36.580: INFO: Found all expected endpoints: [netserver-0]
Oct  7 17:48:36.583: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.15 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9821 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:48:36.583: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:48:37.756: INFO: Found all expected endpoints: [netserver-1]
Oct  7 17:48:37.759: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.4.6 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9821 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:48:37.759: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:48:38.926: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:48:38.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9821" for this suite.
Oct  7 17:48:50.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:48:51.001: INFO: namespace pod-network-test-9821 deletion completed in 12.071308749s

• [SLOW TEST:35.822 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:48:51.002: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 17:48:51.743: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 17:48:54.770: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:48:54.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9435" for this suite.
Oct  7 17:49:00.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:49:01.053: INFO: namespace webhook-9435 deletion completed in 6.075742627s
STEP: Destroying namespace "webhook-9435-markers" for this suite.
Oct  7 17:49:07.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:49:07.135: INFO: namespace webhook-9435-markers deletion completed in 6.08127582s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.147 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:49:07.150: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  7 17:49:07.336: INFO: Waiting up to 5m0s for pod "pod-ffd52987-b52e-4346-acf0-d6285791e044" in namespace "emptydir-5007" to be "success or failure"
Oct  7 17:49:07.339: INFO: Pod "pod-ffd52987-b52e-4346-acf0-d6285791e044": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818958ms
Oct  7 17:49:09.342: INFO: Pod "pod-ffd52987-b52e-4346-acf0-d6285791e044": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006413807s
STEP: Saw pod success
Oct  7 17:49:09.342: INFO: Pod "pod-ffd52987-b52e-4346-acf0-d6285791e044" satisfied condition "success or failure"
Oct  7 17:49:09.345: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod pod-ffd52987-b52e-4346-acf0-d6285791e044 container test-container: <nil>
STEP: delete the pod
Oct  7 17:49:09.375: INFO: Waiting for pod pod-ffd52987-b52e-4346-acf0-d6285791e044 to disappear
Oct  7 17:49:09.379: INFO: Pod pod-ffd52987-b52e-4346-acf0-d6285791e044 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:49:09.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5007" for this suite.
Oct  7 17:49:15.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:49:15.454: INFO: namespace emptydir-5007 deletion completed in 6.071635208s

• [SLOW TEST:8.304 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:49:15.454: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1629
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  7 17:49:15.629: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  7 17:49:37.706: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.18:8080/dial?request=hostName&protocol=udp&host=10.244.4.7&port=8081&tries=1'] Namespace:pod-network-test-1629 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:49:37.706: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:49:37.890: INFO: Waiting for endpoints: map[]
Oct  7 17:49:37.893: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.18:8080/dial?request=hostName&protocol=udp&host=10.244.1.22&port=8081&tries=1'] Namespace:pod-network-test-1629 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:49:37.893: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:49:38.080: INFO: Waiting for endpoints: map[]
Oct  7 17:49:38.083: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.18:8080/dial?request=hostName&protocol=udp&host=10.244.3.17&port=8081&tries=1'] Namespace:pod-network-test-1629 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:49:38.083: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:49:38.265: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:49:38.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1629" for this suite.
Oct  7 17:49:50.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:49:50.348: INFO: namespace pod-network-test-1629 deletion completed in 12.078992013s

• [SLOW TEST:34.893 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:49:50.350: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:50:06.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9934" for this suite.
Oct  7 17:50:12.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:50:12.690: INFO: namespace resourcequota-9934 deletion completed in 6.074499108s

• [SLOW TEST:22.341 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:50:12.692: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1455
I1007 17:50:12.876347      19 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1455, replica count: 1
I1007 17:50:13.927170      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1007 17:50:14.927353      19 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  7 17:50:15.050: INFO: Created: latency-svc-jbhnp
Oct  7 17:50:15.087: INFO: Got endpoints: latency-svc-jbhnp [59.331902ms]
Oct  7 17:50:15.109: INFO: Created: latency-svc-5gh6q
Oct  7 17:50:15.116: INFO: Got endpoints: latency-svc-5gh6q [29.193203ms]
Oct  7 17:50:15.125: INFO: Created: latency-svc-bgvb8
Oct  7 17:50:15.128: INFO: Got endpoints: latency-svc-bgvb8 [40.972738ms]
Oct  7 17:50:15.147: INFO: Created: latency-svc-t9ngd
Oct  7 17:50:15.176: INFO: Got endpoints: latency-svc-t9ngd [87.306775ms]
Oct  7 17:50:15.195: INFO: Created: latency-svc-gzhkf
Oct  7 17:50:15.206: INFO: Got endpoints: latency-svc-gzhkf [118.004226ms]
Oct  7 17:50:15.236: INFO: Created: latency-svc-n4qck
Oct  7 17:50:15.249: INFO: Got endpoints: latency-svc-n4qck [161.418893ms]
Oct  7 17:50:15.259: INFO: Created: latency-svc-ndlz8
Oct  7 17:50:15.267: INFO: Got endpoints: latency-svc-ndlz8 [179.254463ms]
Oct  7 17:50:15.279: INFO: Created: latency-svc-gswbs
Oct  7 17:50:15.284: INFO: Got endpoints: latency-svc-gswbs [195.970655ms]
Oct  7 17:50:15.325: INFO: Created: latency-svc-mzh72
Oct  7 17:50:15.335: INFO: Got endpoints: latency-svc-mzh72 [246.642967ms]
Oct  7 17:50:15.346: INFO: Created: latency-svc-dgtkz
Oct  7 17:50:15.365: INFO: Got endpoints: latency-svc-dgtkz [275.97063ms]
Oct  7 17:50:15.375: INFO: Created: latency-svc-f746d
Oct  7 17:50:15.377: INFO: Got endpoints: latency-svc-f746d [287.542335ms]
Oct  7 17:50:15.438: INFO: Created: latency-svc-8s54h
Oct  7 17:50:15.459: INFO: Got endpoints: latency-svc-8s54h [370.612171ms]
Oct  7 17:50:15.462: INFO: Created: latency-svc-64866
Oct  7 17:50:15.476: INFO: Got endpoints: latency-svc-64866 [387.3083ms]
Oct  7 17:50:15.483: INFO: Created: latency-svc-dmlgr
Oct  7 17:50:15.486: INFO: Got endpoints: latency-svc-dmlgr [396.721962ms]
Oct  7 17:50:15.500: INFO: Created: latency-svc-p6rxh
Oct  7 17:50:15.517: INFO: Got endpoints: latency-svc-p6rxh [428.236535ms]
Oct  7 17:50:15.529: INFO: Created: latency-svc-clpf4
Oct  7 17:50:15.552: INFO: Got endpoints: latency-svc-clpf4 [463.209389ms]
Oct  7 17:50:15.559: INFO: Created: latency-svc-rcqwb
Oct  7 17:50:15.579: INFO: Created: latency-svc-dm8fp
Oct  7 17:50:15.597: INFO: Created: latency-svc-687g8
Oct  7 17:50:15.629: INFO: Got endpoints: latency-svc-dm8fp [500.760412ms]
Oct  7 17:50:15.630: INFO: Got endpoints: latency-svc-rcqwb [513.211322ms]
Oct  7 17:50:15.631: INFO: Got endpoints: latency-svc-687g8 [455.315877ms]
Oct  7 17:50:15.636: INFO: Created: latency-svc-lnh4w
Oct  7 17:50:15.656: INFO: Got endpoints: latency-svc-lnh4w [450.117368ms]
Oct  7 17:50:15.753: INFO: Created: latency-svc-crjqs
Oct  7 17:50:15.759: INFO: Got endpoints: latency-svc-crjqs [508.296816ms]
Oct  7 17:50:15.812: INFO: Created: latency-svc-pq8vl
Oct  7 17:50:15.859: INFO: Got endpoints: latency-svc-pq8vl [591.235903ms]
Oct  7 17:50:15.871: INFO: Created: latency-svc-9ctqt
Oct  7 17:50:15.879: INFO: Got endpoints: latency-svc-9ctqt [595.061709ms]
Oct  7 17:50:15.886: INFO: Created: latency-svc-pbgl2
Oct  7 17:50:15.896: INFO: Got endpoints: latency-svc-pbgl2 [560.710533ms]
Oct  7 17:50:15.918: INFO: Created: latency-svc-rcfdz
Oct  7 17:50:15.918: INFO: Got endpoints: latency-svc-rcfdz [553.076741ms]
Oct  7 17:50:15.949: INFO: Created: latency-svc-g4nfx
Oct  7 17:50:15.954: INFO: Got endpoints: latency-svc-g4nfx [577.102165ms]
Oct  7 17:50:15.973: INFO: Created: latency-svc-zkqs4
Oct  7 17:50:15.985: INFO: Got endpoints: latency-svc-zkqs4 [525.072489ms]
Oct  7 17:50:15.989: INFO: Created: latency-svc-m4k48
Oct  7 17:50:16.006: INFO: Got endpoints: latency-svc-m4k48 [528.744526ms]
Oct  7 17:50:16.013: INFO: Created: latency-svc-fvjqh
Oct  7 17:50:16.041: INFO: Created: latency-svc-8dbrz
Oct  7 17:50:16.056: INFO: Got endpoints: latency-svc-fvjqh [570.17129ms]
Oct  7 17:50:16.070: INFO: Got endpoints: latency-svc-8dbrz [552.838712ms]
Oct  7 17:50:16.078: INFO: Created: latency-svc-2sqf2
Oct  7 17:50:16.111: INFO: Created: latency-svc-zrsdc
Oct  7 17:50:16.112: INFO: Created: latency-svc-9qlj9
Oct  7 17:50:16.189: INFO: Created: latency-svc-5kzch
Oct  7 17:50:16.190: INFO: Got endpoints: latency-svc-2sqf2 [638.362334ms]
Oct  7 17:50:16.192: INFO: Got endpoints: latency-svc-zrsdc [562.396911ms]
Oct  7 17:50:16.198: INFO: Got endpoints: latency-svc-5kzch [567.169516ms]
Oct  7 17:50:16.199: INFO: Got endpoints: latency-svc-9qlj9 [568.41509ms]
Oct  7 17:50:16.200: INFO: Created: latency-svc-rjld7
Oct  7 17:50:16.207: INFO: Got endpoints: latency-svc-rjld7 [551.220765ms]
Oct  7 17:50:16.213: INFO: Created: latency-svc-2tgx5
Oct  7 17:50:16.254: INFO: Got endpoints: latency-svc-2tgx5 [495.280871ms]
Oct  7 17:50:16.263: INFO: Created: latency-svc-5nnx4
Oct  7 17:50:16.289: INFO: Got endpoints: latency-svc-5nnx4 [429.796049ms]
Oct  7 17:50:16.334: INFO: Created: latency-svc-gngz2
Oct  7 17:50:16.334: INFO: Got endpoints: latency-svc-gngz2 [454.4246ms]
Oct  7 17:50:16.381: INFO: Created: latency-svc-2ftcz
Oct  7 17:50:16.389: INFO: Got endpoints: latency-svc-2ftcz [492.436669ms]
Oct  7 17:50:16.424: INFO: Created: latency-svc-hzgwl
Oct  7 17:50:16.429: INFO: Got endpoints: latency-svc-hzgwl [509.037512ms]
Oct  7 17:50:16.478: INFO: Created: latency-svc-mnzsr
Oct  7 17:50:16.493: INFO: Got endpoints: latency-svc-mnzsr [538.936941ms]
Oct  7 17:50:16.498: INFO: Created: latency-svc-jfs6p
Oct  7 17:50:16.506: INFO: Created: latency-svc-7qscc
Oct  7 17:50:16.514: INFO: Got endpoints: latency-svc-jfs6p [528.459471ms]
Oct  7 17:50:16.522: INFO: Got endpoints: latency-svc-7qscc [515.910241ms]
Oct  7 17:50:16.531: INFO: Created: latency-svc-6z8q9
Oct  7 17:50:16.537: INFO: Got endpoints: latency-svc-6z8q9 [480.852267ms]
Oct  7 17:50:16.555: INFO: Created: latency-svc-xt47j
Oct  7 17:50:16.560: INFO: Got endpoints: latency-svc-xt47j [489.125575ms]
Oct  7 17:50:16.613: INFO: Created: latency-svc-hmznz
Oct  7 17:50:16.625: INFO: Got endpoints: latency-svc-hmznz [433.319064ms]
Oct  7 17:50:16.630: INFO: Created: latency-svc-lcxz8
Oct  7 17:50:16.647: INFO: Got endpoints: latency-svc-lcxz8 [454.440399ms]
Oct  7 17:50:16.682: INFO: Created: latency-svc-vjl55
Oct  7 17:50:16.696: INFO: Got endpoints: latency-svc-vjl55 [496.822819ms]
Oct  7 17:50:16.707: INFO: Created: latency-svc-qb8fd
Oct  7 17:50:16.722: INFO: Got endpoints: latency-svc-qb8fd [523.302945ms]
Oct  7 17:50:16.729: INFO: Created: latency-svc-nfccp
Oct  7 17:50:16.743: INFO: Got endpoints: latency-svc-nfccp [535.756696ms]
Oct  7 17:50:16.749: INFO: Created: latency-svc-n9jqv
Oct  7 17:50:16.752: INFO: Got endpoints: latency-svc-n9jqv [497.84005ms]
Oct  7 17:50:16.769: INFO: Created: latency-svc-lqvtq
Oct  7 17:50:16.792: INFO: Got endpoints: latency-svc-lqvtq [502.961979ms]
Oct  7 17:50:16.800: INFO: Created: latency-svc-vqrkc
Oct  7 17:50:16.813: INFO: Got endpoints: latency-svc-vqrkc [479.065934ms]
Oct  7 17:50:16.816: INFO: Created: latency-svc-r9gf7
Oct  7 17:50:16.846: INFO: Got endpoints: latency-svc-r9gf7 [456.350042ms]
Oct  7 17:50:16.850: INFO: Created: latency-svc-rx77c
Oct  7 17:50:16.864: INFO: Got endpoints: latency-svc-rx77c [435.36618ms]
Oct  7 17:50:16.880: INFO: Created: latency-svc-8h988
Oct  7 17:50:16.900: INFO: Created: latency-svc-qq4wg
Oct  7 17:50:16.903: INFO: Got endpoints: latency-svc-8h988 [409.444276ms]
Oct  7 17:50:16.908: INFO: Got endpoints: latency-svc-qq4wg [393.154856ms]
Oct  7 17:50:16.924: INFO: Created: latency-svc-v784t
Oct  7 17:50:16.941: INFO: Got endpoints: latency-svc-v784t [418.599639ms]
Oct  7 17:50:16.955: INFO: Created: latency-svc-hv8fj
Oct  7 17:50:16.961: INFO: Got endpoints: latency-svc-hv8fj [423.978348ms]
Oct  7 17:50:16.972: INFO: Created: latency-svc-hkgg2
Oct  7 17:50:16.988: INFO: Got endpoints: latency-svc-hkgg2 [426.774417ms]
Oct  7 17:50:16.997: INFO: Created: latency-svc-9wvqz
Oct  7 17:50:17.083: INFO: Got endpoints: latency-svc-9wvqz [457.022411ms]
Oct  7 17:50:17.087: INFO: Created: latency-svc-nvh2g
Oct  7 17:50:17.087: INFO: Got endpoints: latency-svc-nvh2g [440.464983ms]
Oct  7 17:50:17.105: INFO: Created: latency-svc-5zj6t
Oct  7 17:50:17.116: INFO: Got endpoints: latency-svc-5zj6t [420.000082ms]
Oct  7 17:50:17.126: INFO: Created: latency-svc-6rpp5
Oct  7 17:50:17.134: INFO: Got endpoints: latency-svc-6rpp5 [411.550557ms]
Oct  7 17:50:17.146: INFO: Created: latency-svc-5gxjr
Oct  7 17:50:17.153: INFO: Got endpoints: latency-svc-5gxjr [409.235513ms]
Oct  7 17:50:17.173: INFO: Created: latency-svc-nzmr7
Oct  7 17:50:17.220: INFO: Got endpoints: latency-svc-nzmr7 [467.423564ms]
Oct  7 17:50:17.226: INFO: Created: latency-svc-2tz5l
Oct  7 17:50:17.238: INFO: Got endpoints: latency-svc-2tz5l [445.219145ms]
Oct  7 17:50:17.251: INFO: Created: latency-svc-v9ltv
Oct  7 17:50:17.251: INFO: Got endpoints: latency-svc-v9ltv [438.211691ms]
Oct  7 17:50:17.304: INFO: Created: latency-svc-b5d5n
Oct  7 17:50:17.316: INFO: Got endpoints: latency-svc-b5d5n [469.163655ms]
Oct  7 17:50:17.343: INFO: Created: latency-svc-sn2nn
Oct  7 17:50:17.366: INFO: Got endpoints: latency-svc-sn2nn [501.178581ms]
Oct  7 17:50:17.385: INFO: Created: latency-svc-hjrc9
Oct  7 17:50:17.396: INFO: Got endpoints: latency-svc-hjrc9 [493.171219ms]
Oct  7 17:50:17.426: INFO: Created: latency-svc-b7wxx
Oct  7 17:50:17.432: INFO: Got endpoints: latency-svc-b7wxx [524.581994ms]
Oct  7 17:50:17.457: INFO: Created: latency-svc-sdpt9
Oct  7 17:50:17.459: INFO: Got endpoints: latency-svc-sdpt9 [517.697258ms]
Oct  7 17:50:17.481: INFO: Created: latency-svc-489xz
Oct  7 17:50:17.485: INFO: Got endpoints: latency-svc-489xz [523.444369ms]
Oct  7 17:50:17.497: INFO: Created: latency-svc-hw9kr
Oct  7 17:50:17.504: INFO: Got endpoints: latency-svc-hw9kr [516.763936ms]
Oct  7 17:50:17.521: INFO: Created: latency-svc-8n25d
Oct  7 17:50:17.566: INFO: Got endpoints: latency-svc-8n25d [483.23188ms]
Oct  7 17:50:17.579: INFO: Created: latency-svc-rxp8l
Oct  7 17:50:17.592: INFO: Got endpoints: latency-svc-rxp8l [504.783011ms]
Oct  7 17:50:17.597: INFO: Created: latency-svc-k45z9
Oct  7 17:50:17.623: INFO: Created: latency-svc-clfcc
Oct  7 17:50:17.635: INFO: Got endpoints: latency-svc-k45z9 [519.472506ms]
Oct  7 17:50:17.639: INFO: Got endpoints: latency-svc-clfcc [503.888306ms]
Oct  7 17:50:17.648: INFO: Created: latency-svc-mpv9t
Oct  7 17:50:17.656: INFO: Got endpoints: latency-svc-mpv9t [502.742347ms]
Oct  7 17:50:17.710: INFO: Created: latency-svc-v2stj
Oct  7 17:50:17.711: INFO: Got endpoints: latency-svc-v2stj [491.27351ms]
Oct  7 17:50:17.719: INFO: Created: latency-svc-96twj
Oct  7 17:50:17.729: INFO: Got endpoints: latency-svc-96twj [490.641052ms]
Oct  7 17:50:17.746: INFO: Created: latency-svc-qtmfj
Oct  7 17:50:17.762: INFO: Got endpoints: latency-svc-qtmfj [510.651808ms]
Oct  7 17:50:17.769: INFO: Created: latency-svc-89zhx
Oct  7 17:50:17.797: INFO: Got endpoints: latency-svc-89zhx [480.64623ms]
Oct  7 17:50:17.803: INFO: Created: latency-svc-wtp8f
Oct  7 17:50:17.832: INFO: Got endpoints: latency-svc-wtp8f [466.347187ms]
Oct  7 17:50:17.837: INFO: Created: latency-svc-ddr7n
Oct  7 17:50:17.863: INFO: Created: latency-svc-zllls
Oct  7 17:50:17.879: INFO: Created: latency-svc-9klf4
Oct  7 17:50:17.880: INFO: Got endpoints: latency-svc-ddr7n [483.53095ms]
Oct  7 17:50:17.897: INFO: Created: latency-svc-jlxts
Oct  7 17:50:17.925: INFO: Created: latency-svc-fb72w
Oct  7 17:50:17.934: INFO: Got endpoints: latency-svc-zllls [500.444586ms]
Oct  7 17:50:17.952: INFO: Created: latency-svc-rscxh
Oct  7 17:50:17.964: INFO: Created: latency-svc-kgfnp
Oct  7 17:50:17.978: INFO: Got endpoints: latency-svc-9klf4 [518.061587ms]
Oct  7 17:50:17.985: INFO: Created: latency-svc-5df8w
Oct  7 17:50:18.021: INFO: Created: latency-svc-h9c4j
Oct  7 17:50:18.029: INFO: Got endpoints: latency-svc-jlxts [543.647047ms]
Oct  7 17:50:18.067: INFO: Created: latency-svc-vlxz5
Oct  7 17:50:18.083: INFO: Got endpoints: latency-svc-fb72w [577.627091ms]
Oct  7 17:50:18.086: INFO: Created: latency-svc-r48qk
Oct  7 17:50:18.108: INFO: Created: latency-svc-9jpjr
Oct  7 17:50:18.140: INFO: Got endpoints: latency-svc-rscxh [573.973614ms]
Oct  7 17:50:18.146: INFO: Created: latency-svc-229xj
Oct  7 17:50:18.189: INFO: Got endpoints: latency-svc-kgfnp [596.626228ms]
Oct  7 17:50:18.206: INFO: Created: latency-svc-4tbgz
Oct  7 17:50:18.241: INFO: Got endpoints: latency-svc-5df8w [605.840484ms]
Oct  7 17:50:18.268: INFO: Created: latency-svc-8ksj4
Oct  7 17:50:18.306: INFO: Got endpoints: latency-svc-h9c4j [667.582853ms]
Oct  7 17:50:18.333: INFO: Created: latency-svc-rl4db
Oct  7 17:50:18.334: INFO: Got endpoints: latency-svc-vlxz5 [677.598007ms]
Oct  7 17:50:18.360: INFO: Created: latency-svc-j8fs2
Oct  7 17:50:18.367: INFO: Created: latency-svc-5tx84
Oct  7 17:50:18.379: INFO: Got endpoints: latency-svc-r48qk [667.925396ms]
Oct  7 17:50:18.393: INFO: Created: latency-svc-q95xk
Oct  7 17:50:18.433: INFO: Got endpoints: latency-svc-9jpjr [704.388259ms]
Oct  7 17:50:18.439: INFO: Created: latency-svc-hqdwl
Oct  7 17:50:18.481: INFO: Created: latency-svc-66727
Oct  7 17:50:18.503: INFO: Got endpoints: latency-svc-229xj [740.938196ms]
Oct  7 17:50:18.513: INFO: Created: latency-svc-zrtb2
Oct  7 17:50:18.528: INFO: Got endpoints: latency-svc-4tbgz [730.339066ms]
Oct  7 17:50:18.534: INFO: Created: latency-svc-wcpjv
Oct  7 17:50:18.547: INFO: Created: latency-svc-dvjr5
Oct  7 17:50:18.567: INFO: Created: latency-svc-ll4rd
Oct  7 17:50:18.580: INFO: Got endpoints: latency-svc-8ksj4 [748.020821ms]
Oct  7 17:50:18.590: INFO: Created: latency-svc-ggj8x
Oct  7 17:50:18.605: INFO: Created: latency-svc-n2vms
Oct  7 17:50:18.627: INFO: Created: latency-svc-ldthd
Oct  7 17:50:18.655: INFO: Got endpoints: latency-svc-rl4db [775.006163ms]
Oct  7 17:50:18.671: INFO: Created: latency-svc-bsrm2
Oct  7 17:50:18.685: INFO: Got endpoints: latency-svc-j8fs2 [750.838522ms]
Oct  7 17:50:18.695: INFO: Created: latency-svc-pckhq
Oct  7 17:50:18.720: INFO: Created: latency-svc-p8tcn
Oct  7 17:50:18.727: INFO: Got endpoints: latency-svc-5tx84 [749.150439ms]
Oct  7 17:50:18.740: INFO: Created: latency-svc-2bbsd
Oct  7 17:50:18.776: INFO: Created: latency-svc-nvlmt
Oct  7 17:50:18.778: INFO: Got endpoints: latency-svc-q95xk [748.211445ms]
Oct  7 17:50:18.833: INFO: Got endpoints: latency-svc-hqdwl [749.80947ms]
Oct  7 17:50:18.837: INFO: Created: latency-svc-pwj5n
Oct  7 17:50:18.858: INFO: Created: latency-svc-ttj6x
Oct  7 17:50:18.881: INFO: Got endpoints: latency-svc-66727 [740.719867ms]
Oct  7 17:50:18.904: INFO: Created: latency-svc-rph44
Oct  7 17:50:18.926: INFO: Got endpoints: latency-svc-zrtb2 [737.816223ms]
Oct  7 17:50:18.949: INFO: Created: latency-svc-z58tp
Oct  7 17:50:18.977: INFO: Got endpoints: latency-svc-wcpjv [735.38471ms]
Oct  7 17:50:19.011: INFO: Created: latency-svc-5vfrm
Oct  7 17:50:19.028: INFO: Got endpoints: latency-svc-dvjr5 [721.316442ms]
Oct  7 17:50:19.068: INFO: Created: latency-svc-4t54g
Oct  7 17:50:19.076: INFO: Got endpoints: latency-svc-ll4rd [742.383343ms]
Oct  7 17:50:19.126: INFO: Got endpoints: latency-svc-ggj8x [745.521274ms]
Oct  7 17:50:19.130: INFO: Created: latency-svc-c4t4l
Oct  7 17:50:19.151: INFO: Created: latency-svc-gcz62
Oct  7 17:50:19.176: INFO: Got endpoints: latency-svc-n2vms [743.165925ms]
Oct  7 17:50:19.200: INFO: Created: latency-svc-m9ffp
Oct  7 17:50:19.231: INFO: Got endpoints: latency-svc-ldthd [727.817354ms]
Oct  7 17:50:19.253: INFO: Created: latency-svc-2hd47
Oct  7 17:50:19.278: INFO: Got endpoints: latency-svc-bsrm2 [750.091491ms]
Oct  7 17:50:19.314: INFO: Created: latency-svc-m8tbm
Oct  7 17:50:19.348: INFO: Got endpoints: latency-svc-pckhq [767.048016ms]
Oct  7 17:50:19.370: INFO: Created: latency-svc-clf69
Oct  7 17:50:19.375: INFO: Got endpoints: latency-svc-p8tcn [720.021732ms]
Oct  7 17:50:19.398: INFO: Created: latency-svc-bh694
Oct  7 17:50:19.427: INFO: Got endpoints: latency-svc-2bbsd [740.622212ms]
Oct  7 17:50:19.455: INFO: Created: latency-svc-5wpwr
Oct  7 17:50:19.478: INFO: Got endpoints: latency-svc-nvlmt [750.094112ms]
Oct  7 17:50:19.498: INFO: Created: latency-svc-ftmkp
Oct  7 17:50:19.526: INFO: Got endpoints: latency-svc-pwj5n [748.050791ms]
Oct  7 17:50:19.566: INFO: Created: latency-svc-xs7fz
Oct  7 17:50:19.576: INFO: Got endpoints: latency-svc-ttj6x [742.348862ms]
Oct  7 17:50:19.608: INFO: Created: latency-svc-2p4wh
Oct  7 17:50:19.626: INFO: Got endpoints: latency-svc-rph44 [744.059544ms]
Oct  7 17:50:19.646: INFO: Created: latency-svc-69586
Oct  7 17:50:19.676: INFO: Got endpoints: latency-svc-z58tp [749.871708ms]
Oct  7 17:50:19.698: INFO: Created: latency-svc-6r2t9
Oct  7 17:50:19.726: INFO: Got endpoints: latency-svc-5vfrm [748.860817ms]
Oct  7 17:50:19.747: INFO: Created: latency-svc-khqmj
Oct  7 17:50:19.794: INFO: Got endpoints: latency-svc-4t54g [766.499269ms]
Oct  7 17:50:19.815: INFO: Created: latency-svc-g2q7f
Oct  7 17:50:19.827: INFO: Got endpoints: latency-svc-c4t4l [749.370288ms]
Oct  7 17:50:19.865: INFO: Created: latency-svc-fj68f
Oct  7 17:50:19.876: INFO: Got endpoints: latency-svc-gcz62 [750.203854ms]
Oct  7 17:50:19.923: INFO: Created: latency-svc-pjqpn
Oct  7 17:50:19.928: INFO: Got endpoints: latency-svc-m9ffp [751.422882ms]
Oct  7 17:50:19.947: INFO: Created: latency-svc-vsk9k
Oct  7 17:50:19.977: INFO: Got endpoints: latency-svc-2hd47 [745.555992ms]
Oct  7 17:50:20.000: INFO: Created: latency-svc-4rfqk
Oct  7 17:50:20.060: INFO: Got endpoints: latency-svc-m8tbm [781.81798ms]
Oct  7 17:50:20.079: INFO: Got endpoints: latency-svc-clf69 [731.40101ms]
Oct  7 17:50:20.084: INFO: Created: latency-svc-sdbrk
Oct  7 17:50:20.112: INFO: Created: latency-svc-zvxr8
Oct  7 17:50:20.126: INFO: Got endpoints: latency-svc-bh694 [750.579103ms]
Oct  7 17:50:20.147: INFO: Created: latency-svc-2fbdd
Oct  7 17:50:20.177: INFO: Got endpoints: latency-svc-5wpwr [750.396326ms]
Oct  7 17:50:20.199: INFO: Created: latency-svc-5gl4q
Oct  7 17:50:20.226: INFO: Got endpoints: latency-svc-ftmkp [746.87765ms]
Oct  7 17:50:20.260: INFO: Created: latency-svc-qrhnh
Oct  7 17:50:20.276: INFO: Got endpoints: latency-svc-xs7fz [748.817435ms]
Oct  7 17:50:20.303: INFO: Created: latency-svc-xtvw4
Oct  7 17:50:20.329: INFO: Got endpoints: latency-svc-2p4wh [751.488112ms]
Oct  7 17:50:20.350: INFO: Created: latency-svc-qrgld
Oct  7 17:50:20.376: INFO: Got endpoints: latency-svc-69586 [749.364825ms]
Oct  7 17:50:20.428: INFO: Got endpoints: latency-svc-6r2t9 [750.75912ms]
Oct  7 17:50:20.430: INFO: Created: latency-svc-fkvxf
Oct  7 17:50:20.479: INFO: Got endpoints: latency-svc-khqmj [751.445453ms]
Oct  7 17:50:20.481: INFO: Created: latency-svc-vw2m7
Oct  7 17:50:20.532: INFO: Got endpoints: latency-svc-g2q7f [736.263763ms]
Oct  7 17:50:20.541: INFO: Created: latency-svc-wzbzx
Oct  7 17:50:20.562: INFO: Created: latency-svc-qmjrc
Oct  7 17:50:20.580: INFO: Got endpoints: latency-svc-fj68f [752.905185ms]
Oct  7 17:50:20.602: INFO: Created: latency-svc-wx6gm
Oct  7 17:50:20.628: INFO: Got endpoints: latency-svc-pjqpn [751.808004ms]
Oct  7 17:50:20.676: INFO: Created: latency-svc-rlwp7
Oct  7 17:50:20.677: INFO: Got endpoints: latency-svc-vsk9k [748.718671ms]
Oct  7 17:50:20.700: INFO: Created: latency-svc-kzvh5
Oct  7 17:50:20.727: INFO: Got endpoints: latency-svc-4rfqk [749.692872ms]
Oct  7 17:50:20.747: INFO: Created: latency-svc-z9fg8
Oct  7 17:50:20.803: INFO: Got endpoints: latency-svc-sdbrk [743.257372ms]
Oct  7 17:50:20.844: INFO: Got endpoints: latency-svc-zvxr8 [764.265902ms]
Oct  7 17:50:20.847: INFO: Created: latency-svc-nwtkq
Oct  7 17:50:20.866: INFO: Created: latency-svc-df22d
Oct  7 17:50:20.875: INFO: Got endpoints: latency-svc-2fbdd [748.016044ms]
Oct  7 17:50:20.902: INFO: Created: latency-svc-4bws2
Oct  7 17:50:20.934: INFO: Got endpoints: latency-svc-5gl4q [757.335004ms]
Oct  7 17:50:20.955: INFO: Created: latency-svc-kzwrm
Oct  7 17:50:20.978: INFO: Got endpoints: latency-svc-qrhnh [750.614657ms]
Oct  7 17:50:21.001: INFO: Created: latency-svc-5jhqk
Oct  7 17:50:21.027: INFO: Got endpoints: latency-svc-xtvw4 [751.081937ms]
Oct  7 17:50:21.063: INFO: Created: latency-svc-ckggj
Oct  7 17:50:21.077: INFO: Got endpoints: latency-svc-qrgld [747.8565ms]
Oct  7 17:50:21.099: INFO: Created: latency-svc-f4x4x
Oct  7 17:50:21.128: INFO: Got endpoints: latency-svc-fkvxf [752.133445ms]
Oct  7 17:50:21.182: INFO: Created: latency-svc-g577k
Oct  7 17:50:21.183: INFO: Got endpoints: latency-svc-vw2m7 [753.989329ms]
Oct  7 17:50:21.203: INFO: Created: latency-svc-cbb7s
Oct  7 17:50:21.226: INFO: Got endpoints: latency-svc-wzbzx [747.254265ms]
Oct  7 17:50:21.243: INFO: Created: latency-svc-bgwth
Oct  7 17:50:21.276: INFO: Got endpoints: latency-svc-qmjrc [743.771433ms]
Oct  7 17:50:21.297: INFO: Created: latency-svc-p4hxs
Oct  7 17:50:21.326: INFO: Got endpoints: latency-svc-wx6gm [744.280354ms]
Oct  7 17:50:21.343: INFO: Created: latency-svc-jlfsd
Oct  7 17:50:21.377: INFO: Got endpoints: latency-svc-rlwp7 [748.33052ms]
Oct  7 17:50:21.403: INFO: Created: latency-svc-mq8k9
Oct  7 17:50:21.426: INFO: Got endpoints: latency-svc-kzvh5 [747.90399ms]
Oct  7 17:50:21.444: INFO: Created: latency-svc-dkzbw
Oct  7 17:50:21.477: INFO: Got endpoints: latency-svc-z9fg8 [750.099661ms]
Oct  7 17:50:21.521: INFO: Created: latency-svc-w8pm8
Oct  7 17:50:21.526: INFO: Got endpoints: latency-svc-nwtkq [722.239911ms]
Oct  7 17:50:21.552: INFO: Created: latency-svc-lzrnc
Oct  7 17:50:21.578: INFO: Got endpoints: latency-svc-df22d [734.309877ms]
Oct  7 17:50:21.607: INFO: Created: latency-svc-mvrjp
Oct  7 17:50:21.625: INFO: Got endpoints: latency-svc-4bws2 [748.970833ms]
Oct  7 17:50:21.660: INFO: Created: latency-svc-lfx5k
Oct  7 17:50:21.676: INFO: Got endpoints: latency-svc-kzwrm [740.625652ms]
Oct  7 17:50:21.712: INFO: Created: latency-svc-ck27f
Oct  7 17:50:21.726: INFO: Got endpoints: latency-svc-5jhqk [747.420958ms]
Oct  7 17:50:21.748: INFO: Created: latency-svc-md6lt
Oct  7 17:50:21.777: INFO: Got endpoints: latency-svc-ckggj [749.587087ms]
Oct  7 17:50:21.901: INFO: Created: latency-svc-lsfs2
Oct  7 17:50:21.903: INFO: Got endpoints: latency-svc-g577k [774.125148ms]
Oct  7 17:50:21.903: INFO: Got endpoints: latency-svc-f4x4x [826.035993ms]
Oct  7 17:50:21.944: INFO: Got endpoints: latency-svc-cbb7s [760.175637ms]
Oct  7 17:50:21.965: INFO: Created: latency-svc-x2jdk
Oct  7 17:50:21.986: INFO: Got endpoints: latency-svc-bgwth [760.014484ms]
Oct  7 17:50:22.000: INFO: Created: latency-svc-9kql9
Oct  7 17:50:22.030: INFO: Created: latency-svc-cqr2s
Oct  7 17:50:22.037: INFO: Got endpoints: latency-svc-p4hxs [761.17435ms]
Oct  7 17:50:22.069: INFO: Created: latency-svc-nkbnt
Oct  7 17:50:22.096: INFO: Got endpoints: latency-svc-jlfsd [768.848996ms]
Oct  7 17:50:22.099: INFO: Created: latency-svc-9dj8m
Oct  7 17:50:22.117: INFO: Created: latency-svc-vxbjp
Oct  7 17:50:22.126: INFO: Got endpoints: latency-svc-mq8k9 [748.209356ms]
Oct  7 17:50:22.145: INFO: Created: latency-svc-vzrwr
Oct  7 17:50:22.176: INFO: Got endpoints: latency-svc-dkzbw [749.868989ms]
Oct  7 17:50:22.196: INFO: Created: latency-svc-fxmj7
Oct  7 17:50:22.227: INFO: Got endpoints: latency-svc-w8pm8 [748.900334ms]
Oct  7 17:50:22.245: INFO: Created: latency-svc-rqnsw
Oct  7 17:50:22.302: INFO: Got endpoints: latency-svc-lzrnc [776.00918ms]
Oct  7 17:50:22.324: INFO: Created: latency-svc-npsld
Oct  7 17:50:22.326: INFO: Got endpoints: latency-svc-mvrjp [748.211118ms]
Oct  7 17:50:22.345: INFO: Created: latency-svc-5fmxg
Oct  7 17:50:22.376: INFO: Got endpoints: latency-svc-lfx5k [750.055775ms]
Oct  7 17:50:22.396: INFO: Created: latency-svc-mjn98
Oct  7 17:50:22.426: INFO: Got endpoints: latency-svc-ck27f [750.241846ms]
Oct  7 17:50:22.446: INFO: Created: latency-svc-sl8zf
Oct  7 17:50:22.477: INFO: Got endpoints: latency-svc-md6lt [750.680279ms]
Oct  7 17:50:22.495: INFO: Created: latency-svc-l9g4p
Oct  7 17:50:22.527: INFO: Got endpoints: latency-svc-lsfs2 [749.548789ms]
Oct  7 17:50:22.547: INFO: Created: latency-svc-m4j59
Oct  7 17:50:22.577: INFO: Got endpoints: latency-svc-x2jdk [674.171669ms]
Oct  7 17:50:22.597: INFO: Created: latency-svc-r4zqz
Oct  7 17:50:22.628: INFO: Got endpoints: latency-svc-9kql9 [723.679055ms]
Oct  7 17:50:22.646: INFO: Created: latency-svc-rzpfl
Oct  7 17:50:22.676: INFO: Got endpoints: latency-svc-cqr2s [731.589004ms]
Oct  7 17:50:22.694: INFO: Created: latency-svc-2tgd9
Oct  7 17:50:22.732: INFO: Got endpoints: latency-svc-nkbnt [745.929186ms]
Oct  7 17:50:22.758: INFO: Created: latency-svc-r8zmd
Oct  7 17:50:22.776: INFO: Got endpoints: latency-svc-9dj8m [738.687155ms]
Oct  7 17:50:22.795: INFO: Created: latency-svc-k5zbr
Oct  7 17:50:22.827: INFO: Got endpoints: latency-svc-vxbjp [731.555128ms]
Oct  7 17:50:22.850: INFO: Created: latency-svc-4hpws
Oct  7 17:50:22.879: INFO: Got endpoints: latency-svc-vzrwr [752.775987ms]
Oct  7 17:50:22.902: INFO: Created: latency-svc-9htjb
Oct  7 17:50:22.927: INFO: Got endpoints: latency-svc-fxmj7 [750.747813ms]
Oct  7 17:50:22.976: INFO: Got endpoints: latency-svc-rqnsw [749.189107ms]
Oct  7 17:50:23.026: INFO: Got endpoints: latency-svc-npsld [724.365397ms]
Oct  7 17:50:23.076: INFO: Got endpoints: latency-svc-5fmxg [749.488439ms]
Oct  7 17:50:23.126: INFO: Got endpoints: latency-svc-mjn98 [749.88323ms]
Oct  7 17:50:23.176: INFO: Got endpoints: latency-svc-sl8zf [749.209763ms]
Oct  7 17:50:23.229: INFO: Got endpoints: latency-svc-l9g4p [751.990233ms]
Oct  7 17:50:23.277: INFO: Got endpoints: latency-svc-m4j59 [750.494385ms]
Oct  7 17:50:23.327: INFO: Got endpoints: latency-svc-r4zqz [749.264948ms]
Oct  7 17:50:23.377: INFO: Got endpoints: latency-svc-rzpfl [749.099059ms]
Oct  7 17:50:23.426: INFO: Got endpoints: latency-svc-2tgd9 [750.279615ms]
Oct  7 17:50:23.476: INFO: Got endpoints: latency-svc-r8zmd [743.996233ms]
Oct  7 17:50:23.528: INFO: Got endpoints: latency-svc-k5zbr [752.261468ms]
Oct  7 17:50:23.577: INFO: Got endpoints: latency-svc-4hpws [749.201385ms]
Oct  7 17:50:23.627: INFO: Got endpoints: latency-svc-9htjb [747.826597ms]
Oct  7 17:50:23.628: INFO: Latencies: [29.193203ms 40.972738ms 87.306775ms 118.004226ms 161.418893ms 179.254463ms 195.970655ms 246.642967ms 275.97063ms 287.542335ms 370.612171ms 387.3083ms 393.154856ms 396.721962ms 409.235513ms 409.444276ms 411.550557ms 418.599639ms 420.000082ms 423.978348ms 426.774417ms 428.236535ms 429.796049ms 433.319064ms 435.36618ms 438.211691ms 440.464983ms 445.219145ms 450.117368ms 454.4246ms 454.440399ms 455.315877ms 456.350042ms 457.022411ms 463.209389ms 466.347187ms 467.423564ms 469.163655ms 479.065934ms 480.64623ms 480.852267ms 483.23188ms 483.53095ms 489.125575ms 490.641052ms 491.27351ms 492.436669ms 493.171219ms 495.280871ms 496.822819ms 497.84005ms 500.444586ms 500.760412ms 501.178581ms 502.742347ms 502.961979ms 503.888306ms 504.783011ms 508.296816ms 509.037512ms 510.651808ms 513.211322ms 515.910241ms 516.763936ms 517.697258ms 518.061587ms 519.472506ms 523.302945ms 523.444369ms 524.581994ms 525.072489ms 528.459471ms 528.744526ms 535.756696ms 538.936941ms 543.647047ms 551.220765ms 552.838712ms 553.076741ms 560.710533ms 562.396911ms 567.169516ms 568.41509ms 570.17129ms 573.973614ms 577.102165ms 577.627091ms 591.235903ms 595.061709ms 596.626228ms 605.840484ms 638.362334ms 667.582853ms 667.925396ms 674.171669ms 677.598007ms 704.388259ms 720.021732ms 721.316442ms 722.239911ms 723.679055ms 724.365397ms 727.817354ms 730.339066ms 731.40101ms 731.555128ms 731.589004ms 734.309877ms 735.38471ms 736.263763ms 737.816223ms 738.687155ms 740.622212ms 740.625652ms 740.719867ms 740.938196ms 742.348862ms 742.383343ms 743.165925ms 743.257372ms 743.771433ms 743.996233ms 744.059544ms 744.280354ms 745.521274ms 745.555992ms 745.929186ms 746.87765ms 747.254265ms 747.420958ms 747.826597ms 747.8565ms 747.90399ms 748.016044ms 748.020821ms 748.050791ms 748.209356ms 748.211118ms 748.211445ms 748.33052ms 748.718671ms 748.817435ms 748.860817ms 748.900334ms 748.970833ms 749.099059ms 749.150439ms 749.189107ms 749.201385ms 749.209763ms 749.264948ms 749.364825ms 749.370288ms 749.488439ms 749.548789ms 749.587087ms 749.692872ms 749.80947ms 749.868989ms 749.871708ms 749.88323ms 750.055775ms 750.091491ms 750.094112ms 750.099661ms 750.203854ms 750.241846ms 750.279615ms 750.396326ms 750.494385ms 750.579103ms 750.614657ms 750.680279ms 750.747813ms 750.75912ms 750.838522ms 751.081937ms 751.422882ms 751.445453ms 751.488112ms 751.808004ms 751.990233ms 752.133445ms 752.261468ms 752.775987ms 752.905185ms 753.989329ms 757.335004ms 760.014484ms 760.175637ms 761.17435ms 764.265902ms 766.499269ms 767.048016ms 768.848996ms 774.125148ms 775.006163ms 776.00918ms 781.81798ms 826.035993ms]
Oct  7 17:50:23.629: INFO: 50 %ile: 723.679055ms
Oct  7 17:50:23.629: INFO: 90 %ile: 751.808004ms
Oct  7 17:50:23.629: INFO: 99 %ile: 781.81798ms
Oct  7 17:50:23.629: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:50:23.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1455" for this suite.
Oct  7 17:50:39.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:50:39.711: INFO: namespace svc-latency-1455 deletion completed in 16.077265292s

• [SLOW TEST:27.019 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:50:39.711: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 17:50:39.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63" in namespace "downward-api-2452" to be "success or failure"
Oct  7 17:50:39.881: INFO: Pod "downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.752705ms
Oct  7 17:50:41.885: INFO: Pod "downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006287907s
STEP: Saw pod success
Oct  7 17:50:41.885: INFO: Pod "downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63" satisfied condition "success or failure"
Oct  7 17:50:41.888: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-clj9s pod downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63 container client-container: <nil>
STEP: delete the pod
Oct  7 17:50:41.916: INFO: Waiting for pod downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63 to disappear
Oct  7 17:50:41.918: INFO: Pod downwardapi-volume-06ecae0e-f6d2-4c0b-8f8c-251d55bacf63 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:50:41.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2452" for this suite.
Oct  7 17:50:47.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:50:47.992: INFO: namespace downward-api-2452 deletion completed in 6.070521208s

• [SLOW TEST:8.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:50:47.993: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-773
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-773
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-773
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-773
Oct  7 17:50:48.160: INFO: Found 0 stateful pods, waiting for 1
Oct  7 17:50:58.166: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Oct  7 17:50:58.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 17:50:58.455: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 17:50:58.455: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 17:50:58.455: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 17:50:58.459: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 17:50:58.459: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 17:50:58.472: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999766s
Oct  7 17:50:59.475: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997347405s
Oct  7 17:51:00.479: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99398859s
Oct  7 17:51:01.482: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990534737s
Oct  7 17:51:02.488: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986901769s
Oct  7 17:51:03.492: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.981311412s
Oct  7 17:51:04.495: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977508159s
Oct  7 17:51:05.500: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.973947159s
Oct  7 17:51:06.504: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.969546892s
Oct  7 17:51:07.508: INFO: Verifying statefulset ss doesn't scale past 1 for another 965.419698ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-773
Oct  7 17:51:08.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 17:51:08.768: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 17:51:08.768: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 17:51:08.768: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 17:51:08.772: INFO: Found 1 stateful pods, waiting for 3
Oct  7 17:51:18.778: INFO: Found 2 stateful pods, waiting for 3
Oct  7 17:51:28.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 17:51:28.778: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 17:51:28.778: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Oct  7 17:51:38.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 17:51:38.778: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 17:51:38.778: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Oct  7 17:51:38.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 17:51:39.054: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 17:51:39.054: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 17:51:39.054: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 17:51:39.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 17:51:39.338: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 17:51:39.338: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 17:51:39.338: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 17:51:39.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 17:51:39.601: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 17:51:39.601: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 17:51:39.601: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 17:51:39.601: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 17:51:39.604: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Oct  7 17:51:49.617: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 17:51:49.617: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 17:51:49.617: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 17:51:49.637: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999785s
Oct  7 17:51:50.641: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990953955s
Oct  7 17:51:51.645: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.986936199s
Oct  7 17:51:52.650: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982724471s
Oct  7 17:51:53.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978068289s
Oct  7 17:51:54.657: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974819906s
Oct  7 17:51:55.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971671313s
Oct  7 17:51:56.665: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967255319s
Oct  7 17:51:57.669: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963251119s
Oct  7 17:51:58.676: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.364083ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-773
Oct  7 17:51:59.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 17:51:59.952: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 17:51:59.952: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 17:51:59.952: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 17:51:59.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 17:52:00.275: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 17:52:00.275: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 17:52:00.275: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 17:52:00.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-773 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 17:52:00.512: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 17:52:00.512: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 17:52:00.512: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 17:52:00.512: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 17:52:30.527: INFO: Deleting all statefulset in ns statefulset-773
Oct  7 17:52:30.531: INFO: Scaling statefulset ss to 0
Oct  7 17:52:30.538: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 17:52:30.541: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:52:30.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-773" for this suite.
Oct  7 17:52:36.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:52:36.633: INFO: namespace statefulset-773 deletion completed in 6.074602326s

• [SLOW TEST:108.641 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:52:36.635: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1893
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 17:52:36.814: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:52:37.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1893" for this suite.
Oct  7 17:52:43.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:52:43.474: INFO: namespace custom-resource-definition-1893 deletion completed in 6.084296468s

• [SLOW TEST:6.840 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:52:43.475: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  7 17:52:45.660: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:52:45.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-441" for this suite.
Oct  7 17:52:51.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:52:51.753: INFO: namespace container-runtime-441 deletion completed in 6.073794837s

• [SLOW TEST:8.278 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:52:51.753: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5277
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 17:52:51.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5277'
Oct  7 17:52:52.005: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  7 17:52:52.005: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Oct  7 17:52:52.019: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-g8tt7]
Oct  7 17:52:52.019: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-g8tt7" in namespace "kubectl-5277" to be "running and ready"
Oct  7 17:52:52.024: INFO: Pod "e2e-test-httpd-rc-g8tt7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.747558ms
Oct  7 17:52:54.027: INFO: Pod "e2e-test-httpd-rc-g8tt7": Phase="Running", Reason="", readiness=true. Elapsed: 2.008040589s
Oct  7 17:52:54.027: INFO: Pod "e2e-test-httpd-rc-g8tt7" satisfied condition "running and ready"
Oct  7 17:52:54.027: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-g8tt7]
Oct  7 17:52:54.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs rc/e2e-test-httpd-rc --namespace=kubectl-5277'
Oct  7 17:52:54.141: INFO: stderr: ""
Oct  7 17:52:54.141: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.27. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.27. Set the 'ServerName' directive globally to suppress this message\n[Mon Oct 07 17:52:52.750518 2019] [mpm_event:notice] [pid 1:tid 140143644310376] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Oct 07 17:52:52.750581 2019] [core:notice] [pid 1:tid 140143644310376] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Oct  7 17:52:54.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete rc e2e-test-httpd-rc --namespace=kubectl-5277'
Oct  7 17:52:54.228: INFO: stderr: ""
Oct  7 17:52:54.228: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:52:54.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5277" for this suite.
Oct  7 17:53:00.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:53:00.304: INFO: namespace kubectl-5277 deletion completed in 6.072482032s

• [SLOW TEST:8.551 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:53:00.306: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-598
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Oct  7 17:53:00.473: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Oct  7 17:53:00.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:00.787: INFO: stderr: ""
Oct  7 17:53:00.787: INFO: stdout: "service/redis-slave created\n"
Oct  7 17:53:00.789: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Oct  7 17:53:00.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:01.158: INFO: stderr: ""
Oct  7 17:53:01.158: INFO: stdout: "service/redis-master created\n"
Oct  7 17:53:01.158: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Oct  7 17:53:01.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:01.490: INFO: stderr: ""
Oct  7 17:53:01.490: INFO: stdout: "service/frontend created\n"
Oct  7 17:53:01.490: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Oct  7 17:53:01.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:01.811: INFO: stderr: ""
Oct  7 17:53:01.811: INFO: stdout: "deployment.apps/frontend created\n"
Oct  7 17:53:01.812: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Oct  7 17:53:01.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:02.042: INFO: stderr: ""
Oct  7 17:53:02.042: INFO: stdout: "deployment.apps/redis-master created\n"
Oct  7 17:53:02.042: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Oct  7 17:53:02.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-598'
Oct  7 17:53:02.284: INFO: stderr: ""
Oct  7 17:53:02.284: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Oct  7 17:53:02.284: INFO: Waiting for all frontend pods to be Running.
Oct  7 17:53:27.335: INFO: Waiting for frontend to serve content.
Oct  7 17:53:27.349: INFO: Trying to add a new entry to the guestbook.
Oct  7 17:53:27.364: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Oct  7 17:53:27.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:27.492: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:27.492: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Oct  7 17:53:27.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:27.653: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:27.653: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  7 17:53:27.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:27.808: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:27.808: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  7 17:53:27.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:27.952: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:27.952: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Oct  7 17:53:27.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:28.037: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:28.037: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Oct  7 17:53:28.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-598'
Oct  7 17:53:28.129: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 17:53:28.129: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:53:28.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-598" for this suite.
Oct  7 17:53:40.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:53:40.212: INFO: namespace kubectl-598 deletion completed in 12.078948689s

• [SLOW TEST:39.906 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:53:40.212: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7697
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Oct  7 17:53:40.374: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Oct  7 17:54:00.457: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.31:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7697 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:54:00.457: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:54:00.636: INFO: Found all expected endpoints: [netserver-0]
Oct  7 17:54:00.639: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.24:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7697 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:54:00.639: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:54:00.831: INFO: Found all expected endpoints: [netserver-1]
Oct  7 17:54:00.834: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.4.10:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7697 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 17:54:00.834: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 17:54:01.047: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:54:01.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7697" for this suite.
Oct  7 17:54:13.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:54:13.128: INFO: namespace pod-network-test-7697 deletion completed in 12.076369612s

• [SLOW TEST:32.916 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:54:13.129: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:54:15.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6897" for this suite.
Oct  7 17:55:05.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:55:05.447: INFO: namespace kubelet-test-6897 deletion completed in 50.076082121s

• [SLOW TEST:52.318 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:55:05.447: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 17:55:05.611: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-ae64094b-29a2-4f31-ac68-7cce1ccedbc5" in namespace "security-context-test-8493" to be "success or failure"
Oct  7 17:55:05.614: INFO: Pod "busybox-privileged-false-ae64094b-29a2-4f31-ac68-7cce1ccedbc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.628553ms
Oct  7 17:55:07.617: INFO: Pod "busybox-privileged-false-ae64094b-29a2-4f31-ac68-7cce1ccedbc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006102269s
Oct  7 17:55:07.617: INFO: Pod "busybox-privileged-false-ae64094b-29a2-4f31-ac68-7cce1ccedbc5" satisfied condition "success or failure"
Oct  7 17:55:07.625: INFO: Got logs for pod "busybox-privileged-false-ae64094b-29a2-4f31-ac68-7cce1ccedbc5": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:55:07.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8493" for this suite.
Oct  7 17:55:13.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:55:13.715: INFO: namespace security-context-test-8493 deletion completed in 6.085881564s

• [SLOW TEST:8.267 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:55:13.716: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  7 17:55:13.874: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  7 17:55:13.885: INFO: Waiting for terminating namespaces to be deleted...
Oct  7 17:55:13.887: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-clj9s before test
Oct  7 17:55:13.904: INFO: kube-flannel-ds-amd64-nlfgj from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.904: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 17:55:13.904: INFO: sonobuoy from sonobuoy started at 2019-10-07 17:41:21 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.904: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  7 17:55:13.904: INFO: kube-proxy-9mtkh from kube-system started at 2019-10-07 17:39:22 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.904: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 17:55:13.904: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-lrncj before test
Oct  7 17:55:13.922: INFO: sonobuoy-e2e-job-24ad69244f4745c0 from sonobuoy started at 2019-10-07 17:41:22 +0000 UTC (2 container statuses recorded)
Oct  7 17:55:13.922: INFO: 	Container e2e ready: true, restart count 0
Oct  7 17:55:13.922: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  7 17:55:13.922: INFO: coredns-5644d7b6d9-cbm4m from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.922: INFO: 	Container coredns ready: true, restart count 0
Oct  7 17:55:13.922: INFO: kube-flannel-ds-amd64-wgm5j from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.922: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 17:55:13.922: INFO: kube-proxy-nghr9 from kube-system started at 2019-10-07 17:39:14 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.922: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 17:55:13.922: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-ns4sr before test
Oct  7 17:55:13.932: INFO: coredns-5644d7b6d9-nkvbc from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.932: INFO: 	Container coredns ready: true, restart count 0
Oct  7 17:55:13.932: INFO: kube-flannel-ds-amd64-6hxsg from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.932: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 17:55:13.932: INFO: kube-proxy-p4d5z from kube-system started at 2019-10-07 17:39:07 +0000 UTC (1 container statuses recorded)
Oct  7 17:55:13.932: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-959de63d-369b-44e6-859b-aee635ebd2af 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-959de63d-369b-44e6-859b-aee635ebd2af off the node talos-v020-gcp-workers-654f4446bf-clj9s
STEP: verifying the node doesn't have the label kubernetes.io/e2e-959de63d-369b-44e6-859b-aee635ebd2af
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:55:22.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5974" for this suite.
Oct  7 17:55:36.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:55:36.165: INFO: namespace sched-pred-5974 deletion completed in 14.075807577s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:22.449 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:55:36.165: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  7 17:55:36.332: INFO: Waiting up to 5m0s for pod "downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb" in namespace "downward-api-3186" to be "success or failure"
Oct  7 17:55:36.336: INFO: Pod "downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.30516ms
Oct  7 17:55:38.340: INFO: Pod "downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007020027s
STEP: Saw pod success
Oct  7 17:55:38.340: INFO: Pod "downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb" satisfied condition "success or failure"
Oct  7 17:55:38.342: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb container dapi-container: <nil>
STEP: delete the pod
Oct  7 17:55:38.365: INFO: Waiting for pod downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb to disappear
Oct  7 17:55:38.368: INFO: Pod downward-api-483dde3a-135c-44d8-84e9-f642cfb9e0fb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:55:38.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3186" for this suite.
Oct  7 17:55:44.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:55:44.448: INFO: namespace downward-api-3186 deletion completed in 6.076844428s

• [SLOW TEST:8.283 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:55:44.449: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  7 17:55:44.630: INFO: Waiting up to 5m0s for pod "downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b" in namespace "downward-api-424" to be "success or failure"
Oct  7 17:55:44.632: INFO: Pod "downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.508634ms
Oct  7 17:55:46.636: INFO: Pod "downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006133001s
STEP: Saw pod success
Oct  7 17:55:46.636: INFO: Pod "downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b" satisfied condition "success or failure"
Oct  7 17:55:46.638: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b container dapi-container: <nil>
STEP: delete the pod
Oct  7 17:55:46.657: INFO: Waiting for pod downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b to disappear
Oct  7 17:55:46.660: INFO: Pod downward-api-7a0c973c-edf5-4987-9d1d-04f59944896b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:55:46.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-424" for this suite.
Oct  7 17:55:52.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:55:52.742: INFO: namespace downward-api-424 deletion completed in 6.075648171s

• [SLOW TEST:8.293 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:55:52.742: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-3199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Oct  7 17:55:52.898: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  7 17:56:52.916: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 17:56:52.919: INFO: Starting informer...
STEP: Starting pod...
Oct  7 17:56:53.131: INFO: Pod is running on talos-v020-gcp-workers-654f4446bf-ns4sr. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Oct  7 17:56:53.151: INFO: Pod wasn't evicted. Proceeding
Oct  7 17:56:53.151: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Oct  7 17:58:08.169: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:58:08.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3199" for this suite.
Oct  7 17:58:36.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:58:36.250: INFO: namespace taint-single-pod-3199 deletion completed in 28.073954953s

• [SLOW TEST:163.508 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:58:36.252: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3631
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3631, will wait for the garbage collector to delete the pods
Oct  7 17:58:38.503: INFO: Deleting Job.batch foo took: 18.666169ms
Oct  7 17:58:38.803: INFO: Terminating Job.batch foo pods took: 300.262582ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:59:12.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3631" for this suite.
Oct  7 17:59:18.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:59:18.385: INFO: namespace job-3631 deletion completed in 6.074010868s

• [SLOW TEST:42.133 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:59:18.386: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 17:59:18.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a" in namespace "projected-6800" to be "success or failure"
Oct  7 17:59:18.550: INFO: Pod "downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.237491ms
Oct  7 17:59:20.554: INFO: Pod "downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005877255s
STEP: Saw pod success
Oct  7 17:59:20.554: INFO: Pod "downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a" satisfied condition "success or failure"
Oct  7 17:59:20.557: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a container client-container: <nil>
STEP: delete the pod
Oct  7 17:59:20.590: INFO: Waiting for pod downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a to disappear
Oct  7 17:59:20.592: INFO: Pod downwardapi-volume-95c89720-5d9d-4055-8519-faee1971453a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 17:59:20.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6800" for this suite.
Oct  7 17:59:26.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 17:59:26.673: INFO: namespace projected-6800 deletion completed in 6.076963615s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 17:59:26.673: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Oct  7 18:00:06.865: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1007 18:00:06.865879      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:00:06.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2095" for this suite.
Oct  7 18:00:12.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:12.983: INFO: namespace gc-2095 deletion completed in 6.113431737s

• [SLOW TEST:46.310 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:00:12.983: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  7 18:00:13.135: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  7 18:00:13.144: INFO: Waiting for terminating namespaces to be deleted...
Oct  7 18:00:13.146: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-clj9s before test
Oct  7 18:00:13.164: INFO: kube-flannel-ds-amd64-nlfgj from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.164: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:00:13.164: INFO: sonobuoy from sonobuoy started at 2019-10-07 17:41:21 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.164: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  7 18:00:13.164: INFO: coredns-5644d7b6d9-gshlc from kube-system started at 2019-10-07 17:56:53 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.164: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:00:13.164: INFO: kube-proxy-9mtkh from kube-system started at 2019-10-07 17:39:22 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.164: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:00:13.164: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-lrncj before test
Oct  7 18:00:13.179: INFO: sonobuoy-e2e-job-24ad69244f4745c0 from sonobuoy started at 2019-10-07 17:41:22 +0000 UTC (2 container statuses recorded)
Oct  7 18:00:13.179: INFO: 	Container e2e ready: true, restart count 0
Oct  7 18:00:13.179: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  7 18:00:13.179: INFO: coredns-5644d7b6d9-cbm4m from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.179: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:00:13.179: INFO: kube-flannel-ds-amd64-wgm5j from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.179: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:00:13.179: INFO: kube-proxy-nghr9 from kube-system started at 2019-10-07 17:39:14 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.179: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:00:13.179: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-ns4sr before test
Oct  7 18:00:13.185: INFO: kube-proxy-p4d5z from kube-system started at 2019-10-07 17:39:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.185: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:00:13.185: INFO: kube-flannel-ds-amd64-6hxsg from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:00:13.185: INFO: 	Container kube-flannel ready: true, restart count 6
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cb6f3f6cae2999], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15cb6f3f6d8ca471], Reason = [FailedScheduling], Message = [0/6 nodes are available: 6 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:00:14.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9450" for this suite.
Oct  7 18:00:20.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:20.289: INFO: namespace sched-pred-9450 deletion completed in 6.073953026s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.306 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:00:20.289: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:00:21.415: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  7 18:00:23.425: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706068021, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706068021, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706068021, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706068021, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:00:26.447: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:00:26.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9849" for this suite.
Oct  7 18:00:32.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:32.603: INFO: namespace webhook-9849 deletion completed in 6.074871756s
STEP: Destroying namespace "webhook-9849-markers" for this suite.
Oct  7 18:00:38.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:38.706: INFO: namespace webhook-9849-markers deletion completed in 6.102676581s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.430 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:00:38.721: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1591
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2126
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4868
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:00:45.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1591" for this suite.
Oct  7 18:00:51.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:51.327: INFO: namespace namespaces-1591 deletion completed in 6.076810953s
STEP: Destroying namespace "nsdeletetest-2126" for this suite.
Oct  7 18:00:51.330: INFO: Namespace nsdeletetest-2126 was already deleted
STEP: Destroying namespace "nsdeletetest-4868" for this suite.
Oct  7 18:00:57.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:00:57.405: INFO: namespace nsdeletetest-4868 deletion completed in 6.075688601s

• [SLOW TEST:18.686 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:00:57.405: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8870
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Oct  7 18:01:00.080: INFO: Successfully updated pod "adopt-release-7sx4b"
STEP: Checking that the Job readopts the Pod
Oct  7 18:01:00.080: INFO: Waiting up to 15m0s for pod "adopt-release-7sx4b" in namespace "job-8870" to be "adopted"
Oct  7 18:01:00.084: INFO: Pod "adopt-release-7sx4b": Phase="Running", Reason="", readiness=true. Elapsed: 3.881339ms
Oct  7 18:01:02.087: INFO: Pod "adopt-release-7sx4b": Phase="Running", Reason="", readiness=true. Elapsed: 2.007684517s
Oct  7 18:01:02.087: INFO: Pod "adopt-release-7sx4b" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Oct  7 18:01:02.597: INFO: Successfully updated pod "adopt-release-7sx4b"
STEP: Checking that the Job releases the Pod
Oct  7 18:01:02.597: INFO: Waiting up to 15m0s for pod "adopt-release-7sx4b" in namespace "job-8870" to be "released"
Oct  7 18:01:02.600: INFO: Pod "adopt-release-7sx4b": Phase="Running", Reason="", readiness=true. Elapsed: 2.85864ms
Oct  7 18:01:04.603: INFO: Pod "adopt-release-7sx4b": Phase="Running", Reason="", readiness=true. Elapsed: 2.006466827s
Oct  7 18:01:04.603: INFO: Pod "adopt-release-7sx4b" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:01:04.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8870" for this suite.
Oct  7 18:01:54.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:01:54.679: INFO: namespace job-8870 deletion completed in 50.071532786s

• [SLOW TEST:57.273 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:01:54.679: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:02:10.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1285" for this suite.
Oct  7 18:02:16.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:02:16.954: INFO: namespace resourcequota-1285 deletion completed in 6.075484008s

• [SLOW TEST:22.275 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:02:16.955: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  7 18:02:19.640: INFO: Successfully updated pod "pod-update-fa15cc8b-ad27-4f91-8472-9a3b7f1124d4"
STEP: verifying the updated pod is in kubernetes
Oct  7 18:02:19.646: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:02:19.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8101" for this suite.
Oct  7 18:02:31.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:02:31.732: INFO: namespace pods-8101 deletion completed in 12.082415381s

• [SLOW TEST:14.777 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:02:31.733: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4324/configmap-test-5ecb2159-0b94-46d8-8f11-8e415b57d3e1
STEP: Creating a pod to test consume configMaps
Oct  7 18:02:31.930: INFO: Waiting up to 5m0s for pod "pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f" in namespace "configmap-4324" to be "success or failure"
Oct  7 18:02:31.932: INFO: Pod "pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.352102ms
Oct  7 18:02:33.936: INFO: Pod "pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006225111s
STEP: Saw pod success
Oct  7 18:02:33.936: INFO: Pod "pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f" satisfied condition "success or failure"
Oct  7 18:02:33.939: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f container env-test: <nil>
STEP: delete the pod
Oct  7 18:02:33.986: INFO: Waiting for pod pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f to disappear
Oct  7 18:02:33.988: INFO: Pod pod-configmaps-586f03d6-5afe-44b7-8940-056e77ff882f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:02:33.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4324" for this suite.
Oct  7 18:02:40.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:02:40.068: INFO: namespace configmap-4324 deletion completed in 6.072113124s

• [SLOW TEST:8.335 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:02:40.070: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-bc49b68c-aca5-4120-8e23-eb0c8bbbfb70 in namespace container-probe-6574
Oct  7 18:02:44.273: INFO: Started pod test-webserver-bc49b68c-aca5-4120-8e23-eb0c8bbbfb70 in namespace container-probe-6574
STEP: checking the pod's current state and verifying that restartCount is present
Oct  7 18:02:44.275: INFO: Initial restart count of pod test-webserver-bc49b68c-aca5-4120-8e23-eb0c8bbbfb70 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:06:44.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6574" for this suite.
Oct  7 18:06:50.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:06:50.935: INFO: namespace container-probe-6574 deletion completed in 6.075905635s

• [SLOW TEST:250.774 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:06:50.936: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5431
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  7 18:06:55.133: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  7 18:06:55.135: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  7 18:06:57.136: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  7 18:06:57.139: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  7 18:06:59.136: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  7 18:06:59.140: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  7 18:07:01.136: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  7 18:07:01.139: INFO: Pod pod-with-prestop-exec-hook still exists
Oct  7 18:07:03.136: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Oct  7 18:07:03.139: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:07:03.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5431" for this suite.
Oct  7 18:07:15.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:07:15.241: INFO: namespace container-lifecycle-hook-5431 deletion completed in 12.075398728s

• [SLOW TEST:24.304 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:07:15.242: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  7 18:07:15.420: INFO: Waiting up to 5m0s for pod "pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d" in namespace "emptydir-1978" to be "success or failure"
Oct  7 18:07:15.422: INFO: Pod "pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.535717ms
Oct  7 18:07:17.426: INFO: Pod "pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006027399s
STEP: Saw pod success
Oct  7 18:07:17.426: INFO: Pod "pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d" satisfied condition "success or failure"
Oct  7 18:07:17.428: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d container test-container: <nil>
STEP: delete the pod
Oct  7 18:07:17.445: INFO: Waiting for pod pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d to disappear
Oct  7 18:07:17.448: INFO: Pod pod-e63cb6a6-2bfd-457b-b9e6-2b9b788ce84d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:07:17.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1978" for this suite.
Oct  7 18:07:23.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:07:23.525: INFO: namespace emptydir-1978 deletion completed in 6.074417871s

• [SLOW TEST:8.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:07:23.526: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:07:24.187: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:07:27.215: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:07:27.218: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4564-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:07:28.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-480" for this suite.
Oct  7 18:07:34.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:07:34.431: INFO: namespace webhook-480 deletion completed in 6.076379571s
STEP: Destroying namespace "webhook-480-markers" for this suite.
Oct  7 18:07:40.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:07:40.508: INFO: namespace webhook-480-markers deletion completed in 6.07651253s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.995 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:07:40.522: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2418
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-24098871-f1ad-4150-84d3-f82e910e0995
STEP: Creating a pod to test consume secrets
Oct  7 18:07:40.688: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56" in namespace "projected-2418" to be "success or failure"
Oct  7 18:07:40.690: INFO: Pod "pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.410192ms
Oct  7 18:07:42.694: INFO: Pod "pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005839433s
STEP: Saw pod success
Oct  7 18:07:42.694: INFO: Pod "pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56" satisfied condition "success or failure"
Oct  7 18:07:42.696: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  7 18:07:42.717: INFO: Waiting for pod pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56 to disappear
Oct  7 18:07:42.720: INFO: Pod pod-projected-secrets-2b022d95-c757-4df9-9f3e-6ab0b6d8ab56 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:07:42.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2418" for this suite.
Oct  7 18:07:48.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:07:48.829: INFO: namespace projected-2418 deletion completed in 6.078517935s

• [SLOW TEST:8.308 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:07:48.830: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8819
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:07:48.985: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:07:56.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8819" for this suite.
Oct  7 18:08:02.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:08:02.316: INFO: namespace custom-resource-definition-8819 deletion completed in 6.078284476s

• [SLOW TEST:13.486 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:08:02.317: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  7 18:08:02.505: INFO: Waiting up to 5m0s for pod "pod-1e89f673-c356-4579-86cd-8f144db77ee7" in namespace "emptydir-2189" to be "success or failure"
Oct  7 18:08:02.507: INFO: Pod "pod-1e89f673-c356-4579-86cd-8f144db77ee7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.531258ms
Oct  7 18:08:04.511: INFO: Pod "pod-1e89f673-c356-4579-86cd-8f144db77ee7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006085511s
STEP: Saw pod success
Oct  7 18:08:04.511: INFO: Pod "pod-1e89f673-c356-4579-86cd-8f144db77ee7" satisfied condition "success or failure"
Oct  7 18:08:04.513: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-1e89f673-c356-4579-86cd-8f144db77ee7 container test-container: <nil>
STEP: delete the pod
Oct  7 18:08:04.533: INFO: Waiting for pod pod-1e89f673-c356-4579-86cd-8f144db77ee7 to disappear
Oct  7 18:08:04.535: INFO: Pod pod-1e89f673-c356-4579-86cd-8f144db77ee7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:08:04.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2189" for this suite.
Oct  7 18:08:10.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:08:10.611: INFO: namespace emptydir-2189 deletion completed in 6.073119019s

• [SLOW TEST:8.295 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:08:10.612: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 18:08:32.797: INFO: DNS probes using dns-test-cbf03363-678a-4672-9ad7-0e3513f08ff8 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 18:08:34.847: INFO: File wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local from pod  dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  7 18:08:34.854: INFO: File jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local from pod  dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  7 18:08:34.854: INFO: Lookups using dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 failed for: [wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local]

Oct  7 18:08:39.859: INFO: File wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local from pod  dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  7 18:08:39.863: INFO: File jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local from pod  dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  7 18:08:39.863: INFO: Lookups using dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 failed for: [wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local]

Oct  7 18:08:44.859: INFO: File wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local from pod  dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 contains 'foo.example.com.
' instead of 'bar.example.com.'
Oct  7 18:08:44.863: INFO: Lookups using dns-1829/dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 failed for: [wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local]

Oct  7 18:08:49.870: INFO: DNS probes using dns-test-0919df68-72ab-4f15-a7c3-17710cd35057 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1829.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1829.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 18:09:11.997: INFO: DNS probes using dns-test-a8678586-7ada-4625-8a46-c08782646ece succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:09:12.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1829" for this suite.
Oct  7 18:09:18.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:09:18.133: INFO: namespace dns-1829 deletion completed in 6.081241124s

• [SLOW TEST:67.521 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:09:18.133: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Oct  7 18:09:28.315: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1007 18:09:28.315227      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:09:28.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4743" for this suite.
Oct  7 18:09:34.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:09:34.401: INFO: namespace gc-4743 deletion completed in 6.083430838s

• [SLOW TEST:16.268 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:09:34.402: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Oct  7 18:09:34.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 api-versions'
Oct  7 18:09:34.737: INFO: stderr: ""
Oct  7 18:09:34.737: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:09:34.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5545" for this suite.
Oct  7 18:09:40.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:09:40.819: INFO: namespace kubectl-5545 deletion completed in 6.078218497s

• [SLOW TEST:6.418 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:09:40.820: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-a6c118d4-2df3-47ae-a4f4-2c96d4830480
STEP: Creating a pod to test consume secrets
Oct  7 18:09:41.002: INFO: Waiting up to 5m0s for pod "pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53" in namespace "secrets-3064" to be "success or failure"
Oct  7 18:09:41.005: INFO: Pod "pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53": Phase="Pending", Reason="", readiness=false. Elapsed: 3.092087ms
Oct  7 18:09:43.009: INFO: Pod "pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0071717s
STEP: Saw pod success
Oct  7 18:09:43.009: INFO: Pod "pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53" satisfied condition "success or failure"
Oct  7 18:09:43.012: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 18:09:43.044: INFO: Waiting for pod pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53 to disappear
Oct  7 18:09:43.047: INFO: Pod pod-secrets-c3f3b85c-18f1-4855-b226-34180a060b53 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:09:43.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3064" for this suite.
Oct  7 18:09:49.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:09:49.140: INFO: namespace secrets-3064 deletion completed in 6.085189132s

• [SLOW TEST:8.320 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:09:49.144: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:09:49.329: INFO: (0) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 16.659596ms)
Oct  7 18:09:49.334: INFO: (1) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.820185ms)
Oct  7 18:09:49.339: INFO: (2) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.272731ms)
Oct  7 18:09:49.343: INFO: (3) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.006589ms)
Oct  7 18:09:49.347: INFO: (4) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.995606ms)
Oct  7 18:09:49.351: INFO: (5) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.257325ms)
Oct  7 18:09:49.355: INFO: (6) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.852305ms)
Oct  7 18:09:49.359: INFO: (7) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.825465ms)
Oct  7 18:09:49.363: INFO: (8) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.844533ms)
Oct  7 18:09:49.366: INFO: (9) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.599835ms)
Oct  7 18:09:49.370: INFO: (10) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.733071ms)
Oct  7 18:09:49.374: INFO: (11) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.856438ms)
Oct  7 18:09:49.378: INFO: (12) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.725624ms)
Oct  7 18:09:49.382: INFO: (13) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.62567ms)
Oct  7 18:09:49.385: INFO: (14) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.699387ms)
Oct  7 18:09:49.389: INFO: (15) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.381239ms)
Oct  7 18:09:49.393: INFO: (16) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.211795ms)
Oct  7 18:09:49.397: INFO: (17) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.403528ms)
Oct  7 18:09:49.401: INFO: (18) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.45451ms)
Oct  7 18:09:49.404: INFO: (19) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.561276ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:09:49.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2966" for this suite.
Oct  7 18:09:55.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:09:55.503: INFO: namespace proxy-2966 deletion completed in 6.094362663s

• [SLOW TEST:6.359 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:09:55.503: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4152
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:09:55.659: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  7 18:09:58.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-4152 create -f -'
Oct  7 18:09:59.836: INFO: stderr: ""
Oct  7 18:09:59.836: INFO: stdout: "e2e-test-crd-publish-openapi-3274-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  7 18:09:59.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-4152 delete e2e-test-crd-publish-openapi-3274-crds test-cr'
Oct  7 18:09:59.959: INFO: stderr: ""
Oct  7 18:09:59.960: INFO: stdout: "e2e-test-crd-publish-openapi-3274-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Oct  7 18:09:59.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-4152 apply -f -'
Oct  7 18:10:00.289: INFO: stderr: ""
Oct  7 18:10:00.289: INFO: stdout: "e2e-test-crd-publish-openapi-3274-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Oct  7 18:10:00.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-4152 delete e2e-test-crd-publish-openapi-3274-crds test-cr'
Oct  7 18:10:00.404: INFO: stderr: ""
Oct  7 18:10:00.404: INFO: stdout: "e2e-test-crd-publish-openapi-3274-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct  7 18:10:00.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-3274-crds'
Oct  7 18:10:00.641: INFO: stderr: ""
Oct  7 18:10:00.641: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3274-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:10:03.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4152" for this suite.
Oct  7 18:10:09.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:10:09.625: INFO: namespace crd-publish-openapi-4152 deletion completed in 6.075757093s

• [SLOW TEST:14.122 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:10:09.626: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:10:09.816: INFO: Create a RollingUpdate DaemonSet
Oct  7 18:10:09.838: INFO: Check that daemon pods launch on every node of the cluster
Oct  7 18:10:09.843: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:09.843: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:09.843: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:09.866: INFO: Number of nodes with available pods: 0
Oct  7 18:10:09.866: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:10:10.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:10.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:10.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:10.925: INFO: Number of nodes with available pods: 0
Oct  7 18:10:10.925: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:10:11.871: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:11.871: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:11.871: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:11.874: INFO: Number of nodes with available pods: 3
Oct  7 18:10:11.874: INFO: Number of running nodes: 3, number of available pods: 3
Oct  7 18:10:11.874: INFO: Update the DaemonSet to trigger a rollout
Oct  7 18:10:11.882: INFO: Updating DaemonSet daemon-set
Oct  7 18:10:15.897: INFO: Roll back the DaemonSet before rollout is complete
Oct  7 18:10:15.906: INFO: Updating DaemonSet daemon-set
Oct  7 18:10:15.906: INFO: Make sure DaemonSet rollback is complete
Oct  7 18:10:15.909: INFO: Wrong image for pod: daemon-set-psfl5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct  7 18:10:15.909: INFO: Pod daemon-set-psfl5 is not available
Oct  7 18:10:15.913: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:15.913: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:15.913: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:16.917: INFO: Wrong image for pod: daemon-set-psfl5. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Oct  7 18:10:16.917: INFO: Pod daemon-set-psfl5 is not available
Oct  7 18:10:16.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:16.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:16.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:17.917: INFO: Pod daemon-set-cfb9t is not available
Oct  7 18:10:17.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:17.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:10:17.921: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1097, will wait for the garbage collector to delete the pods
Oct  7 18:10:17.988: INFO: Deleting DaemonSet.extensions daemon-set took: 7.84735ms
Oct  7 18:10:18.288: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.24602ms
Oct  7 18:10:24.992: INFO: Number of nodes with available pods: 0
Oct  7 18:10:24.992: INFO: Number of running nodes: 0, number of available pods: 0
Oct  7 18:10:24.997: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1097/daemonsets","resourceVersion":"11187"},"items":null}

Oct  7 18:10:25.000: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1097/pods","resourceVersion":"11187"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:10:25.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1097" for this suite.
Oct  7 18:10:31.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:10:31.096: INFO: namespace daemonsets-1097 deletion completed in 6.083171819s

• [SLOW TEST:21.470 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:10:31.098: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:10:49.305: INFO: Container started at 2019-10-07 18:10:32 +0000 UTC, pod became ready at 2019-10-07 18:10:47 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:10:49.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4552" for this suite.
Oct  7 18:11:01.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:11:01.389: INFO: namespace container-probe-4552 deletion completed in 12.080568817s

• [SLOW TEST:30.292 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:11:01.389: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-668
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:11:18.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-668" for this suite.
Oct  7 18:11:24.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:11:24.697: INFO: namespace resourcequota-668 deletion completed in 6.080212985s

• [SLOW TEST:23.308 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:11:24.698: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6536
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6536
STEP: Creating statefulset with conflicting port in namespace statefulset-6536
STEP: Waiting until pod test-pod will start running in namespace statefulset-6536
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6536
Oct  7 18:11:28.900: INFO: Observed stateful pod in namespace: statefulset-6536, name: ss-0, uid: 35fc2b9d-3969-4cac-b045-7b129f42f1a6, status phase: Pending. Waiting for statefulset controller to delete.
Oct  7 18:11:29.080: INFO: Observed stateful pod in namespace: statefulset-6536, name: ss-0, uid: 35fc2b9d-3969-4cac-b045-7b129f42f1a6, status phase: Failed. Waiting for statefulset controller to delete.
Oct  7 18:11:29.088: INFO: Observed stateful pod in namespace: statefulset-6536, name: ss-0, uid: 35fc2b9d-3969-4cac-b045-7b129f42f1a6, status phase: Failed. Waiting for statefulset controller to delete.
Oct  7 18:11:29.096: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6536
STEP: Removing pod with conflicting port in namespace statefulset-6536
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6536 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 18:11:33.122: INFO: Deleting all statefulset in ns statefulset-6536
Oct  7 18:11:33.125: INFO: Scaling statefulset ss to 0
Oct  7 18:11:43.142: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:11:43.149: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:11:43.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6536" for this suite.
Oct  7 18:11:49.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:11:49.244: INFO: namespace statefulset-6536 deletion completed in 6.078953265s

• [SLOW TEST:24.546 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:11:49.244: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8a94977c-70df-4c16-8fcb-d07627345649
STEP: Creating a pod to test consume configMaps
Oct  7 18:11:49.416: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917" in namespace "configmap-1797" to be "success or failure"
Oct  7 18:11:49.418: INFO: Pod "pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917": Phase="Pending", Reason="", readiness=false. Elapsed: 2.795794ms
Oct  7 18:11:51.422: INFO: Pod "pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006407057s
STEP: Saw pod success
Oct  7 18:11:51.422: INFO: Pod "pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917" satisfied condition "success or failure"
Oct  7 18:11:51.425: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 18:11:51.459: INFO: Waiting for pod pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917 to disappear
Oct  7 18:11:51.462: INFO: Pod pod-configmaps-ac481357-5fdf-401a-996e-f64dc8e6b917 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:11:51.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1797" for this suite.
Oct  7 18:11:57.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:11:57.549: INFO: namespace configmap-1797 deletion completed in 6.082822966s

• [SLOW TEST:8.305 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:11:57.550: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-ad014001-9ce2-4ebe-a677-eb6a9dca80f4
STEP: Creating secret with name secret-projected-all-test-volume-d4ab2461-e864-4815-a9cd-073b5c6d104f
STEP: Creating a pod to test Check all projections for projected volume plugin
Oct  7 18:11:57.726: INFO: Waiting up to 5m0s for pod "projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0" in namespace "projected-186" to be "success or failure"
Oct  7 18:11:57.729: INFO: Pod "projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.379142ms
Oct  7 18:11:59.732: INFO: Pod "projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006177151s
STEP: Saw pod success
Oct  7 18:11:59.732: INFO: Pod "projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0" satisfied condition "success or failure"
Oct  7 18:11:59.736: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0 container projected-all-volume-test: <nil>
STEP: delete the pod
Oct  7 18:11:59.754: INFO: Waiting for pod projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0 to disappear
Oct  7 18:11:59.758: INFO: Pod projected-volume-25babdf3-b423-43b1-a816-4a5bd838b5c0 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:11:59.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-186" for this suite.
Oct  7 18:12:05.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:12:05.836: INFO: namespace projected-186 deletion completed in 6.07420178s

• [SLOW TEST:8.286 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:12:05.836: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-612
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  7 18:12:06.001: INFO: Waiting up to 5m0s for pod "pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c" in namespace "emptydir-612" to be "success or failure"
Oct  7 18:12:06.004: INFO: Pod "pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.885738ms
Oct  7 18:12:08.008: INFO: Pod "pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006679582s
STEP: Saw pod success
Oct  7 18:12:08.008: INFO: Pod "pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c" satisfied condition "success or failure"
Oct  7 18:12:08.010: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c container test-container: <nil>
STEP: delete the pod
Oct  7 18:12:08.031: INFO: Waiting for pod pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c to disappear
Oct  7 18:12:08.033: INFO: Pod pod-a85f81f2-cb9f-40c7-b1aa-6fbca0eab09c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:12:08.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-612" for this suite.
Oct  7 18:12:14.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:12:14.134: INFO: namespace emptydir-612 deletion completed in 6.096672677s

• [SLOW TEST:8.298 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:12:14.135: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:12:14.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7367" for this suite.
Oct  7 18:12:20.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:12:20.439: INFO: namespace tables-7367 deletion completed in 6.079040321s

• [SLOW TEST:6.305 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:12:20.439: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Oct  7 18:12:20.600: INFO: Waiting up to 5m0s for pod "pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e" in namespace "emptydir-2924" to be "success or failure"
Oct  7 18:12:20.603: INFO: Pod "pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318227ms
Oct  7 18:12:22.606: INFO: Pod "pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005891272s
STEP: Saw pod success
Oct  7 18:12:22.606: INFO: Pod "pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e" satisfied condition "success or failure"
Oct  7 18:12:22.609: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e container test-container: <nil>
STEP: delete the pod
Oct  7 18:12:22.627: INFO: Waiting for pod pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e to disappear
Oct  7 18:12:22.630: INFO: Pod pod-57e3acc2-cb48-45f2-8aaa-ae8b41e5fe6e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:12:22.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2924" for this suite.
Oct  7 18:12:28.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:12:28.707: INFO: namespace emptydir-2924 deletion completed in 6.073784328s

• [SLOW TEST:8.268 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:12:28.709: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1969
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-1969
Oct  7 18:12:28.907: INFO: Found 0 stateful pods, waiting for 1
Oct  7 18:12:38.911: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 18:12:38.928: INFO: Deleting all statefulset in ns statefulset-1969
Oct  7 18:12:38.934: INFO: Scaling statefulset ss to 0
Oct  7 18:12:48.984: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:12:48.987: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:12:48.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1969" for this suite.
Oct  7 18:12:55.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:12:55.081: INFO: namespace statefulset-1969 deletion completed in 6.077513357s

• [SLOW TEST:26.372 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:12:55.082: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-2cefa38c-9ffd-4280-9cfd-400a1cfde9f9
STEP: Creating a pod to test consume configMaps
Oct  7 18:12:55.249: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1" in namespace "configmap-6752" to be "success or failure"
Oct  7 18:12:55.252: INFO: Pod "pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.810981ms
Oct  7 18:12:57.255: INFO: Pod "pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006523269s
STEP: Saw pod success
Oct  7 18:12:57.255: INFO: Pod "pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1" satisfied condition "success or failure"
Oct  7 18:12:57.258: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 18:12:57.281: INFO: Waiting for pod pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1 to disappear
Oct  7 18:12:57.284: INFO: Pod pod-configmaps-2e064d45-e565-41f4-ba46-7e81967aa9e1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:12:57.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6752" for this suite.
Oct  7 18:13:03.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:13:03.364: INFO: namespace configmap-6752 deletion completed in 6.075096254s

• [SLOW TEST:8.282 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:13:03.364: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6865
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  7 18:13:03.536: INFO: Waiting up to 5m0s for pod "pod-5bd0bc98-15ce-4366-8514-c550d0abe945" in namespace "emptydir-6865" to be "success or failure"
Oct  7 18:13:03.538: INFO: Pod "pod-5bd0bc98-15ce-4366-8514-c550d0abe945": Phase="Pending", Reason="", readiness=false. Elapsed: 2.695589ms
Oct  7 18:13:05.542: INFO: Pod "pod-5bd0bc98-15ce-4366-8514-c550d0abe945": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006492201s
STEP: Saw pod success
Oct  7 18:13:05.542: INFO: Pod "pod-5bd0bc98-15ce-4366-8514-c550d0abe945" satisfied condition "success or failure"
Oct  7 18:13:05.546: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-5bd0bc98-15ce-4366-8514-c550d0abe945 container test-container: <nil>
STEP: delete the pod
Oct  7 18:13:05.568: INFO: Waiting for pod pod-5bd0bc98-15ce-4366-8514-c550d0abe945 to disappear
Oct  7 18:13:05.570: INFO: Pod pod-5bd0bc98-15ce-4366-8514-c550d0abe945 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:13:05.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6865" for this suite.
Oct  7 18:13:11.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:13:11.660: INFO: namespace emptydir-6865 deletion completed in 6.081065123s

• [SLOW TEST:8.295 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:13:11.662: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Oct  7 18:13:12.867: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1007 18:13:12.867026      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  7 18:13:12.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6616" for this suite.
Oct  7 18:13:18.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:13:18.944: INFO: namespace gc-6616 deletion completed in 6.07340968s

• [SLOW TEST:7.283 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:13:18.945: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-9267
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Oct  7 18:13:23.134: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:23.134: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:23.325: INFO: Exec stderr: ""
Oct  7 18:13:23.325: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:23.325: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:23.513: INFO: Exec stderr: ""
Oct  7 18:13:23.513: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:23.513: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:23.689: INFO: Exec stderr: ""
Oct  7 18:13:23.689: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:23.690: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:23.913: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Oct  7 18:13:23.913: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:23.913: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:24.102: INFO: Exec stderr: ""
Oct  7 18:13:24.102: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:24.103: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:24.292: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Oct  7 18:13:24.292: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:24.292: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:24.478: INFO: Exec stderr: ""
Oct  7 18:13:24.478: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:24.478: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:24.683: INFO: Exec stderr: ""
Oct  7 18:13:24.683: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:24.683: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:24.853: INFO: Exec stderr: ""
Oct  7 18:13:24.853: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9267 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Oct  7 18:13:24.853: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:13:25.027: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:13:25.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9267" for this suite.
Oct  7 18:14:15.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:14:15.166: INFO: namespace e2e-kubelet-etc-hosts-9267 deletion completed in 50.080108136s

• [SLOW TEST:56.167 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:14:15.167: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Oct  7 18:14:15.344: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1197 /api/v1/namespaces/watch-1197/configmaps/e2e-watch-test-watch-closed 1902c440-ced5-4a89-9deb-a0b7ba938c14 12249 0 2019-10-07 18:14:15 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  7 18:14:15.345: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1197 /api/v1/namespaces/watch-1197/configmaps/e2e-watch-test-watch-closed 1902c440-ced5-4a89-9deb-a0b7ba938c14 12250 0 2019-10-07 18:14:15 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Oct  7 18:14:15.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1197 /api/v1/namespaces/watch-1197/configmaps/e2e-watch-test-watch-closed 1902c440-ced5-4a89-9deb-a0b7ba938c14 12251 0 2019-10-07 18:14:15 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  7 18:14:15.360: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1197 /api/v1/namespaces/watch-1197/configmaps/e2e-watch-test-watch-closed 1902c440-ced5-4a89-9deb-a0b7ba938c14 12252 0 2019-10-07 18:14:15 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:14:15.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1197" for this suite.
Oct  7 18:14:21.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:14:21.452: INFO: namespace watch-1197 deletion completed in 6.086447394s

• [SLOW TEST:6.285 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:14:21.452: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4465
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4465
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-4465
I1007 18:14:21.694619      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4465, replica count: 2
Oct  7 18:14:24.746: INFO: Creating new exec pod
I1007 18:14:24.746208      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  7 18:14:27.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-4465 execpodq87ck -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct  7 18:14:28.049: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  7 18:14:28.049: INFO: stdout: ""
Oct  7 18:14:28.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-4465 execpodq87ck -- /bin/sh -x -c nc -zv -t -w 2 10.110.184.35 80'
Oct  7 18:14:28.320: INFO: stderr: "+ nc -zv -t -w 2 10.110.184.35 80\nConnection to 10.110.184.35 80 port [tcp/http] succeeded!\n"
Oct  7 18:14:28.320: INFO: stdout: ""
Oct  7 18:14:28.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-4465 execpodq87ck -- /bin/sh -x -c nc -zv -t -w 2 10.128.15.226 32411'
Oct  7 18:14:28.616: INFO: stderr: "+ nc -zv -t -w 2 10.128.15.226 32411\nConnection to 10.128.15.226 32411 port [tcp/32411] succeeded!\n"
Oct  7 18:14:28.616: INFO: stdout: ""
Oct  7 18:14:28.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-4465 execpodq87ck -- /bin/sh -x -c nc -zv -t -w 2 10.128.0.63 32411'
Oct  7 18:14:28.908: INFO: stderr: "+ nc -zv -t -w 2 10.128.0.63 32411\nConnection to 10.128.0.63 32411 port [tcp/32411] succeeded!\n"
Oct  7 18:14:28.908: INFO: stdout: ""
Oct  7 18:14:28.908: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:14:29.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4465" for this suite.
Oct  7 18:14:35.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:14:35.102: INFO: namespace services-4465 deletion completed in 6.076745236s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.651 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:14:35.103: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:14:35.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153" in namespace "downward-api-9665" to be "success or failure"
Oct  7 18:14:35.275: INFO: Pod "downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153": Phase="Pending", Reason="", readiness=false. Elapsed: 3.135352ms
Oct  7 18:14:37.279: INFO: Pod "downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007391294s
STEP: Saw pod success
Oct  7 18:14:37.279: INFO: Pod "downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153" satisfied condition "success or failure"
Oct  7 18:14:37.282: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153 container client-container: <nil>
STEP: delete the pod
Oct  7 18:14:37.313: INFO: Waiting for pod downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153 to disappear
Oct  7 18:14:37.316: INFO: Pod downwardapi-volume-5b238027-3016-49ab-96e4-ac26b4eae153 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:14:37.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9665" for this suite.
Oct  7 18:14:43.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:14:43.402: INFO: namespace downward-api-9665 deletion completed in 6.082249246s

• [SLOW TEST:8.299 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:14:43.403: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f8ce18a6-e186-41a4-80aa-1517bfaef2e3
STEP: Creating a pod to test consume secrets
Oct  7 18:14:43.578: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb" in namespace "projected-6566" to be "success or failure"
Oct  7 18:14:43.581: INFO: Pod "pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.30703ms
Oct  7 18:14:45.608: INFO: Pod "pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030471038s
STEP: Saw pod success
Oct  7 18:14:45.608: INFO: Pod "pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb" satisfied condition "success or failure"
Oct  7 18:14:45.611: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  7 18:14:45.631: INFO: Waiting for pod pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb to disappear
Oct  7 18:14:45.634: INFO: Pod pod-projected-secrets-eddcc351-0ef0-4f12-9c12-e911b5d44fdb no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:14:45.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6566" for this suite.
Oct  7 18:14:51.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:14:51.722: INFO: namespace projected-6566 deletion completed in 6.084537179s

• [SLOW TEST:8.319 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:14:51.725: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-8909
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8909 to expose endpoints map[]
Oct  7 18:14:51.902: INFO: Get endpoints failed (4.444011ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Oct  7 18:14:52.906: INFO: successfully validated that service endpoint-test2 in namespace services-8909 exposes endpoints map[] (1.00787552s elapsed)
STEP: Creating pod pod1 in namespace services-8909
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8909 to expose endpoints map[pod1:[80]]
Oct  7 18:14:54.937: INFO: successfully validated that service endpoint-test2 in namespace services-8909 exposes endpoints map[pod1:[80]] (2.017775323s elapsed)
STEP: Creating pod pod2 in namespace services-8909
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8909 to expose endpoints map[pod1:[80] pod2:[80]]
Oct  7 18:14:55.964: INFO: successfully validated that service endpoint-test2 in namespace services-8909 exposes endpoints map[pod1:[80] pod2:[80]] (1.019409825s elapsed)
STEP: Deleting pod pod1 in namespace services-8909
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8909 to expose endpoints map[pod2:[80]]
Oct  7 18:14:56.987: INFO: successfully validated that service endpoint-test2 in namespace services-8909 exposes endpoints map[pod2:[80]] (1.016323226s elapsed)
STEP: Deleting pod pod2 in namespace services-8909
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8909 to expose endpoints map[]
Oct  7 18:14:58.002: INFO: successfully validated that service endpoint-test2 in namespace services-8909 exposes endpoints map[] (1.006437344s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:14:58.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8909" for this suite.
Oct  7 18:15:04.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:15:04.117: INFO: namespace services-8909 deletion completed in 6.077267977s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.392 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:15:04.117: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  7 18:15:04.294: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  7 18:15:04.304: INFO: Waiting for terminating namespaces to be deleted...
Oct  7 18:15:04.307: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-clj9s before test
Oct  7 18:15:04.326: INFO: kube-flannel-ds-amd64-nlfgj from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.326: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:04.326: INFO: sonobuoy from sonobuoy started at 2019-10-07 17:41:21 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.326: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  7 18:15:04.326: INFO: coredns-5644d7b6d9-gshlc from kube-system started at 2019-10-07 17:56:53 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.326: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:15:04.326: INFO: kube-proxy-9mtkh from kube-system started at 2019-10-07 17:39:22 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.326: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:15:04.326: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-lrncj before test
Oct  7 18:15:04.358: INFO: kube-proxy-nghr9 from kube-system started at 2019-10-07 17:39:14 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.358: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:15:04.358: INFO: sonobuoy-e2e-job-24ad69244f4745c0 from sonobuoy started at 2019-10-07 17:41:22 +0000 UTC (2 container statuses recorded)
Oct  7 18:15:04.358: INFO: 	Container e2e ready: true, restart count 0
Oct  7 18:15:04.358: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  7 18:15:04.358: INFO: coredns-5644d7b6d9-cbm4m from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.358: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:15:04.358: INFO: kube-flannel-ds-amd64-wgm5j from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.358: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:04.358: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-ns4sr before test
Oct  7 18:15:04.365: INFO: kube-flannel-ds-amd64-6hxsg from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.365: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:04.365: INFO: kube-proxy-p4d5z from kube-system started at 2019-10-07 17:39:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:04.365: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2bc13100-a03f-46bd-a9d5-1266a8e697f4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-2bc13100-a03f-46bd-a9d5-1266a8e697f4 off the node talos-v020-gcp-workers-654f4446bf-ns4sr
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2bc13100-a03f-46bd-a9d5-1266a8e697f4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:15:08.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6683" for this suite.
Oct  7 18:15:26.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:15:26.624: INFO: namespace sched-pred-6683 deletion completed in 18.07788415s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:22.507 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:15:26.625: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1981.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1981.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 18:15:28.828: INFO: DNS probes using dns-1981/dns-test-dab5afbf-9259-4737-9ff8-35baca520ad4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:15:28.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1981" for this suite.
Oct  7 18:15:34.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:15:34.932: INFO: namespace dns-1981 deletion completed in 6.076415342s

• [SLOW TEST:8.307 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:15:34.935: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:15:35.141: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06837024-08e2-447c-a721-c0728e019341" in namespace "projected-7908" to be "success or failure"
Oct  7 18:15:35.143: INFO: Pod "downwardapi-volume-06837024-08e2-447c-a721-c0728e019341": Phase="Pending", Reason="", readiness=false. Elapsed: 2.790864ms
Oct  7 18:15:37.147: INFO: Pod "downwardapi-volume-06837024-08e2-447c-a721-c0728e019341": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006232431s
STEP: Saw pod success
Oct  7 18:15:37.147: INFO: Pod "downwardapi-volume-06837024-08e2-447c-a721-c0728e019341" satisfied condition "success or failure"
Oct  7 18:15:37.150: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-06837024-08e2-447c-a721-c0728e019341 container client-container: <nil>
STEP: delete the pod
Oct  7 18:15:37.167: INFO: Waiting for pod downwardapi-volume-06837024-08e2-447c-a721-c0728e019341 to disappear
Oct  7 18:15:37.169: INFO: Pod downwardapi-volume-06837024-08e2-447c-a721-c0728e019341 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:15:37.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7908" for this suite.
Oct  7 18:15:43.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:15:43.251: INFO: namespace projected-7908 deletion completed in 6.078238369s

• [SLOW TEST:8.317 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:15:43.254: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  7 18:15:43.444: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  7 18:15:43.453: INFO: Waiting for terminating namespaces to be deleted...
Oct  7 18:15:43.457: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-clj9s before test
Oct  7 18:15:43.462: INFO: kube-flannel-ds-amd64-nlfgj from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.462: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:43.462: INFO: sonobuoy from sonobuoy started at 2019-10-07 17:41:21 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.462: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  7 18:15:43.462: INFO: coredns-5644d7b6d9-gshlc from kube-system started at 2019-10-07 17:56:53 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.462: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:15:43.462: INFO: kube-proxy-9mtkh from kube-system started at 2019-10-07 17:39:22 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.462: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:15:43.463: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-lrncj before test
Oct  7 18:15:43.468: INFO: kube-flannel-ds-amd64-wgm5j from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.468: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:43.468: INFO: kube-proxy-nghr9 from kube-system started at 2019-10-07 17:39:14 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.468: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:15:43.468: INFO: sonobuoy-e2e-job-24ad69244f4745c0 from sonobuoy started at 2019-10-07 17:41:22 +0000 UTC (2 container statuses recorded)
Oct  7 18:15:43.468: INFO: 	Container e2e ready: true, restart count 0
Oct  7 18:15:43.468: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  7 18:15:43.468: INFO: coredns-5644d7b6d9-cbm4m from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.468: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:15:43.468: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-ns4sr before test
Oct  7 18:15:43.474: INFO: kube-flannel-ds-amd64-6hxsg from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.474: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:15:43.474: INFO: kube-proxy-p4d5z from kube-system started at 2019-10-07 17:39:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:15:43.474: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node talos-v020-gcp-workers-654f4446bf-clj9s
STEP: verifying the node has the label node talos-v020-gcp-workers-654f4446bf-lrncj
STEP: verifying the node has the label node talos-v020-gcp-workers-654f4446bf-ns4sr
Oct  7 18:15:43.518: INFO: Pod coredns-5644d7b6d9-cbm4m requesting resource cpu=100m on Node talos-v020-gcp-workers-654f4446bf-lrncj
Oct  7 18:15:43.518: INFO: Pod coredns-5644d7b6d9-gshlc requesting resource cpu=100m on Node talos-v020-gcp-workers-654f4446bf-clj9s
Oct  7 18:15:43.518: INFO: Pod kube-flannel-ds-amd64-6hxsg requesting resource cpu=100m on Node talos-v020-gcp-workers-654f4446bf-ns4sr
Oct  7 18:15:43.518: INFO: Pod kube-flannel-ds-amd64-nlfgj requesting resource cpu=100m on Node talos-v020-gcp-workers-654f4446bf-clj9s
Oct  7 18:15:43.518: INFO: Pod kube-flannel-ds-amd64-wgm5j requesting resource cpu=100m on Node talos-v020-gcp-workers-654f4446bf-lrncj
Oct  7 18:15:43.518: INFO: Pod kube-proxy-9mtkh requesting resource cpu=0m on Node talos-v020-gcp-workers-654f4446bf-clj9s
Oct  7 18:15:43.518: INFO: Pod kube-proxy-nghr9 requesting resource cpu=0m on Node talos-v020-gcp-workers-654f4446bf-lrncj
Oct  7 18:15:43.518: INFO: Pod kube-proxy-p4d5z requesting resource cpu=0m on Node talos-v020-gcp-workers-654f4446bf-ns4sr
Oct  7 18:15:43.518: INFO: Pod sonobuoy requesting resource cpu=0m on Node talos-v020-gcp-workers-654f4446bf-clj9s
Oct  7 18:15:43.518: INFO: Pod sonobuoy-e2e-job-24ad69244f4745c0 requesting resource cpu=0m on Node talos-v020-gcp-workers-654f4446bf-lrncj
STEP: Starting Pods to consume most of the cluster CPU.
Oct  7 18:15:43.518: INFO: Creating a pod which consumes cpu=1260m on Node talos-v020-gcp-workers-654f4446bf-clj9s
Oct  7 18:15:43.525: INFO: Creating a pod which consumes cpu=1260m on Node talos-v020-gcp-workers-654f4446bf-lrncj
Oct  7 18:15:43.532: INFO: Creating a pod which consumes cpu=1330m on Node talos-v020-gcp-workers-654f4446bf-ns4sr
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef.15cb701808733bed], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2559/filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef to talos-v020-gcp-workers-654f4446bf-ns4sr]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef.15cb701824a78845], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef.15cb70182bf3bd1f], Reason = [Created], Message = [Created container filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef.15cb7018316e01d0], Reason = [Started], Message = [Started container filler-pod-1efd3144-b859-43a6-9dd6-ab4b21d4ccef]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2.15cb7018080b5d44], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2559/filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2 to talos-v020-gcp-workers-654f4446bf-clj9s]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2.15cb70182c7a0e6e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2.15cb70183162511c], Reason = [Created], Message = [Created container filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2.15cb7018362f0307], Reason = [Started], Message = [Started container filler-pod-58851f0b-4dd3-4eeb-8afd-ce297cbf15f2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a.15cb70180805849c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2559/filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a to talos-v020-gcp-workers-654f4446bf-lrncj]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a.15cb70182d9b5dfe], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a.15cb701835de8b59], Reason = [Created], Message = [Created container filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a.15cb70183ae633e7], Reason = [Started], Message = [Started container filler-pod-a9d032de-9591-4759-b74e-34d652a7cd6a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cb70187eb15183], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15cb7018813c9c49], Reason = [FailedScheduling], Message = [0/6 nodes are available: 3 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node talos-v020-gcp-workers-654f4446bf-clj9s
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node talos-v020-gcp-workers-654f4446bf-lrncj
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node talos-v020-gcp-workers-654f4446bf-ns4sr
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:15:46.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2559" for this suite.
Oct  7 18:15:52.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:15:52.711: INFO: namespace sched-pred-2559 deletion completed in 6.073574599s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.457 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:15:52.712: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-dvcv
STEP: Creating a pod to test atomic-volume-subpath
Oct  7 18:15:52.914: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dvcv" in namespace "subpath-8207" to be "success or failure"
Oct  7 18:15:52.918: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.978823ms
Oct  7 18:15:54.921: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 2.006534693s
Oct  7 18:15:56.925: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 4.010529735s
Oct  7 18:15:58.929: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 6.013984621s
Oct  7 18:16:00.932: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 8.017870337s
Oct  7 18:16:02.936: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 10.021424553s
Oct  7 18:16:04.940: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 12.025325688s
Oct  7 18:16:06.944: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 14.029471441s
Oct  7 18:16:08.947: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 16.032945067s
Oct  7 18:16:10.951: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 18.036683707s
Oct  7 18:16:12.955: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Running", Reason="", readiness=true. Elapsed: 20.040456075s
Oct  7 18:16:14.959: INFO: Pod "pod-subpath-test-configmap-dvcv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.044279727s
STEP: Saw pod success
Oct  7 18:16:14.959: INFO: Pod "pod-subpath-test-configmap-dvcv" satisfied condition "success or failure"
Oct  7 18:16:14.962: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-subpath-test-configmap-dvcv container test-container-subpath-configmap-dvcv: <nil>
STEP: delete the pod
Oct  7 18:16:14.982: INFO: Waiting for pod pod-subpath-test-configmap-dvcv to disappear
Oct  7 18:16:14.984: INFO: Pod pod-subpath-test-configmap-dvcv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dvcv
Oct  7 18:16:14.984: INFO: Deleting pod "pod-subpath-test-configmap-dvcv" in namespace "subpath-8207"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:16:14.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8207" for this suite.
Oct  7 18:16:21.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:16:21.071: INFO: namespace subpath-8207 deletion completed in 6.079355428s

• [SLOW TEST:28.359 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:16:21.075: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  7 18:16:21.257: INFO: Waiting up to 5m0s for pod "downward-api-04985b62-7491-48c0-93e3-1234a408c707" in namespace "downward-api-9477" to be "success or failure"
Oct  7 18:16:21.260: INFO: Pod "downward-api-04985b62-7491-48c0-93e3-1234a408c707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.821564ms
Oct  7 18:16:23.263: INFO: Pod "downward-api-04985b62-7491-48c0-93e3-1234a408c707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006389567s
STEP: Saw pod success
Oct  7 18:16:23.263: INFO: Pod "downward-api-04985b62-7491-48c0-93e3-1234a408c707" satisfied condition "success or failure"
Oct  7 18:16:23.266: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downward-api-04985b62-7491-48c0-93e3-1234a408c707 container dapi-container: <nil>
STEP: delete the pod
Oct  7 18:16:23.286: INFO: Waiting for pod downward-api-04985b62-7491-48c0-93e3-1234a408c707 to disappear
Oct  7 18:16:23.288: INFO: Pod downward-api-04985b62-7491-48c0-93e3-1234a408c707 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:16:23.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9477" for this suite.
Oct  7 18:16:29.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:16:29.372: INFO: namespace downward-api-9477 deletion completed in 6.080377278s

• [SLOW TEST:8.297 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:16:29.373: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:16:30.144: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:16:33.173: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:16:33.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2525" for this suite.
Oct  7 18:16:45.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:16:45.308: INFO: namespace webhook-2525 deletion completed in 12.08326847s
STEP: Destroying namespace "webhook-2525-markers" for this suite.
Oct  7 18:16:51.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:16:51.393: INFO: namespace webhook-2525-markers deletion completed in 6.085062947s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.033 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:16:51.407: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-bf67a378-e9d1-46e6-99db-dc7762aa9df4
STEP: Creating a pod to test consume configMaps
Oct  7 18:16:51.638: INFO: Waiting up to 5m0s for pod "pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b" in namespace "configmap-1911" to be "success or failure"
Oct  7 18:16:51.641: INFO: Pod "pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.711456ms
Oct  7 18:16:53.644: INFO: Pod "pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006297289s
STEP: Saw pod success
Oct  7 18:16:53.644: INFO: Pod "pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b" satisfied condition "success or failure"
Oct  7 18:16:53.647: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 18:16:53.664: INFO: Waiting for pod pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b to disappear
Oct  7 18:16:53.667: INFO: Pod pod-configmaps-81a05c88-dcf5-4cea-919a-b42b792cf82b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:16:53.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1911" for this suite.
Oct  7 18:16:59.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:16:59.766: INFO: namespace configmap-1911 deletion completed in 6.094243361s

• [SLOW TEST:8.359 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:16:59.767: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7418
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:16:59.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa" in namespace "projected-7418" to be "success or failure"
Oct  7 18:16:59.950: INFO: Pod "downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.052146ms
Oct  7 18:17:01.954: INFO: Pod "downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006767017s
STEP: Saw pod success
Oct  7 18:17:01.954: INFO: Pod "downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa" satisfied condition "success or failure"
Oct  7 18:17:01.957: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa container client-container: <nil>
STEP: delete the pod
Oct  7 18:17:01.976: INFO: Waiting for pod downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa to disappear
Oct  7 18:17:01.978: INFO: Pod downwardapi-volume-229fbf54-c8b0-4649-bc43-d7d593fe4caa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:17:01.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7418" for this suite.
Oct  7 18:17:07.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:17:08.061: INFO: namespace projected-7418 deletion completed in 6.079515302s

• [SLOW TEST:8.294 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:17:08.063: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6760
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:17:08.236: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338" in namespace "downward-api-6760" to be "success or failure"
Oct  7 18:17:08.239: INFO: Pod "downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338": Phase="Pending", Reason="", readiness=false. Elapsed: 3.002757ms
Oct  7 18:17:10.243: INFO: Pod "downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007282909s
STEP: Saw pod success
Oct  7 18:17:10.243: INFO: Pod "downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338" satisfied condition "success or failure"
Oct  7 18:17:10.246: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338 container client-container: <nil>
STEP: delete the pod
Oct  7 18:17:10.268: INFO: Waiting for pod downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338 to disappear
Oct  7 18:17:10.271: INFO: Pod downwardapi-volume-f9ca9121-1365-4275-8795-7090b17e2338 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:17:10.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6760" for this suite.
Oct  7 18:17:16.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:17:16.345: INFO: namespace downward-api-6760 deletion completed in 6.07088264s

• [SLOW TEST:8.282 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:17:16.348: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Oct  7 18:17:16.574: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8839" to be "success or failure"
Oct  7 18:17:16.576: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.247635ms
Oct  7 18:17:18.580: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006095402s
STEP: Saw pod success
Oct  7 18:17:18.580: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Oct  7 18:17:18.583: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Oct  7 18:17:18.603: INFO: Waiting for pod pod-host-path-test to disappear
Oct  7 18:17:18.606: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:17:18.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8839" for this suite.
Oct  7 18:17:24.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:17:24.705: INFO: namespace hostpath-8839 deletion completed in 6.095214688s

• [SLOW TEST:8.357 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:17:24.709: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:17:26.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4102" for this suite.
Oct  7 18:17:32.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:17:33.049: INFO: namespace emptydir-wrapper-4102 deletion completed in 6.092872622s

• [SLOW TEST:8.339 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:17:33.049: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2334
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Oct  7 18:17:33.244: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 18:17:36.168: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:17:47.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2334" for this suite.
Oct  7 18:17:53.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:17:53.819: INFO: namespace crd-publish-openapi-2334 deletion completed in 6.091511642s

• [SLOW TEST:20.771 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:17:53.821: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5179
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:18:54.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5179" for this suite.
Oct  7 18:19:06.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:19:06.113: INFO: namespace container-probe-5179 deletion completed in 12.074791688s

• [SLOW TEST:72.293 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:19:06.114: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Oct  7 18:19:08.302: INFO: &Pod{ObjectMeta:{send-events-c18d6921-ef47-470f-b60b-dbc888c1f3e2  events-2605 /api/v1/namespaces/events-2605/pods/send-events-c18d6921-ef47-470f-b60b-dbc888c1f3e2 f9a5e6b9-5e0a-4261-9018-c934d4584e64 13562 0 2019-10-07 18:19:06 +0000 UTC <nil> <nil> map[name:foo time:282358967] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mc9jc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mc9jc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mc9jc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:19:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:19:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:19:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.84,StartTime:2019-10-07 18:19:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:19:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://cf9b17dfd0d8b01247ee098cc3ff859b140d282bff5020255f1691c51c5092c0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Oct  7 18:19:10.307: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Oct  7 18:19:12.311: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:19:12.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2605" for this suite.
Oct  7 18:19:56.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:19:56.397: INFO: namespace events-2605 deletion completed in 44.075057586s

• [SLOW TEST:50.283 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:19:56.398: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Oct  7 18:19:58.572: INFO: Pod pod-hostip-f27af8bb-ba3d-4ffb-bf27-c3c9907a942e has hostIP: 10.128.15.228
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:19:58.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1012" for this suite.
Oct  7 18:20:26.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:20:26.652: INFO: namespace pods-1012 deletion completed in 28.07667065s

• [SLOW TEST:30.255 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:20:26.653: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Oct  7 18:20:26.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=kubectl-6918 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Oct  7 18:20:28.840: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Oct  7 18:20:28.841: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:20:30.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6918" for this suite.
Oct  7 18:20:36.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:20:36.948: INFO: namespace kubectl-6918 deletion completed in 6.099103235s

• [SLOW TEST:10.296 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:20:36.949: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2036
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:20:37.118: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:20:39.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2036" for this suite.
Oct  7 18:21:25.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:21:25.252: INFO: namespace pods-2036 deletion completed in 46.0765772s

• [SLOW TEST:48.304 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:21:25.254: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:21:25.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501" in namespace "projected-3134" to be "success or failure"
Oct  7 18:21:25.470: INFO: Pod "downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501": Phase="Pending", Reason="", readiness=false. Elapsed: 3.31414ms
Oct  7 18:21:27.474: INFO: Pod "downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006895023s
STEP: Saw pod success
Oct  7 18:21:27.474: INFO: Pod "downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501" satisfied condition "success or failure"
Oct  7 18:21:27.477: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501 container client-container: <nil>
STEP: delete the pod
Oct  7 18:21:27.506: INFO: Waiting for pod downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501 to disappear
Oct  7 18:21:27.508: INFO: Pod downwardapi-volume-a780cada-72ba-451b-9002-2b614f8d4501 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:21:27.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3134" for this suite.
Oct  7 18:21:33.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:21:33.617: INFO: namespace projected-3134 deletion completed in 6.105035962s

• [SLOW TEST:8.363 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:21:33.618: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  7 18:21:33.782: INFO: Waiting up to 5m0s for pod "pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6" in namespace "emptydir-1288" to be "success or failure"
Oct  7 18:21:33.785: INFO: Pod "pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.789992ms
Oct  7 18:21:35.788: INFO: Pod "pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006142931s
STEP: Saw pod success
Oct  7 18:21:35.788: INFO: Pod "pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6" satisfied condition "success or failure"
Oct  7 18:21:35.791: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6 container test-container: <nil>
STEP: delete the pod
Oct  7 18:21:35.826: INFO: Waiting for pod pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6 to disappear
Oct  7 18:21:35.829: INFO: Pod pod-db4b5a77-f729-4f1f-b1fb-f107dff42ed6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:21:35.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1288" for this suite.
Oct  7 18:21:41.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:21:41.911: INFO: namespace emptydir-1288 deletion completed in 6.078364939s

• [SLOW TEST:8.293 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:21:41.912: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:21:42.081: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Oct  7 18:21:42.113: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:42.113: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:42.113: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:42.123: INFO: Number of nodes with available pods: 0
Oct  7 18:21:42.123: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:21:43.128: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:43.128: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:43.128: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:43.131: INFO: Number of nodes with available pods: 0
Oct  7 18:21:43.131: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:21:44.127: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:44.127: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:44.127: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:44.163: INFO: Number of nodes with available pods: 3
Oct  7 18:21:44.163: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Oct  7 18:21:44.196: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:44.196: INFO: Wrong image for pod: daemon-set-b5svs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:44.196: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:44.199: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:44.199: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:44.200: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:45.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:45.205: INFO: Wrong image for pod: daemon-set-b5svs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:45.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:45.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:45.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:45.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:46.209: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:46.209: INFO: Wrong image for pod: daemon-set-b5svs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:46.209: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:46.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:46.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:46.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:47.206: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:47.206: INFO: Wrong image for pod: daemon-set-b5svs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:47.206: INFO: Pod daemon-set-b5svs is not available
Oct  7 18:21:47.206: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:47.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:47.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:47.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:48.204: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:48.204: INFO: Pod daemon-set-d7zxb is not available
Oct  7 18:21:48.204: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:48.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:48.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:48.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:49.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:49.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:49.205: INFO: Pod daemon-set-glqcg is not available
Oct  7 18:21:49.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:49.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:49.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:50.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:50.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:50.205: INFO: Pod daemon-set-glqcg is not available
Oct  7 18:21:50.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:50.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:50.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:51.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:51.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:51.205: INFO: Pod daemon-set-glqcg is not available
Oct  7 18:21:51.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:51.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:51.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:52.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:52.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:52.205: INFO: Pod daemon-set-glqcg is not available
Oct  7 18:21:52.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:52.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:52.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:53.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:53.205: INFO: Wrong image for pod: daemon-set-glqcg. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:53.205: INFO: Pod daemon-set-glqcg is not available
Oct  7 18:21:53.212: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:53.212: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:53.212: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:54.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:54.205: INFO: Pod daemon-set-qwpgk is not available
Oct  7 18:21:54.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:54.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:54.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:55.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:55.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:55.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:55.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:56.204: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:56.204: INFO: Pod daemon-set-878nw is not available
Oct  7 18:21:56.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:56.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:56.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:57.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:57.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:21:57.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:57.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:57.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:58.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:58.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:21:58.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:58.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:58.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:59.207: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:21:59.207: INFO: Pod daemon-set-878nw is not available
Oct  7 18:21:59.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:59.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:21:59.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:00.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:22:00.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:22:00.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:00.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:00.208: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:01.206: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:22:01.206: INFO: Pod daemon-set-878nw is not available
Oct  7 18:22:01.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:01.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:01.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:02.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:22:02.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:22:02.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:02.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:02.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:03.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:22:03.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:22:03.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:03.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:03.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:04.205: INFO: Wrong image for pod: daemon-set-878nw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Oct  7 18:22:04.205: INFO: Pod daemon-set-878nw is not available
Oct  7 18:22:04.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:04.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:04.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.206: INFO: Pod daemon-set-t8kbg is not available
Oct  7 18:22:05.209: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.210: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Oct  7 18:22:05.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.213: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:05.216: INFO: Number of nodes with available pods: 2
Oct  7 18:22:05.216: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:22:06.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:06.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:06.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:06.224: INFO: Number of nodes with available pods: 2
Oct  7 18:22:06.224: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:22:07.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:07.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:07.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:07.224: INFO: Number of nodes with available pods: 2
Oct  7 18:22:07.224: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:22:08.222: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:08.222: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:08.222: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:08.226: INFO: Number of nodes with available pods: 2
Oct  7 18:22:08.226: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:22:09.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:09.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:09.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:22:09.224: INFO: Number of nodes with available pods: 3
Oct  7 18:22:09.224: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2875, will wait for the garbage collector to delete the pods
Oct  7 18:22:09.299: INFO: Deleting DaemonSet.extensions daemon-set took: 8.028349ms
Oct  7 18:22:09.599: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.268971ms
Oct  7 18:22:15.102: INFO: Number of nodes with available pods: 0
Oct  7 18:22:15.102: INFO: Number of running nodes: 0, number of available pods: 0
Oct  7 18:22:15.104: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2875/daemonsets","resourceVersion":"14212"},"items":null}

Oct  7 18:22:15.107: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2875/pods","resourceVersion":"14212"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:22:15.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2875" for this suite.
Oct  7 18:22:21.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:22:21.194: INFO: namespace daemonsets-2875 deletion completed in 6.074417279s

• [SLOW TEST:39.282 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:22:21.195: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  7 18:22:21.362: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:22:23.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4478" for this suite.
Oct  7 18:22:30.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:22:30.098: INFO: namespace init-container-4478 deletion completed in 6.12246173s

• [SLOW TEST:8.903 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:22:30.099: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-3198
STEP: creating replication controller nodeport-test in namespace services-3198
I1007 18:22:30.287122      19 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-3198, replica count: 2
Oct  7 18:22:33.337: INFO: Creating new exec pod
I1007 18:22:33.337519      19 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  7 18:22:36.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-3198 execpod9wtwf -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Oct  7 18:22:36.628: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Oct  7 18:22:36.628: INFO: stdout: ""
Oct  7 18:22:36.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-3198 execpod9wtwf -- /bin/sh -x -c nc -zv -t -w 2 10.109.92.71 80'
Oct  7 18:22:36.894: INFO: stderr: "+ nc -zv -t -w 2 10.109.92.71 80\nConnection to 10.109.92.71 80 port [tcp/http] succeeded!\n"
Oct  7 18:22:36.894: INFO: stdout: ""
Oct  7 18:22:36.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-3198 execpod9wtwf -- /bin/sh -x -c nc -zv -t -w 2 10.128.15.226 31396'
Oct  7 18:22:37.157: INFO: stderr: "+ nc -zv -t -w 2 10.128.15.226 31396\nConnection to 10.128.15.226 31396 port [tcp/31396] succeeded!\n"
Oct  7 18:22:37.157: INFO: stdout: ""
Oct  7 18:22:37.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-3198 execpod9wtwf -- /bin/sh -x -c nc -zv -t -w 2 10.128.0.63 31396'
Oct  7 18:22:37.446: INFO: stderr: "+ nc -zv -t -w 2 10.128.0.63 31396\nConnection to 10.128.0.63 31396 port [tcp/31396] succeeded!\n"
Oct  7 18:22:37.446: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:22:37.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3198" for this suite.
Oct  7 18:22:43.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:22:43.531: INFO: namespace services-3198 deletion completed in 6.081186059s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.432 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:22:43.532: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7911
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:22:44.542: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:22:47.579: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:22:47.583: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-870-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:22:48.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7911" for this suite.
Oct  7 18:22:54.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:22:54.814: INFO: namespace webhook-7911 deletion completed in 6.079086295s
STEP: Destroying namespace "webhook-7911-markers" for this suite.
Oct  7 18:23:00.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:00.885: INFO: namespace webhook-7911-markers deletion completed in 6.071316396s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.366 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:00.899: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4748
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-535b6ee7-97ca-4161-826d-a9c983684fba
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:23:01.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4748" for this suite.
Oct  7 18:23:07.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:07.148: INFO: namespace secrets-4748 deletion completed in 6.075170027s

• [SLOW TEST:6.249 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:07.149: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8919
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:23:07.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8919" for this suite.
Oct  7 18:23:13.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:13.397: INFO: namespace custom-resource-definition-8919 deletion completed in 6.076881063s

• [SLOW TEST:6.248 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:13.400: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Oct  7 18:23:13.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 cluster-info'
Oct  7 18:23:13.672: INFO: stderr: ""
Oct  7 18:23:13.672: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:23:13.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6454" for this suite.
Oct  7 18:23:19.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:19.752: INFO: namespace kubectl-6454 deletion completed in 6.075133894s

• [SLOW TEST:6.352 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:19.752: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:23:20.236: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Oct  7 18:23:22.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706069400, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706069400, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706069400, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706069400, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:23:25.294: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:23:25.298: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:23:26.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9970" for this suite.
Oct  7 18:23:32.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:32.601: INFO: namespace crd-webhook-9970 deletion completed in 6.07729897s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.863 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:32.616: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7240
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7240
I1007 18:23:32.853782      19 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7240, replica count: 2
Oct  7 18:23:35.904: INFO: Creating new exec pod
I1007 18:23:35.904169      19 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  7 18:23:38.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-7240 execpodw75vh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Oct  7 18:23:39.199: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Oct  7 18:23:39.199: INFO: stdout: ""
Oct  7 18:23:39.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-7240 execpodw75vh -- /bin/sh -x -c nc -zv -t -w 2 10.109.56.176 80'
Oct  7 18:23:39.450: INFO: stderr: "+ nc -zv -t -w 2 10.109.56.176 80\nConnection to 10.109.56.176 80 port [tcp/http] succeeded!\n"
Oct  7 18:23:39.450: INFO: stdout: ""
Oct  7 18:23:39.450: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:23:39.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7240" for this suite.
Oct  7 18:23:45.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:23:45.614: INFO: namespace services-7240 deletion completed in 6.089247655s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.998 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:23:45.616: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-da5af64c-1322-4630-81f7-2d7c750ea2cc in namespace container-probe-5814
Oct  7 18:23:47.828: INFO: Started pod liveness-da5af64c-1322-4630-81f7-2d7c750ea2cc in namespace container-probe-5814
STEP: checking the pod's current state and verifying that restartCount is present
Oct  7 18:23:47.831: INFO: Initial restart count of pod liveness-da5af64c-1322-4630-81f7-2d7c750ea2cc is 0
Oct  7 18:24:03.862: INFO: Restart count of pod container-probe-5814/liveness-da5af64c-1322-4630-81f7-2d7c750ea2cc is now 1 (16.031312699s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:24:03.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5814" for this suite.
Oct  7 18:24:09.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:24:09.961: INFO: namespace container-probe-5814 deletion completed in 6.077001309s

• [SLOW TEST:24.345 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:24:09.962: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Oct  7 18:24:14.177: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:14.179: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  7 18:24:16.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:16.184: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  7 18:24:18.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:18.185: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  7 18:24:20.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:20.185: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  7 18:24:22.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:22.183: INFO: Pod pod-with-poststart-exec-hook still exists
Oct  7 18:24:24.180: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Oct  7 18:24:24.208: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:24:24.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9754" for this suite.
Oct  7 18:24:36.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:24:36.348: INFO: namespace container-lifecycle-hook-9754 deletion completed in 12.077993866s

• [SLOW TEST:26.328 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:24:36.348: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7037
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5a4f4c91-dc08-42e5-aaa2-7724f23fa71d
STEP: Creating a pod to test consume secrets
Oct  7 18:24:36.537: INFO: Waiting up to 5m0s for pod "pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf" in namespace "secrets-7037" to be "success or failure"
Oct  7 18:24:36.539: INFO: Pod "pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.553373ms
Oct  7 18:24:38.543: INFO: Pod "pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005837473s
STEP: Saw pod success
Oct  7 18:24:38.543: INFO: Pod "pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf" satisfied condition "success or failure"
Oct  7 18:24:38.546: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf container secret-env-test: <nil>
STEP: delete the pod
Oct  7 18:24:38.563: INFO: Waiting for pod pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf to disappear
Oct  7 18:24:38.566: INFO: Pod pod-secrets-e4ceea41-7481-414b-ad1a-e40174c35ccf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:24:38.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7037" for this suite.
Oct  7 18:24:44.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:24:44.646: INFO: namespace secrets-7037 deletion completed in 6.07697646s

• [SLOW TEST:8.298 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:24:44.646: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  7 18:24:46.825: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:24:46.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6541" for this suite.
Oct  7 18:24:52.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:24:52.920: INFO: namespace container-runtime-6541 deletion completed in 6.074893282s

• [SLOW TEST:8.274 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:24:52.920: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:24:53.839: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:24:56.876: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:24:56.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3042" for this suite.
Oct  7 18:25:02.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:25:03.041: INFO: namespace webhook-3042 deletion completed in 6.078476484s
STEP: Destroying namespace "webhook-3042-markers" for this suite.
Oct  7 18:25:09.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:25:09.117: INFO: namespace webhook-3042-markers deletion completed in 6.07551396s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.210 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:25:09.131: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:25:09.309: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Oct  7 18:25:09.316: INFO: Number of nodes with available pods: 0
Oct  7 18:25:09.316: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Oct  7 18:25:09.348: INFO: Number of nodes with available pods: 0
Oct  7 18:25:09.348: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:10.352: INFO: Number of nodes with available pods: 0
Oct  7 18:25:10.352: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:11.353: INFO: Number of nodes with available pods: 1
Oct  7 18:25:11.353: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Oct  7 18:25:11.369: INFO: Number of nodes with available pods: 1
Oct  7 18:25:11.369: INFO: Number of running nodes: 0, number of available pods: 1
Oct  7 18:25:12.373: INFO: Number of nodes with available pods: 0
Oct  7 18:25:12.373: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Oct  7 18:25:12.382: INFO: Number of nodes with available pods: 0
Oct  7 18:25:12.382: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:13.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:13.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:14.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:14.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:15.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:15.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:16.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:16.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:17.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:17.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:18.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:18.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:19.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:19.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:20.389: INFO: Number of nodes with available pods: 0
Oct  7 18:25:20.389: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:21.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:21.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:22.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:22.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:23.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:23.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:24.386: INFO: Number of nodes with available pods: 0
Oct  7 18:25:24.386: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:25:25.386: INFO: Number of nodes with available pods: 1
Oct  7 18:25:25.386: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5881, will wait for the garbage collector to delete the pods
Oct  7 18:25:25.452: INFO: Deleting DaemonSet.extensions daemon-set took: 9.118421ms
Oct  7 18:25:25.753: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.26073ms
Oct  7 18:25:33.257: INFO: Number of nodes with available pods: 0
Oct  7 18:25:33.258: INFO: Number of running nodes: 0, number of available pods: 0
Oct  7 18:25:33.261: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5881/daemonsets","resourceVersion":"15284"},"items":null}

Oct  7 18:25:33.264: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5881/pods","resourceVersion":"15284"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:25:33.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5881" for this suite.
Oct  7 18:25:39.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:25:39.359: INFO: namespace daemonsets-5881 deletion completed in 6.072847879s

• [SLOW TEST:30.228 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:25:39.359: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1864
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1864
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct  7 18:25:39.529: INFO: Found 0 stateful pods, waiting for 3
Oct  7 18:25:49.534: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:25:49.534: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:25:49.534: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct  7 18:25:49.560: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Oct  7 18:25:59.612: INFO: Updating stateful set ss2
Oct  7 18:25:59.617: INFO: Waiting for Pod statefulset-1864/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Oct  7 18:26:09.682: INFO: Found 2 stateful pods, waiting for 3
Oct  7 18:26:19.688: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:26:19.688: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:26:19.688: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Oct  7 18:26:19.712: INFO: Updating stateful set ss2
Oct  7 18:26:19.719: INFO: Waiting for Pod statefulset-1864/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  7 18:26:29.747: INFO: Updating stateful set ss2
Oct  7 18:26:29.755: INFO: Waiting for StatefulSet statefulset-1864/ss2 to complete update
Oct  7 18:26:29.755: INFO: Waiting for Pod statefulset-1864/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  7 18:26:39.764: INFO: Waiting for StatefulSet statefulset-1864/ss2 to complete update
Oct  7 18:26:39.765: INFO: Waiting for Pod statefulset-1864/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Oct  7 18:26:49.762: INFO: Waiting for StatefulSet statefulset-1864/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 18:26:59.762: INFO: Deleting all statefulset in ns statefulset-1864
Oct  7 18:26:59.765: INFO: Scaling statefulset ss2 to 0
Oct  7 18:27:19.779: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:27:19.782: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:27:19.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1864" for this suite.
Oct  7 18:27:25.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:27:25.870: INFO: namespace statefulset-1864 deletion completed in 6.072873771s

• [SLOW TEST:106.510 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:27:25.871: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5435
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Oct  7 18:27:26.028: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-832208514 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:27:26.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5435" for this suite.
Oct  7 18:27:32.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:27:32.176: INFO: namespace kubectl-5435 deletion completed in 6.073704677s

• [SLOW TEST:6.305 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:27:32.176: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Oct  7 18:27:32.337: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15837 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  7 18:27:32.337: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15837 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Oct  7 18:27:42.347: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15858 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  7 18:27:42.347: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15858 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Oct  7 18:27:52.357: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15880 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  7 18:27:52.358: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15880 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Oct  7 18:28:02.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15900 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  7 18:28:02.368: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-a 6ce72c93-e102-4f7a-a237-eb0917885714 15900 0 2019-10-07 18:27:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Oct  7 18:28:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-b 070a2894-6cfe-43ea-af9b-baf8472582ae 15920 0 2019-10-07 18:28:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  7 18:28:12.378: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-b 070a2894-6cfe-43ea-af9b-baf8472582ae 15920 0 2019-10-07 18:28:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Oct  7 18:28:22.388: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-b 070a2894-6cfe-43ea-af9b-baf8472582ae 15941 0 2019-10-07 18:28:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  7 18:28:22.388: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8776 /api/v1/namespaces/watch-8776/configmaps/e2e-watch-test-configmap-b 070a2894-6cfe-43ea-af9b-baf8472582ae 15941 0 2019-10-07 18:28:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:28:32.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8776" for this suite.
Oct  7 18:28:38.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:28:38.473: INFO: namespace watch-8776 deletion completed in 6.079002872s

• [SLOW TEST:66.297 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:28:38.474: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5748
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:28:49.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5748" for this suite.
Oct  7 18:28:55.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:28:55.833: INFO: namespace resourcequota-5748 deletion completed in 6.077660626s

• [SLOW TEST:17.359 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:28:55.834: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct  7 18:28:56.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-5789'
Oct  7 18:28:56.431: INFO: stderr: ""
Oct  7 18:28:56.431: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 18:28:56.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:28:56.516: INFO: stderr: ""
Oct  7 18:28:56.516: INFO: stdout: "update-demo-nautilus-qzbpw update-demo-nautilus-rj2mr "
Oct  7 18:28:56.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:28:56.596: INFO: stderr: ""
Oct  7 18:28:56.596: INFO: stdout: ""
Oct  7 18:28:56.596: INFO: update-demo-nautilus-qzbpw is created but not running
Oct  7 18:29:01.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:01.681: INFO: stderr: ""
Oct  7 18:29:01.681: INFO: stdout: "update-demo-nautilus-qzbpw update-demo-nautilus-rj2mr "
Oct  7 18:29:01.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:01.765: INFO: stderr: ""
Oct  7 18:29:01.765: INFO: stdout: "true"
Oct  7 18:29:01.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:01.846: INFO: stderr: ""
Oct  7 18:29:01.846: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:29:01.846: INFO: validating pod update-demo-nautilus-qzbpw
Oct  7 18:29:01.852: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:29:01.852: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:29:01.852: INFO: update-demo-nautilus-qzbpw is verified up and running
Oct  7 18:29:01.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-rj2mr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:01.936: INFO: stderr: ""
Oct  7 18:29:01.936: INFO: stdout: "true"
Oct  7 18:29:01.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-rj2mr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:02.018: INFO: stderr: ""
Oct  7 18:29:02.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:29:02.018: INFO: validating pod update-demo-nautilus-rj2mr
Oct  7 18:29:02.030: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:29:02.030: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:29:02.030: INFO: update-demo-nautilus-rj2mr is verified up and running
STEP: scaling down the replication controller
Oct  7 18:29:02.033: INFO: scanned /root for discovery docs: <nil>
Oct  7 18:29:02.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-5789'
Oct  7 18:29:03.139: INFO: stderr: ""
Oct  7 18:29:03.139: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 18:29:03.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:03.224: INFO: stderr: ""
Oct  7 18:29:03.224: INFO: stdout: "update-demo-nautilus-qzbpw update-demo-nautilus-rj2mr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  7 18:29:08.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:08.308: INFO: stderr: ""
Oct  7 18:29:08.308: INFO: stdout: "update-demo-nautilus-qzbpw update-demo-nautilus-rj2mr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  7 18:29:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:13.394: INFO: stderr: ""
Oct  7 18:29:13.394: INFO: stdout: "update-demo-nautilus-qzbpw update-demo-nautilus-rj2mr "
STEP: Replicas for name=update-demo: expected=1 actual=2
Oct  7 18:29:18.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:18.480: INFO: stderr: ""
Oct  7 18:29:18.480: INFO: stdout: "update-demo-nautilus-qzbpw "
Oct  7 18:29:18.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:18.562: INFO: stderr: ""
Oct  7 18:29:18.562: INFO: stdout: "true"
Oct  7 18:29:18.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:18.641: INFO: stderr: ""
Oct  7 18:29:18.641: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:29:18.641: INFO: validating pod update-demo-nautilus-qzbpw
Oct  7 18:29:18.647: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:29:18.648: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:29:18.648: INFO: update-demo-nautilus-qzbpw is verified up and running
STEP: scaling up the replication controller
Oct  7 18:29:18.650: INFO: scanned /root for discovery docs: <nil>
Oct  7 18:29:18.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-5789'
Oct  7 18:29:19.757: INFO: stderr: ""
Oct  7 18:29:19.757: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 18:29:19.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5789'
Oct  7 18:29:19.840: INFO: stderr: ""
Oct  7 18:29:19.840: INFO: stdout: "update-demo-nautilus-gl8pr update-demo-nautilus-qzbpw "
Oct  7 18:29:19.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-gl8pr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:19.920: INFO: stderr: ""
Oct  7 18:29:19.920: INFO: stdout: "true"
Oct  7 18:29:19.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-gl8pr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:20.001: INFO: stderr: ""
Oct  7 18:29:20.001: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:29:20.001: INFO: validating pod update-demo-nautilus-gl8pr
Oct  7 18:29:20.007: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:29:20.007: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:29:20.007: INFO: update-demo-nautilus-gl8pr is verified up and running
Oct  7 18:29:20.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:20.088: INFO: stderr: ""
Oct  7 18:29:20.088: INFO: stdout: "true"
Oct  7 18:29:20.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-qzbpw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5789'
Oct  7 18:29:20.168: INFO: stderr: ""
Oct  7 18:29:20.168: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:29:20.168: INFO: validating pod update-demo-nautilus-qzbpw
Oct  7 18:29:20.173: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:29:20.173: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:29:20.173: INFO: update-demo-nautilus-qzbpw is verified up and running
STEP: using delete to clean up resources
Oct  7 18:29:20.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-5789'
Oct  7 18:29:20.265: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 18:29:20.265: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  7 18:29:20.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5789'
Oct  7 18:29:20.356: INFO: stderr: "No resources found in kubectl-5789 namespace.\n"
Oct  7 18:29:20.356: INFO: stdout: ""
Oct  7 18:29:20.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -l name=update-demo --namespace=kubectl-5789 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  7 18:29:20.440: INFO: stderr: ""
Oct  7 18:29:20.440: INFO: stdout: "update-demo-nautilus-gl8pr\nupdate-demo-nautilus-qzbpw\n"
Oct  7 18:29:20.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-5789'
Oct  7 18:29:21.049: INFO: stderr: "No resources found in kubectl-5789 namespace.\n"
Oct  7 18:29:21.049: INFO: stdout: ""
Oct  7 18:29:21.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -l name=update-demo --namespace=kubectl-5789 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  7 18:29:21.134: INFO: stderr: ""
Oct  7 18:29:21.134: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:29:21.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5789" for this suite.
Oct  7 18:29:49.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:29:49.225: INFO: namespace kubectl-5789 deletion completed in 28.086997722s

• [SLOW TEST:53.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:29:49.227: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 18:29:49.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2844'
Oct  7 18:29:49.492: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  7 18:29:49.492: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Oct  7 18:29:49.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete jobs e2e-test-httpd-job --namespace=kubectl-2844'
Oct  7 18:29:49.593: INFO: stderr: ""
Oct  7 18:29:49.593: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:29:49.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2844" for this suite.
Oct  7 18:29:55.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:29:55.682: INFO: namespace kubectl-2844 deletion completed in 6.084217668s

• [SLOW TEST:6.455 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:29:55.684: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:30:01.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8397" for this suite.
Oct  7 18:30:07.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:30:07.481: INFO: namespace watch-8397 deletion completed in 6.172322707s

• [SLOW TEST:11.797 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:30:07.481: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2822
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2822
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2822
Oct  7 18:30:07.678: INFO: Found 0 stateful pods, waiting for 1
Oct  7 18:30:17.682: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Oct  7 18:30:17.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:30:17.986: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:30:17.986: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:30:17.986: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 18:30:17.989: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Oct  7 18:30:28.028: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 18:30:28.028: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:30:28.046: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:30:28.046: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:18 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:30:28.046: INFO: 
Oct  7 18:30:28.046: INFO: StatefulSet ss has not reached scale 3, at 1
Oct  7 18:30:29.051: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992898384s
Oct  7 18:30:30.055: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988063173s
Oct  7 18:30:31.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983658472s
Oct  7 18:30:32.064: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979227348s
Oct  7 18:30:33.068: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975231904s
Oct  7 18:30:34.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971039288s
Oct  7 18:30:35.081: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.962587274s
Oct  7 18:30:36.085: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.958116936s
Oct  7 18:30:37.090: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.737681ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2822
Oct  7 18:30:38.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:30:39.113: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 18:30:39.113: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 18:30:39.113: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 18:30:39.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:30:39.385: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  7 18:30:39.385: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 18:30:39.385: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 18:30:39.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:30:39.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Oct  7 18:30:39.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 18:30:39.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 18:30:39.657: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Oct  7 18:30:49.662: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:30:49.662: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:30:49.662: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Oct  7 18:30:49.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:30:49.937: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:30:49.937: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:30:49.937: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 18:30:49.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:30:50.273: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:30:50.273: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:30:50.273: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 18:30:50.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:30:50.583: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:30:50.583: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:30:50.583: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 18:30:50.583: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:30:50.587: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Oct  7 18:31:00.596: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 18:31:00.596: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 18:31:00.596: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Oct  7 18:31:00.608: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:00.609: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:00.609: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:00.609: INFO: ss-2  talos-v020-gcp-workers-654f4446bf-lrncj  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:00.609: INFO: 
Oct  7 18:31:00.609: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  7 18:31:01.613: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:01.613: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:01.613: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:01.613: INFO: ss-2  talos-v020-gcp-workers-654f4446bf-lrncj  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:01.613: INFO: 
Oct  7 18:31:01.613: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  7 18:31:02.618: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:02.618: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:02.618: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:02.618: INFO: ss-2  talos-v020-gcp-workers-654f4446bf-lrncj  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:02.618: INFO: 
Oct  7 18:31:02.618: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  7 18:31:03.622: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:03.622: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:03.622: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:03.622: INFO: ss-2  talos-v020-gcp-workers-654f4446bf-lrncj  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:03.622: INFO: 
Oct  7 18:31:03.622: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  7 18:31:04.626: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:04.626: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:04.626: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:04.626: INFO: ss-2  talos-v020-gcp-workers-654f4446bf-lrncj  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:51 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:04.626: INFO: 
Oct  7 18:31:04.626: INFO: StatefulSet ss has not reached scale 0, at 3
Oct  7 18:31:05.631: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:05.631: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:05.631: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:05.631: INFO: 
Oct  7 18:31:05.631: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  7 18:31:06.635: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:06.635: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:06.635: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:06.635: INFO: 
Oct  7 18:31:06.635: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  7 18:31:07.640: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:07.640: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:07.640: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:07.640: INFO: 
Oct  7 18:31:07.640: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  7 18:31:08.644: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:08.644: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:08.644: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:08.644: INFO: 
Oct  7 18:31:08.644: INFO: StatefulSet ss has not reached scale 0, at 2
Oct  7 18:31:09.649: INFO: POD   NODE                                     PHASE    GRACE  CONDITIONS
Oct  7 18:31:09.649: INFO: ss-0  talos-v020-gcp-workers-654f4446bf-ns4sr  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:07 +0000 UTC  }]
Oct  7 18:31:09.649: INFO: ss-1  talos-v020-gcp-workers-654f4446bf-clj9s  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:50 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-10-07 18:30:28 +0000 UTC  }]
Oct  7 18:31:09.649: INFO: 
Oct  7 18:31:09.649: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2822
Oct  7 18:31:10.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:31:10.770: INFO: rc: 1
Oct  7 18:31:10.770: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc003623950 exit status 1 <nil> <nil> true [0xc00218adf0 0xc00218ae20 0xc00218ae68] [0xc00218adf0 0xc00218ae20 0xc00218ae68] [0xc00218ae10 0xc00218ae58] [0x10ef310 0x10ef310] 0xc00362c600 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Oct  7 18:31:20.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:31:20.855: INFO: rc: 1
Oct  7 18:31:20.855: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003bfedb0 exit status 1 <nil> <nil> true [0xc007cff8d0 0xc007cff8e8 0xc007cff900] [0xc007cff8d0 0xc007cff8e8 0xc007cff900] [0xc007cff8e0 0xc007cff8f8] [0x10ef310 0x10ef310] 0xc003cac120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:31:30.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:31:30.939: INFO: rc: 1
Oct  7 18:31:30.939: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e300 exit status 1 <nil> <nil> true [0xc0025d8008 0xc0025d8020 0xc0025d8040] [0xc0025d8008 0xc0025d8020 0xc0025d8040] [0xc0025d8018 0xc0025d8030] [0x10ef310 0x10ef310] 0xc0038422a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:31:40.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:31:41.022: INFO: rc: 1
Oct  7 18:31:41.023: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e660 exit status 1 <nil> <nil> true [0xc0025d8048 0xc0025d8060 0xc0025d8078] [0xc0025d8048 0xc0025d8060 0xc0025d8078] [0xc0025d8058 0xc0025d8070] [0x10ef310 0x10ef310] 0xc003842600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:31:51.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:31:51.127: INFO: rc: 1
Oct  7 18:31:51.127: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4390 exit status 1 <nil> <nil> true [0xc001ac8168 0xc001ac8658 0xc001ac92f8] [0xc001ac8168 0xc001ac8658 0xc001ac92f8] [0xc001ac8588 0xc001ac8ab8] [0x10ef310 0x10ef310] 0xc00219e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:01.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:01.215: INFO: rc: 1
Oct  7 18:32:01.216: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207eae0 exit status 1 <nil> <nil> true [0xc0025d80b0 0xc0025d80c8 0xc0025d80e0] [0xc0025d80b0 0xc0025d80c8 0xc0025d80e0] [0xc0025d80c0 0xc0025d80d8] [0x10ef310 0x10ef310] 0xc003842b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:11.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:11.302: INFO: rc: 1
Oct  7 18:32:11.303: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207ee10 exit status 1 <nil> <nil> true [0xc0025d80e8 0xc0025d8100 0xc0025d8118] [0xc0025d80e8 0xc0025d8100 0xc0025d8118] [0xc0025d80f8 0xc0025d8110] [0x10ef310 0x10ef310] 0xc003842ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:21.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:21.410: INFO: rc: 1
Oct  7 18:32:21.410: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f170 exit status 1 <nil> <nil> true [0xc0025d8120 0xc0025d8138 0xc0025d8150] [0xc0025d8120 0xc0025d8138 0xc0025d8150] [0xc0025d8130 0xc0025d8148] [0x10ef310 0x10ef310] 0xc003843200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:31.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:31.494: INFO: rc: 1
Oct  7 18:32:31.494: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f4d0 exit status 1 <nil> <nil> true [0xc0025d8158 0xc0025d8170 0xc0025d8188] [0xc0025d8158 0xc0025d8170 0xc0025d8188] [0xc0025d8168 0xc0025d8180] [0x10ef310 0x10ef310] 0xc003843560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:41.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:41.580: INFO: rc: 1
Oct  7 18:32:41.580: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4720 exit status 1 <nil> <nil> true [0xc001ac9580 0xc001ac9b78 0xc001ac9fd0] [0xc001ac9580 0xc001ac9b78 0xc001ac9fd0] [0xc001ac9b40 0xc001ac9e80] [0x10ef310 0x10ef310] 0xc00219e600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:32:51.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:32:51.668: INFO: rc: 1
Oct  7 18:32:51.668: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4a80 exit status 1 <nil> <nil> true [0xc001068788 0xc001068f58 0xc001069370] [0xc001068788 0xc001068f58 0xc001069370] [0xc001068ca0 0xc001069228] [0x10ef310 0x10ef310] 0xc00219e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:01.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:01.754: INFO: rc: 1
Oct  7 18:33:01.754: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f890 exit status 1 <nil> <nil> true [0xc0025d8190 0xc0025d81a8 0xc0025d81c0] [0xc0025d8190 0xc0025d81a8 0xc0025d81c0] [0xc0025d81a0 0xc0025d81b8] [0x10ef310 0x10ef310] 0xc0038438c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:11.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:11.839: INFO: rc: 1
Oct  7 18:33:11.839: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4e40 exit status 1 <nil> <nil> true [0xc001069430 0xc001069548 0xc001069ee8] [0xc001069430 0xc001069548 0xc001069ee8] [0xc0010694d0 0xc001069b20] [0x10ef310 0x10ef310] 0xc00219ed20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:21.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:21.928: INFO: rc: 1
Oct  7 18:33:21.928: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df51a0 exit status 1 <nil> <nil> true [0xc000736d40 0xc000737210 0xc0007379a8] [0xc000736d40 0xc000737210 0xc0007379a8] [0xc000736ff0 0xc0007376d8] [0x10ef310 0x10ef310] 0xc00219f080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:31.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:32.014: INFO: rc: 1
Oct  7 18:33:32.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e330 exit status 1 <nil> <nil> true [0xc001068a78 0xc0010690a0 0xc001069430] [0xc001068a78 0xc0010690a0 0xc001069430] [0xc001068f58 0xc001069370] [0x10ef310 0x10ef310] 0xc0038422a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:42.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:42.100: INFO: rc: 1
Oct  7 18:33:42.101: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e690 exit status 1 <nil> <nil> true [0xc0010694a0 0xc0010698d0 0xc001ac8168] [0xc0010694a0 0xc0010698d0 0xc001ac8168] [0xc001069548 0xc001069ee8] [0x10ef310 0x10ef310] 0xc003842600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:33:52.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:33:52.189: INFO: rc: 1
Oct  7 18:33:52.189: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e9f0 exit status 1 <nil> <nil> true [0xc001ac83d0 0xc001ac8a40 0xc001ac9580] [0xc001ac83d0 0xc001ac8a40 0xc001ac9580] [0xc001ac8658 0xc001ac92f8] [0x10ef310 0x10ef310] 0xc003842a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:02.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:02.278: INFO: rc: 1
Oct  7 18:34:02.278: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207ed80 exit status 1 <nil> <nil> true [0xc001ac98f8 0xc001ac9d48 0xc0025d8000] [0xc001ac98f8 0xc001ac9d48 0xc0025d8000] [0xc001ac9b78 0xc001ac9fd0] [0x10ef310 0x10ef310] 0xc003842d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:12.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:12.367: INFO: rc: 1
Oct  7 18:34:12.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4420 exit status 1 <nil> <nil> true [0xc000736d40 0xc000737210 0xc0007379a8] [0xc000736d40 0xc000737210 0xc0007379a8] [0xc000736ff0 0xc0007376d8] [0x10ef310 0x10ef310] 0xc00219e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:22.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:22.456: INFO: rc: 1
Oct  7 18:34:22.456: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df47b0 exit status 1 <nil> <nil> true [0xc000737b20 0xc000010348 0xc000158340] [0xc000737b20 0xc000010348 0xc000158340] [0xc000737e68 0xc000158218] [0x10ef310 0x10ef310] 0xc00219e600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:32.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:32.541: INFO: rc: 1
Oct  7 18:34:32.541: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4b40 exit status 1 <nil> <nil> true [0xc000158c68 0xc002cbe080 0xc002cbe190] [0xc000158c68 0xc002cbe080 0xc002cbe190] [0xc000159748 0xc002cbe120] [0x10ef310 0x10ef310] 0xc00219e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:42.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:42.627: INFO: rc: 1
Oct  7 18:34:42.627: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f140 exit status 1 <nil> <nil> true [0xc0025d8008 0xc0025d8020 0xc0025d8040] [0xc0025d8008 0xc0025d8020 0xc0025d8040] [0xc0025d8018 0xc0025d8030] [0x10ef310 0x10ef310] 0xc0038430e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:34:52.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:34:52.714: INFO: rc: 1
Oct  7 18:34:52.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f4a0 exit status 1 <nil> <nil> true [0xc0025d8048 0xc0025d8060 0xc0025d8078] [0xc0025d8048 0xc0025d8060 0xc0025d8078] [0xc0025d8058 0xc0025d8070] [0x10ef310 0x10ef310] 0xc003843440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:02.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:02.808: INFO: rc: 1
Oct  7 18:35:02.808: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4fc0 exit status 1 <nil> <nil> true [0xc002cbe1b8 0xc002cbe3b8 0xc002cbe540] [0xc002cbe1b8 0xc002cbe3b8 0xc002cbe540] [0xc002cbe2c0 0xc002cbe520] [0x10ef310 0x10ef310] 0xc00219ed20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:12.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:12.916: INFO: rc: 1
Oct  7 18:35:12.916: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207f860 exit status 1 <nil> <nil> true [0xc0025d8080 0xc0025d8098 0xc0025d80b0] [0xc0025d8080 0xc0025d8098 0xc0025d80b0] [0xc0025d8090 0xc0025d80a8] [0x10ef310 0x10ef310] 0xc0038437a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:22.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:23.004: INFO: rc: 1
Oct  7 18:35:23.004: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207fbc0 exit status 1 <nil> <nil> true [0xc0025d80b8 0xc0025d80d0 0xc0025d80e8] [0xc0025d80b8 0xc0025d80d0 0xc0025d80e8] [0xc0025d80c8 0xc0025d80e0] [0x10ef310 0x10ef310] 0xc003843b00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:33.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:33.089: INFO: rc: 1
Oct  7 18:35:33.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4360 exit status 1 <nil> <nil> true [0xc000736f30 0xc0007374d0 0xc000737b20] [0xc000736f30 0xc0007374d0 0xc000737b20] [0xc000737210 0xc0007379a8] [0x10ef310 0x10ef310] 0xc00219e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:43.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:43.175: INFO: rc: 1
Oct  7 18:35:43.175: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df46f0 exit status 1 <nil> <nil> true [0xc000737bf0 0xc001ac83d0 0xc001ac8a40] [0xc000737bf0 0xc001ac83d0 0xc001ac8a40] [0xc001ac8168 0xc001ac8658] [0x10ef310 0x10ef310] 0xc00219e600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:35:53.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:35:53.258: INFO: rc: 1
Oct  7 18:35:53.258: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00207e360 exit status 1 <nil> <nil> true [0xc001068788 0xc001068f58 0xc001069370] [0xc001068788 0xc001068f58 0xc001069370] [0xc001068ca0 0xc001069228] [0x10ef310 0x10ef310] 0xc0038422a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:36:03.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:36:03.350: INFO: rc: 1
Oct  7 18:36:03.350: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001df4ae0 exit status 1 <nil> <nil> true [0xc001ac8ab8 0xc001ac98f8 0xc001ac9d48] [0xc001ac8ab8 0xc001ac98f8 0xc001ac9d48] [0xc001ac9580 0xc001ac9b78] [0x10ef310 0x10ef310] 0xc00219e9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Oct  7 18:36:13.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-2822 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:36:13.439: INFO: rc: 1
Oct  7 18:36:13.439: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Oct  7 18:36:13.439: INFO: Scaling statefulset ss to 0
Oct  7 18:36:13.450: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 18:36:13.452: INFO: Deleting all statefulset in ns statefulset-2822
Oct  7 18:36:13.455: INFO: Scaling statefulset ss to 0
Oct  7 18:36:13.464: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:36:13.467: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:36:13.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2822" for this suite.
Oct  7 18:36:19.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:36:19.580: INFO: namespace statefulset-2822 deletion completed in 6.096251705s

• [SLOW TEST:372.066 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:36:19.581: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5714
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-a1b41eaa-4b87-42bc-bbe7-44b129220ee1
STEP: Creating secret with name s-test-opt-upd-864fc797-3929-4cf1-a13a-5fe7b4d1f9c0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-a1b41eaa-4b87-42bc-bbe7-44b129220ee1
STEP: Updating secret s-test-opt-upd-864fc797-3929-4cf1-a13a-5fe7b4d1f9c0
STEP: Creating secret with name s-test-opt-create-c7dd816e-99e1-4e84-9d68-44fb3bafee1a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:37:52.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5714" for this suite.
Oct  7 18:38:04.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:04.318: INFO: namespace secrets-5714 deletion completed in 12.098788819s

• [SLOW TEST:104.736 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:04.318: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Oct  7 18:38:04.493: INFO: Waiting up to 5m0s for pod "pod-094fa5c7-d111-41bf-afb6-aa5792189554" in namespace "emptydir-3" to be "success or failure"
Oct  7 18:38:04.496: INFO: Pod "pod-094fa5c7-d111-41bf-afb6-aa5792189554": Phase="Pending", Reason="", readiness=false. Elapsed: 3.015044ms
Oct  7 18:38:06.500: INFO: Pod "pod-094fa5c7-d111-41bf-afb6-aa5792189554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006685302s
STEP: Saw pod success
Oct  7 18:38:06.500: INFO: Pod "pod-094fa5c7-d111-41bf-afb6-aa5792189554" satisfied condition "success or failure"
Oct  7 18:38:06.503: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-094fa5c7-d111-41bf-afb6-aa5792189554 container test-container: <nil>
STEP: delete the pod
Oct  7 18:38:06.538: INFO: Waiting for pod pod-094fa5c7-d111-41bf-afb6-aa5792189554 to disappear
Oct  7 18:38:06.541: INFO: Pod pod-094fa5c7-d111-41bf-afb6-aa5792189554 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:06.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3" for this suite.
Oct  7 18:38:12.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:12.637: INFO: namespace emptydir-3 deletion completed in 6.090928768s

• [SLOW TEST:8.319 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:12.639: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3379
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:38:12.810: INFO: (0) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 6.627167ms)
Oct  7 18:38:12.815: INFO: (1) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.767721ms)
Oct  7 18:38:12.820: INFO: (2) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.192272ms)
Oct  7 18:38:12.823: INFO: (3) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.700996ms)
Oct  7 18:38:12.827: INFO: (4) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.844884ms)
Oct  7 18:38:12.831: INFO: (5) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.848372ms)
Oct  7 18:38:12.835: INFO: (6) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.617112ms)
Oct  7 18:38:12.839: INFO: (7) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.826919ms)
Oct  7 18:38:12.843: INFO: (8) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.217608ms)
Oct  7 18:38:12.847: INFO: (9) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.081306ms)
Oct  7 18:38:12.852: INFO: (10) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.086789ms)
Oct  7 18:38:12.856: INFO: (11) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.970339ms)
Oct  7 18:38:12.860: INFO: (12) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.009804ms)
Oct  7 18:38:12.864: INFO: (13) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.94642ms)
Oct  7 18:38:12.868: INFO: (14) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.123275ms)
Oct  7 18:38:12.873: INFO: (15) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.64526ms)
Oct  7 18:38:12.877: INFO: (16) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.274774ms)
Oct  7 18:38:12.881: INFO: (17) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.203118ms)
Oct  7 18:38:12.885: INFO: (18) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.88731ms)
Oct  7 18:38:12.889: INFO: (19) /api/v1/nodes/talos-v020-gcp-workers-654f4446bf-clj9s/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.229379ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:12.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3379" for this suite.
Oct  7 18:38:18.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:19.014: INFO: namespace proxy-3379 deletion completed in 6.120432001s

• [SLOW TEST:6.376 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:19.015: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Oct  7 18:38:21.225: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-832208514 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Oct  7 18:38:26.343: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:26.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5502" for this suite.
Oct  7 18:38:32.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:32.433: INFO: namespace pods-5502 deletion completed in 6.082373578s

• [SLOW TEST:13.418 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:32.434: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-3c6b169e-3497-476a-a5d2-faf6c9008492
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:32.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9463" for this suite.
Oct  7 18:38:38.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:38.700: INFO: namespace configmap-9463 deletion completed in 6.090924031s

• [SLOW TEST:6.267 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:38.704: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:38:38.920: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777" in namespace "downward-api-4052" to be "success or failure"
Oct  7 18:38:38.923: INFO: Pod "downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777": Phase="Pending", Reason="", readiness=false. Elapsed: 3.553567ms
Oct  7 18:38:40.927: INFO: Pod "downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007429442s
STEP: Saw pod success
Oct  7 18:38:40.927: INFO: Pod "downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777" satisfied condition "success or failure"
Oct  7 18:38:40.931: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777 container client-container: <nil>
STEP: delete the pod
Oct  7 18:38:40.956: INFO: Waiting for pod downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777 to disappear
Oct  7 18:38:40.959: INFO: Pod downwardapi-volume-e987c290-950a-46ae-a102-6a7271b91777 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:40.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4052" for this suite.
Oct  7 18:38:46.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:47.053: INFO: namespace downward-api-4052 deletion completed in 6.089880257s

• [SLOW TEST:8.349 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:47.053: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-7828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:38:48.518: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:38:51.708: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:38:51.712: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:38:52.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7828" for this suite.
Oct  7 18:38:58.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:38:59.041: INFO: namespace crd-webhook-7828 deletion completed in 6.091695238s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.001 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:38:59.057: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:39:01.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8636" for this suite.
Oct  7 18:39:45.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:39:45.350: INFO: namespace kubelet-test-8636 deletion completed in 44.090930574s

• [SLOW TEST:46.294 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:39:45.351: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:39:45.521: INFO: Creating ReplicaSet my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa
Oct  7 18:39:45.532: INFO: Pod name my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa: Found 0 pods out of 1
Oct  7 18:39:50.536: INFO: Pod name my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa: Found 1 pods out of 1
Oct  7 18:39:50.537: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa" is running
Oct  7 18:39:50.540: INFO: Pod "my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa-2sbd6" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 18:39:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 18:39:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 18:39:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 18:39:45 +0000 UTC Reason: Message:}])
Oct  7 18:39:50.540: INFO: Trying to dial the pod
Oct  7 18:39:55.553: INFO: Controller my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa: Got expected result from replica 1 [my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa-2sbd6]: "my-hostname-basic-166e15e0-7c06-4fb6-ac65-746958b980aa-2sbd6", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:39:55.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6603" for this suite.
Oct  7 18:40:01.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:40:01.639: INFO: namespace replicaset-6603 deletion completed in 6.080471174s

• [SLOW TEST:16.288 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:40:01.640: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2614
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Oct  7 18:40:01.833: INFO: Waiting up to 5m0s for pod "pod-cb379f24-9d60-4796-8953-08c1e02f5602" in namespace "emptydir-2614" to be "success or failure"
Oct  7 18:40:01.836: INFO: Pod "pod-cb379f24-9d60-4796-8953-08c1e02f5602": Phase="Pending", Reason="", readiness=false. Elapsed: 3.05982ms
Oct  7 18:40:03.840: INFO: Pod "pod-cb379f24-9d60-4796-8953-08c1e02f5602": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006390936s
STEP: Saw pod success
Oct  7 18:40:03.840: INFO: Pod "pod-cb379f24-9d60-4796-8953-08c1e02f5602" satisfied condition "success or failure"
Oct  7 18:40:03.843: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-cb379f24-9d60-4796-8953-08c1e02f5602 container test-container: <nil>
STEP: delete the pod
Oct  7 18:40:03.861: INFO: Waiting for pod pod-cb379f24-9d60-4796-8953-08c1e02f5602 to disappear
Oct  7 18:40:03.864: INFO: Pod pod-cb379f24-9d60-4796-8953-08c1e02f5602 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:40:03.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2614" for this suite.
Oct  7 18:40:09.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:40:09.949: INFO: namespace emptydir-2614 deletion completed in 6.080558802s

• [SLOW TEST:8.310 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:40:09.950: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8578
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Oct  7 18:40:10.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8578 -- logs-generator --log-lines-total 100 --run-duration 20s'
Oct  7 18:40:10.234: INFO: stderr: ""
Oct  7 18:40:10.234: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Oct  7 18:40:10.234: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Oct  7 18:40:10.234: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8578" to be "running and ready, or succeeded"
Oct  7 18:40:10.245: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.12188ms
Oct  7 18:40:12.249: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.014060275s
Oct  7 18:40:12.249: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Oct  7 18:40:12.249: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Oct  7 18:40:12.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578'
Oct  7 18:40:12.358: INFO: stderr: ""
Oct  7 18:40:12.358: INFO: stdout: "I1007 18:40:11.042703       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/5s4 378\nI1007 18:40:11.242863       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/swq 516\nI1007 18:40:11.442889       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/9t5 449\nI1007 18:40:11.642894       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jw67 362\nI1007 18:40:11.842910       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/h74w 502\nI1007 18:40:12.042900       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/697n 429\nI1007 18:40:12.242890       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/wg6 525\n"
STEP: limiting log lines
Oct  7 18:40:12.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578 --tail=1'
Oct  7 18:40:12.455: INFO: stderr: ""
Oct  7 18:40:12.455: INFO: stdout: "I1007 18:40:12.442956       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/lgfs 493\n"
STEP: limiting log bytes
Oct  7 18:40:12.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578 --limit-bytes=1'
Oct  7 18:40:12.566: INFO: stderr: ""
Oct  7 18:40:12.566: INFO: stdout: "I"
STEP: exposing timestamps
Oct  7 18:40:12.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578 --tail=1 --timestamps'
Oct  7 18:40:12.662: INFO: stderr: ""
Oct  7 18:40:12.662: INFO: stdout: "2019-10-07T18:40:12.643027716Z I1007 18:40:12.642867       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/fwj 481\n"
STEP: restricting to a time range
Oct  7 18:40:15.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578 --since=1s'
Oct  7 18:40:15.257: INFO: stderr: ""
Oct  7 18:40:15.257: INFO: stdout: "I1007 18:40:14.442861       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/v8x 340\nI1007 18:40:14.642907       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/6zg 349\nI1007 18:40:14.842899       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/mtfw 358\nI1007 18:40:15.042899       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/f99 507\nI1007 18:40:15.242847       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/pzrc 273\n"
Oct  7 18:40:15.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 logs logs-generator logs-generator --namespace=kubectl-8578 --since=24h'
Oct  7 18:40:15.358: INFO: stderr: ""
Oct  7 18:40:15.358: INFO: stdout: "I1007 18:40:11.042703       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/5s4 378\nI1007 18:40:11.242863       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/swq 516\nI1007 18:40:11.442889       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/9t5 449\nI1007 18:40:11.642894       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jw67 362\nI1007 18:40:11.842910       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/h74w 502\nI1007 18:40:12.042900       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/697n 429\nI1007 18:40:12.242890       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/wg6 525\nI1007 18:40:12.442956       1 logs_generator.go:76] 7 POST /api/v1/namespaces/kube-system/pods/lgfs 493\nI1007 18:40:12.642867       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/fwj 481\nI1007 18:40:12.842846       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/kpx 585\nI1007 18:40:13.042922       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/m57 449\nI1007 18:40:13.242883       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/48d 411\nI1007 18:40:13.442914       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/hpr 461\nI1007 18:40:13.642925       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/m89 474\nI1007 18:40:13.842890       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/xkdr 439\nI1007 18:40:14.042911       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/8wh7 460\nI1007 18:40:14.242909       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/zjqx 494\nI1007 18:40:14.442861       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/v8x 340\nI1007 18:40:14.642907       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/6zg 349\nI1007 18:40:14.842899       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/mtfw 358\nI1007 18:40:15.042899       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/f99 507\nI1007 18:40:15.242847       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/pzrc 273\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Oct  7 18:40:15.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete pod logs-generator --namespace=kubectl-8578'
Oct  7 18:40:24.067: INFO: stderr: ""
Oct  7 18:40:24.067: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:40:24.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8578" for this suite.
Oct  7 18:40:30.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:40:30.159: INFO: namespace kubectl-8578 deletion completed in 6.087428269s

• [SLOW TEST:20.209 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:40:30.159: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:40:32.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1143" for this suite.
Oct  7 18:40:40.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:40:40.440: INFO: namespace containers-1143 deletion completed in 8.090459422s

• [SLOW TEST:10.281 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:40:40.441: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-knv5
STEP: Creating a pod to test atomic-volume-subpath
Oct  7 18:40:40.623: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-knv5" in namespace "subpath-3582" to be "success or failure"
Oct  7 18:40:40.626: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.330757ms
Oct  7 18:40:42.630: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 2.00719875s
Oct  7 18:40:44.634: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 4.011330578s
Oct  7 18:40:46.638: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 6.015216504s
Oct  7 18:40:48.642: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 8.019119543s
Oct  7 18:40:50.645: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 10.022922351s
Oct  7 18:40:52.650: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 12.026949319s
Oct  7 18:40:54.654: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 14.03101642s
Oct  7 18:40:56.657: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 16.03453005s
Oct  7 18:40:58.661: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 18.038607898s
Oct  7 18:41:00.665: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Running", Reason="", readiness=true. Elapsed: 20.042218684s
Oct  7 18:41:02.669: INFO: Pod "pod-subpath-test-configmap-knv5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.046098522s
STEP: Saw pod success
Oct  7 18:41:02.669: INFO: Pod "pod-subpath-test-configmap-knv5" satisfied condition "success or failure"
Oct  7 18:41:02.672: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-subpath-test-configmap-knv5 container test-container-subpath-configmap-knv5: <nil>
STEP: delete the pod
Oct  7 18:41:02.696: INFO: Waiting for pod pod-subpath-test-configmap-knv5 to disappear
Oct  7 18:41:02.699: INFO: Pod pod-subpath-test-configmap-knv5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-knv5
Oct  7 18:41:02.699: INFO: Deleting pod "pod-subpath-test-configmap-knv5" in namespace "subpath-3582"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:41:02.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3582" for this suite.
Oct  7 18:41:08.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:41:08.787: INFO: namespace subpath-3582 deletion completed in 6.081449151s

• [SLOW TEST:28.347 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:41:08.788: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:41:09.010: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81" in namespace "downward-api-1590" to be "success or failure"
Oct  7 18:41:09.014: INFO: Pod "downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81": Phase="Pending", Reason="", readiness=false. Elapsed: 3.632526ms
Oct  7 18:41:11.018: INFO: Pod "downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007648019s
STEP: Saw pod success
Oct  7 18:41:11.018: INFO: Pod "downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81" satisfied condition "success or failure"
Oct  7 18:41:11.021: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81 container client-container: <nil>
STEP: delete the pod
Oct  7 18:41:11.043: INFO: Waiting for pod downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81 to disappear
Oct  7 18:41:11.045: INFO: Pod downwardapi-volume-3d01347a-087c-418c-aa5a-0c28936f7d81 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:41:11.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1590" for this suite.
Oct  7 18:41:17.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:41:17.138: INFO: namespace downward-api-1590 deletion completed in 6.08863978s

• [SLOW TEST:8.350 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:41:17.138: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1126
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  7 18:41:17.375: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:17.375: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:17.375: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:17.379: INFO: Number of nodes with available pods: 0
Oct  7 18:41:17.379: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:41:18.383: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:18.383: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:18.384: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:18.387: INFO: Number of nodes with available pods: 0
Oct  7 18:41:18.387: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 18:41:19.384: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.384: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.384: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.388: INFO: Number of nodes with available pods: 3
Oct  7 18:41:19.388: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Oct  7 18:41:19.425: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.425: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.425: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:19.430: INFO: Number of nodes with available pods: 2
Oct  7 18:41:19.430: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:41:20.434: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:20.435: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:20.435: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:20.438: INFO: Number of nodes with available pods: 2
Oct  7 18:41:20.438: INFO: Node talos-v020-gcp-workers-654f4446bf-lrncj is running more than one daemon pod
Oct  7 18:41:21.435: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:21.435: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:21.435: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 18:41:21.438: INFO: Number of nodes with available pods: 3
Oct  7 18:41:21.438: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1126, will wait for the garbage collector to delete the pods
Oct  7 18:41:21.506: INFO: Deleting DaemonSet.extensions daemon-set took: 8.787374ms
Oct  7 18:41:21.807: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.305271ms
Oct  7 18:41:35.110: INFO: Number of nodes with available pods: 0
Oct  7 18:41:35.110: INFO: Number of running nodes: 0, number of available pods: 0
Oct  7 18:41:35.113: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1126/daemonsets","resourceVersion":"18478"},"items":null}

Oct  7 18:41:35.115: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1126/pods","resourceVersion":"18478"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:41:35.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1126" for this suite.
Oct  7 18:41:41.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:41:41.205: INFO: namespace daemonsets-1126 deletion completed in 6.07476995s

• [SLOW TEST:24.067 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:41:41.207: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:41:43.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6990" for this suite.
Oct  7 18:42:27.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:42:27.477: INFO: namespace kubelet-test-6990 deletion completed in 44.078466024s

• [SLOW TEST:46.271 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:42:27.477: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Oct  7 18:42:27.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-8188'
Oct  7 18:42:28.589: INFO: stderr: ""
Oct  7 18:42:28.589: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 18:42:28.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8188'
Oct  7 18:42:28.694: INFO: stderr: ""
Oct  7 18:42:28.694: INFO: stdout: "update-demo-nautilus-4c4rh update-demo-nautilus-m5dd6 "
Oct  7 18:42:28.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-4c4rh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8188'
Oct  7 18:42:28.788: INFO: stderr: ""
Oct  7 18:42:28.788: INFO: stdout: ""
Oct  7 18:42:28.788: INFO: update-demo-nautilus-4c4rh is created but not running
Oct  7 18:42:33.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8188'
Oct  7 18:42:33.875: INFO: stderr: ""
Oct  7 18:42:33.875: INFO: stdout: "update-demo-nautilus-4c4rh update-demo-nautilus-m5dd6 "
Oct  7 18:42:33.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-4c4rh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8188'
Oct  7 18:42:33.959: INFO: stderr: ""
Oct  7 18:42:33.959: INFO: stdout: "true"
Oct  7 18:42:33.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-4c4rh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8188'
Oct  7 18:42:34.040: INFO: stderr: ""
Oct  7 18:42:34.040: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:42:34.041: INFO: validating pod update-demo-nautilus-4c4rh
Oct  7 18:42:34.047: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:42:34.047: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:42:34.047: INFO: update-demo-nautilus-4c4rh is verified up and running
Oct  7 18:42:34.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-m5dd6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8188'
Oct  7 18:42:34.127: INFO: stderr: ""
Oct  7 18:42:34.127: INFO: stdout: "true"
Oct  7 18:42:34.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-m5dd6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8188'
Oct  7 18:42:34.211: INFO: stderr: ""
Oct  7 18:42:34.211: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 18:42:34.211: INFO: validating pod update-demo-nautilus-m5dd6
Oct  7 18:42:34.217: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 18:42:34.217: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 18:42:34.217: INFO: update-demo-nautilus-m5dd6 is verified up and running
STEP: using delete to clean up resources
Oct  7 18:42:34.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-8188'
Oct  7 18:42:34.303: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 18:42:34.303: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Oct  7 18:42:34.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8188'
Oct  7 18:42:34.395: INFO: stderr: "No resources found in kubectl-8188 namespace.\n"
Oct  7 18:42:34.395: INFO: stdout: ""
Oct  7 18:42:34.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -l name=update-demo --namespace=kubectl-8188 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  7 18:42:34.483: INFO: stderr: ""
Oct  7 18:42:34.483: INFO: stdout: "update-demo-nautilus-4c4rh\nupdate-demo-nautilus-m5dd6\n"
Oct  7 18:42:34.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8188'
Oct  7 18:42:35.069: INFO: stderr: "No resources found in kubectl-8188 namespace.\n"
Oct  7 18:42:35.069: INFO: stdout: ""
Oct  7 18:42:35.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -l name=update-demo --namespace=kubectl-8188 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  7 18:42:35.153: INFO: stderr: ""
Oct  7 18:42:35.153: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:42:35.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8188" for this suite.
Oct  7 18:42:47.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:42:47.238: INFO: namespace kubectl-8188 deletion completed in 12.079737324s

• [SLOW TEST:19.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:42:47.239: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-4821
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4821 to expose endpoints map[]
Oct  7 18:42:47.433: INFO: Get endpoints failed (8.347724ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Oct  7 18:42:48.437: INFO: successfully validated that service multi-endpoint-test in namespace services-4821 exposes endpoints map[] (1.012446742s elapsed)
STEP: Creating pod pod1 in namespace services-4821
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4821 to expose endpoints map[pod1:[100]]
Oct  7 18:42:50.475: INFO: successfully validated that service multi-endpoint-test in namespace services-4821 exposes endpoints map[pod1:[100]] (2.018550022s elapsed)
STEP: Creating pod pod2 in namespace services-4821
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4821 to expose endpoints map[pod1:[100] pod2:[101]]
Oct  7 18:42:51.503: INFO: successfully validated that service multi-endpoint-test in namespace services-4821 exposes endpoints map[pod1:[100] pod2:[101]] (1.01926609s elapsed)
STEP: Deleting pod pod1 in namespace services-4821
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4821 to expose endpoints map[pod2:[101]]
Oct  7 18:42:52.527: INFO: successfully validated that service multi-endpoint-test in namespace services-4821 exposes endpoints map[pod2:[101]] (1.013991126s elapsed)
STEP: Deleting pod pod2 in namespace services-4821
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4821 to expose endpoints map[]
Oct  7 18:42:53.544: INFO: successfully validated that service multi-endpoint-test in namespace services-4821 exposes endpoints map[] (1.006355291s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:42:53.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4821" for this suite.
Oct  7 18:42:59.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:42:59.720: INFO: namespace services-4821 deletion completed in 6.134109652s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.481 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:42:59.720: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  7 18:42:59.874: INFO: PodSpec: initContainers in spec.initContainers
Oct  7 18:43:44.521: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3bc2cd67-b917-462e-99ab-6cea4172eb34", GenerateName:"", Namespace:"init-container-1865", SelfLink:"/api/v1/namespaces/init-container-1865/pods/pod-init-3bc2cd67-b917-462e-99ab-6cea4172eb34", UID:"e339f27e-8b15-458c-acba-eb7e1e20d2af", ResourceVersion:"18946", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63706070579, loc:(*time.Location)(0x84be2c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"874917412"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-scgqj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00328c000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-scgqj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-scgqj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-scgqj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0036ae088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"talos-v020-gcp-workers-654f4446bf-clj9s", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002c6e0c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0036ae100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0036ae120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0036ae128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0036ae12c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706070579, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706070579, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706070579, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706070579, loc:(*time.Location)(0x84be2c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.128.15.226", PodIP:"10.244.1.67", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.67"}}, StartTime:(*v1.Time)(0xc002f16080), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f318f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f31960)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://e6a550a55dcfb79c8a772ef63f693fe538ac73b677b2f98e6ef107c82d3a26c0", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002f160c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002f160a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0036ae1af)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:43:44.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1865" for this suite.
Oct  7 18:43:56.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:43:56.604: INFO: namespace init-container-1865 deletion completed in 12.074706559s

• [SLOW TEST:56.884 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:43:56.607: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 18:43:56.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9706'
Oct  7 18:43:56.887: INFO: stderr: ""
Oct  7 18:43:56.887: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Oct  7 18:43:56.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete pods e2e-test-httpd-pod --namespace=kubectl-9706'
Oct  7 18:44:04.059: INFO: stderr: ""
Oct  7 18:44:04.059: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:44:04.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9706" for this suite.
Oct  7 18:44:10.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:44:10.165: INFO: namespace kubectl-9706 deletion completed in 6.101732769s

• [SLOW TEST:13.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:44:10.167: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2333
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6799
STEP: Creating secret with name secret-test-1312d7e9-48c6-4ee2-8c80-e67026c9d62d
STEP: Creating a pod to test consume secrets
Oct  7 18:44:10.514: INFO: Waiting up to 5m0s for pod "pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07" in namespace "secrets-2333" to be "success or failure"
Oct  7 18:44:10.516: INFO: Pod "pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.431955ms
Oct  7 18:44:12.520: INFO: Pod "pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00575945s
STEP: Saw pod success
Oct  7 18:44:12.520: INFO: Pod "pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07" satisfied condition "success or failure"
Oct  7 18:44:12.522: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 18:44:12.560: INFO: Waiting for pod pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07 to disappear
Oct  7 18:44:12.562: INFO: Pod pod-secrets-e67e4113-bd68-4888-8cd5-d3f107077e07 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:44:12.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2333" for this suite.
Oct  7 18:44:18.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:44:18.645: INFO: namespace secrets-2333 deletion completed in 6.078923401s
STEP: Destroying namespace "secret-namespace-6799" for this suite.
Oct  7 18:44:24.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:44:24.724: INFO: namespace secret-namespace-6799 deletion completed in 6.079219238s

• [SLOW TEST:14.557 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:44:24.724: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:44:24.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5890" for this suite.
Oct  7 18:44:30.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:44:31.015: INFO: namespace kubelet-test-5890 deletion completed in 6.081166276s

• [SLOW TEST:6.291 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:44:31.016: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-ac1f9584-715d-424c-be17-ef28dbe6cb89
STEP: Creating a pod to test consume configMaps
Oct  7 18:44:31.188: INFO: Waiting up to 5m0s for pod "pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859" in namespace "configmap-1974" to be "success or failure"
Oct  7 18:44:31.191: INFO: Pod "pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859": Phase="Pending", Reason="", readiness=false. Elapsed: 2.598081ms
Oct  7 18:44:33.274: INFO: Pod "pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006749421s
STEP: Saw pod success
Oct  7 18:44:33.274: INFO: Pod "pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859" satisfied condition "success or failure"
Oct  7 18:44:33.278: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 18:44:33.305: INFO: Waiting for pod pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859 to disappear
Oct  7 18:44:33.308: INFO: Pod pod-configmaps-bf1ea5cd-02a2-4f26-9532-ad8206578859 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:44:33.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1974" for this suite.
Oct  7 18:44:39.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:44:39.431: INFO: namespace configmap-1974 deletion completed in 6.089640559s

• [SLOW TEST:8.336 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:44:39.432: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1383
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Oct  7 18:44:39.631: INFO: Found 0 stateful pods, waiting for 3
Oct  7 18:44:49.638: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:44:49.638: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:44:49.638: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Oct  7 18:44:49.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:44:49.954: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:44:49.954: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:44:49.954: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Oct  7 18:44:59.990: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Oct  7 18:45:10.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:45:10.277: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 18:45:10.277: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 18:45:10.277: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 18:45:30.302: INFO: Waiting for StatefulSet statefulset-1383/ss2 to complete update
Oct  7 18:45:30.304: INFO: Waiting for Pod statefulset-1383/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Oct  7 18:45:40.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Oct  7 18:45:40.612: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Oct  7 18:45:40.612: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Oct  7 18:45:40.612: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Oct  7 18:45:50.671: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Oct  7 18:46:00.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=statefulset-1383 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Oct  7 18:46:00.938: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Oct  7 18:46:00.938: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Oct  7 18:46:00.938: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Oct  7 18:46:10.960: INFO: Waiting for StatefulSet statefulset-1383/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Oct  7 18:46:20.968: INFO: Deleting all statefulset in ns statefulset-1383
Oct  7 18:46:20.971: INFO: Scaling statefulset ss2 to 0
Oct  7 18:46:50.987: INFO: Waiting for statefulset status.replicas updated to 0
Oct  7 18:46:50.990: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:46:51.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1383" for this suite.
Oct  7 18:46:57.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:46:57.088: INFO: namespace statefulset-1383 deletion completed in 6.083373026s

• [SLOW TEST:137.657 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:46:57.090: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Oct  7 18:46:57.256: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Oct  7 18:46:57.266: INFO: Waiting for terminating namespaces to be deleted...
Oct  7 18:46:57.269: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-clj9s before test
Oct  7 18:46:57.287: INFO: kube-flannel-ds-amd64-nlfgj from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.287: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:46:57.287: INFO: sonobuoy from sonobuoy started at 2019-10-07 17:41:21 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.287: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Oct  7 18:46:57.287: INFO: coredns-5644d7b6d9-gshlc from kube-system started at 2019-10-07 17:56:53 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.287: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:46:57.287: INFO: kube-proxy-9mtkh from kube-system started at 2019-10-07 17:39:22 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.287: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:46:57.287: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-lrncj before test
Oct  7 18:46:57.304: INFO: kube-flannel-ds-amd64-wgm5j from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.304: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:46:57.304: INFO: kube-proxy-nghr9 from kube-system started at 2019-10-07 17:39:14 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.304: INFO: 	Container kube-proxy ready: true, restart count 0
Oct  7 18:46:57.304: INFO: sonobuoy-e2e-job-24ad69244f4745c0 from sonobuoy started at 2019-10-07 17:41:22 +0000 UTC (2 container statuses recorded)
Oct  7 18:46:57.304: INFO: 	Container e2e ready: true, restart count 0
Oct  7 18:46:57.305: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Oct  7 18:46:57.305: INFO: coredns-5644d7b6d9-cbm4m from kube-system started at 2019-10-07 17:39:34 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.305: INFO: 	Container coredns ready: true, restart count 0
Oct  7 18:46:57.305: INFO: 
Logging pods the kubelet thinks is on node talos-v020-gcp-workers-654f4446bf-ns4sr before test
Oct  7 18:46:57.321: INFO: kube-flannel-ds-amd64-6hxsg from kube-system started at 2019-10-07 17:30:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.321: INFO: 	Container kube-flannel ready: true, restart count 6
Oct  7 18:46:57.321: INFO: kube-proxy-p4d5z from kube-system started at 2019-10-07 17:39:07 +0000 UTC (1 container statuses recorded)
Oct  7 18:46:57.321: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-4b5238a9-4930-4971-a2d2-fc53c393549c 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-4b5238a9-4930-4971-a2d2-fc53c393549c off the node talos-v020-gcp-workers-654f4446bf-ns4sr
STEP: verifying the node doesn't have the label kubernetes.io/e2e-4b5238a9-4930-4971-a2d2-fc53c393549c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:52:01.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6939" for this suite.
Oct  7 18:52:09.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:52:09.590: INFO: namespace sched-pred-6939 deletion completed in 8.102695159s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:312.501 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:52:09.593: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:52:09.784: INFO: Creating deployment "test-recreate-deployment"
Oct  7 18:52:09.790: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Oct  7 18:52:09.798: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Oct  7 18:52:11.805: INFO: Waiting deployment "test-recreate-deployment" to complete
Oct  7 18:52:11.807: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Oct  7 18:52:11.814: INFO: Updating deployment test-recreate-deployment
Oct  7 18:52:11.814: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  7 18:52:11.955: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5502 /apis/apps/v1/namespaces/deployment-5502/deployments/test-recreate-deployment 84556835-bff8-45d6-a358-42a1eb6efde8 20557 2 2019-10-07 18:52:09 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00315c268 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-07 18:52:11 +0000 UTC,LastTransitionTime:2019-10-07 18:52:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-10-07 18:52:11 +0000 UTC,LastTransitionTime:2019-10-07 18:52:09 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Oct  7 18:52:11.958: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5502 /apis/apps/v1/namespaces/deployment-5502/replicasets/test-recreate-deployment-5f94c574ff 4f567d3a-b962-4f62-9371-ba275328a84d 20556 1 2019-10-07 18:52:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 84556835-bff8-45d6-a358-42a1eb6efde8 0xc00315c647 0xc00315c648}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00315c6a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:52:11.958: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Oct  7 18:52:11.958: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5502 /apis/apps/v1/namespaces/deployment-5502/replicasets/test-recreate-deployment-68fc85c7bb c316b4d9-f5d9-47ef-8c4f-9ebd9306aa43 20545 2 2019-10-07 18:52:09 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 84556835-bff8-45d6-a358-42a1eb6efde8 0xc00315c717 0xc00315c718}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00315c788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:52:11.962: INFO: Pod "test-recreate-deployment-5f94c574ff-85922" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-85922 test-recreate-deployment-5f94c574ff- deployment-5502 /api/v1/namespaces/deployment-5502/pods/test-recreate-deployment-5f94c574ff-85922 bee87458-abc9-47fe-9721-6fee53bed335 20555 0 2019-10-07 18:52:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 4f567d3a-b962-4f62-9371-ba275328a84d 0xc00315cc07 0xc00315cc08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-77j2n,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-77j2n,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-77j2n,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:52:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:52:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:52:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:52:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:52:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:52:11.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5502" for this suite.
Oct  7 18:52:17.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:52:18.040: INFO: namespace deployment-5502 deletion completed in 6.073884818s

• [SLOW TEST:8.447 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:52:18.040: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:52:21.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5290" for this suite.
Oct  7 18:52:33.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:52:33.327: INFO: namespace replication-controller-5290 deletion completed in 12.077119364s

• [SLOW TEST:15.286 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:52:33.327: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 18:52:33.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1603'
Oct  7 18:52:34.028: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  7 18:52:34.028: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Oct  7 18:52:36.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1603'
Oct  7 18:52:36.143: INFO: stderr: ""
Oct  7 18:52:36.143: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:52:36.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1603" for this suite.
Oct  7 18:52:48.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:52:48.257: INFO: namespace kubectl-1603 deletion completed in 12.108692834s

• [SLOW TEST:14.930 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:52:48.258: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Oct  7 18:52:58.503: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1007 18:52:58.502993      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:52:58.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4643" for this suite.
Oct  7 18:53:04.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:53:04.587: INFO: namespace gc-4643 deletion completed in 6.080034355s

• [SLOW TEST:16.329 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:53:04.587: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 18:53:04.755: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa" in namespace "downward-api-301" to be "success or failure"
Oct  7 18:53:04.757: INFO: Pod "downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.725748ms
Oct  7 18:53:06.761: INFO: Pod "downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006294183s
STEP: Saw pod success
Oct  7 18:53:06.761: INFO: Pod "downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa" satisfied condition "success or failure"
Oct  7 18:53:06.763: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa container client-container: <nil>
STEP: delete the pod
Oct  7 18:53:06.793: INFO: Waiting for pod downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa to disappear
Oct  7 18:53:06.796: INFO: Pod downwardapi-volume-4f737a31-02da-4025-8f77-8c0707ed97fa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:53:06.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-301" for this suite.
Oct  7 18:53:12.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:53:12.873: INFO: namespace downward-api-301 deletion completed in 6.073698075s

• [SLOW TEST:8.286 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:53:12.875: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9357
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:53:13.032: INFO: Creating deployment "webserver-deployment"
Oct  7 18:53:13.037: INFO: Waiting for observed generation 1
Oct  7 18:53:15.044: INFO: Waiting for all required pods to come up
Oct  7 18:53:15.048: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Oct  7 18:53:17.056: INFO: Waiting for deployment "webserver-deployment" to complete
Oct  7 18:53:17.061: INFO: Updating deployment "webserver-deployment" with a non-existent image
Oct  7 18:53:17.067: INFO: Updating deployment webserver-deployment
Oct  7 18:53:17.067: INFO: Waiting for observed generation 2
Oct  7 18:53:19.074: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Oct  7 18:53:19.077: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Oct  7 18:53:19.079: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  7 18:53:19.086: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Oct  7 18:53:19.086: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Oct  7 18:53:19.089: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Oct  7 18:53:19.093: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Oct  7 18:53:19.093: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Oct  7 18:53:19.100: INFO: Updating deployment webserver-deployment
Oct  7 18:53:19.100: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Oct  7 18:53:19.109: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Oct  7 18:53:19.112: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  7 18:53:21.131: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9357 /apis/apps/v1/namespaces/deployment-9357/deployments/webserver-deployment be8b8ab8-f7fa-4600-98da-ad27253355ba 21433 3 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004fd9668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-10-07 18:53:19 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-10-07 18:53:21 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,},},ReadyReplicas:10,CollisionCount:nil,},}

Oct  7 18:53:21.135: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9357 /apis/apps/v1/namespaces/deployment-9357/replicasets/webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 21349 3 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment be8b8ab8-f7fa-4600-98da-ad27253355ba 0xc004fd9f27 0xc004fd9f28}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00479c008 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:53:21.135: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Oct  7 18:53:21.135: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9357 /apis/apps/v1/namespaces/deployment-9357/replicasets/webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 21432 3 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment be8b8ab8-f7fa-4600-98da-ad27253355ba 0xc004fd9db7 0xc004fd9db8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004fd9ec8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:53:21.141: INFO: Pod "webserver-deployment-595b5b9587-4fzl7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4fzl7 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-4fzl7 9d2fe686-c2a9-40de-bebf-aa96ecde45e7 21143 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479c517 0xc00479c518}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.76,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://f53a22ebc90b196ee47c1346493cc362d2d447ebb182eb5c18d82521ed56bd79,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.141: INFO: Pod "webserver-deployment-595b5b9587-5g5nb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5g5nb webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-5g5nb 347c3f0f-e548-4d99-9a4d-e697e0e403c9 21360 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479c680 0xc00479c681}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.141: INFO: Pod "webserver-deployment-595b5b9587-5qbwj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5qbwj webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-5qbwj d4d2e2a1-fa77-4ee8-9da0-7c94d72db90a 21374 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479c7c7 0xc00479c7c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.141: INFO: Pod "webserver-deployment-595b5b9587-9bpvq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9bpvq webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-9bpvq aef825d7-cec7-413f-9cf7-4b3238e6b807 21299 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479c917 0xc00479c918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.141: INFO: Pod "webserver-deployment-595b5b9587-bjs6z" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bjs6z webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-bjs6z c2c7843d-3b40-485c-be53-9c8bd4fb3c9e 21358 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479ca67 0xc00479ca68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-g8llb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-g8llb webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-g8llb 9ee53cd7-47e9-4567-a8b3-7c3949a6f952 21401 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479cbb7 0xc00479cbb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-hn8bc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hn8bc webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-hn8bc 59a70df0-c2c4-46ff-b27a-1d9343278b87 21350 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479cd07 0xc00479cd08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-j87nl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j87nl webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-j87nl 005b4524-2524-4946-828c-bdf0c797f68d 21159 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479ce57 0xc00479ce58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.148,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a42f34ef81017bc9d24fbb8153fba8c3f3d1bcdb519323ff8b04e84e94f854eb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-jk2pm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jk2pm webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-jk2pm ff0575d0-7ec5-4e2a-be49-22e28a160540 21431 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479cfc7 0xc00479cfc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.38,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://8d1216072c3ed0efe9bbc7583412058b65f1f11a5588e5b1babdbcd92f42540b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.38,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-llsl8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-llsl8 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-llsl8 642595fb-dc84-4d99-8c69-f7fc8dd3ee83 21150 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d130 0xc00479d131}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.32,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://758e1b51f10867a49d6d2fdf01ee33fa6580d50279bef88f09c70e396eba0f81,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.142: INFO: Pod "webserver-deployment-595b5b9587-m5c9x" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-m5c9x webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-m5c9x 28afb9e9-845b-409d-bc67-8a97e1d003db 21332 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d290 0xc00479d291}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.143: INFO: Pod "webserver-deployment-595b5b9587-mjw78" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mjw78 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-mjw78 d7d64e3a-2407-4370-a2ea-c3c65094b755 21155 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d3d7 0xc00479d3d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.33,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3140435c20b1caff6f771ff302536ef32fe4a25f00b6d010217e17790b69ce89,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.143: INFO: Pod "webserver-deployment-595b5b9587-pb5nd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pb5nd webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-pb5nd 00024cd2-419f-440b-9f60-a411741fc892 21146 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d540 0xc00479d541}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.75,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://fe71bd3c4b943cbf3fcadb8f790aef2c2edafaea80016c63bf13e6a6dd801658,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.143: INFO: Pod "webserver-deployment-595b5b9587-r9pb8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r9pb8 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-r9pb8 5df54f7d-dd3b-43ac-b964-c6ae2bd69bcc 21168 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d6a0 0xc00479d6a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.74,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e16a92482945769a37cad534eed3c29e580da1ae55038ca14560cc43124975ad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.143: INFO: Pod "webserver-deployment-595b5b9587-spfn9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-spfn9 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-spfn9 4bb2bdbd-07da-4def-8ddb-1b13076b4727 21338 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d800 0xc00479d801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.144: INFO: Pod "webserver-deployment-595b5b9587-thq74" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-thq74 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-thq74 9105fa6a-ae06-4bca-955f-f7099d0f5182 21152 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479d947 0xc00479d948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.34,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://c8bddb81b541d73561b35d01543670e55dc0c62cb12bdf1c7389d75a4a82d282,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.144: INFO: Pod "webserver-deployment-595b5b9587-tjd8s" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tjd8s webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-tjd8s 3cb5374b-6739-4c69-97bc-8baaa4942e9b 21131 0 2019-10-07 18:53:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479dab0 0xc00479dab1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.146,StartTime:2019-10-07 18:53:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://0b155a62ece8fbf7762b7e05fc85b7f3297a25d5bd3c2a1803eac9f66b022fdb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.144: INFO: Pod "webserver-deployment-595b5b9587-vj2bt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vj2bt webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-vj2bt 17a14457-0552-42a3-a69a-d7206591d413 21420 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479dc17 0xc00479dc18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.39,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:53:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://3d93abf45edd7a2d22ee3ede7663d5d713e5851a399cfdd2593df684a0c0809f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.145: INFO: Pod "webserver-deployment-595b5b9587-xgkl9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xgkl9 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-xgkl9 c04fbc9d-8b1b-408d-b37f-d3a98e194b07 21362 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479dd80 0xc00479dd81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.145: INFO: Pod "webserver-deployment-595b5b9587-xjmt6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xjmt6 webserver-deployment-595b5b9587- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-595b5b9587-xjmt6 9bb5a9e2-c4b3-4009-b00c-663ba6cb7114 21347 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 128d3b33-3958-413d-93ae-9c878d8cdf34 0xc00479dec7 0xc00479dec8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.146: INFO: Pod "webserver-deployment-c7997dcc8-4jj8t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4jj8t webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-4jj8t 075c2cfe-466b-460d-99f0-640e2c6fc09e 21426 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02017 0xc007c02018}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.78,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.146: INFO: Pod "webserver-deployment-c7997dcc8-7l4th" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7l4th webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-7l4th a4cb7ce9-36f0-4876-828b-5eb659684620 21354 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c021b0 0xc007c021b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.146: INFO: Pod "webserver-deployment-c7997dcc8-9r7ff" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9r7ff webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-9r7ff 4c232f66-2519-4a70-8b35-974481b1c1c7 21378 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02317 0xc007c02318}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.147: INFO: Pod "webserver-deployment-c7997dcc8-dggb5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dggb5 webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-dggb5 28128c3f-110a-4a32-963a-90d3d59c47cb 21418 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02487 0xc007c02488}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.37,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.147: INFO: Pod "webserver-deployment-c7997dcc8-dt4wh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dt4wh webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-dt4wh 32e76924-a599-4e94-9a48-a3f037d5f03b 21249 0 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02620 0xc007c02621}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.77,StartTime:2019-10-07 18:53:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.147: INFO: Pod "webserver-deployment-c7997dcc8-hhk8d" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hhk8d webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-hhk8d 86fe7c16-c59a-4284-841b-66c99dd3f819 21344 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c027b0 0xc007c027b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.148: INFO: Pod "webserver-deployment-c7997dcc8-hwnzj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hwnzj webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-hwnzj e1503e42-1dd7-4d99-929b-24cd2b1005a5 21352 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02917 0xc007c02918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.148: INFO: Pod "webserver-deployment-c7997dcc8-m7lzf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m7lzf webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-m7lzf 3e04f707-de4d-40cf-a166-98db8b9e7c4e 21395 0 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02a87 0xc007c02a88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.150,StartTime:2019-10-07 18:53:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.150,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.148: INFO: Pod "webserver-deployment-c7997dcc8-sqdzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sqdzh webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-sqdzh dc8917d2-a1cc-4567-8c8d-44f8d3514973 21252 0 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02c27 0xc007c02c28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.36,StartTime:2019-10-07 18:53:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.149: INFO: Pod "webserver-deployment-c7997dcc8-thrvb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-thrvb webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-thrvb 89b3649e-821e-43d2-8b3e-ce3eb99db86b 21421 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02dc0 0xc007c02dc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.40,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.149: INFO: Pod "webserver-deployment-c7997dcc8-trxjl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-trxjl webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-trxjl fd7e6e46-1336-45af-9314-c9b04932a026 21256 0 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c02f50 0xc007c02f51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-lrncj,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.0.63,PodIP:10.244.4.35,StartTime:2019-10-07 18:53:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.149: INFO: Pod "webserver-deployment-c7997dcc8-whvfj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-whvfj webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-whvfj f59aaeb5-b1ef-45e5-a537-e187eb2bf4a7 21423 0 2019-10-07 18:53:17 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c030e0 0xc007c030e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.151,StartTime:2019-10-07 18:53:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to resolve image "docker.io/library/webserver:404": no available registry endpoint: pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.151,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Oct  7 18:53:21.150: INFO: Pod "webserver-deployment-c7997dcc8-z9894" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-z9894 webserver-deployment-c7997dcc8- deployment-9357 /api/v1/namespaces/deployment-9357/pods/webserver-deployment-c7997dcc8-z9894 850c49d2-ed99-4138-b247-7600df4068f0 21355 0 2019-10-07 18:53:19 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c2e319e2-41c3-4951-b1e5-f050793192ce 0xc007c03277 0xc007c03278}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9wrrb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9wrrb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9wrrb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:53:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:,StartTime:2019-10-07 18:53:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:53:21.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9357" for this suite.
Oct  7 18:53:29.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:53:29.237: INFO: namespace deployment-9357 deletion completed in 8.083038777s

• [SLOW TEST:16.362 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:53:29.238: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:53:29.797: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:53:32.828: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Oct  7 18:53:32.852: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:53:32.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3844" for this suite.
Oct  7 18:53:38.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:53:38.946: INFO: namespace webhook-3844 deletion completed in 6.074813442s
STEP: Destroying namespace "webhook-3844-markers" for this suite.
Oct  7 18:53:44.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:53:45.026: INFO: namespace webhook-3844-markers deletion completed in 6.079861214s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.803 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:53:45.042: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:53:47.246: INFO: Waiting up to 5m0s for pod "client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad" in namespace "pods-5010" to be "success or failure"
Oct  7 18:53:47.250: INFO: Pod "client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad": Phase="Pending", Reason="", readiness=false. Elapsed: 3.753109ms
Oct  7 18:53:49.254: INFO: Pod "client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007869998s
STEP: Saw pod success
Oct  7 18:53:49.254: INFO: Pod "client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad" satisfied condition "success or failure"
Oct  7 18:53:49.257: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad container env3cont: <nil>
STEP: delete the pod
Oct  7 18:53:49.304: INFO: Waiting for pod client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad to disappear
Oct  7 18:53:49.307: INFO: Pod client-envvars-fc1d8039-80fd-493d-9c95-fdca58c80bad no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:53:49.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5010" for this suite.
Oct  7 18:54:01.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:54:01.399: INFO: namespace pods-5010 deletion completed in 12.087110507s

• [SLOW TEST:16.357 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:54:01.399: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7831
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Oct  7 18:54:01.982: INFO: Pod name wrapped-volume-race-add9c1af-d010-4507-bb94-ecdcda7211c9: Found 0 pods out of 5
Oct  7 18:54:06.987: INFO: Pod name wrapped-volume-race-add9c1af-d010-4507-bb94-ecdcda7211c9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-add9c1af-d010-4507-bb94-ecdcda7211c9 in namespace emptydir-wrapper-7831, will wait for the garbage collector to delete the pods
Oct  7 18:54:17.067: INFO: Deleting ReplicationController wrapped-volume-race-add9c1af-d010-4507-bb94-ecdcda7211c9 took: 9.417931ms
Oct  7 18:54:17.368: INFO: Terminating ReplicationController wrapped-volume-race-add9c1af-d010-4507-bb94-ecdcda7211c9 pods took: 300.370002ms
STEP: Creating RC which spawns configmap-volume pods
Oct  7 18:54:53.388: INFO: Pod name wrapped-volume-race-9fa76d39-88ea-47ee-b607-99448ec2ecea: Found 0 pods out of 5
Oct  7 18:54:58.394: INFO: Pod name wrapped-volume-race-9fa76d39-88ea-47ee-b607-99448ec2ecea: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9fa76d39-88ea-47ee-b607-99448ec2ecea in namespace emptydir-wrapper-7831, will wait for the garbage collector to delete the pods
Oct  7 18:55:10.497: INFO: Deleting ReplicationController wrapped-volume-race-9fa76d39-88ea-47ee-b607-99448ec2ecea took: 32.801071ms
Oct  7 18:55:10.798: INFO: Terminating ReplicationController wrapped-volume-race-9fa76d39-88ea-47ee-b607-99448ec2ecea pods took: 300.278579ms
STEP: Creating RC which spawns configmap-volume pods
Oct  7 18:55:53.419: INFO: Pod name wrapped-volume-race-9ab90da7-a98c-499b-b575-f6cf1abbf5e4: Found 0 pods out of 5
Oct  7 18:55:58.424: INFO: Pod name wrapped-volume-race-9ab90da7-a98c-499b-b575-f6cf1abbf5e4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9ab90da7-a98c-499b-b575-f6cf1abbf5e4 in namespace emptydir-wrapper-7831, will wait for the garbage collector to delete the pods
Oct  7 18:56:12.541: INFO: Deleting ReplicationController wrapped-volume-race-9ab90da7-a98c-499b-b575-f6cf1abbf5e4 took: 10.104813ms
Oct  7 18:56:12.841: INFO: Terminating ReplicationController wrapped-volume-race-9ab90da7-a98c-499b-b575-f6cf1abbf5e4 pods took: 300.225013ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:56:54.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7831" for this suite.
Oct  7 18:57:02.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:02.814: INFO: namespace emptydir-wrapper-7831 deletion completed in 8.100966529s

• [SLOW TEST:181.415 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:02.818: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:57:03.001: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Oct  7 18:57:03.011: INFO: Pod name sample-pod: Found 0 pods out of 1
Oct  7 18:57:08.016: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  7 18:57:08.016: INFO: Creating deployment "test-rolling-update-deployment"
Oct  7 18:57:08.043: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Oct  7 18:57:08.053: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Oct  7 18:57:10.060: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Oct  7 18:57:10.062: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  7 18:57:10.071: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-645 /apis/apps/v1/namespaces/deployment-645/deployments/test-rolling-update-deployment 613b0414-aa91-4137-9cc1-245d8befa26b 23201 1 2019-10-07 18:57:08 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000dfac58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-07 18:57:08 +0000 UTC,LastTransitionTime:2019-10-07 18:57:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-10-07 18:57:09 +0000 UTC,LastTransitionTime:2019-10-07 18:57:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  7 18:57:10.075: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-645 /apis/apps/v1/namespaces/deployment-645/replicasets/test-rolling-update-deployment-55d946486 9b652a52-745b-45ce-aada-eecc3c4767f3 23188 1 2019-10-07 18:57:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 613b0414-aa91-4137-9cc1-245d8befa26b 0xc000dfb150 0xc000dfb151}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000dfb1b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:57:10.075: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Oct  7 18:57:10.075: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-645 /apis/apps/v1/namespaces/deployment-645/replicasets/test-rolling-update-controller dff76405-e8ef-474a-b00f-5658a2c3c756 23199 2 2019-10-07 18:57:03 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 613b0414-aa91-4137-9cc1-245d8befa26b 0xc000dfb087 0xc000dfb088}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000dfb0e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:57:10.079: INFO: Pod "test-rolling-update-deployment-55d946486-vmfdv" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-vmfdv test-rolling-update-deployment-55d946486- deployment-645 /api/v1/namespaces/deployment-645/pods/test-rolling-update-deployment-55d946486-vmfdv c37c3cf7-52e5-48f3-a911-985aabc669d2 23187 0 2019-10-07 18:57:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 9b652a52-745b-45ce-aada-eecc3c4767f3 0xc000dfb630 0xc000dfb631}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lm44m,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lm44m,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lm44m,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:57:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:57:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:57:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:57:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.163,StartTime:2019-10-07 18:57:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:57:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://4db4d98009239302bf4fc3951d8dd3a58add668966834c43afecdde37a400e58,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.163,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:10.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-645" for this suite.
Oct  7 18:57:16.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:16.175: INFO: namespace deployment-645 deletion completed in 6.092325384s

• [SLOW TEST:13.357 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:16.177: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:16.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9436" for this suite.
Oct  7 18:57:22.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:22.466: INFO: namespace resourcequota-9436 deletion completed in 6.092363433s

• [SLOW TEST:6.289 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:22.469: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 18:57:23.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  7 18:57:25.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071443, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071443, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071443, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071443, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 18:57:28.211: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:28.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-681" for this suite.
Oct  7 18:57:34.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:34.309: INFO: namespace webhook-681 deletion completed in 6.087202351s
STEP: Destroying namespace "webhook-681-markers" for this suite.
Oct  7 18:57:40.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:40.389: INFO: namespace webhook-681-markers deletion completed in 6.080231553s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.934 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:40.404: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4179
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Oct  7 18:57:40.612: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4179 /api/v1/namespaces/watch-4179/configmaps/e2e-watch-test-resource-version 3aab9570-afc6-4fc6-a120-3c4b1a483f80 23380 0 2019-10-07 18:57:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  7 18:57:40.612: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4179 /api/v1/namespaces/watch-4179/configmaps/e2e-watch-test-resource-version 3aab9570-afc6-4fc6-a120-3c4b1a483f80 23381 0 2019-10-07 18:57:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:40.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4179" for this suite.
Oct  7 18:57:46.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:46.699: INFO: namespace watch-4179 deletion completed in 6.083460376s

• [SLOW TEST:6.295 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:46.700: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:57:46.960: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-b66aaf7c-a463-4b02-8743-e1a5bb369884" in namespace "security-context-test-4383" to be "success or failure"
Oct  7 18:57:46.964: INFO: Pod "busybox-readonly-false-b66aaf7c-a463-4b02-8743-e1a5bb369884": Phase="Pending", Reason="", readiness=false. Elapsed: 3.57001ms
Oct  7 18:57:48.968: INFO: Pod "busybox-readonly-false-b66aaf7c-a463-4b02-8743-e1a5bb369884": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007487878s
Oct  7 18:57:48.968: INFO: Pod "busybox-readonly-false-b66aaf7c-a463-4b02-8743-e1a5bb369884" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:48.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4383" for this suite.
Oct  7 18:57:54.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:57:55.060: INFO: namespace security-context-test-4383 deletion completed in 6.088161675s

• [SLOW TEST:8.361 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:57:55.063: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-1c1983f9-6cbf-46d3-b285-1220e10bfb51
STEP: Creating a pod to test consume secrets
Oct  7 18:57:55.234: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71" in namespace "projected-5134" to be "success or failure"
Oct  7 18:57:55.238: INFO: Pod "pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71": Phase="Pending", Reason="", readiness=false. Elapsed: 3.026765ms
Oct  7 18:57:57.241: INFO: Pod "pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006560013s
STEP: Saw pod success
Oct  7 18:57:57.241: INFO: Pod "pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71" satisfied condition "success or failure"
Oct  7 18:57:57.244: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  7 18:57:57.274: INFO: Waiting for pod pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71 to disappear
Oct  7 18:57:57.276: INFO: Pod pod-projected-secrets-e90de5e5-df93-4b3a-afa1-262ef52a4a71 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:57:57.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5134" for this suite.
Oct  7 18:58:03.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:58:03.376: INFO: namespace projected-5134 deletion completed in 6.09395889s

• [SLOW TEST:8.313 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:58:03.377: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-e4d1c0b3-6a8a-46c0-bf8a-314fbc0e0078 in namespace container-probe-1665
Oct  7 18:58:05.563: INFO: Started pod busybox-e4d1c0b3-6a8a-46c0-bf8a-314fbc0e0078 in namespace container-probe-1665
STEP: checking the pod's current state and verifying that restartCount is present
Oct  7 18:58:05.568: INFO: Initial restart count of pod busybox-e4d1c0b3-6a8a-46c0-bf8a-314fbc0e0078 is 0
Oct  7 18:58:59.779: INFO: Restart count of pod container-probe-1665/busybox-e4d1c0b3-6a8a-46c0-bf8a-314fbc0e0078 is now 1 (54.133861602s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:58:59.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1665" for this suite.
Oct  7 18:59:05.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:59:05.891: INFO: namespace container-probe-1665 deletion completed in 6.090736587s

• [SLOW TEST:62.437 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:59:05.891: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:59:06.084: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e019132a-4a82-4d09-a4cd-ecfa10bcaebc" in namespace "security-context-test-8875" to be "success or failure"
Oct  7 18:59:06.087: INFO: Pod "busybox-user-65534-e019132a-4a82-4d09-a4cd-ecfa10bcaebc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.190022ms
Oct  7 18:59:08.091: INFO: Pod "busybox-user-65534-e019132a-4a82-4d09-a4cd-ecfa10bcaebc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007155991s
Oct  7 18:59:08.091: INFO: Pod "busybox-user-65534-e019132a-4a82-4d09-a4cd-ecfa10bcaebc" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:59:08.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8875" for this suite.
Oct  7 18:59:14.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:59:14.179: INFO: namespace security-context-test-8875 deletion completed in 6.083473818s

• [SLOW TEST:8.288 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:59:14.179: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1122
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:59:14.392: INFO: Pod name rollover-pod: Found 0 pods out of 1
Oct  7 18:59:19.400: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  7 18:59:19.401: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Oct  7 18:59:21.404: INFO: Creating deployment "test-rollover-deployment"
Oct  7 18:59:21.413: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Oct  7 18:59:23.424: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Oct  7 18:59:23.429: INFO: Ensure that both replica sets have 1 created replica
Oct  7 18:59:23.435: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Oct  7 18:59:23.449: INFO: Updating deployment test-rollover-deployment
Oct  7 18:59:23.449: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Oct  7 18:59:25.455: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Oct  7 18:59:25.461: INFO: Make sure deployment "test-rollover-deployment" is complete
Oct  7 18:59:25.466: INFO: all replica sets need to contain the pod-template-hash label
Oct  7 18:59:25.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071565, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 18:59:27.473: INFO: all replica sets need to contain the pod-template-hash label
Oct  7 18:59:27.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071565, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 18:59:29.473: INFO: all replica sets need to contain the pod-template-hash label
Oct  7 18:59:29.473: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071565, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 18:59:31.474: INFO: all replica sets need to contain the pod-template-hash label
Oct  7 18:59:31.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071565, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 18:59:33.474: INFO: all replica sets need to contain the pod-template-hash label
Oct  7 18:59:33.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071565, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706071561, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 18:59:35.473: INFO: 
Oct  7 18:59:35.473: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  7 18:59:35.482: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1122 /apis/apps/v1/namespaces/deployment-1122/deployments/test-rollover-deployment 3c6437e1-5880-41d5-bda0-287b4198943a 23814 2 2019-10-07 18:59:21 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bc0be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-10-07 18:59:21 +0000 UTC,LastTransitionTime:2019-10-07 18:59:21 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-10-07 18:59:35 +0000 UTC,LastTransitionTime:2019-10-07 18:59:21 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Oct  7 18:59:35.485: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-1122 /apis/apps/v1/namespaces/deployment-1122/replicasets/test-rollover-deployment-7d7dc6548c 1cab12e5-baa4-45b1-ba50-825ae0b25b61 23803 2 2019-10-07 18:59:23 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 3c6437e1-5880-41d5-bda0-287b4198943a 0xc004bc10a7 0xc004bc10a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bc1108 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:59:35.485: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Oct  7 18:59:35.485: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1122 /apis/apps/v1/namespaces/deployment-1122/replicasets/test-rollover-controller 51dc7f79-d348-4863-8494-2c4bd21d7d6c 23812 2 2019-10-07 18:59:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 3c6437e1-5880-41d5-bda0-287b4198943a 0xc004bc0fd7 0xc004bc0fd8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004bc1038 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:59:35.485: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-1122 /apis/apps/v1/namespaces/deployment-1122/replicasets/test-rollover-deployment-f6c94f66c 7b6657fd-d55c-47d3-8066-7641e3a746ab 23765 2 2019-10-07 18:59:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 3c6437e1-5880-41d5-bda0-287b4198943a 0xc004bc1170 0xc004bc1171}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bc11e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Oct  7 18:59:35.489: INFO: Pod "test-rollover-deployment-7d7dc6548c-d5chd" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-d5chd test-rollover-deployment-7d7dc6548c- deployment-1122 /api/v1/namespaces/deployment-1122/pods/test-rollover-deployment-7d7dc6548c-d5chd cfe86900-8e2d-4781-b8b0-4d070174f4f6 23779 0 2019-10-07 18:59:23 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 1cab12e5-baa4-45b1-ba50-825ae0b25b61 0xc004bc1737 0xc004bc1738}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gf8rj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gf8rj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gf8rj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-clj9s,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:59:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:59:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 18:59:23 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.226,PodIP:10.244.1.101,StartTime:2019-10-07 18:59:23 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 18:59:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://b83a4c41ee2435a81814c6fbada946db496c914c1e8bfb870678c1fc5bd70a1f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:59:35.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1122" for this suite.
Oct  7 18:59:41.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:59:41.578: INFO: namespace deployment-1122 deletion completed in 6.085960549s

• [SLOW TEST:27.399 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:59:41.579: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Oct  7 18:59:41.761: INFO: Waiting up to 5m0s for pod "client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797" in namespace "containers-8563" to be "success or failure"
Oct  7 18:59:41.764: INFO: Pod "client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797": Phase="Pending", Reason="", readiness=false. Elapsed: 2.96224ms
Oct  7 18:59:43.768: INFO: Pod "client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007436269s
STEP: Saw pod success
Oct  7 18:59:43.768: INFO: Pod "client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797" satisfied condition "success or failure"
Oct  7 18:59:43.772: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797 container test-container: <nil>
STEP: delete the pod
Oct  7 18:59:43.807: INFO: Waiting for pod client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797 to disappear
Oct  7 18:59:43.810: INFO: Pod client-containers-656897eb-a2b6-4fcb-99e3-7f8a0c218797 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:59:43.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8563" for this suite.
Oct  7 18:59:49.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:59:49.945: INFO: namespace containers-8563 deletion completed in 6.129299877s

• [SLOW TEST:8.366 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:59:49.947: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 18:59:50.153: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-b7ef5975-b05f-40ed-9742-bb06b3a698a1" in namespace "security-context-test-4980" to be "success or failure"
Oct  7 18:59:50.164: INFO: Pod "alpine-nnp-false-b7ef5975-b05f-40ed-9742-bb06b3a698a1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.619141ms
Oct  7 18:59:52.168: INFO: Pod "alpine-nnp-false-b7ef5975-b05f-40ed-9742-bb06b3a698a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014312618s
Oct  7 18:59:52.168: INFO: Pod "alpine-nnp-false-b7ef5975-b05f-40ed-9742-bb06b3a698a1" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:59:52.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4980" for this suite.
Oct  7 18:59:58.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 18:59:58.278: INFO: namespace security-context-test-4980 deletion completed in 6.093506133s

• [SLOW TEST:8.331 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 18:59:58.280: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 18:59:58.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9778" for this suite.
Oct  7 19:00:04.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:00:04.573: INFO: namespace services-9778 deletion completed in 6.09181997s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.293 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:00:04.575: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Oct  7 19:00:04.750: INFO: Waiting up to 5m0s for pod "downward-api-11c10a73-fb58-416f-865a-623a06cded10" in namespace "downward-api-8229" to be "success or failure"
Oct  7 19:00:04.753: INFO: Pod "downward-api-11c10a73-fb58-416f-865a-623a06cded10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.303248ms
Oct  7 19:00:06.757: INFO: Pod "downward-api-11c10a73-fb58-416f-865a-623a06cded10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007040993s
STEP: Saw pod success
Oct  7 19:00:06.757: INFO: Pod "downward-api-11c10a73-fb58-416f-865a-623a06cded10" satisfied condition "success or failure"
Oct  7 19:00:06.760: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downward-api-11c10a73-fb58-416f-865a-623a06cded10 container dapi-container: <nil>
STEP: delete the pod
Oct  7 19:00:06.783: INFO: Waiting for pod downward-api-11c10a73-fb58-416f-865a-623a06cded10 to disappear
Oct  7 19:00:06.785: INFO: Pod downward-api-11c10a73-fb58-416f-865a-623a06cded10 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:00:06.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8229" for this suite.
Oct  7 19:00:12.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:00:12.870: INFO: namespace downward-api-8229 deletion completed in 6.081449351s

• [SLOW TEST:8.297 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:00:12.870: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3578
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:00:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  7 19:00:15.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-3578 create -f -'
Oct  7 19:00:16.888: INFO: stderr: ""
Oct  7 19:00:16.888: INFO: stdout: "e2e-test-crd-publish-openapi-3423-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  7 19:00:16.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-3578 delete e2e-test-crd-publish-openapi-3423-crds test-cr'
Oct  7 19:00:17.023: INFO: stderr: ""
Oct  7 19:00:17.023: INFO: stdout: "e2e-test-crd-publish-openapi-3423-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Oct  7 19:00:17.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-3578 apply -f -'
Oct  7 19:00:17.396: INFO: stderr: ""
Oct  7 19:00:17.396: INFO: stdout: "e2e-test-crd-publish-openapi-3423-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Oct  7 19:00:17.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-3578 delete e2e-test-crd-publish-openapi-3423-crds test-cr'
Oct  7 19:00:17.495: INFO: stderr: ""
Oct  7 19:00:17.495: INFO: stdout: "e2e-test-crd-publish-openapi-3423-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Oct  7 19:00:17.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-3423-crds'
Oct  7 19:00:17.734: INFO: stderr: ""
Oct  7 19:00:17.734: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3423-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:00:20.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3578" for this suite.
Oct  7 19:00:26.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:00:26.746: INFO: namespace crd-publish-openapi-3578 deletion completed in 6.085084158s

• [SLOW TEST:13.876 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:00:26.748: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-s24c
STEP: Creating a pod to test atomic-volume-subpath
Oct  7 19:00:26.967: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-s24c" in namespace "subpath-1915" to be "success or failure"
Oct  7 19:00:26.970: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.859882ms
Oct  7 19:00:28.974: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 2.006475642s
Oct  7 19:00:30.977: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 4.010200849s
Oct  7 19:00:32.981: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 6.01382825s
Oct  7 19:00:34.985: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 8.0180135s
Oct  7 19:00:36.989: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 10.022021309s
Oct  7 19:00:38.993: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 12.025883748s
Oct  7 19:00:40.997: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 14.02969387s
Oct  7 19:00:43.001: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 16.033615536s
Oct  7 19:00:45.004: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 18.037117005s
Oct  7 19:00:47.008: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Running", Reason="", readiness=true. Elapsed: 20.04115453s
Oct  7 19:00:49.012: INFO: Pod "pod-subpath-test-downwardapi-s24c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.044961432s
STEP: Saw pod success
Oct  7 19:00:49.012: INFO: Pod "pod-subpath-test-downwardapi-s24c" satisfied condition "success or failure"
Oct  7 19:00:49.015: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-subpath-test-downwardapi-s24c container test-container-subpath-downwardapi-s24c: <nil>
STEP: delete the pod
Oct  7 19:00:49.035: INFO: Waiting for pod pod-subpath-test-downwardapi-s24c to disappear
Oct  7 19:00:49.038: INFO: Pod pod-subpath-test-downwardapi-s24c no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-s24c
Oct  7 19:00:49.038: INFO: Deleting pod "pod-subpath-test-downwardapi-s24c" in namespace "subpath-1915"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:00:49.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1915" for this suite.
Oct  7 19:00:55.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:00:55.128: INFO: namespace subpath-1915 deletion completed in 6.083640973s

• [SLOW TEST:28.380 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:00:55.129: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  7 19:00:57.857: INFO: Successfully updated pod "annotationupdate00013ac4-28ee-4409-8047-67fb32e65f32"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:01:01.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1069" for this suite.
Oct  7 19:01:29.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:01:29.993: INFO: namespace downward-api-1069 deletion completed in 28.107127907s

• [SLOW TEST:34.863 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:01:29.993: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wczhm in namespace proxy-2102
I1007 19:01:30.209525      19 runners.go:184] Created replication controller with name: proxy-service-wczhm, namespace: proxy-2102, replica count: 1
I1007 19:01:31.261357      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1007 19:01:32.262286      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:33.263128      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:34.263374      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:35.263567      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:36.263947      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:37.264176      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:38.264449      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:39.264739      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:40.264930      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:41.265238      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1007 19:01:42.265514      19 runners.go:184] proxy-service-wczhm Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Oct  7 19:01:42.269: INFO: setup took 12.103456478s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Oct  7 19:01:42.279: INFO: (0) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.317556ms)
Oct  7 19:01:42.283: INFO: (0) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 13.42598ms)
Oct  7 19:01:42.283: INFO: (0) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 12.705829ms)
Oct  7 19:01:42.291: INFO: (0) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 19.494909ms)
Oct  7 19:01:42.291: INFO: (0) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 21.071065ms)
Oct  7 19:01:42.291: INFO: (0) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 19.270539ms)
Oct  7 19:01:42.291: INFO: (0) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 19.953558ms)
Oct  7 19:01:42.291: INFO: (0) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 20.184333ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 21.033003ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 20.815563ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 20.959886ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 22.361034ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 21.320652ms)
Oct  7 19:01:42.292: INFO: (0) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 21.206117ms)
Oct  7 19:01:42.296: INFO: (0) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 25.287477ms)
Oct  7 19:01:42.298: INFO: (0) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 26.873091ms)
Oct  7 19:01:42.305: INFO: (1) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 6.850667ms)
Oct  7 19:01:42.308: INFO: (1) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 9.219908ms)
Oct  7 19:01:42.310: INFO: (1) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 11.004525ms)
Oct  7 19:01:42.311: INFO: (1) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 11.845494ms)
Oct  7 19:01:42.311: INFO: (1) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 12.326604ms)
Oct  7 19:01:42.312: INFO: (1) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.93639ms)
Oct  7 19:01:42.312: INFO: (1) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 12.996396ms)
Oct  7 19:01:42.314: INFO: (1) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 14.594132ms)
Oct  7 19:01:42.315: INFO: (1) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 16.408548ms)
Oct  7 19:01:42.316: INFO: (1) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 16.745617ms)
Oct  7 19:01:42.316: INFO: (1) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 17.615033ms)
Oct  7 19:01:42.316: INFO: (1) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 17.103103ms)
Oct  7 19:01:42.316: INFO: (1) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 17.193802ms)
Oct  7 19:01:42.317: INFO: (1) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 17.570372ms)
Oct  7 19:01:42.317: INFO: (1) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 18.567532ms)
Oct  7 19:01:42.319: INFO: (1) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 19.897454ms)
Oct  7 19:01:42.327: INFO: (2) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 7.756985ms)
Oct  7 19:01:42.330: INFO: (2) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.151621ms)
Oct  7 19:01:42.333: INFO: (2) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 13.171348ms)
Oct  7 19:01:42.333: INFO: (2) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 13.343881ms)
Oct  7 19:01:42.333: INFO: (2) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 13.623451ms)
Oct  7 19:01:42.333: INFO: (2) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 13.532506ms)
Oct  7 19:01:42.334: INFO: (2) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 14.509069ms)
Oct  7 19:01:42.336: INFO: (2) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 16.303262ms)
Oct  7 19:01:42.336: INFO: (2) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 16.579537ms)
Oct  7 19:01:42.336: INFO: (2) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 16.85239ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 18.883389ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 18.748404ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 18.877921ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 18.56719ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 18.594555ms)
Oct  7 19:01:42.338: INFO: (2) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 18.832354ms)
Oct  7 19:01:42.345: INFO: (3) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 6.405394ms)
Oct  7 19:01:42.346: INFO: (3) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 7.120792ms)
Oct  7 19:01:42.346: INFO: (3) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 7.660285ms)
Oct  7 19:01:42.347: INFO: (3) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 8.191267ms)
Oct  7 19:01:42.347: INFO: (3) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 8.50465ms)
Oct  7 19:01:42.348: INFO: (3) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.420622ms)
Oct  7 19:01:42.349: INFO: (3) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 9.54141ms)
Oct  7 19:01:42.349: INFO: (3) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.792222ms)
Oct  7 19:01:42.350: INFO: (3) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 11.110981ms)
Oct  7 19:01:42.351: INFO: (3) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 12.055335ms)
Oct  7 19:01:42.351: INFO: (3) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 12.457671ms)
Oct  7 19:01:42.352: INFO: (3) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 13.041453ms)
Oct  7 19:01:42.352: INFO: (3) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 13.775645ms)
Oct  7 19:01:42.352: INFO: (3) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 13.641964ms)
Oct  7 19:01:42.354: INFO: (3) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 15.463688ms)
Oct  7 19:01:42.355: INFO: (3) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 15.980256ms)
Oct  7 19:01:42.364: INFO: (4) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 7.533921ms)
Oct  7 19:01:42.364: INFO: (4) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 7.752779ms)
Oct  7 19:01:42.364: INFO: (4) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 7.750294ms)
Oct  7 19:01:42.365: INFO: (4) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.589202ms)
Oct  7 19:01:42.366: INFO: (4) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 10.097794ms)
Oct  7 19:01:42.369: INFO: (4) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.213013ms)
Oct  7 19:01:42.372: INFO: (4) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 16.396544ms)
Oct  7 19:01:42.373: INFO: (4) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 16.491203ms)
Oct  7 19:01:42.373: INFO: (4) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 16.96845ms)
Oct  7 19:01:42.373: INFO: (4) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 16.770575ms)
Oct  7 19:01:42.373: INFO: (4) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 18.149679ms)
Oct  7 19:01:42.374: INFO: (4) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 17.255396ms)
Oct  7 19:01:42.374: INFO: (4) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 18.215419ms)
Oct  7 19:01:42.374: INFO: (4) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 18.09985ms)
Oct  7 19:01:42.374: INFO: (4) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 17.884422ms)
Oct  7 19:01:42.374: INFO: (4) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 18.856513ms)
Oct  7 19:01:42.383: INFO: (5) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 7.849012ms)
Oct  7 19:01:42.384: INFO: (5) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 8.695737ms)
Oct  7 19:01:42.384: INFO: (5) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 9.300362ms)
Oct  7 19:01:42.384: INFO: (5) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 8.318448ms)
Oct  7 19:01:42.385: INFO: (5) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 10.113706ms)
Oct  7 19:01:42.385: INFO: (5) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.297933ms)
Oct  7 19:01:42.386: INFO: (5) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 10.929338ms)
Oct  7 19:01:42.387: INFO: (5) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.742049ms)
Oct  7 19:01:42.387: INFO: (5) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.784838ms)
Oct  7 19:01:42.390: INFO: (5) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 15.005066ms)
Oct  7 19:01:42.390: INFO: (5) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 15.072908ms)
Oct  7 19:01:42.390: INFO: (5) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 14.869604ms)
Oct  7 19:01:42.390: INFO: (5) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 14.832209ms)
Oct  7 19:01:42.391: INFO: (5) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 15.474796ms)
Oct  7 19:01:42.391: INFO: (5) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 14.649934ms)
Oct  7 19:01:42.391: INFO: (5) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.798992ms)
Oct  7 19:01:42.399: INFO: (6) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 8.289822ms)
Oct  7 19:01:42.399: INFO: (6) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 8.068058ms)
Oct  7 19:01:42.402: INFO: (6) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 10.719743ms)
Oct  7 19:01:42.402: INFO: (6) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 11.004035ms)
Oct  7 19:01:42.402: INFO: (6) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.279632ms)
Oct  7 19:01:42.403: INFO: (6) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 11.543058ms)
Oct  7 19:01:42.403: INFO: (6) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 11.791563ms)
Oct  7 19:01:42.403: INFO: (6) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 11.831057ms)
Oct  7 19:01:42.403: INFO: (6) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.071587ms)
Oct  7 19:01:42.404: INFO: (6) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 12.870475ms)
Oct  7 19:01:42.404: INFO: (6) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 12.569081ms)
Oct  7 19:01:42.404: INFO: (6) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 12.665011ms)
Oct  7 19:01:42.404: INFO: (6) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 13.01742ms)
Oct  7 19:01:42.406: INFO: (6) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 14.356664ms)
Oct  7 19:01:42.406: INFO: (6) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 14.769124ms)
Oct  7 19:01:42.406: INFO: (6) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 15.080676ms)
Oct  7 19:01:42.413: INFO: (7) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 5.863821ms)
Oct  7 19:01:42.413: INFO: (7) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 6.884829ms)
Oct  7 19:01:42.416: INFO: (7) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 8.282094ms)
Oct  7 19:01:42.416: INFO: (7) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 8.519947ms)
Oct  7 19:01:42.416: INFO: (7) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 8.814175ms)
Oct  7 19:01:42.416: INFO: (7) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 8.716901ms)
Oct  7 19:01:42.417: INFO: (7) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 9.762123ms)
Oct  7 19:01:42.418: INFO: (7) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 11.076234ms)
Oct  7 19:01:42.418: INFO: (7) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 10.385048ms)
Oct  7 19:01:42.419: INFO: (7) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 12.045624ms)
Oct  7 19:01:42.419: INFO: (7) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 11.870272ms)
Oct  7 19:01:42.419: INFO: (7) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 10.754305ms)
Oct  7 19:01:42.419: INFO: (7) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 11.04422ms)
Oct  7 19:01:42.421: INFO: (7) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 12.609042ms)
Oct  7 19:01:42.421: INFO: (7) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 12.711826ms)
Oct  7 19:01:42.421: INFO: (7) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 12.912499ms)
Oct  7 19:01:42.430: INFO: (8) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 8.56446ms)
Oct  7 19:01:42.430: INFO: (8) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.13915ms)
Oct  7 19:01:42.432: INFO: (8) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 8.566382ms)
Oct  7 19:01:42.434: INFO: (8) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 10.579833ms)
Oct  7 19:01:42.435: INFO: (8) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 11.59256ms)
Oct  7 19:01:42.435: INFO: (8) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 11.54301ms)
Oct  7 19:01:42.435: INFO: (8) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.745109ms)
Oct  7 19:01:42.435: INFO: (8) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 11.79889ms)
Oct  7 19:01:42.436: INFO: (8) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 13.293817ms)
Oct  7 19:01:42.437: INFO: (8) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 13.182762ms)
Oct  7 19:01:42.437: INFO: (8) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 13.762328ms)
Oct  7 19:01:42.437: INFO: (8) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 13.902307ms)
Oct  7 19:01:42.437: INFO: (8) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 14.367265ms)
Oct  7 19:01:42.438: INFO: (8) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 14.410891ms)
Oct  7 19:01:42.438: INFO: (8) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 14.931291ms)
Oct  7 19:01:42.439: INFO: (8) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 15.994891ms)
Oct  7 19:01:42.449: INFO: (9) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 9.93739ms)
Oct  7 19:01:42.450: INFO: (9) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 9.304592ms)
Oct  7 19:01:42.451: INFO: (9) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 10.082545ms)
Oct  7 19:01:42.451: INFO: (9) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 11.106048ms)
Oct  7 19:01:42.452: INFO: (9) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.490278ms)
Oct  7 19:01:42.453: INFO: (9) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 11.973177ms)
Oct  7 19:01:42.453: INFO: (9) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 12.32132ms)
Oct  7 19:01:42.454: INFO: (9) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.945937ms)
Oct  7 19:01:42.454: INFO: (9) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 13.202484ms)
Oct  7 19:01:42.454: INFO: (9) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 14.243397ms)
Oct  7 19:01:42.454: INFO: (9) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 13.195939ms)
Oct  7 19:01:42.454: INFO: (9) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 13.851683ms)
Oct  7 19:01:42.455: INFO: (9) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 13.899108ms)
Oct  7 19:01:42.455: INFO: (9) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 14.096114ms)
Oct  7 19:01:42.455: INFO: (9) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 14.842897ms)
Oct  7 19:01:42.455: INFO: (9) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.202723ms)
Oct  7 19:01:42.462: INFO: (10) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 6.737989ms)
Oct  7 19:01:42.463: INFO: (10) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 7.777337ms)
Oct  7 19:01:42.464: INFO: (10) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 8.138646ms)
Oct  7 19:01:42.464: INFO: (10) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 8.53623ms)
Oct  7 19:01:42.465: INFO: (10) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.189733ms)
Oct  7 19:01:42.468: INFO: (10) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 11.224973ms)
Oct  7 19:01:42.469: INFO: (10) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 12.353979ms)
Oct  7 19:01:42.469: INFO: (10) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 12.486548ms)
Oct  7 19:01:42.470: INFO: (10) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 14.799933ms)
Oct  7 19:01:42.471: INFO: (10) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 14.660768ms)
Oct  7 19:01:42.471: INFO: (10) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 14.190734ms)
Oct  7 19:01:42.471: INFO: (10) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 14.265719ms)
Oct  7 19:01:42.471: INFO: (10) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 14.41117ms)
Oct  7 19:01:42.473: INFO: (10) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 16.637623ms)
Oct  7 19:01:42.473: INFO: (10) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 16.979909ms)
Oct  7 19:01:42.474: INFO: (10) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 17.540156ms)
Oct  7 19:01:42.480: INFO: (11) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 6.039205ms)
Oct  7 19:01:42.482: INFO: (11) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 6.715006ms)
Oct  7 19:01:42.484: INFO: (11) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 9.044938ms)
Oct  7 19:01:42.484: INFO: (11) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 9.361553ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.412493ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 9.861969ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 10.001831ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 10.457086ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.830883ms)
Oct  7 19:01:42.485: INFO: (11) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 10.538351ms)
Oct  7 19:01:42.487: INFO: (11) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 12.791235ms)
Oct  7 19:01:42.489: INFO: (11) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 13.629025ms)
Oct  7 19:01:42.489: INFO: (11) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 14.914193ms)
Oct  7 19:01:42.489: INFO: (11) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 14.996226ms)
Oct  7 19:01:42.490: INFO: (11) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 14.359907ms)
Oct  7 19:01:42.490: INFO: (11) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.560474ms)
Oct  7 19:01:42.497: INFO: (12) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 5.937278ms)
Oct  7 19:01:42.500: INFO: (12) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 7.808257ms)
Oct  7 19:01:42.500: INFO: (12) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 8.207374ms)
Oct  7 19:01:42.500: INFO: (12) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 7.981816ms)
Oct  7 19:01:42.502: INFO: (12) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 10.350966ms)
Oct  7 19:01:42.502: INFO: (12) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 11.095068ms)
Oct  7 19:01:42.502: INFO: (12) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 10.197989ms)
Oct  7 19:01:42.502: INFO: (12) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 9.684951ms)
Oct  7 19:01:42.503: INFO: (12) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 11.408181ms)
Oct  7 19:01:42.505: INFO: (12) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 12.454001ms)
Oct  7 19:01:42.505: INFO: (12) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 13.947486ms)
Oct  7 19:01:42.505: INFO: (12) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 12.83638ms)
Oct  7 19:01:42.506: INFO: (12) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 13.62554ms)
Oct  7 19:01:42.507: INFO: (12) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 14.113467ms)
Oct  7 19:01:42.507: INFO: (12) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 14.159689ms)
Oct  7 19:01:42.507: INFO: (12) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 14.449988ms)
Oct  7 19:01:42.520: INFO: (13) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 10.658485ms)
Oct  7 19:01:42.520: INFO: (13) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 10.953383ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 12.368789ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.075127ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 12.480565ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 12.454118ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 14.195668ms)
Oct  7 19:01:42.522: INFO: (13) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 12.628194ms)
Oct  7 19:01:42.523: INFO: (13) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 14.673504ms)
Oct  7 19:01:42.523: INFO: (13) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 13.887045ms)
Oct  7 19:01:42.523: INFO: (13) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.82421ms)
Oct  7 19:01:42.523: INFO: (13) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 14.216702ms)
Oct  7 19:01:42.523: INFO: (13) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 14.107835ms)
Oct  7 19:01:42.524: INFO: (13) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 14.097027ms)
Oct  7 19:01:42.525: INFO: (13) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 16.398515ms)
Oct  7 19:01:42.526: INFO: (13) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 17.071042ms)
Oct  7 19:01:42.534: INFO: (14) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 7.863694ms)
Oct  7 19:01:42.534: INFO: (14) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 7.692937ms)
Oct  7 19:01:42.534: INFO: (14) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 8.260093ms)
Oct  7 19:01:42.536: INFO: (14) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 9.575754ms)
Oct  7 19:01:42.536: INFO: (14) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 9.503553ms)
Oct  7 19:01:42.537: INFO: (14) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 10.107577ms)
Oct  7 19:01:42.539: INFO: (14) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.14492ms)
Oct  7 19:01:42.539: INFO: (14) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 12.279407ms)
Oct  7 19:01:42.539: INFO: (14) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.372033ms)
Oct  7 19:01:42.539: INFO: (14) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 12.661916ms)
Oct  7 19:01:42.539: INFO: (14) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 12.295168ms)
Oct  7 19:01:42.541: INFO: (14) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 13.685275ms)
Oct  7 19:01:42.541: INFO: (14) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 13.684263ms)
Oct  7 19:01:42.541: INFO: (14) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 13.768176ms)
Oct  7 19:01:42.541: INFO: (14) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 14.122008ms)
Oct  7 19:01:42.541: INFO: (14) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 13.753543ms)
Oct  7 19:01:42.549: INFO: (15) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 6.139343ms)
Oct  7 19:01:42.554: INFO: (15) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 10.440918ms)
Oct  7 19:01:42.556: INFO: (15) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 12.877824ms)
Oct  7 19:01:42.556: INFO: (15) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 12.329781ms)
Oct  7 19:01:42.556: INFO: (15) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 12.859387ms)
Oct  7 19:01:42.556: INFO: (15) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 12.214942ms)
Oct  7 19:01:42.558: INFO: (15) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 14.639164ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 14.740389ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 15.979754ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 14.816062ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 14.984315ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 14.879682ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 15.39059ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 15.355571ms)
Oct  7 19:01:42.560: INFO: (15) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 15.964553ms)
Oct  7 19:01:42.559: INFO: (15) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 14.981558ms)
Oct  7 19:01:42.574: INFO: (16) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 13.11796ms)
Oct  7 19:01:42.574: INFO: (16) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 12.663879ms)
Oct  7 19:01:42.575: INFO: (16) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 13.772205ms)
Oct  7 19:01:42.576: INFO: (16) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 14.504702ms)
Oct  7 19:01:42.576: INFO: (16) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 15.179499ms)
Oct  7 19:01:42.576: INFO: (16) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 14.762358ms)
Oct  7 19:01:42.576: INFO: (16) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 14.431343ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 15.234771ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 15.414935ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 15.373127ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 16.008955ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 15.789238ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 16.743524ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 16.081161ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 16.09369ms)
Oct  7 19:01:42.577: INFO: (16) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 16.67439ms)
Oct  7 19:01:42.588: INFO: (17) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 9.246353ms)
Oct  7 19:01:42.591: INFO: (17) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 11.622559ms)
Oct  7 19:01:42.592: INFO: (17) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 11.448688ms)
Oct  7 19:01:42.592: INFO: (17) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 11.517041ms)
Oct  7 19:01:42.593: INFO: (17) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 12.736435ms)
Oct  7 19:01:42.593: INFO: (17) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 12.720967ms)
Oct  7 19:01:42.594: INFO: (17) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 14.082124ms)
Oct  7 19:01:42.595: INFO: (17) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 14.89764ms)
Oct  7 19:01:42.595: INFO: (17) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 14.849549ms)
Oct  7 19:01:42.595: INFO: (17) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.939219ms)
Oct  7 19:01:42.595: INFO: (17) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 15.121761ms)
Oct  7 19:01:42.598: INFO: (17) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 17.699475ms)
Oct  7 19:01:42.599: INFO: (17) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 18.923008ms)
Oct  7 19:01:42.599: INFO: (17) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 18.914783ms)
Oct  7 19:01:42.599: INFO: (17) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 19.325378ms)
Oct  7 19:01:42.599: INFO: (17) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 19.272375ms)
Oct  7 19:01:42.607: INFO: (18) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 7.132314ms)
Oct  7 19:01:42.608: INFO: (18) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 7.851251ms)
Oct  7 19:01:42.609: INFO: (18) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 7.286967ms)
Oct  7 19:01:42.610: INFO: (18) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 8.390757ms)
Oct  7 19:01:42.610: INFO: (18) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 8.623512ms)
Oct  7 19:01:42.610: INFO: (18) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.726452ms)
Oct  7 19:01:42.610: INFO: (18) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 9.452262ms)
Oct  7 19:01:42.611: INFO: (18) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.325155ms)
Oct  7 19:01:42.611: INFO: (18) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.256026ms)
Oct  7 19:01:42.611: INFO: (18) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 10.762501ms)
Oct  7 19:01:42.614: INFO: (18) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 13.685328ms)
Oct  7 19:01:42.616: INFO: (18) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 15.15879ms)
Oct  7 19:01:42.616: INFO: (18) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 15.474006ms)
Oct  7 19:01:42.617: INFO: (18) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 15.464003ms)
Oct  7 19:01:42.617: INFO: (18) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 15.863337ms)
Oct  7 19:01:42.617: INFO: (18) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 15.535243ms)
Oct  7 19:01:42.625: INFO: (19) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:460/proxy/: tls baz (200; 7.373151ms)
Oct  7 19:01:42.626: INFO: (19) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">... (200; 7.612428ms)
Oct  7 19:01:42.627: INFO: (19) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 8.644374ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:160/proxy/: foo (200; 9.776986ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:1080/proxy/rewriteme">test<... (200; 9.79569ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 9.8747ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/http:proxy-service-wczhm-sqqbl:162/proxy/: bar (200; 10.150397ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:462/proxy/: tls qux (200; 10.274004ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/https:proxy-service-wczhm-sqqbl:443/proxy/tlsrewritem... (200; 10.32089ms)
Oct  7 19:01:42.628: INFO: (19) /api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/: <a href="/api/v1/namespaces/proxy-2102/pods/proxy-service-wczhm-sqqbl/proxy/rewriteme">test</a> (200; 10.446825ms)
Oct  7 19:01:42.631: INFO: (19) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname2/proxy/: bar (200; 12.807899ms)
Oct  7 19:01:42.633: INFO: (19) /api/v1/namespaces/proxy-2102/services/http:proxy-service-wczhm:portname1/proxy/: foo (200; 14.462638ms)
Oct  7 19:01:42.633: INFO: (19) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname1/proxy/: foo (200; 14.815511ms)
Oct  7 19:01:42.634: INFO: (19) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname2/proxy/: tls qux (200; 15.426461ms)
Oct  7 19:01:42.634: INFO: (19) /api/v1/namespaces/proxy-2102/services/https:proxy-service-wczhm:tlsportname1/proxy/: tls baz (200; 15.740968ms)
Oct  7 19:01:42.635: INFO: (19) /api/v1/namespaces/proxy-2102/services/proxy-service-wczhm:portname2/proxy/: bar (200; 16.215408ms)
STEP: deleting ReplicationController proxy-service-wczhm in namespace proxy-2102, will wait for the garbage collector to delete the pods
Oct  7 19:01:42.698: INFO: Deleting ReplicationController proxy-service-wczhm took: 9.550374ms
Oct  7 19:01:42.998: INFO: Terminating ReplicationController proxy-service-wczhm pods took: 300.250814ms
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:01:44.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2102" for this suite.
Oct  7 19:01:50.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:01:50.511: INFO: namespace proxy-2102 deletion completed in 6.108374854s

• [SLOW TEST:20.518 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:01:50.512: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:01:51.168: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:01:54.209: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:02:06.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2385" for this suite.
Oct  7 19:02:12.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:02:12.508: INFO: namespace webhook-2385 deletion completed in 6.097824961s
STEP: Destroying namespace "webhook-2385-markers" for this suite.
Oct  7 19:02:18.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:02:18.622: INFO: namespace webhook-2385-markers deletion completed in 6.114021606s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.125 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:02:18.642: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6645
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Oct  7 19:02:18.837: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 19:02:22.294: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:02:33.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6645" for this suite.
Oct  7 19:02:39.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:02:39.168: INFO: namespace crd-publish-openapi-6645 deletion completed in 6.093452205s

• [SLOW TEST:20.526 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:02:39.168: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:02:39.382: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"a9fe82ae-d46a-42a1-afff-09fe73557fbd", Controller:(*bool)(0xc0044eba06), BlockOwnerDeletion:(*bool)(0xc0044eba07)}}
Oct  7 19:02:39.388: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"449c75fc-10bc-4cdd-9d81-53fcee4fd776", Controller:(*bool)(0xc0048ce766), BlockOwnerDeletion:(*bool)(0xc0048ce767)}}
Oct  7 19:02:39.397: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"17b4a62f-58e5-4d43-a012-d541d36ef708", Controller:(*bool)(0xc0044ebc76), BlockOwnerDeletion:(*bool)(0xc0044ebc77)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:02:44.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7945" for this suite.
Oct  7 19:02:50.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:02:50.494: INFO: namespace gc-7945 deletion completed in 6.082068142s

• [SLOW TEST:11.326 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:02:50.496: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7567a96e-6df1-4355-b179-c9e87988fd6d
STEP: Creating a pod to test consume configMaps
Oct  7 19:02:50.671: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d" in namespace "projected-7664" to be "success or failure"
Oct  7 19:02:50.674: INFO: Pod "pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.042395ms
Oct  7 19:02:52.678: INFO: Pod "pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007165312s
STEP: Saw pod success
Oct  7 19:02:52.678: INFO: Pod "pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d" satisfied condition "success or failure"
Oct  7 19:02:52.682: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 19:02:52.729: INFO: Waiting for pod pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d to disappear
Oct  7 19:02:52.732: INFO: Pod pod-projected-configmaps-ff8849c4-5c39-47fc-b468-14b9b678a27d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:02:52.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7664" for this suite.
Oct  7 19:02:58.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:02:58.818: INFO: namespace projected-7664 deletion completed in 6.082210961s

• [SLOW TEST:8.321 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:02:58.818: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-87
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-87.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-87.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-87.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-87.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-87.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 35.146.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.146.35_udp@PTR;check="$$(dig +tcp +noall +answer +search 35.146.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.146.35_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-87.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-87.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-87.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-87.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-87.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-87.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-87.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 35.146.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.146.35_udp@PTR;check="$$(dig +tcp +noall +answer +search 35.146.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.146.35_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 19:03:03.035: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.040: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.044: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.047: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.069: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.072: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.075: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.078: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:03.098: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:08.103: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.107: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.111: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.114: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.135: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.138: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.145: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.148: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:08.167: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:13.103: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.107: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.110: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.114: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.136: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.141: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.145: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.148: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:13.168: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:18.102: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.113: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.117: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.138: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.141: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.145: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.147: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:18.170: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:23.102: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.106: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.109: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.112: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.134: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.137: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.140: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.143: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:23.161: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:28.102: INFO: Unable to read wheezy_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.114: INFO: Unable to read wheezy_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.118: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.121: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.145: INFO: Unable to read jessie_udp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.148: INFO: Unable to read jessie_tcp@dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.152: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.155: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local from pod dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10: the server could not find the requested resource (get pods dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10)
Oct  7 19:03:28.173: INFO: Lookups using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 failed for: [wheezy_udp@dns-test-service.dns-87.svc.cluster.local wheezy_tcp@dns-test-service.dns-87.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_udp@dns-test-service.dns-87.svc.cluster.local jessie_tcp@dns-test-service.dns-87.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-87.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-87.svc.cluster.local]

Oct  7 19:03:33.166: INFO: DNS probes using dns-87/dns-test-2ab39941-2abc-41dd-8497-bf49fbbf7d10 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:03:33.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-87" for this suite.
Oct  7 19:03:39.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:03:39.382: INFO: namespace dns-87 deletion completed in 6.093736182s

• [SLOW TEST:40.564 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:03:39.383: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-e246e399-6190-4905-aad0-befc975f96c0
STEP: Creating a pod to test consume secrets
Oct  7 19:03:39.562: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542" in namespace "projected-7811" to be "success or failure"
Oct  7 19:03:39.565: INFO: Pod "pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542": Phase="Pending", Reason="", readiness=false. Elapsed: 3.017355ms
Oct  7 19:03:41.568: INFO: Pod "pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006389853s
STEP: Saw pod success
Oct  7 19:03:41.568: INFO: Pod "pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542" satisfied condition "success or failure"
Oct  7 19:03:41.571: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542 container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:03:41.591: INFO: Waiting for pod pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542 to disappear
Oct  7 19:03:41.593: INFO: Pod pod-projected-secrets-46d8b5b2-199b-4522-9862-099fad5f6542 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:03:41.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7811" for this suite.
Oct  7 19:03:47.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:03:47.677: INFO: namespace projected-7811 deletion completed in 6.080793571s

• [SLOW TEST:8.294 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:03:47.678: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9905
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:03:47.863: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Oct  7 19:03:49.914: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:03:50.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9905" for this suite.
Oct  7 19:03:56.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:03:57.015: INFO: namespace replication-controller-9905 deletion completed in 6.088994418s

• [SLOW TEST:9.337 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:03:57.016: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Oct  7 19:03:57.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:57.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:57.221: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:57.226: INFO: Number of nodes with available pods: 0
Oct  7 19:03:57.226: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 19:03:58.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:58.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:58.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:58.233: INFO: Number of nodes with available pods: 0
Oct  7 19:03:58.233: INFO: Node talos-v020-gcp-workers-654f4446bf-clj9s is running more than one daemon pod
Oct  7 19:03:59.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.230: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.238: INFO: Number of nodes with available pods: 3
Oct  7 19:03:59.238: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Oct  7 19:03:59.254: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.254: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.254: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:03:59.257: INFO: Number of nodes with available pods: 2
Oct  7 19:03:59.258: INFO: Node talos-v020-gcp-workers-654f4446bf-ns4sr is running more than one daemon pod
Oct  7 19:04:00.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:00.264: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:00.264: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:00.268: INFO: Number of nodes with available pods: 2
Oct  7 19:04:00.268: INFO: Node talos-v020-gcp-workers-654f4446bf-ns4sr is running more than one daemon pod
Oct  7 19:04:01.262: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:01.262: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:01.262: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:01.265: INFO: Number of nodes with available pods: 2
Oct  7 19:04:01.265: INFO: Node talos-v020-gcp-workers-654f4446bf-ns4sr is running more than one daemon pod
Oct  7 19:04:02.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:02.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:02.264: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:02.267: INFO: Number of nodes with available pods: 2
Oct  7 19:04:02.267: INFO: Node talos-v020-gcp-workers-654f4446bf-ns4sr is running more than one daemon pod
Oct  7 19:04:03.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:03.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:03.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:03.267: INFO: Number of nodes with available pods: 2
Oct  7 19:04:03.267: INFO: Node talos-v020-gcp-workers-654f4446bf-ns4sr is running more than one daemon pod
Oct  7 19:04:04.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:04.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:04.263: INFO: DaemonSet pods can't tolerate node talos-v020-gcp-master-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Oct  7 19:04:04.267: INFO: Number of nodes with available pods: 3
Oct  7 19:04:04.267: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8650, will wait for the garbage collector to delete the pods
Oct  7 19:04:04.335: INFO: Deleting DaemonSet.extensions daemon-set took: 10.48828ms
Oct  7 19:04:04.435: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.199145ms
Oct  7 19:04:14.241: INFO: Number of nodes with available pods: 0
Oct  7 19:04:14.241: INFO: Number of running nodes: 0, number of available pods: 0
Oct  7 19:04:14.244: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8650/daemonsets","resourceVersion":"25052"},"items":null}

Oct  7 19:04:14.247: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8650/pods","resourceVersion":"25052"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:04:14.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8650" for this suite.
Oct  7 19:04:20.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:04:20.341: INFO: namespace daemonsets-8650 deletion completed in 6.079679965s

• [SLOW TEST:23.326 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:04:20.342: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6659
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6659
STEP: creating replication controller externalsvc in namespace services-6659
I1007 19:04:20.582757      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6659, replica count: 2
I1007 19:04:23.634317      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Oct  7 19:04:23.685: INFO: Creating new exec pod
Oct  7 19:04:25.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-6659 execpod8mmb9 -- /bin/sh -x -c nslookup clusterip-service'
Oct  7 19:04:25.988: INFO: stderr: "+ nslookup clusterip-service\n"
Oct  7 19:04:25.988: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-6659.svc.cluster.local\tcanonical name = externalsvc.services-6659.svc.cluster.local.\nName:\texternalsvc.services-6659.svc.cluster.local\nAddress: 10.106.80.251\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6659, will wait for the garbage collector to delete the pods
Oct  7 19:04:26.051: INFO: Deleting ReplicationController externalsvc took: 9.16933ms
Oct  7 19:04:26.352: INFO: Terminating ReplicationController externalsvc pods took: 300.219583ms
Oct  7 19:04:33.406: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:04:33.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6659" for this suite.
Oct  7 19:04:39.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:04:39.541: INFO: namespace services-6659 deletion completed in 6.107520689s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.200 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:04:39.542: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac
Oct  7 19:04:39.733: INFO: Pod name my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac: Found 0 pods out of 1
Oct  7 19:04:44.737: INFO: Pod name my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac: Found 1 pods out of 1
Oct  7 19:04:44.737: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac" are running
Oct  7 19:04:44.740: INFO: Pod "my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac-mz4cp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 19:04:39 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 19:04:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 19:04:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-10-07 19:04:39 +0000 UTC Reason: Message:}])
Oct  7 19:04:44.740: INFO: Trying to dial the pod
Oct  7 19:04:49.756: INFO: Controller my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac: Got expected result from replica 1 [my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac-mz4cp]: "my-hostname-basic-36303789-2dc7-466d-936c-1277ae9a4dac-mz4cp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:04:49.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6421" for this suite.
Oct  7 19:04:55.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:04:55.868: INFO: namespace replication-controller-6421 deletion completed in 6.107161101s

• [SLOW TEST:16.326 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:04:55.868: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9382.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-9382.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9382.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-9382.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-9382.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9382.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 19:04:58.133: INFO: DNS probes using dns-9382/dns-test-2505967e-7e60-49b3-943a-ba9282c1d20a succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:04:58.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9382" for this suite.
Oct  7 19:05:04.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:04.258: INFO: namespace dns-9382 deletion completed in 6.082615919s

• [SLOW TEST:8.389 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:04.258: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-622
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:05:04.417: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Oct  7 19:05:07.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-622 create -f -'
Oct  7 19:05:08.206: INFO: stderr: ""
Oct  7 19:05:08.206: INFO: stdout: "e2e-test-crd-publish-openapi-313-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  7 19:05:08.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-622 delete e2e-test-crd-publish-openapi-313-crds test-cr'
Oct  7 19:05:08.332: INFO: stderr: ""
Oct  7 19:05:08.332: INFO: stdout: "e2e-test-crd-publish-openapi-313-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Oct  7 19:05:08.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-622 apply -f -'
Oct  7 19:05:08.594: INFO: stderr: ""
Oct  7 19:05:08.594: INFO: stdout: "e2e-test-crd-publish-openapi-313-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Oct  7 19:05:08.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-622 delete e2e-test-crd-publish-openapi-313-crds test-cr'
Oct  7 19:05:08.732: INFO: stderr: ""
Oct  7 19:05:08.732: INFO: stdout: "e2e-test-crd-publish-openapi-313-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Oct  7 19:05:08.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-313-crds'
Oct  7 19:05:08.988: INFO: stderr: ""
Oct  7 19:05:08.988: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-313-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:05:11.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-622" for this suite.
Oct  7 19:05:18.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:18.087: INFO: namespace crd-publish-openapi-622 deletion completed in 6.100612675s

• [SLOW TEST:13.829 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:18.088: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6132
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:05:18.293: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662" in namespace "downward-api-6132" to be "success or failure"
Oct  7 19:05:18.297: INFO: Pod "downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662": Phase="Pending", Reason="", readiness=false. Elapsed: 3.180225ms
Oct  7 19:05:20.301: INFO: Pod "downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007840666s
STEP: Saw pod success
Oct  7 19:05:20.302: INFO: Pod "downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662" satisfied condition "success or failure"
Oct  7 19:05:20.304: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662 container client-container: <nil>
STEP: delete the pod
Oct  7 19:05:20.338: INFO: Waiting for pod downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662 to disappear
Oct  7 19:05:20.341: INFO: Pod downwardapi-volume-74001ef6-1ad4-43d1-bb74-30163d2a0662 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:05:20.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6132" for this suite.
Oct  7 19:05:26.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:26.431: INFO: namespace downward-api-6132 deletion completed in 6.086261759s

• [SLOW TEST:8.343 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:26.432: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:05:26.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551" in namespace "projected-744" to be "success or failure"
Oct  7 19:05:26.604: INFO: Pod "downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551": Phase="Pending", Reason="", readiness=false. Elapsed: 3.186122ms
Oct  7 19:05:28.607: INFO: Pod "downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006857605s
STEP: Saw pod success
Oct  7 19:05:28.607: INFO: Pod "downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551" satisfied condition "success or failure"
Oct  7 19:05:28.610: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551 container client-container: <nil>
STEP: delete the pod
Oct  7 19:05:28.630: INFO: Waiting for pod downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551 to disappear
Oct  7 19:05:28.633: INFO: Pod downwardapi-volume-05a03259-2558-4f0b-91f5-857dd9095551 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:05:28.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-744" for this suite.
Oct  7 19:05:34.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:34.725: INFO: namespace projected-744 deletion completed in 6.086994712s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:34.728: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8366
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:05:35.759: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:05:38.788: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:05:39.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8366" for this suite.
Oct  7 19:05:45.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:45.126: INFO: namespace webhook-8366 deletion completed in 6.088913257s
STEP: Destroying namespace "webhook-8366-markers" for this suite.
Oct  7 19:05:51.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:51.209: INFO: namespace webhook-8366-markers deletion completed in 6.082614492s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.495 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:51.225: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-9369/secret-test-b7ea8f3e-c6c5-48c5-8417-a8e926d65e17
STEP: Creating a pod to test consume secrets
Oct  7 19:05:51.418: INFO: Waiting up to 5m0s for pod "pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4" in namespace "secrets-9369" to be "success or failure"
Oct  7 19:05:51.422: INFO: Pod "pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.410798ms
Oct  7 19:05:53.426: INFO: Pod "pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007654974s
STEP: Saw pod success
Oct  7 19:05:53.427: INFO: Pod "pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4" satisfied condition "success or failure"
Oct  7 19:05:53.429: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4 container env-test: <nil>
STEP: delete the pod
Oct  7 19:05:53.469: INFO: Waiting for pod pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4 to disappear
Oct  7 19:05:53.474: INFO: Pod pod-configmaps-a887c96d-7b1d-4f92-80f7-32128aa3adf4 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:05:53.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9369" for this suite.
Oct  7 19:05:59.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:05:59.560: INFO: namespace secrets-9369 deletion completed in 6.081408297s

• [SLOW TEST:8.336 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:05:59.563: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1717
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct  7 19:05:59.738: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:06:14.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1717" for this suite.
Oct  7 19:06:20.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:06:21.020: INFO: namespace crd-publish-openapi-1717 deletion completed in 6.079722993s

• [SLOW TEST:21.457 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:06:21.020: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-5421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-5421
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5421
STEP: Deleting pre-stop pod
Oct  7 19:06:30.231: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:06:30.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5421" for this suite.
Oct  7 19:07:14.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:07:14.322: INFO: namespace prestop-5421 deletion completed in 44.079065062s

• [SLOW TEST:53.302 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:07:14.322: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7426
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Oct  7 19:07:14.495: INFO: Waiting up to 5m0s for pod "pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62" in namespace "emptydir-7426" to be "success or failure"
Oct  7 19:07:14.498: INFO: Pod "pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.299811ms
Oct  7 19:07:16.502: INFO: Pod "pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006263134s
STEP: Saw pod success
Oct  7 19:07:16.502: INFO: Pod "pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62" satisfied condition "success or failure"
Oct  7 19:07:16.505: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62 container test-container: <nil>
STEP: delete the pod
Oct  7 19:07:16.524: INFO: Waiting for pod pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62 to disappear
Oct  7 19:07:16.527: INFO: Pod pod-4e37051e-d071-4ca0-a0a5-adecc66b4e62 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:07:16.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7426" for this suite.
Oct  7 19:07:22.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:07:22.611: INFO: namespace emptydir-7426 deletion completed in 6.0808899s

• [SLOW TEST:8.289 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:07:22.612: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-3be052df-ba7f-4be7-8bc7-62fb1ac241db in namespace container-probe-6602
Oct  7 19:07:24.804: INFO: Started pod busybox-3be052df-ba7f-4be7-8bc7-62fb1ac241db in namespace container-probe-6602
STEP: checking the pod's current state and verifying that restartCount is present
Oct  7 19:07:24.807: INFO: Initial restart count of pod busybox-3be052df-ba7f-4be7-8bc7-62fb1ac241db is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:11:25.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6602" for this suite.
Oct  7 19:11:31.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:11:31.413: INFO: namespace container-probe-6602 deletion completed in 6.075532357s

• [SLOW TEST:248.746 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:11:31.415: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-8463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Oct  7 19:11:31.587: INFO: Waiting up to 1m0s for all nodes to be ready
Oct  7 19:12:31.604: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:12:31.607: INFO: Starting informer...
STEP: Starting pods...
Oct  7 19:12:31.825: INFO: Pod1 is running on talos-v020-gcp-workers-654f4446bf-ns4sr. Tainting Node
Oct  7 19:12:34.046: INFO: Pod2 is running on talos-v020-gcp-workers-654f4446bf-ns4sr. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Oct  7 19:12:40.574: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Oct  7 19:13:00.608: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:13:00.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8463" for this suite.
Oct  7 19:13:06.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:13:06.709: INFO: namespace taint-multiple-pods-8463 deletion completed in 6.081777031s

• [SLOW TEST:95.293 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:13:06.710: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Oct  7 19:13:06.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-8123'
Oct  7 19:13:07.230: INFO: stderr: ""
Oct  7 19:13:07.230: INFO: stdout: "pod/pause created\n"
Oct  7 19:13:07.230: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Oct  7 19:13:07.230: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8123" to be "running and ready"
Oct  7 19:13:07.235: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.269023ms
Oct  7 19:13:09.239: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.008849244s
Oct  7 19:13:09.239: INFO: Pod "pause" satisfied condition "running and ready"
Oct  7 19:13:09.239: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Oct  7 19:13:09.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 label pods pause testing-label=testing-label-value --namespace=kubectl-8123'
Oct  7 19:13:09.335: INFO: stderr: ""
Oct  7 19:13:09.335: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Oct  7 19:13:09.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pod pause -L testing-label --namespace=kubectl-8123'
Oct  7 19:13:09.413: INFO: stderr: ""
Oct  7 19:13:09.413: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Oct  7 19:13:09.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 label pods pause testing-label- --namespace=kubectl-8123'
Oct  7 19:13:09.516: INFO: stderr: ""
Oct  7 19:13:09.516: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Oct  7 19:13:09.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pod pause -L testing-label --namespace=kubectl-8123'
Oct  7 19:13:09.595: INFO: stderr: ""
Oct  7 19:13:09.595: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Oct  7 19:13:09.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete --grace-period=0 --force -f - --namespace=kubectl-8123'
Oct  7 19:13:09.681: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Oct  7 19:13:09.681: INFO: stdout: "pod \"pause\" force deleted\n"
Oct  7 19:13:09.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get rc,svc -l name=pause --no-headers --namespace=kubectl-8123'
Oct  7 19:13:09.770: INFO: stderr: "No resources found in kubectl-8123 namespace.\n"
Oct  7 19:13:09.770: INFO: stdout: ""
Oct  7 19:13:09.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -l name=pause --namespace=kubectl-8123 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Oct  7 19:13:09.851: INFO: stderr: ""
Oct  7 19:13:09.851: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:13:09.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8123" for this suite.
Oct  7 19:13:15.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:13:15.935: INFO: namespace kubectl-8123 deletion completed in 6.079824552s

• [SLOW TEST:9.225 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:13:15.935: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4422
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Oct  7 19:13:16.104: INFO: Pod name pod-release: Found 0 pods out of 1
Oct  7 19:13:21.108: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:13:22.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4422" for this suite.
Oct  7 19:13:28.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:13:28.239: INFO: namespace replication-controller-4422 deletion completed in 6.103224342s

• [SLOW TEST:12.304 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:13:28.240: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  7 19:13:30.974: INFO: Successfully updated pod "labelsupdate9328fdf7-60ac-418c-b457-d41a3c3cd0e6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:13:35.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7466" for this suite.
Oct  7 19:13:47.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:13:47.099: INFO: namespace downward-api-7466 deletion completed in 12.077001657s

• [SLOW TEST:18.859 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:13:47.099: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:13:47.252: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:13:49.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-400" for this suite.
Oct  7 19:14:33.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:14:33.568: INFO: namespace pods-400 deletion completed in 44.097516915s

• [SLOW TEST:46.469 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:14:33.569: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:14:34.058: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Oct  7 19:14:36.067: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706072474, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706072474, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706072474, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706072474, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:14:39.089: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:14:39.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8225" for this suite.
Oct  7 19:14:45.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:14:45.249: INFO: namespace webhook-8225 deletion completed in 6.087167631s
STEP: Destroying namespace "webhook-8225-markers" for this suite.
Oct  7 19:14:51.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:14:51.338: INFO: namespace webhook-8225-markers deletion completed in 6.088787517s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.783 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:14:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-64
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Oct  7 19:14:51.533: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27129 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Oct  7 19:14:51.533: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27130 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Oct  7 19:14:51.534: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27131 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Oct  7 19:15:01.569: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27152 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Oct  7 19:15:01.570: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27153 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Oct  7 19:15:01.570: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-64 /api/v1/namespaces/watch-64/configmaps/e2e-watch-test-label-changed ffb50bba-1c55-4888-9254-9a3d7b113115 27154 0 2019-10-07 19:14:51 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:15:01.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-64" for this suite.
Oct  7 19:15:07.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:15:07.650: INFO: namespace watch-64 deletion completed in 6.075667094s

• [SLOW TEST:16.297 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:15:07.650: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5729
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  7 19:15:07.811: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:15:10.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5729" for this suite.
Oct  7 19:15:32.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:15:32.978: INFO: namespace init-container-5729 deletion completed in 22.084301555s

• [SLOW TEST:25.327 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:15:32.979: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Oct  7 19:15:33.187: INFO: Waiting up to 5m0s for pod "pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e" in namespace "emptydir-2365" to be "success or failure"
Oct  7 19:15:33.191: INFO: Pod "pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.408545ms
Oct  7 19:15:35.195: INFO: Pod "pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007552661s
STEP: Saw pod success
Oct  7 19:15:35.195: INFO: Pod "pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e" satisfied condition "success or failure"
Oct  7 19:15:35.198: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e container test-container: <nil>
STEP: delete the pod
Oct  7 19:15:35.232: INFO: Waiting for pod pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e to disappear
Oct  7 19:15:35.234: INFO: Pod pod-5db11df3-4be2-45e5-9fe7-8f34d3afb93e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:15:35.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2365" for this suite.
Oct  7 19:15:41.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:15:41.325: INFO: namespace emptydir-2365 deletion completed in 6.086369809s

• [SLOW TEST:8.346 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:15:41.326: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4089.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4089.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4089.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 19:15:43.541: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.545: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.548: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.552: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.562: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.566: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.570: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.573: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:43.579: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:15:48.584: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.588: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.591: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.594: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.603: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.606: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.610: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.612: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:48.622: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:15:53.584: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.588: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.592: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.596: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.608: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.612: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.617: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.620: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:53.628: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:15:58.584: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.589: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.593: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.598: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.626: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.630: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.634: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.637: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:15:58.643: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:16:03.584: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.588: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.591: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.595: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.604: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.608: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.611: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.614: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:03.621: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:16:08.584: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.587: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.591: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.595: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.604: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.607: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.610: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.614: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:08.620: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4089.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:16:13.603: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:13.606: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:13.609: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:13.612: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local from pod dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd: the server could not find the requested resource (get pods dns-test-23f75b78-ce25-446f-8c13-0819842718fd)
Oct  7 19:16:13.619: INFO: Lookups using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd failed for: [jessie_udp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4089.svc.cluster.local jessie_udp@dns-test-service-2.dns-4089.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4089.svc.cluster.local]

Oct  7 19:16:18.634: INFO: DNS probes using dns-4089/dns-test-23f75b78-ce25-446f-8c13-0819842718fd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:16:18.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4089" for this suite.
Oct  7 19:16:24.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:16:24.767: INFO: namespace dns-4089 deletion completed in 6.084573967s

• [SLOW TEST:43.441 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:16:24.767: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8152
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-12df954e-e31e-4d01-b0f1-03090e641bcb
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-12df954e-e31e-4d01-b0f1-03090e641bcb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:16:29.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8152" for this suite.
Oct  7 19:16:47.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:16:47.091: INFO: namespace configmap-8152 deletion completed in 18.078062355s

• [SLOW TEST:22.324 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:16:47.092: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:16:47.273: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6" in namespace "downward-api-1466" to be "success or failure"
Oct  7 19:16:47.276: INFO: Pod "downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.871226ms
Oct  7 19:16:49.280: INFO: Pod "downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007132462s
STEP: Saw pod success
Oct  7 19:16:49.281: INFO: Pod "downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6" satisfied condition "success or failure"
Oct  7 19:16:49.284: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6 container client-container: <nil>
STEP: delete the pod
Oct  7 19:16:49.309: INFO: Waiting for pod downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6 to disappear
Oct  7 19:16:49.311: INFO: Pod downwardapi-volume-22d0f272-ef86-49e6-959e-1b456ffdeba6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:16:49.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1466" for this suite.
Oct  7 19:16:55.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:16:55.407: INFO: namespace downward-api-1466 deletion completed in 6.091958143s

• [SLOW TEST:8.315 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:16:55.410: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-690
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 19:16:55.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-690'
Oct  7 19:16:56.221: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  7 19:16:56.221: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Oct  7 19:16:58.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete deployment e2e-test-httpd-deployment --namespace=kubectl-690'
Oct  7 19:16:58.324: INFO: stderr: ""
Oct  7 19:16:58.324: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:16:58.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-690" for this suite.
Oct  7 19:17:10.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:17:10.413: INFO: namespace kubectl-690 deletion completed in 12.081540843s

• [SLOW TEST:15.003 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:17:10.413: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-b355f876-68af-43aa-98f8-69d70c98d8da
STEP: Creating a pod to test consume configMaps
Oct  7 19:17:10.597: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73" in namespace "projected-6835" to be "success or failure"
Oct  7 19:17:10.600: INFO: Pod "pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.776879ms
Oct  7 19:17:12.604: INFO: Pod "pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006740129s
STEP: Saw pod success
Oct  7 19:17:12.604: INFO: Pod "pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73" satisfied condition "success or failure"
Oct  7 19:17:12.607: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 19:17:12.629: INFO: Waiting for pod pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73 to disappear
Oct  7 19:17:12.632: INFO: Pod pod-projected-configmaps-11d60b76-4fc5-4eef-964d-5efd3644cf73 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:17:12.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6835" for this suite.
Oct  7 19:17:18.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:17:18.724: INFO: namespace projected-6835 deletion completed in 6.087887797s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:17:18.724: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Oct  7 19:17:21.420: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c279f49d-a04b-4789-be69-a66f2ee07c26"
Oct  7 19:17:21.420: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c279f49d-a04b-4789-be69-a66f2ee07c26" in namespace "pods-9818" to be "terminated due to deadline exceeded"
Oct  7 19:17:21.423: INFO: Pod "pod-update-activedeadlineseconds-c279f49d-a04b-4789-be69-a66f2ee07c26": Phase="Running", Reason="", readiness=true. Elapsed: 2.700557ms
Oct  7 19:17:23.426: INFO: Pod "pod-update-activedeadlineseconds-c279f49d-a04b-4789-be69-a66f2ee07c26": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.006510611s
Oct  7 19:17:23.427: INFO: Pod "pod-update-activedeadlineseconds-c279f49d-a04b-4789-be69-a66f2ee07c26" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:17:23.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9818" for this suite.
Oct  7 19:17:29.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:17:29.514: INFO: namespace pods-9818 deletion completed in 6.083812711s

• [SLOW TEST:10.790 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:17:29.516: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8390
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Oct  7 19:17:29.677: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Oct  7 19:17:41.183: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
Oct  7 19:17:44.153: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:17:55.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8390" for this suite.
Oct  7 19:18:01.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:18:01.782: INFO: namespace crd-publish-openapi-8390 deletion completed in 6.08760831s

• [SLOW TEST:32.213 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:18:01.783: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:18:13.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7005" for this suite.
Oct  7 19:18:19.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:18:19.133: INFO: namespace resourcequota-7005 deletion completed in 6.0809892s

• [SLOW TEST:17.351 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:18:19.134: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2393
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Oct  7 19:18:19.299: INFO: Waiting up to 5m0s for pod "pod-9b42cdc2-d994-4188-8939-f07a8b4274c7" in namespace "emptydir-2393" to be "success or failure"
Oct  7 19:18:19.302: INFO: Pod "pod-9b42cdc2-d994-4188-8939-f07a8b4274c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.595131ms
Oct  7 19:18:21.305: INFO: Pod "pod-9b42cdc2-d994-4188-8939-f07a8b4274c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006419563s
STEP: Saw pod success
Oct  7 19:18:21.306: INFO: Pod "pod-9b42cdc2-d994-4188-8939-f07a8b4274c7" satisfied condition "success or failure"
Oct  7 19:18:21.308: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-9b42cdc2-d994-4188-8939-f07a8b4274c7 container test-container: <nil>
STEP: delete the pod
Oct  7 19:18:21.345: INFO: Waiting for pod pod-9b42cdc2-d994-4188-8939-f07a8b4274c7 to disappear
Oct  7 19:18:21.348: INFO: Pod pod-9b42cdc2-d994-4188-8939-f07a8b4274c7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:18:21.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2393" for this suite.
Oct  7 19:18:27.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:18:27.423: INFO: namespace emptydir-2393 deletion completed in 6.071218339s

• [SLOW TEST:8.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:18:27.423: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  7 19:18:29.603: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:18:29.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5389" for this suite.
Oct  7 19:18:35.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:18:35.750: INFO: namespace container-runtime-5389 deletion completed in 6.070630716s

• [SLOW TEST:8.327 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:18:35.751: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-65wm
STEP: Creating a pod to test atomic-volume-subpath
Oct  7 19:18:35.920: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-65wm" in namespace "subpath-7704" to be "success or failure"
Oct  7 19:18:35.922: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Pending", Reason="", readiness=false. Elapsed: 2.276335ms
Oct  7 19:18:37.926: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 2.005712808s
Oct  7 19:18:39.929: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 4.009114342s
Oct  7 19:18:41.936: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 6.015619424s
Oct  7 19:18:43.940: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 8.019578716s
Oct  7 19:18:45.943: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 10.023506789s
Oct  7 19:18:47.947: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 12.027281195s
Oct  7 19:18:49.951: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 14.031092017s
Oct  7 19:18:51.955: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 16.034676329s
Oct  7 19:18:53.959: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 18.038791981s
Oct  7 19:18:55.962: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Running", Reason="", readiness=true. Elapsed: 20.042288072s
Oct  7 19:18:57.966: INFO: Pod "pod-subpath-test-projected-65wm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.045844469s
STEP: Saw pod success
Oct  7 19:18:57.966: INFO: Pod "pod-subpath-test-projected-65wm" satisfied condition "success or failure"
Oct  7 19:18:57.969: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-subpath-test-projected-65wm container test-container-subpath-projected-65wm: <nil>
STEP: delete the pod
Oct  7 19:18:57.992: INFO: Waiting for pod pod-subpath-test-projected-65wm to disappear
Oct  7 19:18:57.994: INFO: Pod pod-subpath-test-projected-65wm no longer exists
STEP: Deleting pod pod-subpath-test-projected-65wm
Oct  7 19:18:57.994: INFO: Deleting pod "pod-subpath-test-projected-65wm" in namespace "subpath-7704"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:18:57.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7704" for this suite.
Oct  7 19:19:04.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:19:04.071: INFO: namespace subpath-7704 deletion completed in 6.071414109s

• [SLOW TEST:28.321 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:19:04.072: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  7 19:19:06.783: INFO: Successfully updated pod "annotationupdatedc7ece91-d355-47c5-adce-b7fde4324ae2"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:19:10.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9805" for this suite.
Oct  7 19:19:26.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:19:26.883: INFO: namespace projected-9805 deletion completed in 16.075654319s

• [SLOW TEST:22.811 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:19:26.884: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-5481
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:19:27.083: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Creating first CR 
Oct  7 19:19:27.677: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:27Z generation:1 name:name1 resourceVersion:28160 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9f6fa681-a821-4a85-a40e-d286ff887974] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Oct  7 19:19:37.684: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:37Z generation:1 name:name2 resourceVersion:28181 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3212aa68-ea25-4232-84b9-dfae8a107195] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Oct  7 19:19:47.692: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:27Z generation:2 name:name1 resourceVersion:28203 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9f6fa681-a821-4a85-a40e-d286ff887974] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Oct  7 19:19:57.701: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:37Z generation:2 name:name2 resourceVersion:28223 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3212aa68-ea25-4232-84b9-dfae8a107195] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Oct  7 19:20:07.711: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:27Z generation:2 name:name1 resourceVersion:28243 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9f6fa681-a821-4a85-a40e-d286ff887974] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Oct  7 19:20:17.723: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-10-07T19:19:37Z generation:2 name:name2 resourceVersion:28264 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:3212aa68-ea25-4232-84b9-dfae8a107195] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:20:28.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5481" for this suite.
Oct  7 19:20:34.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:20:34.316: INFO: namespace crd-watch-5481 deletion completed in 6.075541375s

• [SLOW TEST:67.432 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:20:34.318: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3189
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Oct  7 19:20:38.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec pod-sharedvolume-43d15ad6-a14b-406c-a824-b5fb681f8e3b -c busybox-main-container --namespace=emptydir-3189 -- cat /usr/share/volumeshare/shareddata.txt'
Oct  7 19:20:38.804: INFO: stderr: ""
Oct  7 19:20:38.804: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:20:38.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3189" for this suite.
Oct  7 19:20:44.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:20:44.903: INFO: namespace emptydir-3189 deletion completed in 6.078873832s

• [SLOW TEST:10.585 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:20:44.903: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3034
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:20:45.647: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:20:48.670: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:20:48.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3034" for this suite.
Oct  7 19:20:54.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:20:54.827: INFO: namespace webhook-3034 deletion completed in 6.078164108s
STEP: Destroying namespace "webhook-3034-markers" for this suite.
Oct  7 19:21:00.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:00.902: INFO: namespace webhook-3034-markers deletion completed in 6.075683326s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.043 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:00.947: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3989
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-d7c621ce-c1ba-481b-8cb4-a59513e24837
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:03.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3989" for this suite.
Oct  7 19:21:15.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:15.249: INFO: namespace configmap-3989 deletion completed in 12.076233487s

• [SLOW TEST:14.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:15.250: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Oct  7 19:21:15.928: INFO: created pod pod-service-account-defaultsa
Oct  7 19:21:15.928: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Oct  7 19:21:15.935: INFO: created pod pod-service-account-mountsa
Oct  7 19:21:15.935: INFO: pod pod-service-account-mountsa service account token volume mount: true
Oct  7 19:21:15.943: INFO: created pod pod-service-account-nomountsa
Oct  7 19:21:15.943: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Oct  7 19:21:15.951: INFO: created pod pod-service-account-defaultsa-mountspec
Oct  7 19:21:15.951: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Oct  7 19:21:15.959: INFO: created pod pod-service-account-mountsa-mountspec
Oct  7 19:21:15.959: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Oct  7 19:21:15.967: INFO: created pod pod-service-account-nomountsa-mountspec
Oct  7 19:21:15.967: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Oct  7 19:21:15.974: INFO: created pod pod-service-account-defaultsa-nomountspec
Oct  7 19:21:15.974: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Oct  7 19:21:15.981: INFO: created pod pod-service-account-mountsa-nomountspec
Oct  7 19:21:15.981: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Oct  7 19:21:15.987: INFO: created pod pod-service-account-nomountsa-nomountspec
Oct  7 19:21:15.987: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:15.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7467" for this suite.
Oct  7 19:21:22.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:22.116: INFO: namespace svcaccounts-7467 deletion completed in 6.118825588s

• [SLOW TEST:6.866 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:22.116: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9285
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Oct  7 19:21:22.281: INFO: Waiting up to 5m0s for pod "client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558" in namespace "containers-9285" to be "success or failure"
Oct  7 19:21:22.283: INFO: Pod "client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558": Phase="Pending", Reason="", readiness=false. Elapsed: 2.820479ms
Oct  7 19:21:24.287: INFO: Pod "client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006449674s
STEP: Saw pod success
Oct  7 19:21:24.287: INFO: Pod "client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558" satisfied condition "success or failure"
Oct  7 19:21:24.290: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558 container test-container: <nil>
STEP: delete the pod
Oct  7 19:21:24.308: INFO: Waiting for pod client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558 to disappear
Oct  7 19:21:24.310: INFO: Pod client-containers-6582a5b1-cddc-4ea3-a092-700f9bf54558 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:24.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9285" for this suite.
Oct  7 19:21:30.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:30.434: INFO: namespace containers-9285 deletion completed in 6.080156467s

• [SLOW TEST:8.318 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:30.435: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4499
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:21:30.611: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:31.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4499" for this suite.
Oct  7 19:21:37.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:37.748: INFO: namespace custom-resource-definition-4499 deletion completed in 6.096729618s

• [SLOW TEST:7.314 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:37.750: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6032
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:21:37.913: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1" in namespace "projected-6032" to be "success or failure"
Oct  7 19:21:37.916: INFO: Pod "downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.463893ms
Oct  7 19:21:39.919: INFO: Pod "downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005966272s
STEP: Saw pod success
Oct  7 19:21:39.920: INFO: Pod "downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1" satisfied condition "success or failure"
Oct  7 19:21:39.922: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1 container client-container: <nil>
STEP: delete the pod
Oct  7 19:21:39.947: INFO: Waiting for pod downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1 to disappear
Oct  7 19:21:39.950: INFO: Pod downwardapi-volume-dd0a282b-a70b-402d-bfdf-2d0c001613c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:39.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6032" for this suite.
Oct  7 19:21:45.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:46.031: INFO: namespace projected-6032 deletion completed in 6.078119614s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:46.032: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-aff0ddb6-8d92-47d4-93a7-4cd206ff6030
STEP: Creating a pod to test consume configMaps
Oct  7 19:21:46.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83" in namespace "configmap-6454" to be "success or failure"
Oct  7 19:21:46.217: INFO: Pod "pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83": Phase="Pending", Reason="", readiness=false. Elapsed: 2.916972ms
Oct  7 19:21:48.220: INFO: Pod "pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006658793s
STEP: Saw pod success
Oct  7 19:21:48.220: INFO: Pod "pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83" satisfied condition "success or failure"
Oct  7 19:21:48.224: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83 container configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 19:21:48.242: INFO: Waiting for pod pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83 to disappear
Oct  7 19:21:48.244: INFO: Pod pod-configmaps-f7a26ed7-6817-4d42-a559-f0c1a68fcf83 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:21:48.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6454" for this suite.
Oct  7 19:21:54.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:21:54.322: INFO: namespace configmap-6454 deletion completed in 6.074640513s

• [SLOW TEST:8.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:21:54.324: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-2592
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:22:00.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2592" for this suite.
Oct  7 19:22:06.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:22:06.567: INFO: namespace job-2592 deletion completed in 6.075019759s

• [SLOW TEST:12.243 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:22:06.568: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2924
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 19:22:06.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-2924'
Oct  7 19:22:06.892: INFO: stderr: ""
Oct  7 19:22:06.892: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Oct  7 19:22:11.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pod e2e-test-httpd-pod --namespace=kubectl-2924 -o json'
Oct  7 19:22:12.024: INFO: stderr: ""
Oct  7 19:22:12.024: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-10-07T19:22:06Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2924\",\n        \"resourceVersion\": \"28951\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2924/pods/e2e-test-httpd-pod\",\n        \"uid\": \"e99fb519-d892-4f58-9418-35d6ffd89819\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-rlc6p\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"talos-v020-gcp-workers-654f4446bf-ns4sr\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-rlc6p\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-rlc6p\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-07T19:22:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-07T19:22:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-07T19:22:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-10-07T19:22:06Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://053c4294a19f06c916f279e5779e89cc900d2292e638f4e6abde0c5cca2f086a\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-10-07T19:22:07Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.128.15.228\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.230\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.3.230\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-10-07T19:22:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Oct  7 19:22:12.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 replace -f - --namespace=kubectl-2924'
Oct  7 19:22:12.416: INFO: stderr: ""
Oct  7 19:22:12.416: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Oct  7 19:22:12.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete pods e2e-test-httpd-pod --namespace=kubectl-2924'
Oct  7 19:22:14.867: INFO: stderr: ""
Oct  7 19:22:14.867: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:22:14.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2924" for this suite.
Oct  7 19:22:20.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:22:20.953: INFO: namespace kubectl-2924 deletion completed in 6.081559779s

• [SLOW TEST:14.385 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:22:20.954: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5562
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-ec118ec7-4484-4920-8e05-e568d0bde1b9
STEP: Creating configMap with name cm-test-opt-upd-36607a59-4cea-40a1-a8dd-debed308edb5
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ec118ec7-4484-4920-8e05-e568d0bde1b9
STEP: Updating configmap cm-test-opt-upd-36607a59-4cea-40a1-a8dd-debed308edb5
STEP: Creating configMap with name cm-test-opt-create-c0bcd42a-bbe6-4e3a-96f8-c64fe2bdb901
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:22:25.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5562" for this suite.
Oct  7 19:22:37.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:22:37.302: INFO: namespace configmap-5562 deletion completed in 12.072845174s

• [SLOW TEST:16.349 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:22:37.304: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Oct  7 19:22:41.500: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:41.503: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:43.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:43.507: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:45.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:45.507: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:47.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:47.506: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:49.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:49.507: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:51.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:51.507: INFO: Pod pod-with-prestop-http-hook still exists
Oct  7 19:22:53.503: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Oct  7 19:22:53.507: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:22:53.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9099" for this suite.
Oct  7 19:23:05.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:05.587: INFO: namespace container-lifecycle-hook-9099 deletion completed in 12.070178777s

• [SLOW TEST:28.284 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:23:05.588: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:23:05.771: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28" in namespace "projected-9910" to be "success or failure"
Oct  7 19:23:05.774: INFO: Pod "downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28": Phase="Pending", Reason="", readiness=false. Elapsed: 2.624204ms
Oct  7 19:23:07.778: INFO: Pod "downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006268115s
STEP: Saw pod success
Oct  7 19:23:07.778: INFO: Pod "downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28" satisfied condition "success or failure"
Oct  7 19:23:07.781: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28 container client-container: <nil>
STEP: delete the pod
Oct  7 19:23:07.799: INFO: Waiting for pod downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28 to disappear
Oct  7 19:23:07.802: INFO: Pod downwardapi-volume-2e039faf-f8b6-49f6-b20e-afa872c90c28 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:23:07.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9910" for this suite.
Oct  7 19:23:13.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:13.881: INFO: namespace projected-9910 deletion completed in 6.075594891s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:23:13.882: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1944
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Oct  7 19:23:14.039: INFO: Waiting up to 5m0s for pod "pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729" in namespace "emptydir-1944" to be "success or failure"
Oct  7 19:23:14.042: INFO: Pod "pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729": Phase="Pending", Reason="", readiness=false. Elapsed: 2.867998ms
Oct  7 19:23:16.045: INFO: Pod "pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006560629s
STEP: Saw pod success
Oct  7 19:23:16.045: INFO: Pod "pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729" satisfied condition "success or failure"
Oct  7 19:23:16.048: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729 container test-container: <nil>
STEP: delete the pod
Oct  7 19:23:16.065: INFO: Waiting for pod pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729 to disappear
Oct  7 19:23:16.067: INFO: Pod pod-fa3d849a-c7e7-49ce-83e9-2f3ed58eb729 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:23:16.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1944" for this suite.
Oct  7 19:23:22.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:22.141: INFO: namespace emptydir-1944 deletion completed in 6.07096062s

• [SLOW TEST:8.260 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:23:22.143: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3505
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:23:22.728: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:23:25.761: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:23:25.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3505" for this suite.
Oct  7 19:23:31.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:31.882: INFO: namespace webhook-3505 deletion completed in 6.07624706s
STEP: Destroying namespace "webhook-3505-markers" for this suite.
Oct  7 19:23:37.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:37.955: INFO: namespace webhook-3505-markers deletion completed in 6.072659874s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.825 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:23:37.971: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Oct  7 19:23:38.142: INFO: Waiting up to 5m0s for pod "client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277" in namespace "containers-4264" to be "success or failure"
Oct  7 19:23:38.144: INFO: Pod "client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277": Phase="Pending", Reason="", readiness=false. Elapsed: 2.478957ms
Oct  7 19:23:40.148: INFO: Pod "client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006012875s
STEP: Saw pod success
Oct  7 19:23:40.148: INFO: Pod "client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277" satisfied condition "success or failure"
Oct  7 19:23:40.153: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277 container test-container: <nil>
STEP: delete the pod
Oct  7 19:23:40.188: INFO: Waiting for pod client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277 to disappear
Oct  7 19:23:40.191: INFO: Pod client-containers-9788d6b2-3d5b-475f-ac65-95634dd9b277 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:23:40.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4264" for this suite.
Oct  7 19:23:46.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:23:46.272: INFO: namespace containers-4264 deletion completed in 6.077050366s

• [SLOW TEST:8.301 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:23:46.272: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4701
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-8a183a18-f6b7-4e22-9414-478c7425064a
STEP: Creating secret with name s-test-opt-upd-fb50d3e8-c2fc-493a-9f53-58f8b19ca62c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8a183a18-f6b7-4e22-9414-478c7425064a
STEP: Updating secret s-test-opt-upd-fb50d3e8-c2fc-493a-9f53-58f8b19ca62c
STEP: Creating secret with name s-test-opt-create-8ef8fae5-3be5-4962-86f2-54f6dc22f471
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:23:50.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4701" for this suite.
Oct  7 19:24:06.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:24:06.643: INFO: namespace projected-4701 deletion completed in 16.082376031s

• [SLOW TEST:20.371 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:24:06.643: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-1500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9150
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-413
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:24:36.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1500" for this suite.
Oct  7 19:24:42.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:24:42.228: INFO: namespace namespaces-1500 deletion completed in 6.076851793s
STEP: Destroying namespace "nsdeletetest-9150" for this suite.
Oct  7 19:24:42.230: INFO: Namespace nsdeletetest-9150 was already deleted
STEP: Destroying namespace "nsdeletetest-413" for this suite.
Oct  7 19:24:48.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:24:48.302: INFO: namespace nsdeletetest-413 deletion completed in 6.07215324s

• [SLOW TEST:41.659 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:24:48.303: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 in namespace container-probe-6430
Oct  7 19:24:50.475: INFO: Started pod liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 in namespace container-probe-6430
STEP: checking the pod's current state and verifying that restartCount is present
Oct  7 19:24:50.477: INFO: Initial restart count of pod liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is 0
Oct  7 19:25:02.502: INFO: Restart count of pod container-probe-6430/liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is now 1 (12.02443243s elapsed)
Oct  7 19:25:22.538: INFO: Restart count of pod container-probe-6430/liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is now 2 (32.060403131s elapsed)
Oct  7 19:25:42.575: INFO: Restart count of pod container-probe-6430/liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is now 3 (52.097459491s elapsed)
Oct  7 19:26:02.610: INFO: Restart count of pod container-probe-6430/liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is now 4 (1m12.132659128s elapsed)
Oct  7 19:27:04.737: INFO: Restart count of pod container-probe-6430/liveness-b0197be2-e844-4cbf-9cf1-c708b9b1ceb8 is now 5 (2m14.259344824s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:27:04.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6430" for this suite.
Oct  7 19:27:10.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:27:10.845: INFO: namespace container-probe-6430 deletion completed in 6.079050694s

• [SLOW TEST:142.542 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:27:10.846: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-e141cafe-84b7-404b-b19b-3e355ca108f9
STEP: Creating a pod to test consume secrets
Oct  7 19:27:11.011: INFO: Waiting up to 5m0s for pod "pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86" in namespace "secrets-8500" to be "success or failure"
Oct  7 19:27:11.014: INFO: Pod "pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.804825ms
Oct  7 19:27:13.019: INFO: Pod "pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007453075s
STEP: Saw pod success
Oct  7 19:27:13.019: INFO: Pod "pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86" satisfied condition "success or failure"
Oct  7 19:27:13.021: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:27:13.055: INFO: Waiting for pod pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86 to disappear
Oct  7 19:27:13.058: INFO: Pod pod-secrets-367bbc33-d0a8-4bca-a951-f64538a07f86 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:27:13.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8500" for this suite.
Oct  7 19:27:19.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:27:19.133: INFO: namespace secrets-8500 deletion completed in 6.07130204s

• [SLOW TEST:8.287 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:27:19.134: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:27:19.636: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  7 19:27:21.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073239, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073239, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073239, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073239, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:27:24.678: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:27:24.682: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:27:25.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5252" for this suite.
Oct  7 19:27:32.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:27:32.080: INFO: namespace webhook-5252 deletion completed in 6.077775679s
STEP: Destroying namespace "webhook-5252-markers" for this suite.
Oct  7 19:27:38.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:27:38.165: INFO: namespace webhook-5252-markers deletion completed in 6.084694304s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.044 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:27:38.179: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Oct  7 19:27:38.344: INFO: Waiting up to 5m0s for pod "var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5" in namespace "var-expansion-1434" to be "success or failure"
Oct  7 19:27:38.346: INFO: Pod "var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.667031ms
Oct  7 19:27:40.350: INFO: Pod "var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006467869s
STEP: Saw pod success
Oct  7 19:27:40.350: INFO: Pod "var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5" satisfied condition "success or failure"
Oct  7 19:27:40.353: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5 container dapi-container: <nil>
STEP: delete the pod
Oct  7 19:27:40.374: INFO: Waiting for pod var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5 to disappear
Oct  7 19:27:40.377: INFO: Pod var-expansion-4fa35e46-aa15-46a0-92d6-149b72f708b5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:27:40.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1434" for this suite.
Oct  7 19:27:46.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:27:46.467: INFO: namespace var-expansion-1434 deletion completed in 6.086741046s

• [SLOW TEST:8.288 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:27:46.468: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Oct  7 19:27:49.200: INFO: Successfully updated pod "labelsupdate5b1786c9-826c-4fca-8ee8-81e5a1274feb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:27:51.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9819" for this suite.
Oct  7 19:28:03.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:03.294: INFO: namespace projected-9819 deletion completed in 12.077309989s

• [SLOW TEST:16.827 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:28:03.296: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6c50a061-25ad-41be-9ea1-d69d4f9cb709
STEP: Creating a pod to test consume secrets
Oct  7 19:28:03.463: INFO: Waiting up to 5m0s for pod "pod-secrets-c723b8da-42ea-428e-b121-4910413ec600" in namespace "secrets-1353" to be "success or failure"
Oct  7 19:28:03.465: INFO: Pod "pod-secrets-c723b8da-42ea-428e-b121-4910413ec600": Phase="Pending", Reason="", readiness=false. Elapsed: 2.671603ms
Oct  7 19:28:05.472: INFO: Pod "pod-secrets-c723b8da-42ea-428e-b121-4910413ec600": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009293705s
STEP: Saw pod success
Oct  7 19:28:05.472: INFO: Pod "pod-secrets-c723b8da-42ea-428e-b121-4910413ec600" satisfied condition "success or failure"
Oct  7 19:28:05.475: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-c723b8da-42ea-428e-b121-4910413ec600 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:28:05.501: INFO: Waiting for pod pod-secrets-c723b8da-42ea-428e-b121-4910413ec600 to disappear
Oct  7 19:28:05.504: INFO: Pod pod-secrets-c723b8da-42ea-428e-b121-4910413ec600 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:28:05.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1353" for this suite.
Oct  7 19:28:11.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:11.596: INFO: namespace secrets-1353 deletion completed in 6.087946143s

• [SLOW TEST:8.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:28:11.599: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6191
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:28:12.452: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  7 19:28:14.462: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073292, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073292, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073292, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073292, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:28:17.490: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:28:27.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6191" for this suite.
Oct  7 19:28:33.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:33.691: INFO: namespace webhook-6191 deletion completed in 6.084615992s
STEP: Destroying namespace "webhook-6191-markers" for this suite.
Oct  7 19:28:39.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:39.768: INFO: namespace webhook-6191-markers deletion completed in 6.077095284s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.183 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:28:39.782: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Oct  7 19:28:40.022: INFO: Waiting up to 5m0s for pod "pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2" in namespace "emptydir-7743" to be "success or failure"
Oct  7 19:28:40.025: INFO: Pod "pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.569812ms
Oct  7 19:28:42.028: INFO: Pod "pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006165979s
STEP: Saw pod success
Oct  7 19:28:42.028: INFO: Pod "pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2" satisfied condition "success or failure"
Oct  7 19:28:42.032: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2 container test-container: <nil>
STEP: delete the pod
Oct  7 19:28:42.051: INFO: Waiting for pod pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2 to disappear
Oct  7 19:28:42.053: INFO: Pod pod-cf085dcc-971b-473b-b1b7-2b67a85c65f2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:28:42.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7743" for this suite.
Oct  7 19:28:48.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:48.136: INFO: namespace emptydir-7743 deletion completed in 6.079430699s

• [SLOW TEST:8.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:28:48.137: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a70cf536-00ad-4ffc-b102-50229ba08864
STEP: Creating a pod to test consume secrets
Oct  7 19:28:48.319: INFO: Waiting up to 5m0s for pod "pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc" in namespace "secrets-4325" to be "success or failure"
Oct  7 19:28:48.322: INFO: Pod "pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.887002ms
Oct  7 19:28:50.326: INFO: Pod "pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006509872s
STEP: Saw pod success
Oct  7 19:28:50.326: INFO: Pod "pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc" satisfied condition "success or failure"
Oct  7 19:28:50.329: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:28:50.351: INFO: Waiting for pod pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc to disappear
Oct  7 19:28:50.353: INFO: Pod pod-secrets-5c5c0e90-ab53-4e76-89d1-5a3dddfdcebc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:28:50.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4325" for this suite.
Oct  7 19:28:56.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:28:56.432: INFO: namespace secrets-4325 deletion completed in 6.075715523s

• [SLOW TEST:8.296 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:28:56.436: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-007259dc-5c57-437f-966f-c4a80fa974b2
STEP: Creating a pod to test consume secrets
Oct  7 19:28:56.622: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e" in namespace "projected-1393" to be "success or failure"
Oct  7 19:28:56.625: INFO: Pod "pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.116279ms
Oct  7 19:28:58.629: INFO: Pod "pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007170273s
STEP: Saw pod success
Oct  7 19:28:58.629: INFO: Pod "pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e" satisfied condition "success or failure"
Oct  7 19:28:58.632: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:28:58.652: INFO: Waiting for pod pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e to disappear
Oct  7 19:28:58.655: INFO: Pod pod-projected-secrets-4df8809d-b3b2-43e3-b486-856fdd44b76e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:28:58.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1393" for this suite.
Oct  7 19:29:04.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:29:04.742: INFO: namespace projected-1393 deletion completed in 6.081302716s

• [SLOW TEST:8.306 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:29:04.745: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Oct  7 19:29:04.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-8870'
Oct  7 19:29:05.680: INFO: stderr: ""
Oct  7 19:29:05.680: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  7 19:29:06.684: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 19:29:06.684: INFO: Found 1 / 1
Oct  7 19:29:06.684: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Oct  7 19:29:06.687: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 19:29:06.688: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  7 19:29:06.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 patch pod redis-master-q8qpd --namespace=kubectl-8870 -p {"metadata":{"annotations":{"x":"y"}}}'
Oct  7 19:29:06.779: INFO: stderr: ""
Oct  7 19:29:06.779: INFO: stdout: "pod/redis-master-q8qpd patched\n"
STEP: checking annotations
Oct  7 19:29:06.782: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 19:29:06.782: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:29:06.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8870" for this suite.
Oct  7 19:29:34.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:29:34.862: INFO: namespace kubectl-8870 deletion completed in 28.076612537s

• [SLOW TEST:30.117 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:29:34.862: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Oct  7 19:29:35.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-770'
Oct  7 19:29:35.112: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Oct  7 19:29:35.112: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Oct  7 19:29:35.118: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Oct  7 19:29:35.129: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Oct  7 19:29:35.139: INFO: scanned /root for discovery docs: <nil>
Oct  7 19:29:35.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-770'
Oct  7 19:29:51.348: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  7 19:29:51.348: INFO: stdout: "Created e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1\nScaling up e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Oct  7 19:29:51.348: INFO: stdout: "Created e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1\nScaling up e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Oct  7 19:29:51.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-770'
Oct  7 19:29:51.438: INFO: stderr: ""
Oct  7 19:29:51.438: INFO: stdout: "e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1-wl8tt "
Oct  7 19:29:51.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1-wl8tt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-770'
Oct  7 19:29:51.519: INFO: stderr: ""
Oct  7 19:29:51.519: INFO: stdout: "true"
Oct  7 19:29:51.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1-wl8tt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-770'
Oct  7 19:29:51.603: INFO: stderr: ""
Oct  7 19:29:51.603: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Oct  7 19:29:51.603: INFO: e2e-test-httpd-rc-fb6f060b782fc5f6f457b5962188ccd1-wl8tt is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Oct  7 19:29:51.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 delete rc e2e-test-httpd-rc --namespace=kubectl-770'
Oct  7 19:29:51.693: INFO: stderr: ""
Oct  7 19:29:51.693: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:29:51.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-770" for this suite.
Oct  7 19:29:57.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:29:57.784: INFO: namespace kubectl-770 deletion completed in 6.084194134s

• [SLOW TEST:22.922 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:29:57.785: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:29:57.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 version'
Oct  7 19:29:58.064: INFO: stderr: ""
Oct  7 19:29:58.064: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:27:17Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:29:58.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1802" for this suite.
Oct  7 19:30:04.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:30:04.149: INFO: namespace kubectl-1802 deletion completed in 6.080391213s

• [SLOW TEST:6.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:30:04.149: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:30:08.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1298" for this suite.
Oct  7 19:30:14.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:30:14.395: INFO: namespace kubelet-test-1298 deletion completed in 6.074440956s

• [SLOW TEST:10.246 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:30:14.396: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4455.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4455.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4455.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4455.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4455.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Oct  7 19:30:18.601: INFO: DNS probes using dns-4455/dns-test-f33fd229-e86c-451a-aac1-a347d614b65e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:30:18.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4455" for this suite.
Oct  7 19:30:24.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:30:24.702: INFO: namespace dns-4455 deletion completed in 6.075945465s

• [SLOW TEST:10.306 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:30:24.703: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-dffd6bb9-342c-4529-9da4-7c09dba0a565
STEP: Creating a pod to test consume secrets
Oct  7 19:30:24.867: INFO: Waiting up to 5m0s for pod "pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2" in namespace "secrets-3460" to be "success or failure"
Oct  7 19:30:24.869: INFO: Pod "pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.392969ms
Oct  7 19:30:26.873: INFO: Pod "pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005893689s
STEP: Saw pod success
Oct  7 19:30:26.873: INFO: Pod "pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2" satisfied condition "success or failure"
Oct  7 19:30:26.876: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2 container secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:30:26.896: INFO: Waiting for pod pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2 to disappear
Oct  7 19:30:26.899: INFO: Pod pod-secrets-d30684a6-453c-48f1-a661-17b97e381ba2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:30:26.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3460" for this suite.
Oct  7 19:30:32.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:30:32.993: INFO: namespace secrets-3460 deletion completed in 6.090556227s

• [SLOW TEST:8.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:30:32.996: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-279
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4f4b38be-d2ac-4968-b287-d7d0e7dc2ff9
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4f4b38be-d2ac-4968-b287-d7d0e7dc2ff9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:30:39.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-279" for this suite.
Oct  7 19:30:57.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:30:57.304: INFO: namespace projected-279 deletion completed in 18.074711118s

• [SLOW TEST:24.308 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:30:57.305: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Oct  7 19:30:59.997: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4996 pod-service-account-1de2ac8a-07d1-470d-9939-6977539ff188 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Oct  7 19:31:00.277: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4996 pod-service-account-1de2ac8a-07d1-470d-9939-6977539ff188 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Oct  7 19:31:00.575: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4996 pod-service-account-1de2ac8a-07d1-470d-9939-6977539ff188 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:31:00.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4996" for this suite.
Oct  7 19:31:06.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:31:06.937: INFO: namespace svcaccounts-4996 deletion completed in 6.074040382s

• [SLOW TEST:9.632 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:31:06.937: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:31:07.740: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:31:10.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Oct  7 19:31:12.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 attach --namespace=webhook-3633 to-be-attached-pod -i -c=container1'
Oct  7 19:31:12.913: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:31:12.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3633" for this suite.
Oct  7 19:31:24.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:31:24.999: INFO: namespace webhook-3633 deletion completed in 12.07433266s
STEP: Destroying namespace "webhook-3633-markers" for this suite.
Oct  7 19:31:31.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:31:31.078: INFO: namespace webhook-3633-markers deletion completed in 6.078579607s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.154 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:31:31.093: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1992
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:31:31.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-1992'
Oct  7 19:31:31.592: INFO: stderr: ""
Oct  7 19:31:31.592: INFO: stdout: "replicationcontroller/redis-master created\n"
Oct  7 19:31:31.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-1992'
Oct  7 19:31:31.895: INFO: stderr: ""
Oct  7 19:31:31.895: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Oct  7 19:31:32.899: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 19:31:32.900: INFO: Found 1 / 1
Oct  7 19:31:32.900: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Oct  7 19:31:32.915: INFO: Selector matched 1 pods for map[app:redis]
Oct  7 19:31:32.916: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Oct  7 19:31:32.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 describe pod redis-master-7lqln --namespace=kubectl-1992'
Oct  7 19:31:33.040: INFO: stderr: ""
Oct  7 19:31:33.040: INFO: stdout: "Name:         redis-master-7lqln\nNamespace:    kubectl-1992\nPriority:     0\nNode:         talos-v020-gcp-workers-654f4446bf-ns4sr/10.128.15.228\nStart Time:   Mon, 07 Oct 2019 19:31:31 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           10.244.3.4\nIPs:\n  IP:           10.244.3.4\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://9d86d4161dbaa2249978a75821b6587b3522d1a5d0be80a32626bc2993c64c58\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 07 Oct 2019 19:31:32 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-sb5h9 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-sb5h9:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-sb5h9\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                              Message\n  ----    ------     ----       ----                                              -------\n  Normal  Scheduled  <unknown>  default-scheduler                                 Successfully assigned kubectl-1992/redis-master-7lqln to talos-v020-gcp-workers-654f4446bf-ns4sr\n  Normal  Pulled     1s         kubelet, talos-v020-gcp-workers-654f4446bf-ns4sr  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, talos-v020-gcp-workers-654f4446bf-ns4sr  Created container redis-master\n  Normal  Started    1s         kubelet, talos-v020-gcp-workers-654f4446bf-ns4sr  Started container redis-master\n"
Oct  7 19:31:33.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 describe rc redis-master --namespace=kubectl-1992'
Oct  7 19:31:33.150: INFO: stderr: ""
Oct  7 19:31:33.150: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-1992\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-7lqln\n"
Oct  7 19:31:33.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 describe service redis-master --namespace=kubectl-1992'
Oct  7 19:31:33.244: INFO: stderr: ""
Oct  7 19:31:33.244: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-1992\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.103.89.215\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.3.4:6379\nSession Affinity:  None\nEvents:            <none>\n"
Oct  7 19:31:33.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 describe node talos-v020-gcp-master-0'
Oct  7 19:31:33.361: INFO: stderr: ""
Oct  7 19:31:33.361: INFO: stdout: "Name:               talos-v020-gcp-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=talos-v020-gcp-master-0\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"82:b1:8a:e0:e0:b7\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.128.15.193\n                    kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 07 Oct 2019 17:27:12 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 07 Oct 2019 19:30:47 +0000   Mon, 07 Oct 2019 17:27:08 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 07 Oct 2019 19:30:47 +0000   Mon, 07 Oct 2019 17:27:08 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 07 Oct 2019 19:30:47 +0000   Mon, 07 Oct 2019 17:27:08 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 07 Oct 2019 19:30:47 +0000   Mon, 07 Oct 2019 17:30:22 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.128.15.193\n  Hostname:    talos-v020-gcp-master-0\nCapacity:\n cpu:                2\n ephemeral-storage:  51901056Ki\n hugepages-2Mi:      0\n memory:             7642948Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  47832013131\n hugepages-2Mi:      0\n memory:             7540548Ki\n pods:               110\nSystem Info:\n Machine ID:                 311936e2303b034fe7ef70182235b8cb\n System UUID:                5e940302-d2b0-aa6b-a1dc-c871aaebb9a1\n Boot ID:                    ed1476d7-9243-462f-a424-004d4c621134\n Kernel Version:             5.2.8-talos\n OS Image:                   Talos (v0.2.0)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.2.7\n Kubelet Version:            v1.16.0\n Kube-Proxy Version:         v1.16.0\nPodCIDR:                     10.244.0.0/24\nPodCIDRs:                    10.244.0.0/24\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                               ------------  ----------  ---------------  -------------  ---\n  kube-system                etcd-talos-v020-gcp-master-0                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         120m\n  kube-system                kube-apiserver-talos-v020-gcp-master-0             250m (12%)    0 (0%)      0 (0%)           0 (0%)         120m\n  kube-system                kube-controller-manager-talos-v020-gcp-master-0    200m (10%)    0 (0%)      0 (0%)           0 (0%)         120m\n  kube-system                kube-flannel-ds-amd64-8jvmg                        100m (5%)     100m (5%)   50Mi (0%)        50Mi (0%)      121m\n  kube-system                kube-proxy-rqhfp                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         111m\n  kube-system                kube-scheduler-talos-v020-gcp-master-0             100m (5%)     0 (0%)      0 (0%)           0 (0%)         120m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                650m (32%)  100m (5%)\n  memory             50Mi (0%)   50Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Oct  7 19:31:33.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 describe namespace kubectl-1992'
Oct  7 19:31:33.475: INFO: stderr: ""
Oct  7 19:31:33.475: INFO: stdout: "Name:         kubectl-1992\nLabels:       e2e-framework=kubectl\n              e2e-run=d0fe5200-588e-46e6-a22f-38b042e15d06\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:31:33.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1992" for this suite.
Oct  7 19:31:45.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:31:45.560: INFO: namespace kubectl-1992 deletion completed in 12.081541006s

• [SLOW TEST:14.467 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:31:45.561: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1772
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:31:45.716: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Oct  7 19:31:48.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 create -f -'
Oct  7 19:31:49.544: INFO: stderr: ""
Oct  7 19:31:49.544: INFO: stdout: "e2e-test-crd-publish-openapi-2385-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  7 19:31:49.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 delete e2e-test-crd-publish-openapi-2385-crds test-foo'
Oct  7 19:31:49.671: INFO: stderr: ""
Oct  7 19:31:49.671: INFO: stdout: "e2e-test-crd-publish-openapi-2385-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Oct  7 19:31:49.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 apply -f -'
Oct  7 19:31:50.011: INFO: stderr: ""
Oct  7 19:31:50.011: INFO: stdout: "e2e-test-crd-publish-openapi-2385-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Oct  7 19:31:50.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 delete e2e-test-crd-publish-openapi-2385-crds test-foo'
Oct  7 19:31:50.107: INFO: stderr: ""
Oct  7 19:31:50.107: INFO: stdout: "e2e-test-crd-publish-openapi-2385-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Oct  7 19:31:50.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 create -f -'
Oct  7 19:31:50.347: INFO: rc: 1
Oct  7 19:31:50.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 apply -f -'
Oct  7 19:31:50.571: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Oct  7 19:31:50.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 create -f -'
Oct  7 19:31:50.793: INFO: rc: 1
Oct  7 19:31:50.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 --namespace=crd-publish-openapi-1772 apply -f -'
Oct  7 19:31:51.020: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Oct  7 19:31:51.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-2385-crds'
Oct  7 19:31:51.252: INFO: stderr: ""
Oct  7 19:31:51.252: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2385-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Oct  7 19:31:51.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-2385-crds.metadata'
Oct  7 19:31:51.481: INFO: stderr: ""
Oct  7 19:31:51.481: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2385-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Oct  7 19:31:51.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-2385-crds.spec'
Oct  7 19:31:51.719: INFO: stderr: ""
Oct  7 19:31:51.719: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2385-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Oct  7 19:31:51.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-2385-crds.spec.bars'
Oct  7 19:31:51.937: INFO: stderr: ""
Oct  7 19:31:51.937: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2385-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Oct  7 19:31:51.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 explain e2e-test-crd-publish-openapi-2385-crds.spec.bars2'
Oct  7 19:31:52.170: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:31:55.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1772" for this suite.
Oct  7 19:32:01.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:32:01.232: INFO: namespace crd-publish-openapi-1772 deletion completed in 6.079140424s

• [SLOW TEST:15.595 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:32:01.232: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1007 19:32:31.929597      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Oct  7 19:32:31.929: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:32:31.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7754" for this suite.
Oct  7 19:32:37.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:32:38.011: INFO: namespace gc-7754 deletion completed in 6.076425387s

• [SLOW TEST:36.778 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:32:38.011: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Oct  7 19:32:38.165: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Oct  7 19:32:38.444: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Oct  7 19:32:40.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:42.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:44.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:46.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:48.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:50.500: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073558, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Oct  7 19:32:53.166: INFO: Waited 626.388027ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:32:53.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2129" for this suite.
Oct  7 19:32:59.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:32:59.817: INFO: namespace aggregator-2129 deletion completed in 6.112024652s

• [SLOW TEST:21.806 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:32:59.817: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:32:59.983: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Oct  7 19:33:04.987: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Oct  7 19:33:04.987: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Oct  7 19:33:05.010: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4979 /apis/apps/v1/namespaces/deployment-4979/deployments/test-cleanup-deployment 915e59b1-cdba-4db8-a77c-04249cea6bad 31633 1 2019-10-07 19:33:04 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001f0b4d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Oct  7 19:33:05.015: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Oct  7 19:33:05.015: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Oct  7 19:33:05.015: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-4979 /apis/apps/v1/namespaces/deployment-4979/replicasets/test-cleanup-controller 9f79f0b6-838a-4d38-af42-1bfce499213d 31634 1 2019-10-07 19:32:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 915e59b1-cdba-4db8-a77c-04249cea6bad 0xc001f0b9b7 0xc001f0b9b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001f0ba58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Oct  7 19:33:05.024: INFO: Pod "test-cleanup-controller-mn57p" is available:
&Pod{ObjectMeta:{test-cleanup-controller-mn57p test-cleanup-controller- deployment-4979 /api/v1/namespaces/deployment-4979/pods/test-cleanup-controller-mn57p ac11ab13-11ad-4ec1-8b9c-2bc98930b10d 31625 0 2019-10-07 19:32:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller 9f79f0b6-838a-4d38-af42-1bfce499213d 0xc001f0bf97 0xc001f0bf98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8f866,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8f866,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8f866,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:talos-v020-gcp-workers-654f4446bf-ns4sr,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 19:33:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 19:33:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 19:33:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-10-07 19:32:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.128.15.228,PodIP:10.244.3.7,StartTime:2019-10-07 19:33:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-10-07 19:33:00 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://794518bd43481dc65f47f3ef549799b932465236958afe06e16fd216ead209db,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:33:05.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4979" for this suite.
Oct  7 19:33:11.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:33:11.132: INFO: namespace deployment-4979 deletion completed in 6.101649869s

• [SLOW TEST:11.316 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:33:11.134: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:33:22.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9443" for this suite.
Oct  7 19:33:28.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:33:28.484: INFO: namespace resourcequota-9443 deletion completed in 6.082013922s

• [SLOW TEST:17.350 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:33:28.485: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9166/configmap-test-de85e160-6ad5-4bc8-b107-92dff8996394
STEP: Creating a pod to test consume configMaps
Oct  7 19:33:28.652: INFO: Waiting up to 5m0s for pod "pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371" in namespace "configmap-9166" to be "success or failure"
Oct  7 19:33:28.655: INFO: Pod "pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371": Phase="Pending", Reason="", readiness=false. Elapsed: 2.72592ms
Oct  7 19:33:30.658: INFO: Pod "pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006180085s
STEP: Saw pod success
Oct  7 19:33:30.658: INFO: Pod "pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371" satisfied condition "success or failure"
Oct  7 19:33:30.661: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371 container env-test: <nil>
STEP: delete the pod
Oct  7 19:33:30.695: INFO: Waiting for pod pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371 to disappear
Oct  7 19:33:30.698: INFO: Pod pod-configmaps-f0399030-4ce0-4203-ab41-fb25b5218371 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:33:30.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9166" for this suite.
Oct  7 19:33:36.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:33:36.785: INFO: namespace configmap-9166 deletion completed in 6.082670807s

• [SLOW TEST:8.300 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:33:36.786: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Oct  7 19:33:42.969: INFO: 10 pods remaining
Oct  7 19:33:42.969: INFO: 10 pods has nil DeletionTimestamp
Oct  7 19:33:42.969: INFO: 
Oct  7 19:33:43.998: INFO: 0 pods remaining
Oct  7 19:33:43.998: INFO: 0 pods has nil DeletionTimestamp
Oct  7 19:33:43.998: INFO: 
STEP: Gathering metrics
Oct  7 19:33:44.972: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1007 19:33:44.972058      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:33:44.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3488" for this suite.
Oct  7 19:33:50.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:33:51.060: INFO: namespace gc-3488 deletion completed in 6.084438833s

• [SLOW TEST:14.274 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:33:51.061: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8398
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-d9e3d24d-4125-462b-8499-a7e192b5b996
STEP: Creating a pod to test consume secrets
Oct  7 19:33:51.234: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed" in namespace "projected-8398" to be "success or failure"
Oct  7 19:33:51.237: INFO: Pod "pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 3.083035ms
Oct  7 19:33:53.241: INFO: Pod "pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006748842s
STEP: Saw pod success
Oct  7 19:33:53.241: INFO: Pod "pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed" satisfied condition "success or failure"
Oct  7 19:33:53.244: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed container projected-secret-volume-test: <nil>
STEP: delete the pod
Oct  7 19:33:53.266: INFO: Waiting for pod pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed to disappear
Oct  7 19:33:53.268: INFO: Pod pod-projected-secrets-046a4a87-1896-4529-8056-a823a7fac0ed no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:33:53.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8398" for this suite.
Oct  7 19:33:59.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:33:59.353: INFO: namespace projected-8398 deletion completed in 6.081380846s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:33:59.355: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9680
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Oct  7 19:33:59.519: INFO: Waiting up to 5m0s for pod "var-expansion-af72da46-95a6-4693-b532-25a9bb03e139" in namespace "var-expansion-9680" to be "success or failure"
Oct  7 19:33:59.522: INFO: Pod "var-expansion-af72da46-95a6-4693-b532-25a9bb03e139": Phase="Pending", Reason="", readiness=false. Elapsed: 2.871038ms
Oct  7 19:34:01.525: INFO: Pod "var-expansion-af72da46-95a6-4693-b532-25a9bb03e139": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006527987s
STEP: Saw pod success
Oct  7 19:34:01.525: INFO: Pod "var-expansion-af72da46-95a6-4693-b532-25a9bb03e139" satisfied condition "success or failure"
Oct  7 19:34:01.528: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod var-expansion-af72da46-95a6-4693-b532-25a9bb03e139 container dapi-container: <nil>
STEP: delete the pod
Oct  7 19:34:01.549: INFO: Waiting for pod var-expansion-af72da46-95a6-4693-b532-25a9bb03e139 to disappear
Oct  7 19:34:01.552: INFO: Pod var-expansion-af72da46-95a6-4693-b532-25a9bb03e139 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:01.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9680" for this suite.
Oct  7 19:34:07.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:34:07.639: INFO: namespace var-expansion-9680 deletion completed in 6.083084564s

• [SLOW TEST:8.284 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:34:07.640: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:34:07.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32" in namespace "downward-api-9922" to be "success or failure"
Oct  7 19:34:07.818: INFO: Pod "downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.832504ms
Oct  7 19:34:09.821: INFO: Pod "downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006176605s
STEP: Saw pod success
Oct  7 19:34:09.821: INFO: Pod "downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32" satisfied condition "success or failure"
Oct  7 19:34:09.824: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32 container client-container: <nil>
STEP: delete the pod
Oct  7 19:34:09.845: INFO: Waiting for pod downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32 to disappear
Oct  7 19:34:09.848: INFO: Pod downwardapi-volume-dbc5aa33-722b-4573-992e-d6337d2b9f32 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:09.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9922" for this suite.
Oct  7 19:34:15.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:34:15.934: INFO: namespace downward-api-9922 deletion completed in 6.082431721s

• [SLOW TEST:8.294 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:34:15.938: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Oct  7 19:34:16.124: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:19.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7416" for this suite.
Oct  7 19:34:25.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:34:25.438: INFO: namespace init-container-7416 deletion completed in 6.08796678s

• [SLOW TEST:9.500 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:34:25.438: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Oct  7 19:34:25.636: INFO: Waiting up to 5m0s for pod "var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7" in namespace "var-expansion-3436" to be "success or failure"
Oct  7 19:34:25.642: INFO: Pod "var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.780397ms
Oct  7 19:34:27.646: INFO: Pod "var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009388012s
STEP: Saw pod success
Oct  7 19:34:27.646: INFO: Pod "var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7" satisfied condition "success or failure"
Oct  7 19:34:27.649: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7 container dapi-container: <nil>
STEP: delete the pod
Oct  7 19:34:27.670: INFO: Waiting for pod var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7 to disappear
Oct  7 19:34:27.673: INFO: Pod var-expansion-d0af0236-ef4b-4a74-92cf-0f07b817dbb7 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:27.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3436" for this suite.
Oct  7 19:34:33.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:34:33.761: INFO: namespace var-expansion-3436 deletion completed in 6.084348217s

• [SLOW TEST:8.323 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:34:33.763: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6424
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ba9afee1-4d8f-4d0b-a2b8-bb91f335fbd0
STEP: Creating a pod to test consume configMaps
Oct  7 19:34:33.957: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61" in namespace "projected-6424" to be "success or failure"
Oct  7 19:34:33.960: INFO: Pod "pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61": Phase="Pending", Reason="", readiness=false. Elapsed: 3.154956ms
Oct  7 19:34:35.965: INFO: Pod "pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00720115s
STEP: Saw pod success
Oct  7 19:34:35.965: INFO: Pod "pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61" satisfied condition "success or failure"
Oct  7 19:34:35.968: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 19:34:36.004: INFO: Waiting for pod pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61 to disappear
Oct  7 19:34:36.007: INFO: Pod pod-projected-configmaps-01690a13-5d2d-444c-a631-ef00244e2a61 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:36.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6424" for this suite.
Oct  7 19:34:42.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:34:42.102: INFO: namespace projected-6424 deletion completed in 6.08938697s

• [SLOW TEST:8.339 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:34:42.104: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2823
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Oct  7 19:34:42.272: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:34:58.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2823" for this suite.
Oct  7 19:35:04.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:35:05.069: INFO: namespace crd-publish-openapi-2823 deletion completed in 6.086951976s

• [SLOW TEST:22.965 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:35:05.072: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9101
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9101
STEP: creating replication controller externalsvc in namespace services-9101
I1007 19:35:05.292261      19 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9101, replica count: 2
I1007 19:35:08.342755      19 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Oct  7 19:35:08.376: INFO: Creating new exec pod
Oct  7 19:35:10.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 exec --namespace=services-9101 execpodjh6sz -- /bin/sh -x -c nslookup nodeport-service'
Oct  7 19:35:10.661: INFO: stderr: "+ nslookup nodeport-service\n"
Oct  7 19:35:10.661: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-9101.svc.cluster.local\tcanonical name = externalsvc.services-9101.svc.cluster.local.\nName:\texternalsvc.services-9101.svc.cluster.local\nAddress: 10.109.93.217\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9101, will wait for the garbage collector to delete the pods
Oct  7 19:35:10.725: INFO: Deleting ReplicationController externalsvc took: 9.630421ms
Oct  7 19:35:10.825: INFO: Terminating ReplicationController externalsvc pods took: 100.277547ms
Oct  7 19:35:14.557: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:35:14.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9101" for this suite.
Oct  7 19:35:20.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:35:20.692: INFO: namespace services-9101 deletion completed in 6.106654746s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.621 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:35:20.693: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2452
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Oct  7 19:35:22.866: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:35:22.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2452" for this suite.
Oct  7 19:35:28.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:35:28.978: INFO: namespace container-runtime-2452 deletion completed in 6.08975369s

• [SLOW TEST:8.285 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:35:28.978: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Oct  7 19:35:29.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 create -f - --namespace=kubectl-2544'
Oct  7 19:35:29.524: INFO: stderr: ""
Oct  7 19:35:29.524: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 19:35:29.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2544'
Oct  7 19:35:29.609: INFO: stderr: ""
Oct  7 19:35:29.609: INFO: stdout: "update-demo-nautilus-t8j5k update-demo-nautilus-xpnkr "
Oct  7 19:35:29.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-t8j5k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:29.692: INFO: stderr: ""
Oct  7 19:35:29.692: INFO: stdout: ""
Oct  7 19:35:29.692: INFO: update-demo-nautilus-t8j5k is created but not running
Oct  7 19:35:34.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2544'
Oct  7 19:35:34.777: INFO: stderr: ""
Oct  7 19:35:34.777: INFO: stdout: "update-demo-nautilus-t8j5k update-demo-nautilus-xpnkr "
Oct  7 19:35:34.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-t8j5k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:34.857: INFO: stderr: ""
Oct  7 19:35:34.857: INFO: stdout: "true"
Oct  7 19:35:34.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-t8j5k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:34.942: INFO: stderr: ""
Oct  7 19:35:34.942: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 19:35:34.942: INFO: validating pod update-demo-nautilus-t8j5k
Oct  7 19:35:34.949: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 19:35:34.949: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 19:35:34.949: INFO: update-demo-nautilus-t8j5k is verified up and running
Oct  7 19:35:34.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-xpnkr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:35.030: INFO: stderr: ""
Oct  7 19:35:35.030: INFO: stdout: "true"
Oct  7 19:35:35.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-nautilus-xpnkr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:35.111: INFO: stderr: ""
Oct  7 19:35:35.111: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Oct  7 19:35:35.111: INFO: validating pod update-demo-nautilus-xpnkr
Oct  7 19:35:35.118: INFO: got data: {
  "image": "nautilus.jpg"
}

Oct  7 19:35:35.118: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Oct  7 19:35:35.118: INFO: update-demo-nautilus-xpnkr is verified up and running
STEP: rolling-update to new replication controller
Oct  7 19:35:35.120: INFO: scanned /root for discovery docs: <nil>
Oct  7 19:35:35.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2544'
Oct  7 19:35:57.795: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Oct  7 19:35:57.796: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Oct  7 19:35:57.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2544'
Oct  7 19:35:57.880: INFO: stderr: ""
Oct  7 19:35:57.880: INFO: stdout: "update-demo-kitten-hml5g update-demo-kitten-t6jbp "
Oct  7 19:35:57.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-kitten-hml5g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:57.963: INFO: stderr: ""
Oct  7 19:35:57.963: INFO: stdout: "true"
Oct  7 19:35:57.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-kitten-hml5g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:58.046: INFO: stderr: ""
Oct  7 19:35:58.046: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  7 19:35:58.046: INFO: validating pod update-demo-kitten-hml5g
Oct  7 19:35:58.052: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  7 19:35:58.052: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  7 19:35:58.053: INFO: update-demo-kitten-hml5g is verified up and running
Oct  7 19:35:58.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-kitten-t6jbp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:58.133: INFO: stderr: ""
Oct  7 19:35:58.133: INFO: stdout: "true"
Oct  7 19:35:58.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-832208514 get pods update-demo-kitten-t6jbp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2544'
Oct  7 19:35:58.216: INFO: stderr: ""
Oct  7 19:35:58.216: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Oct  7 19:35:58.216: INFO: validating pod update-demo-kitten-t6jbp
Oct  7 19:35:58.223: INFO: got data: {
  "image": "kitten.jpg"
}

Oct  7 19:35:58.223: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Oct  7 19:35:58.223: INFO: update-demo-kitten-t6jbp is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:35:58.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2544" for this suite.
Oct  7 19:36:26.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:36:26.314: INFO: namespace kubectl-2544 deletion completed in 28.085260777s

• [SLOW TEST:57.335 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:36:26.318: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Oct  7 19:36:26.891: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Oct  7 19:36:28.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073787, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073787, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073787, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63706073786, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Oct  7 19:36:31.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Oct  7 19:36:31.969: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-873-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:36:33.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5153" for this suite.
Oct  7 19:36:39.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:36:39.591: INFO: namespace webhook-5153 deletion completed in 6.081102817s
STEP: Destroying namespace "webhook-5153-markers" for this suite.
Oct  7 19:36:45.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:36:45.675: INFO: namespace webhook-5153-markers deletion completed in 6.083866506s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.372 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:36:45.690: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1543e8e8-45ca-47c8-8aed-266ad8910f62
STEP: Creating a pod to test consume configMaps
Oct  7 19:36:45.861: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680" in namespace "projected-9637" to be "success or failure"
Oct  7 19:36:45.863: INFO: Pod "pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680": Phase="Pending", Reason="", readiness=false. Elapsed: 2.617062ms
Oct  7 19:36:47.867: INFO: Pod "pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006397457s
STEP: Saw pod success
Oct  7 19:36:47.867: INFO: Pod "pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680" satisfied condition "success or failure"
Oct  7 19:36:47.870: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Oct  7 19:36:47.899: INFO: Waiting for pod pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680 to disappear
Oct  7 19:36:47.902: INFO: Pod pod-projected-configmaps-065ea80d-6c63-4a27-b763-25299ab0c680 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:36:47.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9637" for this suite.
Oct  7 19:36:53.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:36:53.983: INFO: namespace projected-9637 deletion completed in 6.077236074s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:36:53.983: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Oct  7 19:36:54.142: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:37:04.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1948" for this suite.
Oct  7 19:37:10.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:37:10.451: INFO: namespace pods-1948 deletion completed in 6.139028887s

• [SLOW TEST:16.468 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:37:10.452: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:37:17.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-945" for this suite.
Oct  7 19:37:23.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:37:23.719: INFO: namespace resourcequota-945 deletion completed in 6.082866218s

• [SLOW TEST:13.267 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Oct  7 19:37:23.721: INFO: >>> kubeConfig: /tmp/kubeconfig-832208514
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Oct  7 19:37:23.904: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a" in namespace "projected-5550" to be "success or failure"
Oct  7 19:37:23.907: INFO: Pod "downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.304201ms
Oct  7 19:37:25.912: INFO: Pod "downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007805684s
STEP: Saw pod success
Oct  7 19:37:25.912: INFO: Pod "downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a" satisfied condition "success or failure"
Oct  7 19:37:25.915: INFO: Trying to get logs from node talos-v020-gcp-workers-654f4446bf-ns4sr pod downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a container client-container: <nil>
STEP: delete the pod
Oct  7 19:37:25.939: INFO: Waiting for pod downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a to disappear
Oct  7 19:37:25.942: INFO: Pod downwardapi-volume-36eb1469-a371-4154-b699-b34e95da513a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Oct  7 19:37:25.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5550" for this suite.
Oct  7 19:37:31.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Oct  7 19:37:32.028: INFO: namespace projected-5550 deletion completed in 6.081597265s

• [SLOW TEST:8.307 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSOct  7 19:37:32.029: INFO: Running AfterSuite actions on all nodes
Oct  7 19:37:32.029: INFO: Running AfterSuite actions on node 1
Oct  7 19:37:32.029: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 6966.226 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 1h56m7.819739598s
Test Suite Passed
