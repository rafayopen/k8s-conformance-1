I0922 07:56:49.990998      18 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-153516655
I0922 07:56:49.991100      18 e2e.go:92] Starting e2e run "e25f6d56-3df1-4089-8994-9c7aa9b62dd6" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569139008 - Will randomize all specs
Will run 274 of 4897 specs

Sep 22 07:56:50.041: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 07:56:50.044: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 22 07:56:50.061: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 22 07:56:50.095: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 22 07:56:50.096: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Sep 22 07:56:50.096: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 22 07:56:50.103: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep 22 07:56:50.103: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 22 07:56:50.103: INFO: e2e test version: v1.16.0
Sep 22 07:56:50.104: INFO: kube-apiserver version: v1.16.0
Sep 22 07:56:50.104: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 07:56:50.109: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:56:50.109: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-runtime
Sep 22 07:56:50.136: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 22 07:56:52.152: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:56:52.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3586" for this suite.
Sep 22 07:56:58.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:56:58.244: INFO: namespace container-runtime-3586 deletion completed in 6.079083595s

• [SLOW TEST:8.135 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:56:58.245: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-3408
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3408
STEP: creating replication controller externalsvc in namespace services-3408
I0922 07:56:58.293930      18 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3408, replica count: 2
I0922 07:56:58.294032      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 07:56:58.294051      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 07:57:01.344366      18 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Sep 22 07:57:01.371: INFO: Creating new exec pod
Sep 22 07:57:03.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-3408 execpodzgcjp -- /bin/sh -x -c nslookup nodeport-service'
Sep 22 07:57:03.782: INFO: stderr: "+ nslookup nodeport-service\n"
Sep 22 07:57:03.782: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-3408.svc.cluster.local\tcanonical name = externalsvc.services-3408.svc.cluster.local.\nName:\texternalsvc.services-3408.svc.cluster.local\nAddress: 10.3.225.2\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3408, will wait for the garbage collector to delete the pods
I0922 07:57:03.785557      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 07:57:03.785586      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 07:57:03.840: INFO: Deleting ReplicationController externalsvc took: 4.444161ms
Sep 22 07:57:04.140: INFO: Terminating ReplicationController externalsvc pods took: 300.384788ms
I0922 07:57:04.140345      18 controller_utils.go:810] Ignoring inactive pod services-3408/externalsvc-xd8zd in state Running, deletion time 2019-09-22 07:57:05 +0000 UTC
I0922 07:57:04.140494      18 controller_utils.go:810] Ignoring inactive pod services-3408/externalsvc-6lzx6 in state Running, deletion time 2019-09-22 07:57:05 +0000 UTC
Sep 22 07:57:07.757: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:57:07.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3408" for this suite.
Sep 22 07:57:13.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:13.856: INFO: namespace services-3408 deletion completed in 6.085566139s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.611 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:57:13.859: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7a80cc59-bfb9-4898-b297-4390276535ec
STEP: Creating a pod to test consume configMaps
Sep 22 07:57:13.893: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0" in namespace "projected-826" to be "success or failure"
Sep 22 07:57:13.896: INFO: Pod "pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.454733ms
Sep 22 07:57:15.900: INFO: Pod "pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00726492s
STEP: Saw pod success
Sep 22 07:57:15.900: INFO: Pod "pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0" satisfied condition "success or failure"
Sep 22 07:57:15.903: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 07:57:15.924: INFO: Waiting for pod pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0 to disappear
Sep 22 07:57:15.929: INFO: Pod pod-projected-configmaps-64801df8-0808-47b1-b641-52d19da2b7c0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:57:15.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-826" for this suite.
Sep 22 07:57:21.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:22.012: INFO: namespace projected-826 deletion completed in 6.079924981s

• [SLOW TEST:8.153 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:57:22.012: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 07:57:22.628: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 07:57:25.646: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 07:57:25.649: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6827-crds.webhook.example.com via the AdmissionRegistration API
Sep 22 07:57:26.192: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:57:27.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1066" for this suite.
Sep 22 07:57:33.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:33.149: INFO: namespace webhook-1066 deletion completed in 6.092197866s
STEP: Destroying namespace "webhook-1066-markers" for this suite.
Sep 22 07:57:39.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:39.231: INFO: namespace webhook-1066-markers deletion completed in 6.082162834s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.232 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:57:39.244: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 07:57:39.281: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed" in namespace "projected-5871" to be "success or failure"
Sep 22 07:57:39.286: INFO: Pod "downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.970678ms
Sep 22 07:57:41.290: INFO: Pod "downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00901736s
STEP: Saw pod success
Sep 22 07:57:41.290: INFO: Pod "downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed" satisfied condition "success or failure"
Sep 22 07:57:41.293: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed container client-container: <nil>
STEP: delete the pod
Sep 22 07:57:41.314: INFO: Waiting for pod downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed to disappear
Sep 22 07:57:41.317: INFO: Pod downwardapi-volume-8b36c2af-4168-4177-8e2d-7c6eb130c0ed no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:57:41.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5871" for this suite.
Sep 22 07:57:47.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:47.400: INFO: namespace projected-5871 deletion completed in 6.078838958s

• [SLOW TEST:8.157 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:57:47.404: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 07:57:47.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 version'
Sep 22 07:57:47.524: INFO: stderr: ""
Sep 22 07:57:47.524: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:36:53Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.0\", GitCommit:\"2bd9643cee5b3b3a5ecbd3af49d09018f0773c77\", GitTreeState:\"clean\", BuildDate:\"2019-09-18T14:27:17Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:57:47.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9856" for this suite.
Sep 22 07:57:53.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:57:53.608: INFO: namespace kubectl-9856 deletion completed in 6.078174572s

• [SLOW TEST:6.204 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:57:53.608: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 07:58:19.661: INFO: Container started at 2019-09-22 07:57:54 +0000 UTC, pod became ready at 2019-09-22 07:58:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:58:19.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6127" for this suite.
Sep 22 07:58:31.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:58:31.771: INFO: namespace container-probe-6127 deletion completed in 12.106303147s

• [SLOW TEST:38.163 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:58:31.771: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0922 07:59:11.836158      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 22 07:59:11.836: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:59:11.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2070" for this suite.
Sep 22 07:59:17.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:59:17.965: INFO: namespace gc-2070 deletion completed in 6.126257681s

• [SLOW TEST:46.194 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:59:17.965: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 22 07:59:18.027: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:18.030: INFO: Number of nodes with available pods: 0
Sep 22 07:59:18.030: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:19.039: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:19.042: INFO: Number of nodes with available pods: 0
Sep 22 07:59:19.043: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:20.034: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:20.036: INFO: Number of nodes with available pods: 1
Sep 22 07:59:20.036: INFO: Node ip-10-0-30-60 is running more than one daemon pod
Sep 22 07:59:21.037: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:21.040: INFO: Number of nodes with available pods: 1
Sep 22 07:59:21.040: INFO: Node ip-10-0-30-60 is running more than one daemon pod
Sep 22 07:59:22.033: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:22.036: INFO: Number of nodes with available pods: 2
Sep 22 07:59:22.036: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 22 07:59:22.047: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:22.051: INFO: Number of nodes with available pods: 1
Sep 22 07:59:22.051: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:23.056: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:23.059: INFO: Number of nodes with available pods: 1
Sep 22 07:59:23.059: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:24.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:24.059: INFO: Number of nodes with available pods: 1
Sep 22 07:59:24.059: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:25.056: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:25.060: INFO: Number of nodes with available pods: 1
Sep 22 07:59:25.060: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:26.058: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:26.062: INFO: Number of nodes with available pods: 1
Sep 22 07:59:26.062: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:27.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:27.060: INFO: Number of nodes with available pods: 1
Sep 22 07:59:27.060: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:28.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:28.064: INFO: Number of nodes with available pods: 1
Sep 22 07:59:28.064: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:29.065: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:29.073: INFO: Number of nodes with available pods: 1
Sep 22 07:59:29.073: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:30.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:30.059: INFO: Number of nodes with available pods: 1
Sep 22 07:59:30.059: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:31.059: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:31.062: INFO: Number of nodes with available pods: 1
Sep 22 07:59:31.062: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:32.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:32.057: INFO: Number of nodes with available pods: 1
Sep 22 07:59:32.057: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:33.059: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:33.066: INFO: Number of nodes with available pods: 1
Sep 22 07:59:33.066: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:34.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:34.058: INFO: Number of nodes with available pods: 1
Sep 22 07:59:34.058: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:35.055: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:35.059: INFO: Number of nodes with available pods: 1
Sep 22 07:59:35.059: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:36.058: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:36.062: INFO: Number of nodes with available pods: 1
Sep 22 07:59:36.062: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 07:59:37.054: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 07:59:37.057: INFO: Number of nodes with available pods: 2
Sep 22 07:59:37.057: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9256, will wait for the garbage collector to delete the pods
I0922 07:59:37.063136      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 07:59:37.063172      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 07:59:37.117: INFO: Deleting DaemonSet.extensions daemon-set took: 4.448359ms
Sep 22 07:59:37.417: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.21392ms
I0922 07:59:37.417858      18 controller_utils.go:810] Ignoring inactive pod daemonsets-9256/daemon-set-h9mt5 in state Running, deletion time 2019-09-22 08:00:07 +0000 UTC
I0922 07:59:37.417889      18 controller_utils.go:810] Ignoring inactive pod daemonsets-9256/daemon-set-ntpbf in state Running, deletion time 2019-09-22 08:00:07 +0000 UTC
Sep 22 07:59:45.551: INFO: Number of nodes with available pods: 0
Sep 22 07:59:45.551: INFO: Number of running nodes: 0, number of available pods: 0
Sep 22 07:59:45.579: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9256/daemonsets","resourceVersion":"319930"},"items":null}

Sep 22 07:59:45.593: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9256/pods","resourceVersion":"319930"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:59:45.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9256" for this suite.
Sep 22 07:59:51.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:59:51.720: INFO: namespace daemonsets-9256 deletion completed in 6.076249486s

• [SLOW TEST:33.755 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:59:51.720: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 22 07:59:51.757: INFO: Waiting up to 5m0s for pod "pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff" in namespace "emptydir-4070" to be "success or failure"
Sep 22 07:59:51.760: INFO: Pod "pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.305703ms
Sep 22 07:59:53.763: INFO: Pod "pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006154291s
STEP: Saw pod success
Sep 22 07:59:53.763: INFO: Pod "pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff" satisfied condition "success or failure"
Sep 22 07:59:53.766: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff container test-container: <nil>
STEP: delete the pod
Sep 22 07:59:53.788: INFO: Waiting for pod pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff to disappear
Sep 22 07:59:53.795: INFO: Pod pod-79a4cc60-422a-4f71-b5fc-d3052e5a56ff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 07:59:53.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4070" for this suite.
Sep 22 07:59:59.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 07:59:59.966: INFO: namespace emptydir-4070 deletion completed in 6.163380051s

• [SLOW TEST:8.246 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 07:59:59.966: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-jmzf
STEP: Creating a pod to test atomic-volume-subpath
Sep 22 08:00:00.047: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jmzf" in namespace "subpath-8106" to be "success or failure"
Sep 22 08:00:00.057: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.682937ms
Sep 22 08:00:02.060: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 2.013922829s
Sep 22 08:00:04.064: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 4.017443743s
Sep 22 08:00:06.071: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 6.024138616s
Sep 22 08:00:08.074: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 8.027315339s
Sep 22 08:00:10.077: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 10.030235426s
Sep 22 08:00:12.082: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 12.035680754s
Sep 22 08:00:14.086: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 14.039426409s
Sep 22 08:00:16.090: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 16.042984192s
Sep 22 08:00:18.092: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 18.045930406s
Sep 22 08:00:20.096: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Running", Reason="", readiness=true. Elapsed: 20.049055272s
Sep 22 08:00:22.099: INFO: Pod "pod-subpath-test-configmap-jmzf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.052064662s
STEP: Saw pod success
Sep 22 08:00:22.099: INFO: Pod "pod-subpath-test-configmap-jmzf" satisfied condition "success or failure"
Sep 22 08:00:22.101: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-subpath-test-configmap-jmzf container test-container-subpath-configmap-jmzf: <nil>
STEP: delete the pod
Sep 22 08:00:22.115: INFO: Waiting for pod pod-subpath-test-configmap-jmzf to disappear
Sep 22 08:00:22.118: INFO: Pod pod-subpath-test-configmap-jmzf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jmzf
Sep 22 08:00:22.118: INFO: Deleting pod "pod-subpath-test-configmap-jmzf" in namespace "subpath-8106"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:00:22.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8106" for this suite.
Sep 22 08:00:28.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:00:28.202: INFO: namespace subpath-8106 deletion completed in 6.072600763s

• [SLOW TEST:28.236 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:00:28.202: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-01d217cb-96ec-499c-bce4-e6b4fd102516
STEP: Creating a pod to test consume configMaps
Sep 22 08:00:28.235: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280" in namespace "projected-8120" to be "success or failure"
Sep 22 08:00:28.240: INFO: Pod "pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280": Phase="Pending", Reason="", readiness=false. Elapsed: 5.800278ms
Sep 22 08:00:30.244: INFO: Pod "pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009321677s
STEP: Saw pod success
Sep 22 08:00:30.244: INFO: Pod "pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280" satisfied condition "success or failure"
Sep 22 08:00:30.247: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:00:30.261: INFO: Waiting for pod pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280 to disappear
Sep 22 08:00:30.265: INFO: Pod pod-projected-configmaps-b99757c2-0594-4fc7-afbe-6562083e2280 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:00:30.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8120" for this suite.
Sep 22 08:00:36.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:00:36.358: INFO: namespace projected-8120 deletion completed in 6.087242512s

• [SLOW TEST:8.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:00:36.359: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:00:36.390: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546" in namespace "projected-7626" to be "success or failure"
Sep 22 08:00:36.394: INFO: Pod "downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546": Phase="Pending", Reason="", readiness=false. Elapsed: 4.445591ms
Sep 22 08:00:38.397: INFO: Pod "downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007436811s
STEP: Saw pod success
Sep 22 08:00:38.397: INFO: Pod "downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546" satisfied condition "success or failure"
Sep 22 08:00:38.400: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546 container client-container: <nil>
STEP: delete the pod
Sep 22 08:00:38.414: INFO: Waiting for pod downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546 to disappear
Sep 22 08:00:38.417: INFO: Pod downwardapi-volume-03a866fc-da9c-4c0d-aa3c-efc2d6bd7546 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:00:38.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7626" for this suite.
Sep 22 08:00:44.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:00:44.493: INFO: namespace projected-7626 deletion completed in 6.074175159s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:00:44.494: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:00:45.252: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:00:47.261: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736045, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736045, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736045, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736045, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:00:50.270: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:01:00.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6555" for this suite.
Sep 22 08:01:06.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:01:06.734: INFO: namespace webhook-6555 deletion completed in 6.092186327s
STEP: Destroying namespace "webhook-6555-markers" for this suite.
Sep 22 08:01:12.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:01:12.824: INFO: namespace webhook-6555-markers deletion completed in 6.090200962s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.342 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:01:12.837: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-xmsk
STEP: Creating a pod to test atomic-volume-subpath
Sep 22 08:01:12.899: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-xmsk" in namespace "subpath-4330" to be "success or failure"
Sep 22 08:01:12.901: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Pending", Reason="", readiness=false. Elapsed: 2.209235ms
Sep 22 08:01:14.904: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 2.004965853s
Sep 22 08:01:16.907: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 4.008358202s
Sep 22 08:01:18.911: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 6.01147998s
Sep 22 08:01:20.914: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 8.014982243s
Sep 22 08:01:22.917: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 10.017961069s
Sep 22 08:01:24.920: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 12.020773631s
Sep 22 08:01:26.923: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 14.023856424s
Sep 22 08:01:28.927: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 16.027832065s
Sep 22 08:01:30.930: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 18.031238399s
Sep 22 08:01:32.934: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Running", Reason="", readiness=true. Elapsed: 20.034885794s
Sep 22 08:01:34.939: INFO: Pod "pod-subpath-test-projected-xmsk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.040127379s
STEP: Saw pod success
Sep 22 08:01:34.939: INFO: Pod "pod-subpath-test-projected-xmsk" satisfied condition "success or failure"
Sep 22 08:01:34.942: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-subpath-test-projected-xmsk container test-container-subpath-projected-xmsk: <nil>
STEP: delete the pod
Sep 22 08:01:34.959: INFO: Waiting for pod pod-subpath-test-projected-xmsk to disappear
Sep 22 08:01:34.962: INFO: Pod pod-subpath-test-projected-xmsk no longer exists
STEP: Deleting pod pod-subpath-test-projected-xmsk
Sep 22 08:01:34.962: INFO: Deleting pod "pod-subpath-test-projected-xmsk" in namespace "subpath-4330"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:01:34.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4330" for this suite.
Sep 22 08:01:40.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:01:41.065: INFO: namespace subpath-4330 deletion completed in 6.098552978s

• [SLOW TEST:28.229 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:01:41.067: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 22 08:01:41.106: INFO: Waiting up to 5m0s for pod "pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a" in namespace "emptydir-5797" to be "success or failure"
Sep 22 08:01:41.110: INFO: Pod "pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.569726ms
Sep 22 08:01:43.115: INFO: Pod "pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00873547s
STEP: Saw pod success
Sep 22 08:01:43.115: INFO: Pod "pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a" satisfied condition "success or failure"
Sep 22 08:01:43.118: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a container test-container: <nil>
STEP: delete the pod
Sep 22 08:01:43.132: INFO: Waiting for pod pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a to disappear
Sep 22 08:01:43.136: INFO: Pod pod-c0b6386c-7980-45e9-8359-cdf14bf5aa5a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:01:43.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5797" for this suite.
Sep 22 08:01:49.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:01:49.220: INFO: namespace emptydir-5797 deletion completed in 6.079711744s

• [SLOW TEST:8.154 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:01:49.222: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:02:02.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7527" for this suite.
Sep 22 08:02:08.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:02:08.391: INFO: namespace resourcequota-7527 deletion completed in 6.088826937s

• [SLOW TEST:19.169 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:02:08.394: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7865.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-7865.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7865.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-7865.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-7865.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7865.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 08:02:10.474: INFO: DNS probes using dns-7865/dns-test-5f17b267-0862-40b8-ae16-2aaf0361b92f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:02:10.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7865" for this suite.
Sep 22 08:02:16.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:02:16.579: INFO: namespace dns-7865 deletion completed in 6.09206919s

• [SLOW TEST:8.185 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:02:16.579: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Sep 22 08:02:16.603: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-153516655 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:02:16.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9915" for this suite.
Sep 22 08:02:22.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:02:22.801: INFO: namespace kubectl-9915 deletion completed in 6.083026411s

• [SLOW TEST:6.222 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:02:22.802: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:02:22.833: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036" in namespace "downward-api-391" to be "success or failure"
Sep 22 08:02:22.836: INFO: Pod "downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036": Phase="Pending", Reason="", readiness=false. Elapsed: 2.989741ms
Sep 22 08:02:24.840: INFO: Pod "downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006543034s
STEP: Saw pod success
Sep 22 08:02:24.840: INFO: Pod "downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036" satisfied condition "success or failure"
Sep 22 08:02:24.844: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036 container client-container: <nil>
STEP: delete the pod
Sep 22 08:02:24.859: INFO: Waiting for pod downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036 to disappear
Sep 22 08:02:24.862: INFO: Pod downwardapi-volume-c3b6c6b3-f2fe-43c4-8dc2-8cd41d97f036 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:02:24.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-391" for this suite.
Sep 22 08:02:30.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:02:30.965: INFO: namespace downward-api-391 deletion completed in 6.100327072s

• [SLOW TEST:8.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:02:30.966: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:02:33.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3899" for this suite.
Sep 22 08:03:17.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:03:17.192: INFO: namespace kubelet-test-3899 deletion completed in 44.115875379s

• [SLOW TEST:46.226 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:03:17.195: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Sep 22 08:03:17.233: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:03:20.815: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:03:35.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3955" for this suite.
Sep 22 08:03:41.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:03:41.197: INFO: namespace crd-publish-openapi-3955 deletion completed in 6.086787345s

• [SLOW TEST:24.003 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:03:41.198: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:03:42.246: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:03:45.261: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:03:45.266: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3288-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:03:45.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3189" for this suite.
Sep 22 08:03:51.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:03:52.017: INFO: namespace webhook-3189 deletion completed in 6.082477661s
STEP: Destroying namespace "webhook-3189-markers" for this suite.
Sep 22 08:03:58.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:03:58.098: INFO: namespace webhook-3189-markers deletion completed in 6.080279637s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.909 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:03:58.107: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-k75h8 in namespace proxy-8701
I0922 08:03:58.198499      18 runners.go:184] Created replication controller with name: proxy-service-k75h8, namespace: proxy-8701, replica count: 1
I0922 08:03:58.198687      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:03:58.198707      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:03:59.249234      18 runners.go:184] proxy-service-k75h8 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 08:04:00.249430      18 runners.go:184] proxy-service-k75h8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0922 08:04:01.250244      18 runners.go:184] proxy-service-k75h8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0922 08:04:02.250448      18 runners.go:184] proxy-service-k75h8 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0922 08:04:03.250633      18 runners.go:184] proxy-service-k75h8 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 22 08:04:03.255: INFO: setup took 5.0686665s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 22 08:04:03.265: INFO: (0) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 10.16404ms)
Sep 22 08:04:03.267: INFO: (0) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 10.28789ms)
Sep 22 08:04:03.268: INFO: (0) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 11.049937ms)
Sep 22 08:04:03.272: INFO: (0) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 15.294252ms)
Sep 22 08:04:03.272: INFO: (0) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 14.766369ms)
Sep 22 08:04:03.272: INFO: (0) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 16.409122ms)
Sep 22 08:04:03.278: INFO: (0) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 21.122839ms)
Sep 22 08:04:03.278: INFO: (0) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 21.583019ms)
Sep 22 08:04:03.279: INFO: (0) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 21.658628ms)
Sep 22 08:04:03.279: INFO: (0) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 19.877941ms)
Sep 22 08:04:03.282: INFO: (0) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 26.928086ms)
Sep 22 08:04:03.282: INFO: (0) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 22.988962ms)
Sep 22 08:04:03.282: INFO: (0) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 22.826401ms)
Sep 22 08:04:03.282: INFO: (0) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 24.846355ms)
Sep 22 08:04:03.283: INFO: (0) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 24.063736ms)
Sep 22 08:04:03.283: INFO: (0) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 25.921265ms)
Sep 22 08:04:03.289: INFO: (1) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 5.909597ms)
Sep 22 08:04:03.301: INFO: (1) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 17.433147ms)
Sep 22 08:04:03.301: INFO: (1) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 16.824344ms)
Sep 22 08:04:03.301: INFO: (1) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 16.765924ms)
Sep 22 08:04:03.301: INFO: (1) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 16.642745ms)
Sep 22 08:04:03.301: INFO: (1) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 17.295942ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 16.499827ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 17.342369ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 18.721974ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 18.665898ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 18.376937ms)
Sep 22 08:04:03.302: INFO: (1) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 17.654368ms)
Sep 22 08:04:03.303: INFO: (1) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 17.720987ms)
Sep 22 08:04:03.303: INFO: (1) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 19.478692ms)
Sep 22 08:04:03.303: INFO: (1) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 19.2896ms)
Sep 22 08:04:03.303: INFO: (1) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 19.501541ms)
Sep 22 08:04:03.318: INFO: (2) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 14.470816ms)
Sep 22 08:04:03.318: INFO: (2) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 14.569505ms)
Sep 22 08:04:03.318: INFO: (2) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 14.641827ms)
Sep 22 08:04:03.318: INFO: (2) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 14.15927ms)
Sep 22 08:04:03.318: INFO: (2) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 14.079832ms)
Sep 22 08:04:03.319: INFO: (2) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 14.801199ms)
Sep 22 08:04:03.319: INFO: (2) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 14.587306ms)
Sep 22 08:04:03.319: INFO: (2) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 15.79198ms)
Sep 22 08:04:03.320: INFO: (2) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 15.409729ms)
Sep 22 08:04:03.320: INFO: (2) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 15.643455ms)
Sep 22 08:04:03.320: INFO: (2) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 16.507941ms)
Sep 22 08:04:03.324: INFO: (2) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 19.739134ms)
Sep 22 08:04:03.324: INFO: (2) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 20.092555ms)
Sep 22 08:04:03.324: INFO: (2) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 19.438245ms)
Sep 22 08:04:03.324: INFO: (2) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 19.568098ms)
Sep 22 08:04:03.327: INFO: (2) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 23.251359ms)
Sep 22 08:04:03.332: INFO: (3) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 4.612599ms)
Sep 22 08:04:03.333: INFO: (3) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 5.91268ms)
Sep 22 08:04:03.334: INFO: (3) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 5.67561ms)
Sep 22 08:04:03.334: INFO: (3) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 6.754021ms)
Sep 22 08:04:03.337: INFO: (3) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 9.813749ms)
Sep 22 08:04:03.338: INFO: (3) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 6.469238ms)
Sep 22 08:04:03.338: INFO: (3) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 10.218063ms)
Sep 22 08:04:03.338: INFO: (3) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.80924ms)
Sep 22 08:04:03.338: INFO: (3) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 10.929436ms)
Sep 22 08:04:03.340: INFO: (3) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 8.412021ms)
Sep 22 08:04:03.341: INFO: (3) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 8.707932ms)
Sep 22 08:04:03.341: INFO: (3) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 8.786762ms)
Sep 22 08:04:03.341: INFO: (3) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 9.044529ms)
Sep 22 08:04:03.342: INFO: (3) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 10.706253ms)
Sep 22 08:04:03.342: INFO: (3) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 10.804517ms)
Sep 22 08:04:03.342: INFO: (3) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 10.375637ms)
Sep 22 08:04:03.350: INFO: (4) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 6.593222ms)
Sep 22 08:04:03.350: INFO: (4) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 7.496741ms)
Sep 22 08:04:03.350: INFO: (4) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 7.457116ms)
Sep 22 08:04:03.350: INFO: (4) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 7.657364ms)
Sep 22 08:04:03.352: INFO: (4) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.398994ms)
Sep 22 08:04:03.353: INFO: (4) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 10.419812ms)
Sep 22 08:04:03.354: INFO: (4) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 10.912846ms)
Sep 22 08:04:03.354: INFO: (4) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 10.73394ms)
Sep 22 08:04:03.354: INFO: (4) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 11.506242ms)
Sep 22 08:04:03.354: INFO: (4) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 11.410869ms)
Sep 22 08:04:03.354: INFO: (4) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 11.592578ms)
Sep 22 08:04:03.355: INFO: (4) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 12.161798ms)
Sep 22 08:04:03.355: INFO: (4) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 12.507181ms)
Sep 22 08:04:03.356: INFO: (4) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.667452ms)
Sep 22 08:04:03.356: INFO: (4) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 13.030042ms)
Sep 22 08:04:03.356: INFO: (4) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 12.678765ms)
Sep 22 08:04:03.367: INFO: (5) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 10.333171ms)
Sep 22 08:04:03.367: INFO: (5) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 10.682224ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 11.809673ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 11.717628ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 11.949115ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 11.543798ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 11.859865ms)
Sep 22 08:04:03.368: INFO: (5) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 11.875663ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 13.459102ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 13.544115ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 13.524044ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 13.96028ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 13.766341ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 14.012474ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 13.386758ms)
Sep 22 08:04:03.370: INFO: (5) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 14.185932ms)
Sep 22 08:04:03.380: INFO: (6) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 8.971638ms)
Sep 22 08:04:03.380: INFO: (6) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 9.591502ms)
Sep 22 08:04:03.380: INFO: (6) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.767564ms)
Sep 22 08:04:03.382: INFO: (6) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 11.376281ms)
Sep 22 08:04:03.383: INFO: (6) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 12.861257ms)
Sep 22 08:04:03.384: INFO: (6) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 13.184602ms)
Sep 22 08:04:03.384: INFO: (6) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 13.633488ms)
Sep 22 08:04:03.384: INFO: (6) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 13.550634ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 13.622854ms)
Sep 22 08:04:03.384: INFO: (6) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 13.634198ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 13.820653ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 13.809715ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 14.05357ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 14.056874ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 13.858426ms)
Sep 22 08:04:03.385: INFO: (6) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 13.992535ms)
Sep 22 08:04:03.389: INFO: (7) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 3.703884ms)
Sep 22 08:04:03.391: INFO: (7) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 5.688737ms)
Sep 22 08:04:03.392: INFO: (7) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 6.838804ms)
Sep 22 08:04:03.393: INFO: (7) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 7.167773ms)
Sep 22 08:04:03.393: INFO: (7) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 7.266467ms)
Sep 22 08:04:03.393: INFO: (7) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 7.957392ms)
Sep 22 08:04:03.399: INFO: (7) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 11.861013ms)
Sep 22 08:04:03.400: INFO: (7) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.959167ms)
Sep 22 08:04:03.400: INFO: (7) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 12.678804ms)
Sep 22 08:04:03.400: INFO: (7) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.644132ms)
Sep 22 08:04:03.400: INFO: (7) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 12.533305ms)
Sep 22 08:04:03.401: INFO: (7) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 13.719422ms)
Sep 22 08:04:03.401: INFO: (7) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 13.627272ms)
Sep 22 08:04:03.401: INFO: (7) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 13.715221ms)
Sep 22 08:04:03.402: INFO: (7) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 14.843757ms)
Sep 22 08:04:03.402: INFO: (7) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 14.966536ms)
Sep 22 08:04:03.410: INFO: (8) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 7.474647ms)
Sep 22 08:04:03.411: INFO: (8) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 8.675063ms)
Sep 22 08:04:03.411: INFO: (8) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 8.432814ms)
Sep 22 08:04:03.412: INFO: (8) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 9.739998ms)
Sep 22 08:04:03.415: INFO: (8) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 12.62204ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 14.413373ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 14.932182ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.291042ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 15.109625ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 15.301301ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.202947ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 14.953133ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 12.164477ms)
Sep 22 08:04:03.417: INFO: (8) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 12.636011ms)
Sep 22 08:04:03.418: INFO: (8) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 12.541808ms)
Sep 22 08:04:03.418: INFO: (8) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 12.383875ms)
Sep 22 08:04:03.426: INFO: (9) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 7.29581ms)
Sep 22 08:04:03.427: INFO: (9) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 9.267662ms)
Sep 22 08:04:03.429: INFO: (9) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.196151ms)
Sep 22 08:04:03.429: INFO: (9) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 11.330024ms)
Sep 22 08:04:03.429: INFO: (9) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 11.548277ms)
Sep 22 08:04:03.430: INFO: (9) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 9.335656ms)
Sep 22 08:04:03.431: INFO: (9) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.931364ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 11.389636ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 13.440528ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 12.40059ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 12.045944ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 13.809906ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 13.897833ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 12.414615ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 10.378409ms)
Sep 22 08:04:03.432: INFO: (9) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 13.805621ms)
Sep 22 08:04:03.446: INFO: (10) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 10.730296ms)
Sep 22 08:04:03.446: INFO: (10) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.21021ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 12.074378ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 11.757259ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 12.045242ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 11.447102ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.604224ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 12.593171ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 11.927127ms)
Sep 22 08:04:03.447: INFO: (10) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 12.014761ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.518807ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 12.682359ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 13.085126ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 12.92881ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 15.659264ms)
Sep 22 08:04:03.448: INFO: (10) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 15.545726ms)
Sep 22 08:04:03.453: INFO: (11) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 5.343354ms)
Sep 22 08:04:03.454: INFO: (11) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 5.786694ms)
Sep 22 08:04:03.454: INFO: (11) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 5.531179ms)
Sep 22 08:04:03.454: INFO: (11) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 5.688292ms)
Sep 22 08:04:03.459: INFO: (11) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 10.163085ms)
Sep 22 08:04:03.460: INFO: (11) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 10.661116ms)
Sep 22 08:04:03.460: INFO: (11) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 11.301019ms)
Sep 22 08:04:03.460: INFO: (11) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 11.791796ms)
Sep 22 08:04:03.460: INFO: (11) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 10.903287ms)
Sep 22 08:04:03.460: INFO: (11) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 11.229951ms)
Sep 22 08:04:03.461: INFO: (11) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 12.584852ms)
Sep 22 08:04:03.461: INFO: (11) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 12.434546ms)
Sep 22 08:04:03.462: INFO: (11) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 13.02613ms)
Sep 22 08:04:03.462: INFO: (11) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 13.862241ms)
Sep 22 08:04:03.462: INFO: (11) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 13.68719ms)
Sep 22 08:04:03.462: INFO: (11) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 13.424916ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 11.529574ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.077056ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 12.527344ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 12.028005ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 11.706682ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.410084ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 11.470682ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 11.560726ms)
Sep 22 08:04:03.475: INFO: (12) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 12.037578ms)
Sep 22 08:04:03.477: INFO: (12) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 14.277268ms)
Sep 22 08:04:03.477: INFO: (12) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 14.120698ms)
Sep 22 08:04:03.477: INFO: (12) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 14.479833ms)
Sep 22 08:04:03.477: INFO: (12) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 14.002516ms)
Sep 22 08:04:03.477: INFO: (12) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 14.325168ms)
Sep 22 08:04:03.478: INFO: (12) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 15.213686ms)
Sep 22 08:04:03.478: INFO: (12) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 14.894804ms)
Sep 22 08:04:03.486: INFO: (13) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 7.860671ms)
Sep 22 08:04:03.486: INFO: (13) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 8.052588ms)
Sep 22 08:04:03.486: INFO: (13) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 8.183633ms)
Sep 22 08:04:03.488: INFO: (13) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 8.332175ms)
Sep 22 08:04:03.488: INFO: (13) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.467655ms)
Sep 22 08:04:03.488: INFO: (13) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 9.372553ms)
Sep 22 08:04:03.490: INFO: (13) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 10.483296ms)
Sep 22 08:04:03.490: INFO: (13) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 10.648934ms)
Sep 22 08:04:03.490: INFO: (13) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 11.404214ms)
Sep 22 08:04:03.490: INFO: (13) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 11.174094ms)
Sep 22 08:04:03.491: INFO: (13) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 11.927893ms)
Sep 22 08:04:03.491: INFO: (13) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 12.627867ms)
Sep 22 08:04:03.491: INFO: (13) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 12.234374ms)
Sep 22 08:04:03.492: INFO: (13) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 13.397414ms)
Sep 22 08:04:03.492: INFO: (13) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 13.803278ms)
Sep 22 08:04:03.492: INFO: (13) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 13.878656ms)
Sep 22 08:04:03.501: INFO: (14) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 8.775565ms)
Sep 22 08:04:03.504: INFO: (14) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 11.678858ms)
Sep 22 08:04:03.505: INFO: (14) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.547207ms)
Sep 22 08:04:03.505: INFO: (14) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 12.031616ms)
Sep 22 08:04:03.505: INFO: (14) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 12.385873ms)
Sep 22 08:04:03.505: INFO: (14) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 12.510406ms)
Sep 22 08:04:03.506: INFO: (14) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 12.160598ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 15.024569ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 14.635895ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 14.611991ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 14.590838ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 14.560837ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 14.905875ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 14.523896ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 14.412053ms)
Sep 22 08:04:03.508: INFO: (14) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 14.861502ms)
Sep 22 08:04:03.511: INFO: (15) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 3.017222ms)
Sep 22 08:04:03.519: INFO: (15) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 9.133339ms)
Sep 22 08:04:03.519: INFO: (15) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 8.652381ms)
Sep 22 08:04:03.519: INFO: (15) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 10.858789ms)
Sep 22 08:04:03.519: INFO: (15) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 8.809548ms)
Sep 22 08:04:03.519: INFO: (15) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 9.551425ms)
Sep 22 08:04:03.539: INFO: (15) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 28.869189ms)
Sep 22 08:04:03.539: INFO: (15) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 29.262869ms)
Sep 22 08:04:03.539: INFO: (15) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 29.384317ms)
Sep 22 08:04:03.539: INFO: (15) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 28.795168ms)
Sep 22 08:04:03.539: INFO: (15) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 29.570155ms)
Sep 22 08:04:03.541: INFO: (15) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 30.74688ms)
Sep 22 08:04:03.541: INFO: (15) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 31.688854ms)
Sep 22 08:04:03.542: INFO: (15) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 32.823991ms)
Sep 22 08:04:03.543: INFO: (15) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 33.336482ms)
Sep 22 08:04:03.543: INFO: (15) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 33.213935ms)
Sep 22 08:04:03.561: INFO: (16) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 18.129553ms)
Sep 22 08:04:03.561: INFO: (16) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 17.910055ms)
Sep 22 08:04:03.561: INFO: (16) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 17.862584ms)
Sep 22 08:04:03.561: INFO: (16) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 17.64747ms)
Sep 22 08:04:03.561: INFO: (16) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 17.297364ms)
Sep 22 08:04:03.562: INFO: (16) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 18.516307ms)
Sep 22 08:04:03.562: INFO: (16) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 18.481202ms)
Sep 22 08:04:03.562: INFO: (16) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 18.607951ms)
Sep 22 08:04:03.563: INFO: (16) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 18.722078ms)
Sep 22 08:04:03.563: INFO: (16) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 18.736047ms)
Sep 22 08:04:03.565: INFO: (16) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 20.650803ms)
Sep 22 08:04:03.565: INFO: (16) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 21.889612ms)
Sep 22 08:04:03.565: INFO: (16) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 21.043473ms)
Sep 22 08:04:03.565: INFO: (16) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 21.734982ms)
Sep 22 08:04:03.565: INFO: (16) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 21.085871ms)
Sep 22 08:04:03.566: INFO: (16) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 21.736355ms)
Sep 22 08:04:03.573: INFO: (17) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 6.669672ms)
Sep 22 08:04:03.580: INFO: (17) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 13.063188ms)
Sep 22 08:04:03.580: INFO: (17) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 13.002635ms)
Sep 22 08:04:03.580: INFO: (17) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 13.454586ms)
Sep 22 08:04:03.580: INFO: (17) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 13.382884ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 13.009099ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 13.483938ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 13.609257ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 13.133653ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 13.213604ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 13.445696ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 14.464236ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 13.401164ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 13.565379ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 13.92443ms)
Sep 22 08:04:03.581: INFO: (17) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 13.873718ms)
Sep 22 08:04:03.585: INFO: (18) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 4.059246ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 12.36866ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 11.760579ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 11.974949ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 12.342495ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 12.50497ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 12.782017ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 12.044204ms)
Sep 22 08:04:03.594: INFO: (18) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 12.91805ms)
Sep 22 08:04:03.598: INFO: (18) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 17.033725ms)
Sep 22 08:04:03.599: INFO: (18) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 17.152012ms)
Sep 22 08:04:03.599: INFO: (18) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 17.411696ms)
Sep 22 08:04:03.602: INFO: (18) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 21.029418ms)
Sep 22 08:04:03.602: INFO: (18) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 21.075011ms)
Sep 22 08:04:03.603: INFO: (18) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 21.150736ms)
Sep 22 08:04:03.604: INFO: (18) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 22.722944ms)
Sep 22 08:04:03.608: INFO: (19) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 3.704072ms)
Sep 22 08:04:03.610: INFO: (19) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:443/proxy/tlsrewritem... (200; 5.56648ms)
Sep 22 08:04:03.610: INFO: (19) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:462/proxy/: tls qux (200; 5.72828ms)
Sep 22 08:04:03.619: INFO: (19) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname2/proxy/: tls qux (200; 14.624249ms)
Sep 22 08:04:03.619: INFO: (19) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname2/proxy/: bar (200; 14.69258ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">... (200; 15.108954ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname2/proxy/: bar (200; 15.520695ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:160/proxy/: foo (200; 15.390247ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:1080/proxy/rewriteme">test<... (200; 15.319663ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/http:proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 15.853315ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/services/https:proxy-service-k75h8:tlsportname1/proxy/: tls baz (200; 15.605765ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/services/http:proxy-service-k75h8:portname1/proxy/: foo (200; 15.457838ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/https:proxy-service-k75h8-gnnwq:460/proxy/: tls baz (200; 15.781853ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/: <a href="/api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq/proxy/rewriteme">test</a> (200; 15.628031ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/services/proxy-service-k75h8:portname1/proxy/: foo (200; 15.800185ms)
Sep 22 08:04:03.620: INFO: (19) /api/v1/namespaces/proxy-8701/pods/proxy-service-k75h8-gnnwq:162/proxy/: bar (200; 15.610512ms)
STEP: deleting ReplicationController proxy-service-k75h8 in namespace proxy-8701, will wait for the garbage collector to delete the pods
I0922 08:04:03.624336      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:04:03.624361      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:04:03.679: INFO: Deleting ReplicationController proxy-service-k75h8 took: 5.109153ms
Sep 22 08:04:03.979: INFO: Terminating ReplicationController proxy-service-k75h8 pods took: 300.244942ms
I0922 08:04:03.979789      18 controller_utils.go:810] Ignoring inactive pod proxy-8701/proxy-service-k75h8-gnnwq in state Running, deletion time 2019-09-22 08:04:04 +0000 UTC
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:04:15.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8701" for this suite.
Sep 22 08:04:21.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:04:21.361: INFO: namespace proxy-8701 deletion completed in 6.078434248s

• [SLOW TEST:23.254 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:04:21.362: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 22 08:04:21.396: INFO: Waiting up to 5m0s for pod "pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5" in namespace "emptydir-3251" to be "success or failure"
Sep 22 08:04:21.398: INFO: Pod "pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.483529ms
Sep 22 08:04:23.402: INFO: Pod "pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006028819s
STEP: Saw pod success
Sep 22 08:04:23.402: INFO: Pod "pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5" satisfied condition "success or failure"
Sep 22 08:04:23.405: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5 container test-container: <nil>
STEP: delete the pod
Sep 22 08:04:23.427: INFO: Waiting for pod pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5 to disappear
Sep 22 08:04:23.429: INFO: Pod pod-61d9d1f1-dddd-42aa-91c2-655f0fe89fa5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:04:23.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3251" for this suite.
Sep 22 08:04:29.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:04:29.517: INFO: namespace emptydir-3251 deletion completed in 6.084265949s

• [SLOW TEST:8.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:04:29.517: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 22 08:04:29.552: INFO: Waiting up to 5m0s for pod "pod-ad53d8cc-d402-4160-a843-5b13530cb6cb" in namespace "emptydir-2879" to be "success or failure"
Sep 22 08:04:29.555: INFO: Pod "pod-ad53d8cc-d402-4160-a843-5b13530cb6cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.941955ms
Sep 22 08:04:31.559: INFO: Pod "pod-ad53d8cc-d402-4160-a843-5b13530cb6cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007760956s
STEP: Saw pod success
Sep 22 08:04:31.559: INFO: Pod "pod-ad53d8cc-d402-4160-a843-5b13530cb6cb" satisfied condition "success or failure"
Sep 22 08:04:31.562: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-ad53d8cc-d402-4160-a843-5b13530cb6cb container test-container: <nil>
STEP: delete the pod
Sep 22 08:04:31.580: INFO: Waiting for pod pod-ad53d8cc-d402-4160-a843-5b13530cb6cb to disappear
Sep 22 08:04:31.585: INFO: Pod pod-ad53d8cc-d402-4160-a843-5b13530cb6cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:04:31.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2879" for this suite.
Sep 22 08:04:37.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:04:37.679: INFO: namespace emptydir-2879 deletion completed in 6.088301868s

• [SLOW TEST:8.163 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:04:37.681: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 22 08:04:40.239: INFO: Successfully updated pod "labelsupdate15f35e86-976c-414c-a5b6-bc5c9afdb47a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:04:44.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7177" for this suite.
Sep 22 08:04:56.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:04:56.360: INFO: namespace downward-api-7177 deletion completed in 12.097909035s

• [SLOW TEST:18.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:04:56.360: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:04:56.437: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Creating first CR 
Sep 22 08:04:57.065: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:04:57Z generation:1 name:name1 resourceVersion:321076 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa9cfa0c-6901-49e4-a821-3196a3b5f25f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Sep 22 08:05:07.070: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:05:07Z generation:1 name:name2 resourceVersion:321092 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:707490e0-a089-4b6f-93ce-25631599087b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Sep 22 08:05:17.074: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:04:57Z generation:2 name:name1 resourceVersion:321107 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa9cfa0c-6901-49e4-a821-3196a3b5f25f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Sep 22 08:05:27.079: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:05:07Z generation:2 name:name2 resourceVersion:321122 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:707490e0-a089-4b6f-93ce-25631599087b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Sep 22 08:05:37.085: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:04:57Z generation:2 name:name1 resourceVersion:321137 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:aa9cfa0c-6901-49e4-a821-3196a3b5f25f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Sep 22 08:05:47.091: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-09-22T08:05:07Z generation:2 name:name2 resourceVersion:321152 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:707490e0-a089-4b6f-93ce-25631599087b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:05:57.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8789" for this suite.
Sep 22 08:06:03.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:06:03.728: INFO: namespace crd-watch-8789 deletion completed in 6.120962023s

• [SLOW TEST:67.369 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:06:03.731: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Sep 22 08:06:03.769: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:06:21.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8052" for this suite.
Sep 22 08:06:27.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:06:27.818: INFO: namespace crd-publish-openapi-8052 deletion completed in 6.083871647s

• [SLOW TEST:24.087 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:06:27.818: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 22 08:06:27.845: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 22 08:06:27.852: INFO: Waiting for terminating namespaces to be deleted...
Sep 22 08:06:27.854: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-14-205 before test
Sep 22 08:06:27.866: INFO: calico-node-kfxhb from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.866: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:06:27.866: INFO: sonobuoy from sonobuoy started at 2019-09-22 07:56:45 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.866: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 22 08:06:27.866: INFO: kube-proxy-gxhtr from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.866: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:06:27.866: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:06:27.866: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:06:27.866: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:06:27.866: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-60 before test
Sep 22 08:06:27.884: INFO: sonobuoy-e2e-job-df839470c40a489c from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:06:27.884: INFO: 	Container e2e ready: true, restart count 0
Sep 22 08:06:27.884: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:06:27.884: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:06:27.884: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:06:27.884: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:06:27.884: INFO: calico-node-nzh59 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.884: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:06:27.884: INFO: kube-proxy-mrm99 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.884: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:06:27.884: INFO: coredns-fffcf5449-vn775 from kube-system started at 2019-09-20 01:40:55 +0000 UTC (1 container statuses recorded)
Sep 22 08:06:27.884: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e3a2ec80-7e0b-466f-8905-2c14b9b88301 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-e3a2ec80-7e0b-466f-8905-2c14b9b88301 off the node ip-10-0-14-205
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e3a2ec80-7e0b-466f-8905-2c14b9b88301
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:06:31.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4245" for this suite.
Sep 22 08:06:49.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:06:50.032: INFO: namespace sched-pred-4245 deletion completed in 18.091592548s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
I0922 08:06:50.032869      18 request.go:706] Error in request: resource name may not be empty

• [SLOW TEST:22.214 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:06:50.035: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:06:50.068: INFO: Creating deployment "test-recreate-deployment"
Sep 22 08:06:50.073: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 22 08:06:50.098: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 22 08:06:52.104: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 22 08:06:52.109: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 22 08:06:52.117: INFO: Updating deployment test-recreate-deployment
Sep 22 08:06:52.117: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 22 08:06:52.197: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2338 /apis/apps/v1/namespaces/deployment-2338/deployments/test-recreate-deployment 34a73c6a-0f26-403b-a326-643e59ee1852 321384 2 2019-09-22 08:06:50 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006a35f68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-09-22 08:06:52 +0000 UTC,LastTransitionTime:2019-09-22 08:06:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-09-22 08:06:52 +0000 UTC,LastTransitionTime:2019-09-22 08:06:50 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Sep 22 08:06:52.200: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2338 /apis/apps/v1/namespaces/deployment-2338/replicasets/test-recreate-deployment-5f94c574ff dc350b91-b62d-46fb-8945-3305047ea6f6 321382 1 2019-09-22 08:06:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 34a73c6a-0f26-403b-a326-643e59ee1852 0xc006d9a3e7 0xc006d9a3e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006d9a448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:06:52.201: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 22 08:06:52.201: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2338 /apis/apps/v1/namespaces/deployment-2338/replicasets/test-recreate-deployment-68fc85c7bb cea402d3-6a18-45b0-b4b7-382ee69c9a6c 321372 2 2019-09-22 08:06:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 34a73c6a-0f26-403b-a326-643e59ee1852 0xc006d9a4b7 0xc006d9a4b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006d9a518 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:06:52.204: INFO: Pod "test-recreate-deployment-5f94c574ff-j89jg" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-j89jg test-recreate-deployment-5f94c574ff- deployment-2338 /api/v1/namespaces/deployment-2338/pods/test-recreate-deployment-5f94c574ff-j89jg 279743e6-b943-4964-8106-89b369db3ffb 321383 0 2019-09-22 08:06:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff dc350b91-b62d-46fb-8945-3305047ea6f6 0xc006dbe187 0xc006dbe188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pngg7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pngg7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pngg7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:06:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:06:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:06:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:06:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:,StartTime:2019-09-22 08:06:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:06:52.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2338" for this suite.
Sep 22 08:06:58.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:06:58.288: INFO: namespace deployment-2338 deletion completed in 6.081705556s

• [SLOW TEST:8.253 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:06:58.289: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9ca428cb-aea9-4ce9-83a1-9b44350bef73
STEP: Creating a pod to test consume configMaps
Sep 22 08:06:58.327: INFO: Waiting up to 5m0s for pod "pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119" in namespace "configmap-6465" to be "success or failure"
Sep 22 08:06:58.332: INFO: Pod "pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119": Phase="Pending", Reason="", readiness=false. Elapsed: 4.791335ms
Sep 22 08:07:00.338: INFO: Pod "pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011167881s
STEP: Saw pod success
Sep 22 08:07:00.339: INFO: Pod "pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119" satisfied condition "success or failure"
Sep 22 08:07:00.343: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:07:00.398: INFO: Waiting for pod pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119 to disappear
Sep 22 08:07:00.406: INFO: Pod pod-configmaps-aade3d60-abf4-40f3-8eab-06dfc40f2119 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:07:00.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6465" for this suite.
Sep 22 08:07:06.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:07:06.504: INFO: namespace configmap-6465 deletion completed in 6.089535904s

• [SLOW TEST:8.215 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:07:06.505: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3583
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 22 08:07:06.531: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 22 08:07:26.593: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.212.221:8080/dial?request=hostName&protocol=http&host=10.2.56.159&port=8080&tries=1'] Namespace:pod-network-test-3583 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:07:26.593: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:07:26.727: INFO: Waiting for endpoints: map[]
Sep 22 08:07:26.730: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.212.221:8080/dial?request=hostName&protocol=http&host=10.2.212.223&port=8080&tries=1'] Namespace:pod-network-test-3583 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:07:26.730: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:07:26.823: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:07:26.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3583" for this suite.
Sep 22 08:07:38.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:07:38.900: INFO: namespace pod-network-test-3583 deletion completed in 12.073148494s

• [SLOW TEST:32.395 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:07:38.903: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-6ba3278e-59f3-4690-b4f4-9c5d51c10bae in namespace container-probe-751
Sep 22 08:07:40.943: INFO: Started pod liveness-6ba3278e-59f3-4690-b4f4-9c5d51c10bae in namespace container-probe-751
STEP: checking the pod's current state and verifying that restartCount is present
Sep 22 08:07:40.946: INFO: Initial restart count of pod liveness-6ba3278e-59f3-4690-b4f4-9c5d51c10bae is 0
Sep 22 08:08:00.984: INFO: Restart count of pod container-probe-751/liveness-6ba3278e-59f3-4690-b4f4-9c5d51c10bae is now 1 (20.037943687s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:08:01.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-751" for this suite.
Sep 22 08:08:07.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:08:07.187: INFO: namespace container-probe-751 deletion completed in 6.120475643s

• [SLOW TEST:28.284 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:08:07.188: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:08:07.221: INFO: Waiting up to 5m0s for pod "busybox-user-65534-ecc9ad92-1786-42d9-9fe5-b946533ddbe6" in namespace "security-context-test-5550" to be "success or failure"
Sep 22 08:08:07.226: INFO: Pod "busybox-user-65534-ecc9ad92-1786-42d9-9fe5-b946533ddbe6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.933038ms
Sep 22 08:08:09.229: INFO: Pod "busybox-user-65534-ecc9ad92-1786-42d9-9fe5-b946533ddbe6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007575461s
Sep 22 08:08:09.229: INFO: Pod "busybox-user-65534-ecc9ad92-1786-42d9-9fe5-b946533ddbe6" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:08:09.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5550" for this suite.
Sep 22 08:08:15.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:08:15.321: INFO: namespace security-context-test-5550 deletion completed in 6.088571611s

• [SLOW TEST:8.133 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:08:15.321: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:08:15.355: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:08:15.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8315" for this suite.
Sep 22 08:08:21.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:08:21.988: INFO: namespace custom-resource-definition-8315 deletion completed in 6.088904741s

• [SLOW TEST:6.667 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:08:21.989: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-1d4cfdd5-857c-456c-92d8-c7fb2f6391d2 in namespace container-probe-9773
Sep 22 08:08:24.037: INFO: Started pod busybox-1d4cfdd5-857c-456c-92d8-c7fb2f6391d2 in namespace container-probe-9773
STEP: checking the pod's current state and verifying that restartCount is present
Sep 22 08:08:24.039: INFO: Initial restart count of pod busybox-1d4cfdd5-857c-456c-92d8-c7fb2f6391d2 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:12:24.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9773" for this suite.
Sep 22 08:12:30.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:12:30.573: INFO: namespace container-probe-9773 deletion completed in 6.082030541s

• [SLOW TEST:248.584 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:12:30.576: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:12:32.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-658" for this suite.
Sep 22 08:13:16.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:13:16.757: INFO: namespace kubelet-test-658 deletion completed in 44.096759617s

• [SLOW TEST:46.181 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:13:16.759: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-53669bfb-e3d3-4b63-90b8-94cc133b8215
STEP: Creating a pod to test consume secrets
Sep 22 08:13:16.798: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618" in namespace "projected-4921" to be "success or failure"
Sep 22 08:13:16.801: INFO: Pod "pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618": Phase="Pending", Reason="", readiness=false. Elapsed: 2.795468ms
Sep 22 08:13:18.804: INFO: Pod "pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006133665s
STEP: Saw pod success
Sep 22 08:13:18.804: INFO: Pod "pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618" satisfied condition "success or failure"
Sep 22 08:13:18.806: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 22 08:13:18.823: INFO: Waiting for pod pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618 to disappear
Sep 22 08:13:18.826: INFO: Pod pod-projected-secrets-b10092d8-9f09-4cff-9e70-73f062f40618 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:13:18.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4921" for this suite.
Sep 22 08:13:24.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:13:24.908: INFO: namespace projected-4921 deletion completed in 6.077630205s

• [SLOW TEST:8.149 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:13:24.908: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-d22b9c4b-d712-4553-a53b-4e732d53782d
STEP: Creating a pod to test consume secrets
Sep 22 08:13:24.943: INFO: Waiting up to 5m0s for pod "pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a" in namespace "secrets-3839" to be "success or failure"
Sep 22 08:13:24.946: INFO: Pod "pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.40806ms
Sep 22 08:13:26.948: INFO: Pod "pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005088043s
STEP: Saw pod success
Sep 22 08:13:26.948: INFO: Pod "pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a" satisfied condition "success or failure"
Sep 22 08:13:26.951: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 08:13:27.033: INFO: Waiting for pod pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a to disappear
Sep 22 08:13:27.051: INFO: Pod pod-secrets-11927147-ae5b-41f8-bb3c-d026f29eaa5a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:13:27.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3839" for this suite.
Sep 22 08:13:33.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:13:33.148: INFO: namespace secrets-3839 deletion completed in 6.089777095s

• [SLOW TEST:8.240 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:13:33.148: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8604.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8604.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8604.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8604.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8604.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8604.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 08:13:35.228: INFO: DNS probes using dns-8604/dns-test-99d01634-d0ec-4165-bd37-292f1b431fd3 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:13:35.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8604" for this suite.
Sep 22 08:13:41.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:13:41.390: INFO: namespace dns-8604 deletion completed in 6.136039918s

• [SLOW TEST:8.242 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:13:41.391: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 22 08:13:41.424: INFO: PodSpec: initContainers in spec.initContainers
Sep 22 08:14:25.618: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-92f3f1d9-767e-4f1c-91c8-e4508cc85a6e", GenerateName:"", Namespace:"init-container-1017", SelfLink:"/api/v1/namespaces/init-container-1017/pods/pod-init-92f3f1d9-767e-4f1c-91c8-e4508cc85a6e", UID:"384bac01-5937-433f-bb6d-7fe66729e2d5", ResourceVersion:"322497", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63704736821, loc:(*time.Location)(0x84be2c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"424734642"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.212.230/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-knllh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0037da9c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-knllh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-knllh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-knllh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004c83a78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-14-205", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002f2f920), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c83b10)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c83b30)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004c83b38), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004c83b3c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736821, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736821, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736821, loc:(*time.Location)(0x84be2c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704736821, loc:(*time.Location)(0x84be2c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.14.205", PodIP:"10.2.212.230", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.212.230"}}, StartTime:(*v1.Time)(0xc003050e00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0035b67e0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0035b6850)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4c03333c44f34012e73b708acd4b4553cc53e8f917dcbe16fd32b5a516f221da", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003050e40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003050e20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc004c83bcf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:14:25.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1017" for this suite.
Sep 22 08:14:37.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:14:37.722: INFO: namespace init-container-1017 deletion completed in 12.100607636s

• [SLOW TEST:56.332 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:14:37.728: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:15:37.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3513" for this suite.
Sep 22 08:15:49.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:15:49.866: INFO: namespace container-probe-3513 deletion completed in 12.092773558s

• [SLOW TEST:72.138 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:15:49.870: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 08:15:49.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1529'
Sep 22 08:15:50.270: INFO: stderr: ""
Sep 22 08:15:50.270: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
I0922 08:15:50.270765      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:15:50.270785      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
STEP: verifying the pod e2e-test-httpd-pod was created
Sep 22 08:15:55.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pod e2e-test-httpd-pod --namespace=kubectl-1529 -o json'
Sep 22 08:15:55.408: INFO: stderr: ""
Sep 22 08:15:55.408: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.212.232/32\"\n        },\n        \"creationTimestamp\": \"2019-09-22T08:15:50Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1529\",\n        \"resourceVersion\": \"322694\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1529/pods/e2e-test-httpd-pod\",\n        \"uid\": \"a6376f63-1e12-4a3a-a115-26a60b7bbaaf\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-pwvdb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-14-205\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-pwvdb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-pwvdb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-22T08:15:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-22T08:15:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-22T08:15:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-22T08:15:50Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0b36ff5b991ec7bada051f7360192670cc8a583bba7eeb823bfa88ef87086869\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-22T08:15:51Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.14.205\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.212.232\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.212.232\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-22T08:15:50Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 22 08:15:55.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 replace -f - --namespace=kubectl-1529'
Sep 22 08:15:55.670: INFO: stderr: ""
Sep 22 08:15:55.670: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Sep 22 08:15:55.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete pods e2e-test-httpd-pod --namespace=kubectl-1529'
Sep 22 08:15:57.306: INFO: stderr: ""
Sep 22 08:15:57.306: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:15:57.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1529" for this suite.
Sep 22 08:16:03.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:16:03.409: INFO: namespace kubectl-1529 deletion completed in 6.099878084s

• [SLOW TEST:13.539 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:16:03.410: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:16:03.450: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 22 08:16:07.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-3310 create -f -'
Sep 22 08:16:07.514: INFO: stderr: ""
Sep 22 08:16:07.514: INFO: stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 22 08:16:07.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-3310 delete e2e-test-crd-publish-openapi-7012-crds test-cr'
Sep 22 08:16:07.596: INFO: stderr: ""
Sep 22 08:16:07.596: INFO: stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Sep 22 08:16:07.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-3310 apply -f -'
Sep 22 08:16:07.782: INFO: stderr: ""
Sep 22 08:16:07.782: INFO: stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Sep 22 08:16:07.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-3310 delete e2e-test-crd-publish-openapi-7012-crds test-cr'
Sep 22 08:16:07.859: INFO: stderr: ""
Sep 22 08:16:07.859: INFO: stdout: "e2e-test-crd-publish-openapi-7012-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 22 08:16:07.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-7012-crds'
Sep 22 08:16:08.024: INFO: stderr: ""
Sep 22 08:16:08.024: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7012-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:16:10.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3310" for this suite.
Sep 22 08:16:16.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:16:16.453: INFO: namespace crd-publish-openapi-3310 deletion completed in 6.086505381s

• [SLOW TEST:13.043 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:16:16.455: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Sep 22 08:16:16.489: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:16:20.079: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:16:33.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8936" for this suite.
Sep 22 08:16:39.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:16:40.029: INFO: namespace crd-publish-openapi-8936 deletion completed in 6.140296817s

• [SLOW TEST:23.573 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:16:40.029: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:17:09.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3834" for this suite.
Sep 22 08:17:15.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:17:15.236: INFO: namespace namespaces-3834 deletion completed in 6.098339196s
STEP: Destroying namespace "nsdeletetest-1142" for this suite.
Sep 22 08:17:15.247: INFO: Namespace nsdeletetest-1142 was already deleted
STEP: Destroying namespace "nsdeletetest-7066" for this suite.
Sep 22 08:17:21.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:17:21.328: INFO: namespace nsdeletetest-7066 deletion completed in 6.08092512s

• [SLOW TEST:41.300 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:17:21.331: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:17:21.361: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 22 08:17:24.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-1569 create -f -'
Sep 22 08:17:25.448: INFO: stderr: ""
Sep 22 08:17:25.448: INFO: stdout: "e2e-test-crd-publish-openapi-3121-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 22 08:17:25.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-1569 delete e2e-test-crd-publish-openapi-3121-crds test-cr'
Sep 22 08:17:25.534: INFO: stderr: ""
Sep 22 08:17:25.534: INFO: stdout: "e2e-test-crd-publish-openapi-3121-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Sep 22 08:17:25.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-1569 apply -f -'
Sep 22 08:17:25.775: INFO: stderr: ""
Sep 22 08:17:25.775: INFO: stdout: "e2e-test-crd-publish-openapi-3121-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Sep 22 08:17:25.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-1569 delete e2e-test-crd-publish-openapi-3121-crds test-cr'
Sep 22 08:17:25.858: INFO: stderr: ""
Sep 22 08:17:25.858: INFO: stdout: "e2e-test-crd-publish-openapi-3121-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Sep 22 08:17:25.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-3121-crds'
Sep 22 08:17:26.081: INFO: stderr: ""
Sep 22 08:17:26.081: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3121-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:17:29.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1569" for this suite.
Sep 22 08:17:35.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:17:35.699: INFO: namespace crd-publish-openapi-1569 deletion completed in 6.083917128s

• [SLOW TEST:14.369 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:17:35.707: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-8c5d2bd6-7823-4189-921b-b9a859559ef6
STEP: Creating a pod to test consume configMaps
Sep 22 08:17:35.747: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7" in namespace "projected-1698" to be "success or failure"
Sep 22 08:17:35.751: INFO: Pod "pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7": Phase="Pending", Reason="", readiness=false. Elapsed: 3.239869ms
Sep 22 08:17:37.755: INFO: Pod "pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007343617s
STEP: Saw pod success
Sep 22 08:17:37.755: INFO: Pod "pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7" satisfied condition "success or failure"
Sep 22 08:17:37.761: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:17:37.793: INFO: Waiting for pod pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7 to disappear
Sep 22 08:17:37.796: INFO: Pod pod-projected-configmaps-421dcad5-d81c-4b91-80f4-3e24d5835dd7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:17:37.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1698" for this suite.
Sep 22 08:17:43.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:17:43.881: INFO: namespace projected-1698 deletion completed in 6.081868781s

• [SLOW TEST:8.179 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:17:43.888: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:17:44.355: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:17:47.374: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:17:47.377: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:17:48.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2726" for this suite.
Sep 22 08:17:54.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:17:54.721: INFO: namespace crd-webhook-2726 deletion completed in 6.089488732s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.844 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:17:54.732: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:17:55.432: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:17:58.446: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:18:10.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4350" for this suite.
Sep 22 08:18:16.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:16.639: INFO: namespace webhook-4350 deletion completed in 6.082293074s
STEP: Destroying namespace "webhook-4350-markers" for this suite.
Sep 22 08:18:22.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:22.721: INFO: namespace webhook-4350-markers deletion completed in 6.081396809s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.002 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:18:22.735: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:18:22.771: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266" in namespace "projected-6479" to be "success or failure"
Sep 22 08:18:22.775: INFO: Pod "downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266": Phase="Pending", Reason="", readiness=false. Elapsed: 3.877223ms
Sep 22 08:18:24.778: INFO: Pod "downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006893134s
STEP: Saw pod success
Sep 22 08:18:24.778: INFO: Pod "downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266" satisfied condition "success or failure"
Sep 22 08:18:24.783: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266 container client-container: <nil>
STEP: delete the pod
Sep 22 08:18:24.804: INFO: Waiting for pod downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266 to disappear
Sep 22 08:18:24.808: INFO: Pod downwardapi-volume-c992204e-7873-4734-951f-044b1cfc3266 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:18:24.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6479" for this suite.
Sep 22 08:18:30.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:30.926: INFO: namespace projected-6479 deletion completed in 6.114580287s

• [SLOW TEST:8.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:18:30.926: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:18:31.608: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:18:33.627: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704737111, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704737111, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704737111, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704737111, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:18:36.642: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:18:36.645: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2869-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:18:37.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3393" for this suite.
Sep 22 08:18:43.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:43.847: INFO: namespace webhook-3393 deletion completed in 6.078645651s
STEP: Destroying namespace "webhook-3393-markers" for this suite.
Sep 22 08:18:49.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:49.973: INFO: namespace webhook-3393-markers deletion completed in 6.126188645s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.062 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:18:49.989: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:18:50.642: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:18:53.656: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:18:53.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6445" for this suite.
Sep 22 08:18:59.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:18:59.782: INFO: namespace webhook-6445 deletion completed in 6.085911578s
STEP: Destroying namespace "webhook-6445-markers" for this suite.
Sep 22 08:19:05.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:19:05.861: INFO: namespace webhook-6445-markers deletion completed in 6.079511578s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.883 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:19:05.873: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 08:19:05.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-396'
Sep 22 08:19:06.104: INFO: stderr: ""
Sep 22 08:19:06.104: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Sep 22 08:19:06.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete pods e2e-test-httpd-pod --namespace=kubectl-396'
Sep 22 08:19:15.185: INFO: stderr: ""
Sep 22 08:19:15.185: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:19:15.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-396" for this suite.
Sep 22 08:19:21.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:19:21.285: INFO: namespace kubectl-396 deletion completed in 6.097180922s

• [SLOW TEST:15.412 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:19:21.285: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3509
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Sep 22 08:19:21.322: INFO: Found 0 stateful pods, waiting for 3
Sep 22 08:19:31.326: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:19:31.326: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:19:31.326: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 22 08:19:31.349: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 22 08:19:41.377: INFO: Updating stateful set ss2
Sep 22 08:19:41.387: INFO: Waiting for Pod statefulset-3509/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Sep 22 08:19:51.422: INFO: Found 1 stateful pods, waiting for 3
Sep 22 08:20:01.426: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:20:01.426: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:20:01.426: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 22 08:20:01.492: INFO: Updating stateful set ss2
Sep 22 08:20:01.540: INFO: Waiting for Pod statefulset-3509/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 22 08:20:11.549: INFO: Waiting for Pod statefulset-3509/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 22 08:20:21.563: INFO: Updating stateful set ss2
Sep 22 08:20:21.574: INFO: Waiting for StatefulSet statefulset-3509/ss2 to complete update
Sep 22 08:20:21.574: INFO: Waiting for Pod statefulset-3509/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 08:20:31.592: INFO: Deleting all statefulset in ns statefulset-3509
Sep 22 08:20:31.595: INFO: Scaling statefulset ss2 to 0
Sep 22 08:20:51.613: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 08:20:51.615: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:20:51.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3509" for this suite.
Sep 22 08:20:57.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:20:57.707: INFO: namespace statefulset-3509 deletion completed in 6.077639804s

• [SLOW TEST:96.422 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:20:57.708: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Sep 22 08:20:59.749: INFO: Pod pod-hostip-48a3bbd1-bb32-4ab0-b8c9-029099c1ae46 has hostIP: 10.0.14.205
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:20:59.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8599" for this suite.
Sep 22 08:21:11.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:21:11.824: INFO: namespace pods-8599 deletion completed in 12.072210826s

• [SLOW TEST:14.117 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:21:11.825: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:21:11.872: INFO: (0) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 12.637792ms)
Sep 22 08:21:11.876: INFO: (1) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 3.499072ms)
Sep 22 08:21:11.879: INFO: (2) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.590108ms)
Sep 22 08:21:11.881: INFO: (3) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.389615ms)
Sep 22 08:21:11.884: INFO: (4) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.725622ms)
Sep 22 08:21:11.887: INFO: (5) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 3.176095ms)
Sep 22 08:21:11.890: INFO: (6) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.812422ms)
Sep 22 08:21:11.892: INFO: (7) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.516106ms)
Sep 22 08:21:11.899: INFO: (8) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 6.950795ms)
Sep 22 08:21:11.902: INFO: (9) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 3.064487ms)
Sep 22 08:21:11.905: INFO: (10) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.817877ms)
Sep 22 08:21:11.908: INFO: (11) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.534948ms)
Sep 22 08:21:11.910: INFO: (12) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.325185ms)
Sep 22 08:21:11.913: INFO: (13) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.912993ms)
Sep 22 08:21:11.915: INFO: (14) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.214751ms)
Sep 22 08:21:11.918: INFO: (15) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.426905ms)
Sep 22 08:21:11.920: INFO: (16) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.347084ms)
Sep 22 08:21:11.923: INFO: (17) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.311874ms)
Sep 22 08:21:11.925: INFO: (18) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.36439ms)
Sep 22 08:21:11.927: INFO: (19) /api/v1/nodes/ip-10-0-14-205:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.204106ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:21:11.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6424" for this suite.
Sep 22 08:21:17.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:21:18.028: INFO: namespace proxy-6424 deletion completed in 6.097578373s

• [SLOW TEST:6.203 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:21:18.028: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-3124
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3124 to expose endpoints map[]
Sep 22 08:21:18.071: INFO: Get endpoints failed (4.104447ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 22 08:21:19.075: INFO: successfully validated that service multi-endpoint-test in namespace services-3124 exposes endpoints map[] (1.007230797s elapsed)
STEP: Creating pod pod1 in namespace services-3124
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3124 to expose endpoints map[pod1:[100]]
Sep 22 08:21:21.098: INFO: successfully validated that service multi-endpoint-test in namespace services-3124 exposes endpoints map[pod1:[100]] (2.017954381s elapsed)
STEP: Creating pod pod2 in namespace services-3124
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3124 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 22 08:21:23.136: INFO: successfully validated that service multi-endpoint-test in namespace services-3124 exposes endpoints map[pod1:[100] pod2:[101]] (2.031590814s elapsed)
STEP: Deleting pod pod1 in namespace services-3124
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3124 to expose endpoints map[pod2:[101]]
Sep 22 08:21:23.149: INFO: successfully validated that service multi-endpoint-test in namespace services-3124 exposes endpoints map[pod2:[101]] (7.376438ms elapsed)
STEP: Deleting pod pod2 in namespace services-3124
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3124 to expose endpoints map[]
Sep 22 08:21:23.162: INFO: successfully validated that service multi-endpoint-test in namespace services-3124 exposes endpoints map[] (4.495576ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:21:23.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3124" for this suite.
Sep 22 08:21:51.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:21:51.277: INFO: namespace services-3124 deletion completed in 28.092445634s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:33.249 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:21:51.277: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3642/configmap-test-4063d742-c279-4424-bcb9-ec8b1317ade7
STEP: Creating a pod to test consume configMaps
Sep 22 08:21:51.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825" in namespace "configmap-3642" to be "success or failure"
Sep 22 08:21:51.356: INFO: Pod "pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825": Phase="Pending", Reason="", readiness=false. Elapsed: 8.871274ms
Sep 22 08:21:53.360: INFO: Pod "pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01276203s
STEP: Saw pod success
Sep 22 08:21:53.361: INFO: Pod "pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825" satisfied condition "success or failure"
Sep 22 08:21:53.363: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825 container env-test: <nil>
STEP: delete the pod
Sep 22 08:21:53.385: INFO: Waiting for pod pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825 to disappear
Sep 22 08:21:53.387: INFO: Pod pod-configmaps-85a7d114-1128-47de-ab81-a1b1701f9825 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:21:53.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3642" for this suite.
Sep 22 08:21:59.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:21:59.498: INFO: namespace configmap-3642 deletion completed in 6.107740349s

• [SLOW TEST:8.221 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:21:59.499: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:22:01.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-162" for this suite.
Sep 22 08:22:45.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:22:45.652: INFO: namespace kubelet-test-162 deletion completed in 44.088030131s

• [SLOW TEST:46.154 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:22:45.653: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:22:45.681: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-89b03abe-bb32-449d-9f65-eaa37fe93977" in namespace "security-context-test-4992" to be "success or failure"
Sep 22 08:22:45.684: INFO: Pod "alpine-nnp-false-89b03abe-bb32-449d-9f65-eaa37fe93977": Phase="Pending", Reason="", readiness=false. Elapsed: 2.420496ms
Sep 22 08:22:47.687: INFO: Pod "alpine-nnp-false-89b03abe-bb32-449d-9f65-eaa37fe93977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005527261s
Sep 22 08:22:47.687: INFO: Pod "alpine-nnp-false-89b03abe-bb32-449d-9f65-eaa37fe93977" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:22:47.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4992" for this suite.
Sep 22 08:22:53.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:22:53.783: INFO: namespace security-context-test-4992 deletion completed in 6.084745565s

• [SLOW TEST:8.130 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:22:53.784: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2339.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2339.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 08:22:55.856: INFO: DNS probes using dns-2339/dns-test-c02c1945-0ede-40c4-90a3-0d6a6e396651 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:22:55.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2339" for this suite.
Sep 22 08:23:01.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:01.977: INFO: namespace dns-2339 deletion completed in 6.108687908s

• [SLOW TEST:8.195 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:01.980: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:23:02.072: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023" in namespace "projected-5106" to be "success or failure"
Sep 22 08:23:02.078: INFO: Pod "downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023": Phase="Pending", Reason="", readiness=false. Elapsed: 6.43314ms
Sep 22 08:23:04.081: INFO: Pod "downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009385674s
STEP: Saw pod success
Sep 22 08:23:04.081: INFO: Pod "downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023" satisfied condition "success or failure"
Sep 22 08:23:04.084: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023 container client-container: <nil>
STEP: delete the pod
Sep 22 08:23:04.098: INFO: Waiting for pod downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023 to disappear
Sep 22 08:23:04.101: INFO: Pod downwardapi-volume-28c4321d-bb2a-438e-91d8-c6f3bcbbb023 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:04.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5106" for this suite.
Sep 22 08:23:10.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:10.190: INFO: namespace projected-5106 deletion completed in 6.085284123s

• [SLOW TEST:8.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:10.190: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-5259ce37-049d-47bf-8ea9-d33b8df6d510
STEP: Creating a pod to test consume configMaps
Sep 22 08:23:10.251: INFO: Waiting up to 5m0s for pod "pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f" in namespace "configmap-3565" to be "success or failure"
Sep 22 08:23:10.263: INFO: Pod "pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.805498ms
Sep 22 08:23:12.266: INFO: Pod "pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014899977s
STEP: Saw pod success
Sep 22 08:23:12.266: INFO: Pod "pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f" satisfied condition "success or failure"
Sep 22 08:23:12.268: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:23:12.282: INFO: Waiting for pod pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f to disappear
Sep 22 08:23:12.285: INFO: Pod pod-configmaps-598c8955-dcc4-4420-a746-f69ecb570a1f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:12.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3565" for this suite.
Sep 22 08:23:18.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:18.362: INFO: namespace configmap-3565 deletion completed in 6.074640478s

• [SLOW TEST:8.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:18.362: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 22 08:23:20.920: INFO: Successfully updated pod "labelsupdate4940bf83-fea1-4e10-b557-ec4b249c6bf1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:22.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3455" for this suite.
Sep 22 08:23:34.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:35.094: INFO: namespace projected-3455 deletion completed in 12.146073074s

• [SLOW TEST:16.732 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:35.095: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:23:35.138: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 22 08:23:37.171: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:38.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8800" for this suite.
Sep 22 08:23:44.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:44.282: INFO: namespace replication-controller-8800 deletion completed in 6.087787643s

• [SLOW TEST:9.187 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:44.283: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:23:44.315: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2" in namespace "projected-8428" to be "success or failure"
Sep 22 08:23:44.319: INFO: Pod "downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.804397ms
Sep 22 08:23:46.322: INFO: Pod "downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006922868s
STEP: Saw pod success
Sep 22 08:23:46.322: INFO: Pod "downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2" satisfied condition "success or failure"
Sep 22 08:23:46.325: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2 container client-container: <nil>
STEP: delete the pod
Sep 22 08:23:46.341: INFO: Waiting for pod downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2 to disappear
Sep 22 08:23:46.344: INFO: Pod downwardapi-volume-0aef7c38-3b2c-4145-ad26-3321d299f4d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:46.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8428" for this suite.
Sep 22 08:23:52.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:23:52.422: INFO: namespace projected-8428 deletion completed in 6.074686274s

• [SLOW TEST:8.139 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:23:52.422: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Sep 22 08:23:52.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4704 -- logs-generator --log-lines-total 100 --run-duration 20s'
Sep 22 08:23:52.552: INFO: stderr: ""
Sep 22 08:23:52.552: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Sep 22 08:23:52.552: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Sep 22 08:23:52.552: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4704" to be "running and ready, or succeeded"
Sep 22 08:23:52.555: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609682ms
Sep 22 08:23:54.558: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005719863s
Sep 22 08:23:54.558: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Sep 22 08:23:54.558: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Sep 22 08:23:54.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704'
Sep 22 08:23:54.653: INFO: stderr: ""
Sep 22 08:23:54.653: INFO: stdout: "I0922 08:23:53.552289       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/4wnr 226\nI0922 08:23:53.752512       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/d52 257\nI0922 08:23:53.952432       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/58h 216\nI0922 08:23:54.152439       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/pcgk 528\nI0922 08:23:54.352445       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/n7f 373\nI0922 08:23:54.552430       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/w8q 426\n"
STEP: limiting log lines
Sep 22 08:23:54.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704 --tail=1'
Sep 22 08:23:54.752: INFO: stderr: ""
Sep 22 08:23:54.752: INFO: stdout: "I0922 08:23:54.552430       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/w8q 426\n"
STEP: limiting log bytes
Sep 22 08:23:54.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704 --limit-bytes=1'
Sep 22 08:23:54.864: INFO: stderr: ""
Sep 22 08:23:54.864: INFO: stdout: "I"
STEP: exposing timestamps
Sep 22 08:23:54.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704 --tail=1 --timestamps'
Sep 22 08:23:54.970: INFO: stderr: ""
Sep 22 08:23:54.970: INFO: stdout: "2019-09-22T08:23:54.952580496Z I0922 08:23:54.952453       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/q7tc 425\n"
STEP: restricting to a time range
Sep 22 08:23:57.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704 --since=1s'
Sep 22 08:23:57.574: INFO: stderr: ""
Sep 22 08:23:57.574: INFO: stdout: "I0922 08:23:56.752393       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/jbw9 581\nI0922 08:23:56.952484       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/kvx 380\nI0922 08:23:57.152406       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/25tt 424\nI0922 08:23:57.352391       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/qq5 271\nI0922 08:23:57.552417       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/6nqc 355\n"
Sep 22 08:23:57.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs logs-generator logs-generator --namespace=kubectl-4704 --since=24h'
Sep 22 08:23:57.686: INFO: stderr: ""
Sep 22 08:23:57.686: INFO: stdout: "I0922 08:23:53.552289       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/4wnr 226\nI0922 08:23:53.752512       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/d52 257\nI0922 08:23:53.952432       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/58h 216\nI0922 08:23:54.152439       1 logs_generator.go:76] 3 GET /api/v1/namespaces/kube-system/pods/pcgk 528\nI0922 08:23:54.352445       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/n7f 373\nI0922 08:23:54.552430       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/w8q 426\nI0922 08:23:54.752449       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/ns/pods/smb 210\nI0922 08:23:54.952453       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/q7tc 425\nI0922 08:23:55.152465       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/nkv 515\nI0922 08:23:55.352480       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/f8w5 412\nI0922 08:23:55.552477       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/xjsv 441\nI0922 08:23:55.752443       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/w5wt 550\nI0922 08:23:55.952392       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/j7fq 223\nI0922 08:23:56.152369       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/h7w 391\nI0922 08:23:56.352407       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/c7n 588\nI0922 08:23:56.552393       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/tk7l 502\nI0922 08:23:56.752393       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/jbw9 581\nI0922 08:23:56.952484       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/kvx 380\nI0922 08:23:57.152406       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/25tt 424\nI0922 08:23:57.352391       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/qq5 271\nI0922 08:23:57.552417       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/6nqc 355\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Sep 22 08:23:57.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete pod logs-generator --namespace=kubectl-4704'
Sep 22 08:23:59.335: INFO: stderr: ""
Sep 22 08:23:59.335: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:23:59.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4704" for this suite.
Sep 22 08:24:05.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:24:05.443: INFO: namespace kubectl-4704 deletion completed in 6.10389454s

• [SLOW TEST:13.021 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:24:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-fc72
STEP: Creating a pod to test atomic-volume-subpath
Sep 22 08:24:05.507: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-fc72" in namespace "subpath-1985" to be "success or failure"
Sep 22 08:24:05.514: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.282607ms
Sep 22 08:24:07.519: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 2.011102647s
Sep 22 08:24:09.521: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 4.014011477s
Sep 22 08:24:11.525: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 6.017097809s
Sep 22 08:24:13.528: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 8.020097881s
Sep 22 08:24:15.531: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 10.023198654s
Sep 22 08:24:17.533: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 12.026002832s
Sep 22 08:24:19.537: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 14.029182221s
Sep 22 08:24:21.540: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 16.03211009s
Sep 22 08:24:23.542: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 18.034897599s
Sep 22 08:24:25.546: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Running", Reason="", readiness=true. Elapsed: 20.03850058s
Sep 22 08:24:27.549: INFO: Pod "pod-subpath-test-configmap-fc72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.041286612s
STEP: Saw pod success
Sep 22 08:24:27.549: INFO: Pod "pod-subpath-test-configmap-fc72" satisfied condition "success or failure"
Sep 22 08:24:27.551: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-subpath-test-configmap-fc72 container test-container-subpath-configmap-fc72: <nil>
STEP: delete the pod
Sep 22 08:24:27.564: INFO: Waiting for pod pod-subpath-test-configmap-fc72 to disappear
Sep 22 08:24:27.567: INFO: Pod pod-subpath-test-configmap-fc72 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-fc72
Sep 22 08:24:27.567: INFO: Deleting pod "pod-subpath-test-configmap-fc72" in namespace "subpath-1985"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:24:27.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1985" for this suite.
Sep 22 08:24:33.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:24:33.667: INFO: namespace subpath-1985 deletion completed in 6.094824153s

• [SLOW TEST:28.224 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:24:33.670: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-06a7b467-8a83-43c7-949c-245561263e4d
STEP: Creating a pod to test consume secrets
Sep 22 08:24:33.705: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196" in namespace "projected-7852" to be "success or failure"
Sep 22 08:24:33.707: INFO: Pod "pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024468ms
Sep 22 08:24:35.710: INFO: Pod "pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005038457s
STEP: Saw pod success
Sep 22 08:24:35.710: INFO: Pod "pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196" satisfied condition "success or failure"
Sep 22 08:24:35.713: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 22 08:24:35.727: INFO: Waiting for pod pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196 to disappear
Sep 22 08:24:35.729: INFO: Pod pod-projected-secrets-2909c5fb-217a-42ca-9e18-b482c402e196 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:24:35.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7852" for this suite.
Sep 22 08:24:41.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:24:41.831: INFO: namespace projected-7852 deletion completed in 6.100320215s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:24:41.832: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87
Sep 22 08:24:41.863: INFO: Pod name my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87: Found 0 pods out of 1
Sep 22 08:24:46.869: INFO: Pod name my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87: Found 1 pods out of 1
Sep 22 08:24:46.869: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87" are running
Sep 22 08:24:46.872: INFO: Pod "my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87-cj8c7" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 08:24:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 08:24:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 08:24:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 08:24:41 +0000 UTC Reason: Message:}])
Sep 22 08:24:46.872: INFO: Trying to dial the pod
Sep 22 08:24:51.888: INFO: Controller my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87: Got expected result from replica 1 [my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87-cj8c7]: "my-hostname-basic-f4fd2da7-6d8c-4269-8458-5cacf88fbe87-cj8c7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:24:51.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7520" for this suite.
Sep 22 08:24:57.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:24:57.978: INFO: namespace replication-controller-7520 deletion completed in 6.08416104s

• [SLOW TEST:16.146 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:24:57.979: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a1ec3c38-7d74-4719-9c14-0043afccf00e
STEP: Creating a pod to test consume secrets
Sep 22 08:24:58.018: INFO: Waiting up to 5m0s for pod "pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e" in namespace "secrets-5435" to be "success or failure"
Sep 22 08:24:58.021: INFO: Pod "pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.944486ms
Sep 22 08:25:00.030: INFO: Pod "pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01152448s
STEP: Saw pod success
Sep 22 08:25:00.030: INFO: Pod "pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e" satisfied condition "success or failure"
Sep 22 08:25:00.043: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e container secret-env-test: <nil>
STEP: delete the pod
Sep 22 08:25:00.119: INFO: Waiting for pod pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e to disappear
Sep 22 08:25:00.127: INFO: Pod pod-secrets-e22164d0-6004-4c0d-8a2a-0c72dceb401e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:25:00.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5435" for this suite.
Sep 22 08:25:06.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:25:06.303: INFO: namespace secrets-5435 deletion completed in 6.163653452s

• [SLOW TEST:8.325 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:25:06.303: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 22 08:25:06.336: INFO: Waiting up to 5m0s for pod "pod-6703fa9a-6460-487f-8746-e179a43a85e5" in namespace "emptydir-5251" to be "success or failure"
Sep 22 08:25:06.341: INFO: Pod "pod-6703fa9a-6460-487f-8746-e179a43a85e5": Phase="Pending", Reason="", readiness=false. Elapsed: 5.63626ms
Sep 22 08:25:08.345: INFO: Pod "pod-6703fa9a-6460-487f-8746-e179a43a85e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009415093s
STEP: Saw pod success
Sep 22 08:25:08.345: INFO: Pod "pod-6703fa9a-6460-487f-8746-e179a43a85e5" satisfied condition "success or failure"
Sep 22 08:25:08.350: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-6703fa9a-6460-487f-8746-e179a43a85e5 container test-container: <nil>
STEP: delete the pod
Sep 22 08:25:08.370: INFO: Waiting for pod pod-6703fa9a-6460-487f-8746-e179a43a85e5 to disappear
Sep 22 08:25:08.373: INFO: Pod pod-6703fa9a-6460-487f-8746-e179a43a85e5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:25:08.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5251" for this suite.
Sep 22 08:25:14.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:25:14.472: INFO: namespace emptydir-5251 deletion completed in 6.094622455s

• [SLOW TEST:8.168 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:25:14.472: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:25:30.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7099" for this suite.
Sep 22 08:25:36.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:25:36.654: INFO: namespace resourcequota-7099 deletion completed in 6.075581358s

• [SLOW TEST:22.182 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:25:36.656: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:25:36.684: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:25:38.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3917" for this suite.
Sep 22 08:26:22.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:26:22.818: INFO: namespace pods-3917 deletion completed in 44.105888227s

• [SLOW TEST:46.162 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:26:22.822: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Sep 22 08:26:22.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=kubectl-614 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 22 08:26:24.860: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 22 08:26:24.860: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:26:26.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-614" for this suite.
Sep 22 08:26:36.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:26:36.958: INFO: namespace kubectl-614 deletion completed in 10.089148519s

• [SLOW TEST:14.136 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:26:36.958: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:26:37.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e" in namespace "projected-9862" to be "success or failure"
Sep 22 08:26:37.051: INFO: Pod "downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e": Phase="Pending", Reason="", readiness=false. Elapsed: 22.006697ms
Sep 22 08:26:39.056: INFO: Pod "downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027195074s
STEP: Saw pod success
Sep 22 08:26:39.056: INFO: Pod "downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e" satisfied condition "success or failure"
Sep 22 08:26:39.059: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e container client-container: <nil>
STEP: delete the pod
Sep 22 08:26:39.084: INFO: Waiting for pod downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e to disappear
Sep 22 08:26:39.090: INFO: Pod downwardapi-volume-1205d9e4-e64a-4781-bc0c-38f0fbc6515e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:26:39.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9862" for this suite.
Sep 22 08:26:45.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:26:45.202: INFO: namespace projected-9862 deletion completed in 6.101998232s

• [SLOW TEST:8.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:26:45.203: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3271
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Sep 22 08:26:45.248: INFO: Found 0 stateful pods, waiting for 3
Sep 22 08:26:55.251: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:26:55.251: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:26:55.251: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 08:26:55.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-3271 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 08:26:55.468: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 08:26:55.468: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 08:26:55.468: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Sep 22 08:27:05.503: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 22 08:27:15.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-3271 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 08:27:15.767: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 08:27:15.767: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 08:27:15.767: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 08:27:25.784: INFO: Waiting for StatefulSet statefulset-3271/ss2 to complete update
Sep 22 08:27:25.784: INFO: Waiting for Pod statefulset-3271/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 22 08:27:25.784: INFO: Waiting for Pod statefulset-3271/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Sep 22 08:27:35.790: INFO: Waiting for StatefulSet statefulset-3271/ss2 to complete update
STEP: Rolling back to a previous revision
Sep 22 08:27:45.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-3271 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 08:27:46.216: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 08:27:46.216: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 08:27:46.216: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 08:27:56.243: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 22 08:28:06.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-3271 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 08:28:06.533: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 08:28:06.533: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 08:28:06.533: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 08:28:16.550: INFO: Waiting for StatefulSet statefulset-3271/ss2 to complete update
Sep 22 08:28:16.550: INFO: Waiting for Pod statefulset-3271/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 22 08:28:16.550: INFO: Waiting for Pod statefulset-3271/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 22 08:28:26.557: INFO: Waiting for StatefulSet statefulset-3271/ss2 to complete update
Sep 22 08:28:26.557: INFO: Waiting for Pod statefulset-3271/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Sep 22 08:28:36.597: INFO: Waiting for StatefulSet statefulset-3271/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 08:28:46.556: INFO: Deleting all statefulset in ns statefulset-3271
Sep 22 08:28:46.562: INFO: Scaling statefulset ss2 to 0
Sep 22 08:29:16.575: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 08:29:16.578: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:29:16.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3271" for this suite.
Sep 22 08:29:22.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:29:22.666: INFO: namespace statefulset-3271 deletion completed in 6.075255714s

• [SLOW TEST:157.463 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:29:22.667: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:29:22.693: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 22 08:29:22.700: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 22 08:29:27.704: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 22 08:29:27.704: INFO: Creating deployment "test-rolling-update-deployment"
Sep 22 08:29:27.709: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 22 08:29:27.714: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 22 08:29:29.719: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 22 08:29:29.721: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 22 08:29:29.729: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-904 /apis/apps/v1/namespaces/deployment-904/deployments/test-rolling-update-deployment c5feb32e-40b4-4a9b-9fd2-d845addaecf7 326034 1 2019-09-22 08:29:27 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001728d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-09-22 08:29:27 +0000 UTC,LastTransitionTime:2019-09-22 08:29:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-09-22 08:29:29 +0000 UTC,LastTransitionTime:2019-09-22 08:29:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 22 08:29:29.733: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-904 /apis/apps/v1/namespaces/deployment-904/replicasets/test-rolling-update-deployment-55d946486 e2c77f8a-f7a2-4abb-9ef0-42f30fb19e57 326024 1 2019-09-22 08:29:27 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment c5feb32e-40b4-4a9b-9fd2-d845addaecf7 0xc001729250 0xc001729251}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0017292c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:29:29.733: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 22 08:29:29.734: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-904 /apis/apps/v1/namespaces/deployment-904/replicasets/test-rolling-update-controller c1bd0356-0422-4a1a-8295-809759c3b0d0 326033 2 2019-09-22 08:29:22 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment c5feb32e-40b4-4a9b-9fd2-d845addaecf7 0xc001729187 0xc001729188}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0017291e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:29:29.740: INFO: Pod "test-rolling-update-deployment-55d946486-9brzm" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-9brzm test-rolling-update-deployment-55d946486- deployment-904 /api/v1/namespaces/deployment-904/pods/test-rolling-update-deployment-55d946486-9brzm 763a884c-9a49-4955-9b7a-09bee0d67b23 326023 0 2019-09-22 08:29:27 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:10.2.212.30/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 e2c77f8a-f7a2-4abb-9ef0-42f30fb19e57 0xc001729bb0 0xc001729bb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hr6vr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hr6vr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hr6vr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:29:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:29:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:29:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:29:27 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.30,StartTime:2019-09-22 08:29:27 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:29:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://cdc366cf07fde681139d1a92875257abc7525c47a38d2b4d58726c9fa2ea5713,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.30,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:29:29.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-904" for this suite.
Sep 22 08:29:35.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:29:35.826: INFO: namespace deployment-904 deletion completed in 6.077115194s

• [SLOW TEST:13.159 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:29:35.827: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 22 08:29:45.888: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:29:45.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0922 08:29:45.888631      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6480" for this suite.
Sep 22 08:29:51.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:29:51.976: INFO: namespace gc-6480 deletion completed in 6.081306911s

• [SLOW TEST:16.149 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:29:51.976: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:29:54.055: INFO: Waiting up to 5m0s for pod "client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a" in namespace "pods-754" to be "success or failure"
Sep 22 08:29:54.077: INFO: Pod "client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a": Phase="Pending", Reason="", readiness=false. Elapsed: 22.945616ms
Sep 22 08:29:56.081: INFO: Pod "client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026129133s
STEP: Saw pod success
Sep 22 08:29:56.081: INFO: Pod "client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a" satisfied condition "success or failure"
Sep 22 08:29:56.085: INFO: Trying to get logs from node ip-10-0-14-205 pod client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a container env3cont: <nil>
STEP: delete the pod
Sep 22 08:29:56.108: INFO: Waiting for pod client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a to disappear
Sep 22 08:29:56.111: INFO: Pod client-envvars-29254777-6b0f-45f3-ad23-fa2c6abc706a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:29:56.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-754" for this suite.
Sep 22 08:30:24.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:30:24.208: INFO: namespace pods-754 deletion completed in 28.093958432s

• [SLOW TEST:32.231 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:30:24.208: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 08:30:24.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-978'
Sep 22 08:30:24.359: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 22 08:30:24.359: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Sep 22 08:30:24.372: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-s28ms]
Sep 22 08:30:24.372: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-s28ms" in namespace "kubectl-978" to be "running and ready"
Sep 22 08:30:24.377: INFO: Pod "e2e-test-httpd-rc-s28ms": Phase="Pending", Reason="", readiness=false. Elapsed: 4.859821ms
Sep 22 08:30:26.381: INFO: Pod "e2e-test-httpd-rc-s28ms": Phase="Running", Reason="", readiness=true. Elapsed: 2.008311698s
Sep 22 08:30:26.381: INFO: Pod "e2e-test-httpd-rc-s28ms" satisfied condition "running and ready"
Sep 22 08:30:26.381: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-s28ms]
Sep 22 08:30:26.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs rc/e2e-test-httpd-rc --namespace=kubectl-978'
Sep 22 08:30:26.497: INFO: stderr: ""
Sep 22 08:30:26.497: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.2.212.19. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.2.212.19. Set the 'ServerName' directive globally to suppress this message\n[Sun Sep 22 08:30:25.253410 2019] [mpm_event:notice] [pid 1:tid 140336826588008] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Sun Sep 22 08:30:25.253461 2019] [core:notice] [pid 1:tid 140336826588008] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Sep 22 08:30:26.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete rc e2e-test-httpd-rc --namespace=kubectl-978'
Sep 22 08:30:26.600: INFO: stderr: ""
Sep 22 08:30:26.600: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:30:26.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-978" for this suite.
Sep 22 08:30:32.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:30:32.696: INFO: namespace kubectl-978 deletion completed in 6.089972406s

• [SLOW TEST:8.488 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:30:32.698: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1df32e89-a766-412c-8d0f-37bf17c1ddf9
STEP: Creating a pod to test consume configMaps
Sep 22 08:30:32.734: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d" in namespace "projected-3432" to be "success or failure"
Sep 22 08:30:32.738: INFO: Pod "pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.995174ms
Sep 22 08:30:34.741: INFO: Pod "pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00687725s
STEP: Saw pod success
Sep 22 08:30:34.741: INFO: Pod "pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d" satisfied condition "success or failure"
Sep 22 08:30:34.743: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:30:34.763: INFO: Waiting for pod pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d to disappear
Sep 22 08:30:34.765: INFO: Pod pod-projected-configmaps-21d4d5e7-590a-4399-96fe-af34dee2542d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:30:34.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3432" for this suite.
Sep 22 08:30:40.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:30:40.878: INFO: namespace projected-3432 deletion completed in 6.110257225s

• [SLOW TEST:8.180 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:30:40.878: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Sep 22 08:30:40.943: INFO: Waiting up to 5m0s for pod "client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68" in namespace "containers-8468" to be "success or failure"
Sep 22 08:30:40.949: INFO: Pod "client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68": Phase="Pending", Reason="", readiness=false. Elapsed: 6.034119ms
Sep 22 08:30:42.952: INFO: Pod "client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008852469s
STEP: Saw pod success
Sep 22 08:30:42.952: INFO: Pod "client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68" satisfied condition "success or failure"
Sep 22 08:30:42.955: INFO: Trying to get logs from node ip-10-0-14-205 pod client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68 container test-container: <nil>
STEP: delete the pod
Sep 22 08:30:42.970: INFO: Waiting for pod client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68 to disappear
Sep 22 08:30:42.973: INFO: Pod client-containers-0ce0df23-6782-4b33-a0df-953d90a2bc68 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:30:42.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8468" for this suite.
Sep 22 08:30:48.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:30:49.074: INFO: namespace containers-8468 deletion completed in 6.098278858s

• [SLOW TEST:8.196 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:30:49.074: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 22 08:30:49.124: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326410 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 22 08:30:49.124: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326411 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 22 08:30:49.124: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326412 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 22 08:30:59.146: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326429 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 22 08:30:59.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326430 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 22 08:30:59.147: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5173 /api/v1/namespaces/watch-5173/configmaps/e2e-watch-test-label-changed fa81fd3e-74b2-46e3-8c74-b5a4d8ce91fe 326431 0 2019-09-22 08:30:49 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:30:59.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5173" for this suite.
Sep 22 08:31:05.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:31:05.230: INFO: namespace watch-5173 deletion completed in 6.079330873s

• [SLOW TEST:16.156 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:31:05.231: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 22 08:31:05.513: INFO: Pod name wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09 in namespace emptydir-wrapper-446, will wait for the garbage collector to delete the pods
I0922 08:31:19.562326      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:31:19.562355      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:31:19.617: INFO: Deleting ReplicationController wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09 took: 5.45388ms
I0922 08:31:19.918197      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09-8h22n in state Running, deletion time 2019-09-22 08:31:49 +0000 UTC
I0922 08:31:19.918268      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09-bl82q in state Running, deletion time 2019-09-22 08:31:49 +0000 UTC
I0922 08:31:19.918277      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09-ks8dh in state Running, deletion time 2019-09-22 08:31:49 +0000 UTC
I0922 08:31:19.918284      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09-s9z4s in state Running, deletion time 2019-09-22 08:31:49 +0000 UTC
Sep 22 08:31:19.918: INFO: Terminating ReplicationController wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09 pods took: 300.525199ms
I0922 08:31:19.918315      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-435c924f-447b-4c4e-8b4c-d96e0530ee09-f5srd in state Running, deletion time 2019-09-22 08:31:49 +0000 UTC
STEP: Creating RC which spawns configmap-volume pods
Sep 22 08:32:05.345: INFO: Pod name wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d: Found 0 pods out of 5
Sep 22 08:32:10.351: INFO: Pod name wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d in namespace emptydir-wrapper-446, will wait for the garbage collector to delete the pods
I0922 08:32:20.373651      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:32:20.373679      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:32:20.432: INFO: Deleting ReplicationController wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d took: 5.312769ms
I0922 08:32:20.732467      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d-nzsd4 in state Running, deletion time 2019-09-22 08:32:50 +0000 UTC
I0922 08:32:20.732628      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d-tqwdj in state Running, deletion time 2019-09-22 08:32:50 +0000 UTC
I0922 08:32:20.732764      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d-t2wsl in state Running, deletion time 2019-09-22 08:32:50 +0000 UTC
I0922 08:32:20.732877      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d-52wwc in state Running, deletion time 2019-09-22 08:32:50 +0000 UTC
I0922 08:32:20.733212      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d-sljtd in state Running, deletion time 2019-09-22 08:32:50 +0000 UTC
Sep 22 08:32:20.733: INFO: Terminating ReplicationController wrapped-volume-race-c915a20d-2316-4e04-815f-8be1808eca1d pods took: 301.087802ms
STEP: Creating RC which spawns configmap-volume pods
Sep 22 08:33:06.247: INFO: Pod name wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85: Found 0 pods out of 5
Sep 22 08:33:11.252: INFO: Pod name wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85 in namespace emptydir-wrapper-446, will wait for the garbage collector to delete the pods
I0922 08:33:21.272905      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:33:21.273045      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:33:21.328: INFO: Deleting ReplicationController wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85 took: 5.66417ms
I0922 08:33:21.629021      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85-xfdgd in state Running, deletion time 2019-09-22 08:33:51 +0000 UTC
I0922 08:33:21.629059      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85-s2qbq in state Running, deletion time 2019-09-22 08:33:51 +0000 UTC
I0922 08:33:21.629067      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85-npvtt in state Running, deletion time 2019-09-22 08:33:51 +0000 UTC
I0922 08:33:21.629091      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85-6p97l in state Running, deletion time 2019-09-22 08:33:51 +0000 UTC
Sep 22 08:33:21.629: INFO: Terminating ReplicationController wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85 pods took: 300.420937ms
I0922 08:33:21.629097      18 controller_utils.go:810] Ignoring inactive pod emptydir-wrapper-446/wrapped-volume-race-270f973c-d0c3-4547-8ce1-bfee7ee26b85-bt7mp in state Running, deletion time 2019-09-22 08:33:51 +0000 UTC
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:34:05.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-446" for this suite.
Sep 22 08:34:11.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:34:11.749: INFO: namespace emptydir-wrapper-446 deletion completed in 6.075843549s

• [SLOW TEST:186.518 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:34:11.749: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Sep 22 08:34:11.776: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Sep 22 08:34:25.144: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:34:28.698: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:34:42.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6981" for this suite.
Sep 22 08:34:48.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:34:48.647: INFO: namespace crd-publish-openapi-6981 deletion completed in 6.09340707s

• [SLOW TEST:36.898 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:34:48.648: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:34:48.688: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926" in namespace "downward-api-6048" to be "success or failure"
Sep 22 08:34:48.693: INFO: Pod "downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926": Phase="Pending", Reason="", readiness=false. Elapsed: 5.63976ms
Sep 22 08:34:50.697: INFO: Pod "downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009193789s
STEP: Saw pod success
Sep 22 08:34:50.697: INFO: Pod "downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926" satisfied condition "success or failure"
Sep 22 08:34:50.701: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926 container client-container: <nil>
STEP: delete the pod
Sep 22 08:34:50.737: INFO: Waiting for pod downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926 to disappear
Sep 22 08:34:50.747: INFO: Pod downwardapi-volume-4f20ecb0-dc76-469f-b90e-08768f964926 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:34:50.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6048" for this suite.
Sep 22 08:34:56.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:34:56.840: INFO: namespace downward-api-6048 deletion completed in 6.08921327s

• [SLOW TEST:8.192 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:34:56.840: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-4v85
STEP: Creating a pod to test atomic-volume-subpath
Sep 22 08:34:56.875: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-4v85" in namespace "subpath-9425" to be "success or failure"
Sep 22 08:34:56.878: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.029623ms
Sep 22 08:34:58.881: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 2.006157449s
Sep 22 08:35:00.886: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 4.011169094s
Sep 22 08:35:02.890: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 6.01498481s
Sep 22 08:35:04.901: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 8.025624126s
Sep 22 08:35:06.905: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 10.030230965s
Sep 22 08:35:08.908: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 12.033325787s
Sep 22 08:35:10.921: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 14.046179949s
Sep 22 08:35:12.924: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 16.049054627s
Sep 22 08:35:14.928: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 18.05278693s
Sep 22 08:35:16.932: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Running", Reason="", readiness=true. Elapsed: 20.05661176s
Sep 22 08:35:18.936: INFO: Pod "pod-subpath-test-downwardapi-4v85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.060837847s
STEP: Saw pod success
Sep 22 08:35:18.936: INFO: Pod "pod-subpath-test-downwardapi-4v85" satisfied condition "success or failure"
Sep 22 08:35:18.939: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-subpath-test-downwardapi-4v85 container test-container-subpath-downwardapi-4v85: <nil>
STEP: delete the pod
Sep 22 08:35:18.956: INFO: Waiting for pod pod-subpath-test-downwardapi-4v85 to disappear
Sep 22 08:35:18.960: INFO: Pod pod-subpath-test-downwardapi-4v85 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-4v85
Sep 22 08:35:18.960: INFO: Deleting pod "pod-subpath-test-downwardapi-4v85" in namespace "subpath-9425"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:35:18.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9425" for this suite.
Sep 22 08:35:24.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:35:25.187: INFO: namespace subpath-9425 deletion completed in 6.215213743s

• [SLOW TEST:28.347 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:35:25.187: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:35:25.223: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7" in namespace "downward-api-8384" to be "success or failure"
Sep 22 08:35:25.230: INFO: Pod "downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.878385ms
Sep 22 08:35:27.233: INFO: Pod "downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009857599s
STEP: Saw pod success
Sep 22 08:35:27.233: INFO: Pod "downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7" satisfied condition "success or failure"
Sep 22 08:35:27.236: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7 container client-container: <nil>
STEP: delete the pod
Sep 22 08:35:27.253: INFO: Waiting for pod downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7 to disappear
Sep 22 08:35:27.257: INFO: Pod downwardapi-volume-8e5f8012-22cb-47ea-8f78-53d2bb4484c7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:35:27.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8384" for this suite.
Sep 22 08:35:33.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:35:33.351: INFO: namespace downward-api-8384 deletion completed in 6.090595021s

• [SLOW TEST:8.164 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:35:33.351: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 22 08:35:36.432: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:35:37.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2167" for this suite.
Sep 22 08:36:05.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:36:05.530: INFO: namespace replicaset-2167 deletion completed in 28.084157759s

• [SLOW TEST:32.179 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:36:05.530: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:36:05.919: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:36:07.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738165, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738165, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738165, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738165, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:36:10.941: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:36:11.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5562" for this suite.
Sep 22 08:36:17.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:36:17.209: INFO: namespace webhook-5562 deletion completed in 6.089048438s
STEP: Destroying namespace "webhook-5562-markers" for this suite.
Sep 22 08:36:23.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:36:23.289: INFO: namespace webhook-5562-markers deletion completed in 6.07996805s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.771 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:36:23.302: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Sep 22 08:36:23.329: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Sep 22 08:36:23.862: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
I0922 08:36:27.892144      18 request.go:538] Throttling request took 85.984256ms, request: GET:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
I0922 08:36:28.092327      18 request.go:538] Throttling request took 186.1857ms, request: GET:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
I0922 08:36:28.292168      18 request.go:538] Throttling request took 186.035533ms, request: GET:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
I0922 08:36:28.492175      18 request.go:538] Throttling request took 186.035687ms, request: GET:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
I0922 08:36:28.692152      18 request.go:538] Throttling request took 185.892478ms, request: GET:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
Sep 22 08:36:28.717: INFO: Waited 2.811863427s for the sample-apiserver to be ready to handle requests.
I0922 08:36:28.892210      18 request.go:538] Throttling request took 118.733792ms, request: DELETE:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
I0922 08:36:29.092706      18 request.go:538] Throttling request took 121.447491ms, request: DELETE:https://10.3.0.1:443/apis/apiregistration.k8s.io/v1/apiservices/v1alpha1.wardle.k8s.io
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:36:29.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7707" for this suite.
Sep 22 08:36:35.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:36:35.397: INFO: namespace aggregator-7707 deletion completed in 6.194411821s

• [SLOW TEST:12.095 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:36:35.397: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Sep 22 08:36:35.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 cluster-info'
Sep 22 08:36:35.538: INFO: stderr: ""
Sep 22 08:36:35.538: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:36:35.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5463" for this suite.
Sep 22 08:36:41.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:36:41.617: INFO: namespace kubectl-5463 deletion completed in 6.075761726s

• [SLOW TEST:6.220 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:36:41.618: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b in namespace container-probe-5355
Sep 22 08:36:43.654: INFO: Started pod liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b in namespace container-probe-5355
STEP: checking the pod's current state and verifying that restartCount is present
Sep 22 08:36:43.657: INFO: Initial restart count of pod liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is 0
Sep 22 08:36:59.691: INFO: Restart count of pod container-probe-5355/liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is now 1 (16.03331541s elapsed)
Sep 22 08:37:19.728: INFO: Restart count of pod container-probe-5355/liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is now 2 (36.070397497s elapsed)
Sep 22 08:37:39.765: INFO: Restart count of pod container-probe-5355/liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is now 3 (56.107534598s elapsed)
Sep 22 08:37:59.800: INFO: Restart count of pod container-probe-5355/liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is now 4 (1m16.143165659s elapsed)
Sep 22 08:38:59.917: INFO: Restart count of pod container-probe-5355/liveness-0f9009f3-4479-464f-bc67-3d3928e1e18b is now 5 (2m16.259696971s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:38:59.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5355" for this suite.
Sep 22 08:39:05.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:06.050: INFO: namespace container-probe-5355 deletion completed in 6.122559484s

• [SLOW TEST:144.432 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:06.051: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 22 08:39:06.089: INFO: Waiting up to 5m0s for pod "pod-86fc193b-b948-426f-a6f1-aea80fda3df3" in namespace "emptydir-6256" to be "success or failure"
Sep 22 08:39:06.092: INFO: Pod "pod-86fc193b-b948-426f-a6f1-aea80fda3df3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.88994ms
Sep 22 08:39:08.096: INFO: Pod "pod-86fc193b-b948-426f-a6f1-aea80fda3df3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006792238s
STEP: Saw pod success
Sep 22 08:39:08.096: INFO: Pod "pod-86fc193b-b948-426f-a6f1-aea80fda3df3" satisfied condition "success or failure"
Sep 22 08:39:08.100: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-86fc193b-b948-426f-a6f1-aea80fda3df3 container test-container: <nil>
STEP: delete the pod
Sep 22 08:39:08.121: INFO: Waiting for pod pod-86fc193b-b948-426f-a6f1-aea80fda3df3 to disappear
Sep 22 08:39:08.123: INFO: Pod pod-86fc193b-b948-426f-a6f1-aea80fda3df3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:39:08.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6256" for this suite.
Sep 22 08:39:14.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:14.241: INFO: namespace emptydir-6256 deletion completed in 6.113093379s

• [SLOW TEST:8.191 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:14.242: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:39:22.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6164" for this suite.
Sep 22 08:39:28.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:28.366: INFO: namespace job-6164 deletion completed in 6.076983425s

• [SLOW TEST:14.124 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:28.368: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Sep 22 08:39:28.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8018'
Sep 22 08:39:28.830: INFO: stderr: ""
Sep 22 08:39:28.830: INFO: stdout: "pod/pause created\n"
Sep 22 08:39:28.830: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 22 08:39:28.830: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8018" to be "running and ready"
Sep 22 08:39:28.835: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.209337ms
Sep 22 08:39:30.848: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.017668003s
Sep 22 08:39:30.848: INFO: Pod "pause" satisfied condition "running and ready"
Sep 22 08:39:30.848: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 22 08:39:30.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 label pods pause testing-label=testing-label-value --namespace=kubectl-8018'
Sep 22 08:39:30.948: INFO: stderr: ""
Sep 22 08:39:30.948: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 22 08:39:30.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pod pause -L testing-label --namespace=kubectl-8018'
Sep 22 08:39:31.051: INFO: stderr: ""
Sep 22 08:39:31.051: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 22 08:39:31.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 label pods pause testing-label- --namespace=kubectl-8018'
Sep 22 08:39:31.178: INFO: stderr: ""
Sep 22 08:39:31.178: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 22 08:39:31.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pod pause -L testing-label --namespace=kubectl-8018'
Sep 22 08:39:31.272: INFO: stderr: ""
Sep 22 08:39:31.272: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Sep 22 08:39:31.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8018'
Sep 22 08:39:31.373: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:39:31.373: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 22 08:39:31.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get rc,svc -l name=pause --no-headers --namespace=kubectl-8018'
Sep 22 08:39:31.475: INFO: stderr: "No resources found in kubectl-8018 namespace.\n"
Sep 22 08:39:31.475: INFO: stdout: ""
Sep 22 08:39:31.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -l name=pause --namespace=kubectl-8018 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 22 08:39:31.565: INFO: stderr: ""
Sep 22 08:39:31.565: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:39:31.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8018" for this suite.
Sep 22 08:39:37.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:37.695: INFO: namespace kubectl-8018 deletion completed in 6.12654907s

• [SLOW TEST:9.327 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:37.695: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:39:37.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9097" for this suite.
Sep 22 08:39:43.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:43.812: INFO: namespace custom-resource-definition-9097 deletion completed in 6.08031638s

• [SLOW TEST:6.117 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:43.813: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 22 08:39:46.437: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1704 pod-service-account-3a7b674b-0354-4dbd-b2f1-35862f808e77 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 22 08:39:46.671: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1704 pod-service-account-3a7b674b-0354-4dbd-b2f1-35862f808e77 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 22 08:39:46.868: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1704 pod-service-account-3a7b674b-0354-4dbd-b2f1-35862f808e77 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:39:47.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1704" for this suite.
Sep 22 08:39:53.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:39:53.136: INFO: namespace svcaccounts-1704 deletion completed in 6.07470225s

• [SLOW TEST:9.323 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:39:53.136: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:39:53.592: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:39:55.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738393, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738393, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738393, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704738393, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:39:58.613: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Sep 22 08:40:00.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 attach --namespace=webhook-4019 to-be-attached-pod -i -c=container1'
Sep 22 08:40:00.782: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:40:00.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4019" for this suite.
Sep 22 08:40:12.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:40:12.878: INFO: namespace webhook-4019 deletion completed in 12.088306174s
STEP: Destroying namespace "webhook-4019-markers" for this suite.
Sep 22 08:40:18.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:40:18.969: INFO: namespace webhook-4019-markers deletion completed in 6.090324773s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.846 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:40:18.983: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:40:19.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-3292'
Sep 22 08:40:19.365: INFO: stderr: ""
Sep 22 08:40:19.365: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 22 08:40:19.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-3292'
Sep 22 08:40:19.598: INFO: stderr: ""
Sep 22 08:40:19.598: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 22 08:40:20.603: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:20.603: INFO: Found 0 / 1
Sep 22 08:40:21.604: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:21.604: INFO: Found 1 / 1
Sep 22 08:40:21.604: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 22 08:40:21.617: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:21.617: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 22 08:40:21.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 describe pod redis-master-8cvq9 --namespace=kubectl-3292'
Sep 22 08:40:21.733: INFO: stderr: ""
Sep 22 08:40:21.733: INFO: stdout: "Name:         redis-master-8cvq9\nNamespace:    kubectl-3292\nPriority:     0\nNode:         ip-10-0-14-205/10.0.14.205\nStart Time:   Sun, 22 Sep 2019 08:40:19 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.2.212.62/32\nStatus:       Running\nIP:           10.2.212.62\nIPs:\n  IP:           10.2.212.62\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e856fa42b2333f1cc3df64c370b3d39f16e07d2321e6a02fc124d019364e6587\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 22 Sep 2019 08:40:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-z9dx8 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-z9dx8:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-z9dx8\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                     Message\n  ----    ------     ----       ----                     -------\n  Normal  Scheduled  <unknown>  default-scheduler        Successfully assigned kubectl-3292/redis-master-8cvq9 to ip-10-0-14-205\n  Normal  Pulled     1s         kubelet, ip-10-0-14-205  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, ip-10-0-14-205  Created container redis-master\n  Normal  Started    1s         kubelet, ip-10-0-14-205  Started container redis-master\n"
Sep 22 08:40:21.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 describe rc redis-master --namespace=kubectl-3292'
Sep 22 08:40:21.844: INFO: stderr: ""
Sep 22 08:40:21.844: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3292\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-8cvq9\n"
Sep 22 08:40:21.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 describe service redis-master --namespace=kubectl-3292'
Sep 22 08:40:21.946: INFO: stderr: ""
Sep 22 08:40:21.947: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3292\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.3.104.188\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.2.212.62:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 22 08:40:21.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 describe node ip-10-0-13-176'
Sep 22 08:40:22.138: INFO: stderr: ""
Sep 22 08:40:22.138: INFO: stdout: "Name:               ip-10-0-13-176\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-13-176\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=true\n                    node.kubernetes.io/controller=true\n                    node.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.13.176/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.164.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 20 Sep 2019 01:40:41 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 20 Sep 2019 01:40:53 +0000   Fri, 20 Sep 2019 01:40:53 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sun, 22 Sep 2019 08:40:07 +0000   Fri, 20 Sep 2019 01:40:41 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 22 Sep 2019 08:40:07 +0000   Fri, 20 Sep 2019 01:40:41 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 22 Sep 2019 08:40:07 +0000   Fri, 20 Sep 2019 01:40:41 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 22 Sep 2019 08:40:07 +0000   Fri, 20 Sep 2019 01:40:51 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.13.176\n  Hostname:    ip-10-0-13-176\nCapacity:\n cpu:                2\n ephemeral-storage:  17897500Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             2003072Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  16494335973\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             1900672Ki\n pods:               110\nSystem Info:\n Machine ID:                 ec295b9b23ce8f5cac429c730d2c423f\n System UUID:                ec295b9b-23ce-8f5c-ac42-9c730d2c423f\n Boot ID:                    f2f7a778-75e4-451e-9233-a6768892e30d\n Kernel Version:             4.19.68-coreos\n OS Image:                   Container Linux by CoreOS 2191.5.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.0\n Kube-Proxy Version:         v1.16.0\nPodCIDR:                     10.2.1.0/24\nPodCIDRs:                    10.2.1.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-7jnpf                                          150m (7%)     0 (0%)      0 (0%)           0 (0%)         2d6h\n  kube-system                coredns-fffcf5449-p62j5                                    100m (5%)     0 (0%)      70Mi (3%)        170Mi (9%)     2d6h\n  kube-system                kube-apiserver-ip-10-0-13-176                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h24m\n  kube-system                kube-controller-manager-ip-10-0-13-176                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h28m\n  kube-system                kube-proxy-26jtx                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         2d6h\n  kube-system                kube-scheduler-ip-10-0-13-176                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         5h28m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-597qn    0 (0%)        0 (0%)      0 (0%)           0 (0%)         43m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             70Mi (3%)   170Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Sep 22 08:40:22.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 describe namespace kubectl-3292'
Sep 22 08:40:22.304: INFO: stderr: ""
Sep 22 08:40:22.304: INFO: stdout: "Name:         kubectl-3292\nLabels:       e2e-framework=kubectl\n              e2e-run=e25f6d56-3df1-4089-8994-9c7aa9b62dd6\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:40:22.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3292" for this suite.
Sep 22 08:40:34.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:40:34.385: INFO: namespace kubectl-3292 deletion completed in 12.077470729s

• [SLOW TEST:15.402 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:40:34.386: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-b2b9e02f-3b7e-463f-98de-0b9574c1c46c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b2b9e02f-3b7e-463f-98de-0b9574c1c46c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:40:38.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-130" for this suite.
Sep 22 08:40:56.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:40:56.568: INFO: namespace configmap-130 deletion completed in 18.076266518s

• [SLOW TEST:22.182 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:40:56.575: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Sep 22 08:40:56.608: INFO: namespace kubectl-1179
Sep 22 08:40:56.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-1179'
Sep 22 08:40:56.837: INFO: stderr: ""
Sep 22 08:40:56.837: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 22 08:40:57.840: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:57.840: INFO: Found 0 / 1
Sep 22 08:40:58.841: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:58.841: INFO: Found 1 / 1
Sep 22 08:40:58.841: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 22 08:40:58.844: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 08:40:58.844: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 22 08:40:58.844: INFO: wait on redis-master startup in kubectl-1179 
Sep 22 08:40:58.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 logs redis-master-rnmbc redis-master --namespace=kubectl-1179'
Sep 22 08:40:58.940: INFO: stderr: ""
Sep 22 08:40:58.940: INFO: stdout: "1:C 22 Sep 2019 08:40:57.709 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 22 Sep 2019 08:40:57.709 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 22 Sep 2019 08:40:57.709 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 22 Sep 2019 08:40:57.710 * Running mode=standalone, port=6379.\n1:M 22 Sep 2019 08:40:57.710 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Sep 2019 08:40:57.710 # Server initialized\n1:M 22 Sep 2019 08:40:57.710 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Sep 2019 08:40:57.710 * Ready to accept connections\n"
STEP: exposing RC
Sep 22 08:40:58.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1179'
Sep 22 08:40:59.072: INFO: stderr: ""
Sep 22 08:40:59.072: INFO: stdout: "service/rm2 exposed\n"
Sep 22 08:40:59.075: INFO: Service rm2 in namespace kubectl-1179 found.
STEP: exposing service
Sep 22 08:41:01.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1179'
Sep 22 08:41:01.204: INFO: stderr: ""
Sep 22 08:41:01.204: INFO: stdout: "service/rm3 exposed\n"
Sep 22 08:41:01.209: INFO: Service rm3 in namespace kubectl-1179 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:41:03.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1179" for this suite.
Sep 22 08:41:31.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:41:31.304: INFO: namespace kubectl-1179 deletion completed in 28.087381833s

• [SLOW TEST:34.729 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:41:31.305: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 22 08:41:32.364: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:41:32.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5025" for this suite.
Sep 22 08:41:38.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:41:38.459: INFO: namespace container-runtime-5025 deletion completed in 6.08144381s

• [SLOW TEST:7.154 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:41:38.460: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 22 08:41:38.516: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 22 08:41:43.519: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:41:44.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1054" for this suite.
Sep 22 08:41:50.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:41:50.615: INFO: namespace replication-controller-1054 deletion completed in 6.079249255s

• [SLOW TEST:12.155 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:41:50.618: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:41:50.650: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:41:52.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1677" for this suite.
Sep 22 08:42:36.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:42:36.874: INFO: namespace pods-1677 deletion completed in 44.111517955s

• [SLOW TEST:46.256 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:42:36.880: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-621/secret-test-d07beed7-1491-4472-b3fe-8f32cbe1403c
STEP: Creating a pod to test consume secrets
Sep 22 08:42:36.921: INFO: Waiting up to 5m0s for pod "pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef" in namespace "secrets-621" to be "success or failure"
Sep 22 08:42:36.924: INFO: Pod "pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef": Phase="Pending", Reason="", readiness=false. Elapsed: 3.320705ms
Sep 22 08:42:38.927: INFO: Pod "pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00675715s
STEP: Saw pod success
Sep 22 08:42:38.927: INFO: Pod "pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef" satisfied condition "success or failure"
Sep 22 08:42:38.930: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef container env-test: <nil>
STEP: delete the pod
Sep 22 08:42:38.962: INFO: Waiting for pod pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef to disappear
Sep 22 08:42:38.966: INFO: Pod pod-configmaps-85578dc2-2264-4b89-b080-3707d88d3bef no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:42:38.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-621" for this suite.
Sep 22 08:42:44.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:42:45.110: INFO: namespace secrets-621 deletion completed in 6.140750445s

• [SLOW TEST:8.230 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:42:45.113: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:42:45.151: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb" in namespace "projected-3624" to be "success or failure"
Sep 22 08:42:45.154: INFO: Pod "downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.748243ms
Sep 22 08:42:47.157: INFO: Pod "downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005914717s
STEP: Saw pod success
Sep 22 08:42:47.157: INFO: Pod "downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb" satisfied condition "success or failure"
Sep 22 08:42:47.160: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb container client-container: <nil>
STEP: delete the pod
Sep 22 08:42:47.181: INFO: Waiting for pod downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb to disappear
Sep 22 08:42:47.183: INFO: Pod downwardapi-volume-e9b255af-f8fd-4b00-962d-5b51018c1feb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:42:47.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3624" for this suite.
Sep 22 08:42:53.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:42:53.355: INFO: namespace projected-3624 deletion completed in 6.16803918s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:42:53.355: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 22 08:43:03.527: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:43:03.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0922 08:43:03.527589      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9362" for this suite.
Sep 22 08:43:09.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:43:09.631: INFO: namespace gc-9362 deletion completed in 6.100362562s

• [SLOW TEST:16.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:43:09.638: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:43:09.679: INFO: (0) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 6.577884ms)
Sep 22 08:43:09.681: INFO: (1) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.756974ms)
Sep 22 08:43:09.684: INFO: (2) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.70059ms)
Sep 22 08:43:09.689: INFO: (3) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 5.264801ms)
Sep 22 08:43:09.692: INFO: (4) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 3.010043ms)
Sep 22 08:43:09.696: INFO: (5) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 3.741637ms)
Sep 22 08:43:09.699: INFO: (6) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.415781ms)
Sep 22 08:43:09.701: INFO: (7) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.587539ms)
Sep 22 08:43:09.704: INFO: (8) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.405795ms)
Sep 22 08:43:09.706: INFO: (9) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.532266ms)
Sep 22 08:43:09.709: INFO: (10) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.572358ms)
Sep 22 08:43:09.711: INFO: (11) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.348713ms)
Sep 22 08:43:09.714: INFO: (12) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.441649ms)
Sep 22 08:43:09.716: INFO: (13) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.635839ms)
Sep 22 08:43:09.719: INFO: (14) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.636545ms)
Sep 22 08:43:09.721: INFO: (15) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.328042ms)
Sep 22 08:43:09.724: INFO: (16) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.433468ms)
Sep 22 08:43:09.726: INFO: (17) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.438591ms)
Sep 22 08:43:09.729: INFO: (18) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.313335ms)
Sep 22 08:43:09.731: INFO: (19) /api/v1/nodes/ip-10-0-14-205/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="btmp-20190922.gz">btmp-20190922.gz</a>
<a href="containers... (200; 2.491225ms)
[AfterEach] version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:43:09.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2288" for this suite.
Sep 22 08:43:15.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:43:15.814: INFO: namespace proxy-2288 deletion completed in 6.080188894s

• [SLOW TEST:6.176 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:43:15.815: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-kdd8
STEP: Creating a pod to test atomic-volume-subpath
Sep 22 08:43:15.857: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kdd8" in namespace "subpath-1238" to be "success or failure"
Sep 22 08:43:15.860: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.681383ms
Sep 22 08:43:17.863: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00578793s
Sep 22 08:43:19.866: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 4.008671463s
Sep 22 08:43:21.869: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 6.011979685s
Sep 22 08:43:23.873: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 8.015011345s
Sep 22 08:43:25.876: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 10.018121406s
Sep 22 08:43:27.879: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 12.021941301s
Sep 22 08:43:29.882: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 14.024773457s
Sep 22 08:43:31.885: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 16.027614567s
Sep 22 08:43:33.899: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 18.041934311s
Sep 22 08:43:35.903: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Running", Reason="", readiness=true. Elapsed: 20.04522438s
Sep 22 08:43:37.906: INFO: Pod "pod-subpath-test-secret-kdd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.048068313s
STEP: Saw pod success
Sep 22 08:43:37.906: INFO: Pod "pod-subpath-test-secret-kdd8" satisfied condition "success or failure"
Sep 22 08:43:37.909: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-subpath-test-secret-kdd8 container test-container-subpath-secret-kdd8: <nil>
STEP: delete the pod
Sep 22 08:43:37.928: INFO: Waiting for pod pod-subpath-test-secret-kdd8 to disappear
Sep 22 08:43:37.930: INFO: Pod pod-subpath-test-secret-kdd8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-kdd8
Sep 22 08:43:37.930: INFO: Deleting pod "pod-subpath-test-secret-kdd8" in namespace "subpath-1238"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:43:37.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1238" for this suite.
Sep 22 08:43:43.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:43:44.017: INFO: namespace subpath-1238 deletion completed in 6.080721773s

• [SLOW TEST:28.201 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:43:44.018: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 22 08:43:44.052: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 22 08:43:44.063: INFO: Waiting for terminating namespaces to be deleted...
Sep 22 08:43:44.065: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-14-205 before test
Sep 22 08:43:44.070: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:43:44.070: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:43:44.070: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:43:44.070: INFO: calico-node-kfxhb from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.071: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:43:44.071: INFO: sonobuoy from sonobuoy started at 2019-09-22 07:56:45 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.071: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 22 08:43:44.071: INFO: kube-proxy-gxhtr from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.071: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:43:44.071: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-60 before test
Sep 22 08:43:44.087: INFO: sonobuoy-e2e-job-df839470c40a489c from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:43:44.087: INFO: 	Container e2e ready: true, restart count 0
Sep 22 08:43:44.087: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:43:44.087: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:43:44.088: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:43:44.088: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:43:44.088: INFO: calico-node-nzh59 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.088: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:43:44.088: INFO: kube-proxy-mrm99 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.088: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:43:44.088: INFO: coredns-fffcf5449-vn775 from kube-system started at 2019-09-20 01:40:55 +0000 UTC (1 container statuses recorded)
Sep 22 08:43:44.088: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d6769a2a-290c-4191-9fed-0267bb543a3c 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-d6769a2a-290c-4191-9fed-0267bb543a3c off the node ip-10-0-14-205
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d6769a2a-290c-4191-9fed-0267bb543a3c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:43:52.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2330" for this suite.
Sep 22 08:44:10.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:44:10.298: INFO: namespace sched-pred-2330 deletion completed in 18.095302879s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

I0922 08:44:10.298887      18 request.go:706] Error in request: resource name may not be empty
• [SLOW TEST:26.280 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:44:10.299: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-e904f6a6-945c-4cc1-9c98-f917567c407e
STEP: Creating secret with name s-test-opt-upd-90cc8f09-5bea-4544-b7cd-6cd75bd75ca3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e904f6a6-945c-4cc1-9c98-f917567c407e
STEP: Updating secret s-test-opt-upd-90cc8f09-5bea-4544-b7cd-6cd75bd75ca3
STEP: Creating secret with name s-test-opt-create-18351566-9687-4fd4-a743-80812f1a43a1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:44:14.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-945" for this suite.
Sep 22 08:44:42.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:44:42.560: INFO: namespace secrets-945 deletion completed in 28.08445209s

• [SLOW TEST:32.262 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:44:42.560: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-90c0e94f-5317-4d44-a176-2a0aaa31d8c4
STEP: Creating a pod to test consume secrets
Sep 22 08:44:42.597: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95" in namespace "projected-9936" to be "success or failure"
Sep 22 08:44:42.601: INFO: Pod "pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95": Phase="Pending", Reason="", readiness=false. Elapsed: 3.972607ms
Sep 22 08:44:44.604: INFO: Pod "pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006944991s
STEP: Saw pod success
Sep 22 08:44:44.604: INFO: Pod "pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95" satisfied condition "success or failure"
Sep 22 08:44:44.606: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 22 08:44:44.631: INFO: Waiting for pod pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95 to disappear
Sep 22 08:44:44.634: INFO: Pod pod-projected-secrets-b1df8b68-24c7-4622-afb2-a7e96837cd95 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:44:44.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9936" for this suite.
Sep 22 08:44:50.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:44:50.721: INFO: namespace projected-9936 deletion completed in 6.083313785s

• [SLOW TEST:8.161 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:44:50.722: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:44:50.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8485" for this suite.
Sep 22 08:44:56.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:44:56.848: INFO: namespace kubelet-test-8485 deletion completed in 6.074578113s

• [SLOW TEST:6.125 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:44:56.849: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 22 08:44:56.885: INFO: Waiting up to 5m0s for pod "pod-514dae3c-d539-4b05-8456-e57c95e32ab1" in namespace "emptydir-2519" to be "success or failure"
Sep 22 08:44:56.888: INFO: Pod "pod-514dae3c-d539-4b05-8456-e57c95e32ab1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.210602ms
Sep 22 08:44:58.891: INFO: Pod "pod-514dae3c-d539-4b05-8456-e57c95e32ab1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006247904s
STEP: Saw pod success
Sep 22 08:44:58.891: INFO: Pod "pod-514dae3c-d539-4b05-8456-e57c95e32ab1" satisfied condition "success or failure"
Sep 22 08:44:58.894: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-514dae3c-d539-4b05-8456-e57c95e32ab1 container test-container: <nil>
STEP: delete the pod
Sep 22 08:44:58.914: INFO: Waiting for pod pod-514dae3c-d539-4b05-8456-e57c95e32ab1 to disappear
Sep 22 08:44:58.918: INFO: Pod pod-514dae3c-d539-4b05-8456-e57c95e32ab1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:44:58.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2519" for this suite.
Sep 22 08:45:04.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:45:05.047: INFO: namespace emptydir-2519 deletion completed in 6.126070614s

• [SLOW TEST:8.198 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:45:05.049: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 08:45:05.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5095'
Sep 22 08:45:05.211: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 22 08:45:05.211: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Sep 22 08:45:07.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5095'
Sep 22 08:45:07.322: INFO: stderr: ""
Sep 22 08:45:07.322: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:45:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5095" for this suite.
Sep 22 08:45:19.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:45:19.414: INFO: namespace kubectl-5095 deletion completed in 12.084724268s

• [SLOW TEST:14.366 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:45:19.418: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 22 08:45:21.474: INFO: &Pod{ObjectMeta:{send-events-1abdd5df-81fd-47eb-b678-eb5cd8821614  events-5179 /api/v1/namespaces/events-5179/pods/send-events-1abdd5df-81fd-47eb-b678-eb5cd8821614 f659ae52-f6a8-4cda-858b-dcf4738a670f 330349 0 2019-09-22 08:45:19 +0000 UTC <nil> <nil> map[name:foo time:448825182] map[cni.projectcalico.org/podIP:10.2.212.84/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qxtbr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qxtbr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qxtbr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:45:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:45:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:45:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:45:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.84,StartTime:2019-09-22 08:45:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:45:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://218baeeb4e93a4ec63cca637c230028fcebca65c629c1084237e51445acb2543,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.84,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Sep 22 08:45:23.478: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 22 08:45:25.482: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:45:25.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5179" for this suite.
Sep 22 08:46:09.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:09.608: INFO: namespace events-5179 deletion completed in 44.114975781s

• [SLOW TEST:50.190 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:09.610: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 22 08:46:09.656: INFO: Waiting up to 5m0s for pod "pod-53accf33-7f2c-4951-8ebc-abe94041460e" in namespace "emptydir-204" to be "success or failure"
Sep 22 08:46:09.660: INFO: Pod "pod-53accf33-7f2c-4951-8ebc-abe94041460e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346686ms
Sep 22 08:46:11.668: INFO: Pod "pod-53accf33-7f2c-4951-8ebc-abe94041460e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011983466s
STEP: Saw pod success
Sep 22 08:46:11.668: INFO: Pod "pod-53accf33-7f2c-4951-8ebc-abe94041460e" satisfied condition "success or failure"
Sep 22 08:46:11.671: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-53accf33-7f2c-4951-8ebc-abe94041460e container test-container: <nil>
STEP: delete the pod
Sep 22 08:46:11.685: INFO: Waiting for pod pod-53accf33-7f2c-4951-8ebc-abe94041460e to disappear
Sep 22 08:46:11.687: INFO: Pod pod-53accf33-7f2c-4951-8ebc-abe94041460e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:11.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-204" for this suite.
Sep 22 08:46:17.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:17.766: INFO: namespace emptydir-204 deletion completed in 6.07595095s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:17.768: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 22 08:46:23.835: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:23.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0922 08:46:23.835919      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5402" for this suite.
Sep 22 08:46:29.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:29.920: INFO: namespace gc-5402 deletion completed in 6.081990943s

• [SLOW TEST:12.156 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:29.928: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:46:29.958: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a" in namespace "downward-api-4357" to be "success or failure"
Sep 22 08:46:29.961: INFO: Pod "downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.506831ms
Sep 22 08:46:31.964: INFO: Pod "downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005688375s
STEP: Saw pod success
Sep 22 08:46:31.964: INFO: Pod "downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a" satisfied condition "success or failure"
Sep 22 08:46:31.966: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a container client-container: <nil>
STEP: delete the pod
Sep 22 08:46:31.980: INFO: Waiting for pod downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a to disappear
Sep 22 08:46:31.983: INFO: Pod downwardapi-volume-2e7df88c-9a25-41b0-be12-d7bff0b5348a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:31.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4357" for this suite.
Sep 22 08:46:37.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:38.088: INFO: namespace downward-api-4357 deletion completed in 6.101177213s

• [SLOW TEST:8.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:38.089: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Sep 22 08:46:38.120: INFO: Waiting up to 5m0s for pod "client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd" in namespace "containers-3299" to be "success or failure"
Sep 22 08:46:38.124: INFO: Pod "client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.273958ms
Sep 22 08:46:40.127: INFO: Pod "client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006664912s
STEP: Saw pod success
Sep 22 08:46:40.127: INFO: Pod "client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd" satisfied condition "success or failure"
Sep 22 08:46:40.131: INFO: Trying to get logs from node ip-10-0-14-205 pod client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd container test-container: <nil>
STEP: delete the pod
Sep 22 08:46:40.146: INFO: Waiting for pod client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd to disappear
Sep 22 08:46:40.148: INFO: Pod client-containers-a4aab172-f031-4eab-9ad2-4cc7bb2e7abd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:40.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3299" for this suite.
Sep 22 08:46:46.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:46.248: INFO: namespace containers-3299 deletion completed in 6.096131786s

• [SLOW TEST:8.160 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:46.249: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 22 08:46:46.288: INFO: Waiting up to 5m0s for pod "downward-api-c26294f2-e986-42a9-afce-8727a1df0193" in namespace "downward-api-7090" to be "success or failure"
Sep 22 08:46:46.292: INFO: Pod "downward-api-c26294f2-e986-42a9-afce-8727a1df0193": Phase="Pending", Reason="", readiness=false. Elapsed: 3.376077ms
Sep 22 08:46:48.296: INFO: Pod "downward-api-c26294f2-e986-42a9-afce-8727a1df0193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006859328s
STEP: Saw pod success
Sep 22 08:46:48.296: INFO: Pod "downward-api-c26294f2-e986-42a9-afce-8727a1df0193" satisfied condition "success or failure"
Sep 22 08:46:48.299: INFO: Trying to get logs from node ip-10-0-14-205 pod downward-api-c26294f2-e986-42a9-afce-8727a1df0193 container dapi-container: <nil>
STEP: delete the pod
Sep 22 08:46:48.316: INFO: Waiting for pod downward-api-c26294f2-e986-42a9-afce-8727a1df0193 to disappear
Sep 22 08:46:48.319: INFO: Pod downward-api-c26294f2-e986-42a9-afce-8727a1df0193 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:48.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7090" for this suite.
Sep 22 08:46:54.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:46:54.407: INFO: namespace downward-api-7090 deletion completed in 6.08189883s

• [SLOW TEST:8.158 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:46:54.408: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:46:56.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2893" for this suite.
Sep 22 08:47:26.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:47:26.550: INFO: namespace containers-2893 deletion completed in 30.089263624s

• [SLOW TEST:32.142 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:47:26.554: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 22 08:47:29.120: INFO: Successfully updated pod "annotationupdate153ba0b9-d854-49a0-99de-c61698ea0de3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:47:33.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8156" for this suite.
Sep 22 08:48:01.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:01.295: INFO: namespace downward-api-8156 deletion completed in 28.139860915s

• [SLOW TEST:34.742 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:01.296: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ec4cb4b7-d55c-4885-91d8-49f8720abab6
STEP: Creating a pod to test consume configMaps
Sep 22 08:48:01.366: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51" in namespace "projected-1134" to be "success or failure"
Sep 22 08:48:01.370: INFO: Pod "pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050611ms
Sep 22 08:48:03.373: INFO: Pod "pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007205621s
STEP: Saw pod success
Sep 22 08:48:03.373: INFO: Pod "pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51" satisfied condition "success or failure"
Sep 22 08:48:03.376: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:48:03.419: INFO: Waiting for pod pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51 to disappear
Sep 22 08:48:03.422: INFO: Pod pod-projected-configmaps-1e7c4f20-e87a-4300-bf20-df83f3768b51 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:03.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1134" for this suite.
Sep 22 08:48:09.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:09.526: INFO: namespace projected-1134 deletion completed in 6.098911673s

• [SLOW TEST:8.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:09.528: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 22 08:48:09.560: INFO: Waiting up to 5m0s for pod "pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f" in namespace "emptydir-9188" to be "success or failure"
Sep 22 08:48:09.572: INFO: Pod "pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.767965ms
Sep 22 08:48:11.575: INFO: Pod "pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014511858s
STEP: Saw pod success
Sep 22 08:48:11.575: INFO: Pod "pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f" satisfied condition "success or failure"
Sep 22 08:48:11.579: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f container test-container: <nil>
STEP: delete the pod
Sep 22 08:48:11.596: INFO: Waiting for pod pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f to disappear
Sep 22 08:48:11.599: INFO: Pod pod-ace71bc1-4e14-4854-bb81-bf994ce9fa4f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:11.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9188" for this suite.
Sep 22 08:48:17.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:17.675: INFO: namespace emptydir-9188 deletion completed in 6.073231947s

• [SLOW TEST:8.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:17.676: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 22 08:48:17.709: INFO: Waiting up to 5m0s for pod "pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc" in namespace "emptydir-5126" to be "success or failure"
Sep 22 08:48:17.713: INFO: Pod "pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.996533ms
Sep 22 08:48:19.716: INFO: Pod "pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00688771s
STEP: Saw pod success
Sep 22 08:48:19.716: INFO: Pod "pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc" satisfied condition "success or failure"
Sep 22 08:48:19.718: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc container test-container: <nil>
STEP: delete the pod
Sep 22 08:48:19.731: INFO: Waiting for pod pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc to disappear
Sep 22 08:48:19.733: INFO: Pod pod-9b495894-884a-4d8a-b8e2-0489b4a03bbc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:19.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5126" for this suite.
Sep 22 08:48:25.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:25.825: INFO: namespace emptydir-5126 deletion completed in 6.088655645s

• [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:25.827: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:48:25.855: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Sep 22 08:48:29.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 create -f -'
Sep 22 08:48:29.878: INFO: stderr: ""
Sep 22 08:48:29.878: INFO: stdout: "e2e-test-crd-publish-openapi-5697-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 22 08:48:29.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 delete e2e-test-crd-publish-openapi-5697-crds test-foo'
Sep 22 08:48:29.961: INFO: stderr: ""
Sep 22 08:48:29.961: INFO: stdout: "e2e-test-crd-publish-openapi-5697-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Sep 22 08:48:29.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 apply -f -'
Sep 22 08:48:30.143: INFO: stderr: ""
Sep 22 08:48:30.143: INFO: stdout: "e2e-test-crd-publish-openapi-5697-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Sep 22 08:48:30.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 delete e2e-test-crd-publish-openapi-5697-crds test-foo'
Sep 22 08:48:30.230: INFO: stderr: ""
Sep 22 08:48:30.230: INFO: stdout: "e2e-test-crd-publish-openapi-5697-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Sep 22 08:48:30.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 create -f -'
Sep 22 08:48:30.395: INFO: rc: 1
Sep 22 08:48:30.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 apply -f -'
Sep 22 08:48:30.553: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Sep 22 08:48:30.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 create -f -'
Sep 22 08:48:30.707: INFO: rc: 1
Sep 22 08:48:30.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-696 apply -f -'
Sep 22 08:48:30.863: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Sep 22 08:48:30.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-5697-crds'
Sep 22 08:48:31.031: INFO: stderr: ""
Sep 22 08:48:31.031: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5697-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Sep 22 08:48:31.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-5697-crds.metadata'
Sep 22 08:48:31.195: INFO: stderr: ""
Sep 22 08:48:31.195: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5697-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Sep 22 08:48:31.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-5697-crds.spec'
Sep 22 08:48:31.370: INFO: stderr: ""
Sep 22 08:48:31.370: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5697-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Sep 22 08:48:31.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-5697-crds.spec.bars'
Sep 22 08:48:31.579: INFO: stderr: ""
Sep 22 08:48:31.579: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5697-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Sep 22 08:48:31.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-5697-crds.spec.bars2'
Sep 22 08:48:31.764: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:35.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-696" for this suite.
Sep 22 08:48:41.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:41.387: INFO: namespace crd-publish-openapi-696 deletion completed in 6.08600419s

• [SLOW TEST:15.560 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:41.388: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 08:48:41.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-779'
Sep 22 08:48:41.545: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 22 08:48:41.545: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Sep 22 08:48:41.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete jobs e2e-test-httpd-job --namespace=kubectl-779'
Sep 22 08:48:41.672: INFO: stderr: ""
Sep 22 08:48:41.672: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:41.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-779" for this suite.
Sep 22 08:48:47.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:47.764: INFO: namespace kubectl-779 deletion completed in 6.088249095s

• [SLOW TEST:6.376 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:47.764: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:47.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3671" for this suite.
Sep 22 08:48:53.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:48:53.906: INFO: namespace tables-3671 deletion completed in 6.087593928s

• [SLOW TEST:6.142 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:48:53.910: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-9090e436-de96-4a3c-a65e-79b6b6564bc4
STEP: Creating a pod to test consume secrets
Sep 22 08:48:53.951: INFO: Waiting up to 5m0s for pod "pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4" in namespace "secrets-9771" to be "success or failure"
Sep 22 08:48:53.954: INFO: Pod "pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.655568ms
Sep 22 08:48:55.957: INFO: Pod "pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005773217s
STEP: Saw pod success
Sep 22 08:48:55.957: INFO: Pod "pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4" satisfied condition "success or failure"
Sep 22 08:48:55.960: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4 container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 08:48:55.976: INFO: Waiting for pod pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4 to disappear
Sep 22 08:48:55.987: INFO: Pod pod-secrets-1927a064-f856-43d5-b0a3-805eacd2f5c4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:48:55.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9771" for this suite.
Sep 22 08:49:02.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:49:02.075: INFO: namespace secrets-9771 deletion completed in 6.084871146s

• [SLOW TEST:8.166 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:49:02.076: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:49:02.544: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:49:05.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:49:05.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2593" for this suite.
Sep 22 08:49:17.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:49:17.778: INFO: namespace webhook-2593 deletion completed in 12.089121657s
STEP: Destroying namespace "webhook-2593-markers" for this suite.
Sep 22 08:49:23.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:49:23.856: INFO: namespace webhook-2593-markers deletion completed in 6.077172521s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.795 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:49:23.871: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 22 08:49:23.910: INFO: Waiting up to 5m0s for pod "downward-api-666e33dc-b28b-488a-9edf-047e862f5c38" in namespace "downward-api-1785" to be "success or failure"
Sep 22 08:49:23.912: INFO: Pod "downward-api-666e33dc-b28b-488a-9edf-047e862f5c38": Phase="Pending", Reason="", readiness=false. Elapsed: 1.998136ms
Sep 22 08:49:25.915: INFO: Pod "downward-api-666e33dc-b28b-488a-9edf-047e862f5c38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004888523s
STEP: Saw pod success
Sep 22 08:49:25.915: INFO: Pod "downward-api-666e33dc-b28b-488a-9edf-047e862f5c38" satisfied condition "success or failure"
Sep 22 08:49:25.917: INFO: Trying to get logs from node ip-10-0-14-205 pod downward-api-666e33dc-b28b-488a-9edf-047e862f5c38 container dapi-container: <nil>
STEP: delete the pod
Sep 22 08:49:25.940: INFO: Waiting for pod downward-api-666e33dc-b28b-488a-9edf-047e862f5c38 to disappear
Sep 22 08:49:25.943: INFO: Pod downward-api-666e33dc-b28b-488a-9edf-047e862f5c38 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:49:25.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1785" for this suite.
Sep 22 08:49:31.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:49:32.050: INFO: namespace downward-api-1785 deletion completed in 6.10516834s

• [SLOW TEST:8.179 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:49:32.052: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Sep 22 08:49:32.082: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:49:51.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3616" for this suite.
Sep 22 08:49:57.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:49:57.720: INFO: namespace crd-publish-openapi-3616 deletion completed in 6.090509929s

• [SLOW TEST:25.668 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:49:57.721: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Sep 22 08:49:57.747: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 22 08:49:57.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:58.025: INFO: stderr: ""
Sep 22 08:49:58.025: INFO: stdout: "service/redis-slave created\n"
Sep 22 08:49:58.025: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 22 08:49:58.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:58.309: INFO: stderr: ""
Sep 22 08:49:58.309: INFO: stdout: "service/redis-master created\n"
Sep 22 08:49:58.309: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 22 08:49:58.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:58.596: INFO: stderr: ""
Sep 22 08:49:58.596: INFO: stdout: "service/frontend created\n"
Sep 22 08:49:58.596: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 22 08:49:58.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:58.794: INFO: stderr: ""
Sep 22 08:49:58.794: INFO: stdout: "deployment.apps/frontend created\n"
Sep 22 08:49:58.794: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 22 08:49:58.795: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:58.978: INFO: stderr: ""
Sep 22 08:49:58.978: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 22 08:49:58.978: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 22 08:49:58.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8489'
Sep 22 08:49:59.201: INFO: stderr: ""
Sep 22 08:49:59.201: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 22 08:49:59.201: INFO: Waiting for all frontend pods to be Running.
I0922 08:49:59.201506      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:49:59.201526      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:50:04.251: INFO: Waiting for frontend to serve content.
Sep 22 08:50:04.264: INFO: Trying to add a new entry to the guestbook.
Sep 22 08:50:04.277: INFO: Verifying that added entry can be retrieved.
Sep 22 08:50:04.289: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:09.346: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:14.359: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:19.370: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:24.382: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:29.394: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:34.405: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:39.419: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:44.436: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:49.451: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:54.466: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Sep 22 08:50:59.477: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Sep 22 08:51:04.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:04.640: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:04.641: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 22 08:51:04.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:04.838: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:04.838: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 22 08:51:04.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:04.961: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:04.961: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 22 08:51:04.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:05.107: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:05.107: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 22 08:51:05.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:05.200: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:05.200: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 22 08:51:05.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8489'
Sep 22 08:51:05.283: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 08:51:05.283: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:51:05.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8489" for this suite.
Sep 22 08:51:17.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:51:17.373: INFO: namespace kubectl-8489 deletion completed in 12.085446183s

• [SLOW TEST:79.653 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:51:17.373: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:51:17.409: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 22 08:51:22.414: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 22 08:51:22.414: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 22 08:51:24.417: INFO: Creating deployment "test-rollover-deployment"
Sep 22 08:51:24.427: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 22 08:51:26.434: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 22 08:51:26.440: INFO: Ensure that both replica sets have 1 created replica
Sep 22 08:51:26.445: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 22 08:51:26.462: INFO: Updating deployment test-rollover-deployment
Sep 22 08:51:26.462: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 22 08:51:28.468: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 22 08:51:28.473: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 22 08:51:28.478: INFO: all replica sets need to contain the pod-template-hash label
Sep 22 08:51:28.479: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739088, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 22 08:51:30.486: INFO: all replica sets need to contain the pod-template-hash label
Sep 22 08:51:30.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739088, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 22 08:51:32.484: INFO: all replica sets need to contain the pod-template-hash label
Sep 22 08:51:32.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739088, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 22 08:51:34.484: INFO: all replica sets need to contain the pod-template-hash label
Sep 22 08:51:34.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739088, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 22 08:51:36.484: INFO: all replica sets need to contain the pod-template-hash label
Sep 22 08:51:36.484: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739088, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739084, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 22 08:51:38.484: INFO: 
Sep 22 08:51:38.484: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 22 08:51:38.490: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1829 /apis/apps/v1/namespaces/deployment-1829/deployments/test-rollover-deployment e0690fe9-ed23-4c17-9fa2-00d35162ac6b 332017 2 2019-09-22 08:51:24 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008ebe448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-09-22 08:51:24 +0000 UTC,LastTransitionTime:2019-09-22 08:51:24 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-09-22 08:51:38 +0000 UTC,LastTransitionTime:2019-09-22 08:51:24 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Sep 22 08:51:38.494: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-1829 /apis/apps/v1/namespaces/deployment-1829/replicasets/test-rollover-deployment-7d7dc6548c fc153fb3-f496-4622-8eb4-ab9a0e3e8e86 332006 2 2019-09-22 08:51:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment e0690fe9-ed23-4c17-9fa2-00d35162ac6b 0xc008d38127 0xc008d38128}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008d38188 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:51:38.494: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 22 08:51:38.494: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1829 /apis/apps/v1/namespaces/deployment-1829/replicasets/test-rollover-controller 51a42c24-6248-4ed6-8a98-2a944e95708c 332016 2 2019-09-22 08:51:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment e0690fe9-ed23-4c17-9fa2-00d35162ac6b 0xc008d38057 0xc008d38058}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc008d380b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:51:38.494: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-1829 /apis/apps/v1/namespaces/deployment-1829/replicasets/test-rollover-deployment-f6c94f66c f534e2ce-ba5f-455f-b116-4752bec17d41 331974 2 2019-09-22 08:51:24 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment e0690fe9-ed23-4c17-9fa2-00d35162ac6b 0xc008d38200 0xc008d38201}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008d38278 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:51:38.497: INFO: Pod "test-rollover-deployment-7d7dc6548c-xdf6p" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-xdf6p test-rollover-deployment-7d7dc6548c- deployment-1829 /api/v1/namespaces/deployment-1829/pods/test-rollover-deployment-7d7dc6548c-xdf6p 2fd93adb-02ce-4cab-ab3b-ce2a9885f486 331989 0 2019-09-22 08:51:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:10.2.212.109/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c fc153fb3-f496-4622-8eb4-ab9a0e3e8e86 0xc008ebe877 0xc008ebe878}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-rdcnk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-rdcnk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-rdcnk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:51:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:51:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:51:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.109,StartTime:2019-09-22 08:51:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:51:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://34fa724a95107be0e147c718783c3d0f06aa327c42450a52484b7c92ab5551b4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.109,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:51:38.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1829" for this suite.
Sep 22 08:51:44.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:51:44.576: INFO: namespace deployment-1829 deletion completed in 6.076480495s

• [SLOW TEST:27.203 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:51:44.577: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:51:44.603: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Sep 22 08:51:48.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-7514 create -f -'
Sep 22 08:51:48.530: INFO: stderr: ""
Sep 22 08:51:48.530: INFO: stdout: "e2e-test-crd-publish-openapi-1588-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 22 08:51:48.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-7514 delete e2e-test-crd-publish-openapi-1588-crds test-cr'
Sep 22 08:51:48.615: INFO: stderr: ""
Sep 22 08:51:48.615: INFO: stdout: "e2e-test-crd-publish-openapi-1588-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Sep 22 08:51:48.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-7514 apply -f -'
Sep 22 08:51:48.878: INFO: stderr: ""
Sep 22 08:51:48.878: INFO: stdout: "e2e-test-crd-publish-openapi-1588-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Sep 22 08:51:48.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 --namespace=crd-publish-openapi-7514 delete e2e-test-crd-publish-openapi-1588-crds test-cr'
Sep 22 08:51:48.961: INFO: stderr: ""
Sep 22 08:51:48.961: INFO: stdout: "e2e-test-crd-publish-openapi-1588-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Sep 22 08:51:48.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 explain e2e-test-crd-publish-openapi-1588-crds'
Sep 22 08:51:49.119: INFO: stderr: ""
Sep 22 08:51:49.119: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1588-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:51:52.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7514" for this suite.
Sep 22 08:51:58.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:51:58.855: INFO: namespace crd-publish-openapi-7514 deletion completed in 6.078321607s

• [SLOW TEST:14.278 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:51:58.855: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5486
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5486
STEP: Creating statefulset with conflicting port in namespace statefulset-5486
STEP: Waiting until pod test-pod will start running in namespace statefulset-5486
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5486
Sep 22 08:52:02.914: INFO: Observed stateful pod in namespace: statefulset-5486, name: ss-0, uid: 1c8a3871-3667-4842-9052-307a54fd6655, status phase: Pending. Waiting for statefulset controller to delete.
Sep 22 08:52:03.310: INFO: Observed stateful pod in namespace: statefulset-5486, name: ss-0, uid: 1c8a3871-3667-4842-9052-307a54fd6655, status phase: Failed. Waiting for statefulset controller to delete.
Sep 22 08:52:03.337: INFO: Observed stateful pod in namespace: statefulset-5486, name: ss-0, uid: 1c8a3871-3667-4842-9052-307a54fd6655, status phase: Failed. Waiting for statefulset controller to delete.
Sep 22 08:52:03.351: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5486
STEP: Removing pod with conflicting port in namespace statefulset-5486
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5486 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 08:52:07.408: INFO: Deleting all statefulset in ns statefulset-5486
Sep 22 08:52:07.410: INFO: Scaling statefulset ss to 0
Sep 22 08:52:17.421: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 08:52:17.425: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:52:17.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5486" for this suite.
Sep 22 08:52:23.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:52:23.563: INFO: namespace statefulset-5486 deletion completed in 6.101013882s

• [SLOW TEST:24.708 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:52:23.567: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-3e245861-ea59-432f-b786-c7d75bb14521
STEP: Creating a pod to test consume configMaps
Sep 22 08:52:23.612: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3" in namespace "configmap-8160" to be "success or failure"
Sep 22 08:52:23.614: INFO: Pod "pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095668ms
Sep 22 08:52:25.617: INFO: Pod "pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004922089s
STEP: Saw pod success
Sep 22 08:52:25.617: INFO: Pod "pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3" satisfied condition "success or failure"
Sep 22 08:52:25.620: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:52:25.643: INFO: Waiting for pod pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3 to disappear
Sep 22 08:52:25.645: INFO: Pod pod-configmaps-a2d6b549-0c8b-4386-a09b-185fb2d179e3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:52:25.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8160" for this suite.
Sep 22 08:52:31.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:52:31.738: INFO: namespace configmap-8160 deletion completed in 6.090815707s

• [SLOW TEST:8.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:52:31.739: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:52:31.781: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 22 08:52:31.787: INFO: Number of nodes with available pods: 0
Sep 22 08:52:31.787: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 22 08:52:31.803: INFO: Number of nodes with available pods: 0
Sep 22 08:52:31.804: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:32.807: INFO: Number of nodes with available pods: 1
Sep 22 08:52:32.807: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 22 08:52:32.817: INFO: Number of nodes with available pods: 1
Sep 22 08:52:32.818: INFO: Number of running nodes: 0, number of available pods: 1
Sep 22 08:52:33.820: INFO: Number of nodes with available pods: 0
Sep 22 08:52:33.820: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 22 08:52:33.830: INFO: Number of nodes with available pods: 0
Sep 22 08:52:33.830: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:34.834: INFO: Number of nodes with available pods: 0
Sep 22 08:52:34.834: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:35.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:35.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:36.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:36.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:37.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:37.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:38.838: INFO: Number of nodes with available pods: 0
Sep 22 08:52:38.838: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:39.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:39.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:40.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:40.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:41.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:41.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:42.838: INFO: Number of nodes with available pods: 0
Sep 22 08:52:42.838: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:43.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:43.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:44.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:44.834: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:45.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:45.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:46.833: INFO: Number of nodes with available pods: 0
Sep 22 08:52:46.833: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 08:52:47.833: INFO: Number of nodes with available pods: 1
Sep 22 08:52:47.833: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4713, will wait for the garbage collector to delete the pods
I0922 08:52:47.839574      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:52:47.839597      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 08:52:47.894: INFO: Deleting DaemonSet.extensions daemon-set took: 4.747684ms
Sep 22 08:52:48.194: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.416107ms
I0922 08:52:48.194857      18 controller_utils.go:810] Ignoring inactive pod daemonsets-4713/daemon-set-tdtxx in state Running, deletion time 2019-09-22 08:53:18 +0000 UTC
Sep 22 08:52:55.197: INFO: Number of nodes with available pods: 0
Sep 22 08:52:55.197: INFO: Number of running nodes: 0, number of available pods: 0
Sep 22 08:52:55.199: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4713/daemonsets","resourceVersion":"332438"},"items":null}

Sep 22 08:52:55.203: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4713/pods","resourceVersion":"332438"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:52:55.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4713" for this suite.
Sep 22 08:53:01.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:53:01.316: INFO: namespace daemonsets-4713 deletion completed in 6.085601735s

• [SLOW TEST:29.577 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:53:01.316: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 22 08:53:01.344: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:53:05.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3395" for this suite.
Sep 22 08:53:11.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:53:11.170: INFO: namespace init-container-3395 deletion completed in 6.10547964s

• [SLOW TEST:9.853 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:53:11.170: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 22 08:53:17.249: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.249: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.361: INFO: Exec stderr: ""
Sep 22 08:53:17.361: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.361: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.448: INFO: Exec stderr: ""
Sep 22 08:53:17.448: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.448: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.552: INFO: Exec stderr: ""
Sep 22 08:53:17.552: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.552: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.639: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 22 08:53:17.639: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.639: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.726: INFO: Exec stderr: ""
Sep 22 08:53:17.726: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.726: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.806: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 22 08:53:17.806: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.806: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:17.909: INFO: Exec stderr: ""
Sep 22 08:53:17.909: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:17.909: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:18.018: INFO: Exec stderr: ""
Sep 22 08:53:18.018: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:18.018: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:18.131: INFO: Exec stderr: ""
Sep 22 08:53:18.131: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4857 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 08:53:18.131: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 08:53:18.257: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:53:18.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4857" for this suite.
Sep 22 08:54:02.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:02.371: INFO: namespace e2e-kubelet-etc-hosts-4857 deletion completed in 44.110994813s

• [SLOW TEST:51.202 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:54:02.372: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7317c627-7462-46e7-8167-6ec211c2be0e
STEP: Creating a pod to test consume configMaps
Sep 22 08:54:02.425: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc" in namespace "projected-5561" to be "success or failure"
Sep 22 08:54:02.429: INFO: Pod "pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982507ms
Sep 22 08:54:04.433: INFO: Pod "pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007609299s
STEP: Saw pod success
Sep 22 08:54:04.433: INFO: Pod "pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc" satisfied condition "success or failure"
Sep 22 08:54:04.435: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:54:04.457: INFO: Waiting for pod pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc to disappear
Sep 22 08:54:04.461: INFO: Pod pod-projected-configmaps-f1b4911b-39c9-42a2-bba7-5bd23ea3aedc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:54:04.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5561" for this suite.
Sep 22 08:54:10.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:10.543: INFO: namespace projected-5561 deletion completed in 6.078798309s

• [SLOW TEST:8.172 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:54:10.544: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 08:54:10.578: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c" in namespace "projected-494" to be "success or failure"
Sep 22 08:54:10.581: INFO: Pod "downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82246ms
Sep 22 08:54:12.584: INFO: Pod "downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005850676s
Sep 22 08:54:14.587: INFO: Pod "downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009256424s
STEP: Saw pod success
Sep 22 08:54:14.587: INFO: Pod "downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c" satisfied condition "success or failure"
Sep 22 08:54:14.590: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c container client-container: <nil>
STEP: delete the pod
Sep 22 08:54:14.605: INFO: Waiting for pod downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c to disappear
Sep 22 08:54:14.608: INFO: Pod downwardapi-volume-ea4946da-9134-4230-b7d5-e0982611808c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:54:14.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-494" for this suite.
Sep 22 08:54:20.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:20.741: INFO: namespace projected-494 deletion completed in 6.129483362s

• [SLOW TEST:10.197 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:54:20.742: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-f4d0e627-9934-476e-b07d-c6001014948d
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:54:24.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9006" for this suite.
Sep 22 08:54:36.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:36.914: INFO: namespace configmap-9006 deletion completed in 12.096944514s

• [SLOW TEST:16.173 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:54:36.914: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 22 08:54:36.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3869 /api/v1/namespaces/watch-3869/configmaps/e2e-watch-test-resource-version a5ae6654-e266-4919-a76c-afbf63996a0e 332825 0 2019-09-22 08:54:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 22 08:54:36.964: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3869 /api/v1/namespaces/watch-3869/configmaps/e2e-watch-test-resource-version a5ae6654-e266-4919-a76c-afbf63996a0e 332826 0 2019-09-22 08:54:36 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:54:36.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3869" for this suite.
Sep 22 08:54:42.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:43.103: INFO: namespace watch-3869 deletion completed in 6.136082375s

• [SLOW TEST:6.189 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:54:43.103: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:54:43.604: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:54:45.613: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739283, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739283, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739283, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739283, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:54:48.630: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:54:48.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8346" for this suite.
Sep 22 08:54:54.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:54:54.738: INFO: namespace webhook-8346 deletion completed in 6.079475451s
STEP: Destroying namespace "webhook-8346-markers" for this suite.
Sep 22 08:55:00.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:55:00.846: INFO: namespace webhook-8346-markers deletion completed in 6.107583418s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.762 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:55:00.866: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-92d25478-d82d-42a3-8096-e5440a6c58da
STEP: Creating configMap with name cm-test-opt-upd-3a2044d3-b9a7-40a7-b866-f32d9d7816d2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-92d25478-d82d-42a3-8096-e5440a6c58da
STEP: Updating configmap cm-test-opt-upd-3a2044d3-b9a7-40a7-b866-f32d9d7816d2
STEP: Creating configMap with name cm-test-opt-create-3912c644-c64c-41a9-8835-d641502abc09
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:55:05.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3648" for this suite.
Sep 22 08:55:17.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:55:17.276: INFO: namespace configmap-3648 deletion completed in 12.086731755s

• [SLOW TEST:16.410 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:55:17.276: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 08:55:17.838: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 08:55:19.847: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739317, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739317, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739317, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704739317, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 08:55:22.859: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:55:22.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1075" for this suite.
Sep 22 08:55:28.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:55:29.013: INFO: namespace webhook-1075 deletion completed in 6.092036847s
STEP: Destroying namespace "webhook-1075-markers" for this suite.
Sep 22 08:55:35.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:55:35.124: INFO: namespace webhook-1075-markers deletion completed in 6.11024582s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.861 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:55:35.138: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 22 08:55:35.168: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 22 08:55:35.178: INFO: Waiting for terminating namespaces to be deleted...
Sep 22 08:55:35.181: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-14-205 before test
Sep 22 08:55:35.186: INFO: kube-proxy-gxhtr from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.186: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:55:35.187: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:55:35.187: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:55:35.187: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:55:35.187: INFO: calico-node-kfxhb from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.187: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:55:35.187: INFO: sonobuoy from sonobuoy started at 2019-09-22 07:56:45 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.187: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 22 08:55:35.187: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-60 before test
Sep 22 08:55:35.204: INFO: sonobuoy-e2e-job-df839470c40a489c from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:55:35.204: INFO: 	Container e2e ready: true, restart count 0
Sep 22 08:55:35.204: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:55:35.204: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 08:55:35.204: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 08:55:35.204: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 22 08:55:35.204: INFO: calico-node-nzh59 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.204: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 08:55:35.204: INFO: kube-proxy-mrm99 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.204: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 08:55:35.204: INFO: coredns-fffcf5449-vn775 from kube-system started at 2019-09-20 01:40:55 +0000 UTC (1 container statuses recorded)
Sep 22 08:55:35.204: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
I0922 08:55:35.212363      18 reflector.go:120] Starting reflector *v1.Event (0s) from k8s.io/kubernetes/test/e2e/common/events.go:136
I0922 08:55:35.212395      18 reflector.go:158] Listing and watching *v1.Event from k8s.io/kubernetes/test/e2e/common/events.go:136
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c6b6d275f52a6f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c6b6d276903c3e], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:55:36.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2626" for this suite.
Sep 22 08:55:42.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:55:42.302: INFO: namespace sched-pred-2626 deletion completed in 6.075293608s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.164 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
I0922 08:55:42.302818      18 request.go:706] Error in request: resource name may not be empty
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:55:42.302: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-8617
I0922 08:55:42.343237      18 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-8617, replica count: 1
I0922 08:55:42.343327      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:55:42.343370      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 08:55:43.393504      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 08:55:44.393797      18 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 08:55:44.394266      18 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/network/service_latency.go:323
I0922 08:55:44.394340      18 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/network/service_latency.go:323
Sep 22 08:55:44.500: INFO: Created: latency-svc-5s78v
Sep 22 08:55:44.507: INFO: Got endpoints: latency-svc-5s78v [13.620483ms]
Sep 22 08:55:44.518: INFO: Created: latency-svc-2cxgc
Sep 22 08:55:44.521: INFO: Created: latency-svc-f5h4j
Sep 22 08:55:44.524: INFO: Got endpoints: latency-svc-2cxgc [15.269665ms]
Sep 22 08:55:44.530: INFO: Got endpoints: latency-svc-f5h4j [20.433558ms]
Sep 22 08:55:44.541: INFO: Created: latency-svc-7w5mh
Sep 22 08:55:44.541: INFO: Created: latency-svc-rlzrn
Sep 22 08:55:44.542: INFO: Created: latency-svc-hb8pf
Sep 22 08:55:44.542: INFO: Got endpoints: latency-svc-7w5mh [31.709777ms]
Sep 22 08:55:44.542: INFO: Got endpoints: latency-svc-rlzrn [32.143185ms]
Sep 22 08:55:44.544: INFO: Got endpoints: latency-svc-hb8pf [32.819436ms]
Sep 22 08:55:44.544: INFO: Created: latency-svc-vj7b7
Sep 22 08:55:44.547: INFO: Got endpoints: latency-svc-vj7b7 [35.627851ms]
Sep 22 08:55:44.580: INFO: Created: latency-svc-hwqsr
Sep 22 08:55:44.581: INFO: Created: latency-svc-qm7dq
Sep 22 08:55:44.581: INFO: Created: latency-svc-x4djb
Sep 22 08:55:44.585: INFO: Created: latency-svc-rznl5
Sep 22 08:55:44.585: INFO: Created: latency-svc-wmv2j
Sep 22 08:55:44.585: INFO: Got endpoints: latency-svc-rznl5 [74.031136ms]
Sep 22 08:55:44.585: INFO: Got endpoints: latency-svc-qm7dq [43.761391ms]
Sep 22 08:55:44.585: INFO: Created: latency-svc-dqxxh
Sep 22 08:55:44.586: INFO: Got endpoints: latency-svc-x4djb [74.406927ms]
Sep 22 08:55:44.585: INFO: Got endpoints: latency-svc-wmv2j [72.916784ms]
Sep 22 08:55:44.585: INFO: Created: latency-svc-r92kl
Sep 22 08:55:44.587: INFO: Got endpoints: latency-svc-r92kl [74.682301ms]
Sep 22 08:55:44.584: INFO: Got endpoints: latency-svc-hwqsr [72.172982ms]
Sep 22 08:55:44.595: INFO: Created: latency-svc-lbs86
Sep 22 08:55:44.596: INFO: Got endpoints: latency-svc-dqxxh [85.561758ms]
Sep 22 08:55:44.604: INFO: Got endpoints: latency-svc-lbs86 [92.860183ms]
Sep 22 08:55:44.604: INFO: Created: latency-svc-pfpxw
Sep 22 08:55:44.605: INFO: Created: latency-svc-l9bm7
Sep 22 08:55:44.611: INFO: Created: latency-svc-4fflr
Sep 22 08:55:44.614: INFO: Got endpoints: latency-svc-l9bm7 [106.157437ms]
Sep 22 08:55:44.614: INFO: Got endpoints: latency-svc-pfpxw [101.423138ms]
Sep 22 08:55:44.626: INFO: Got endpoints: latency-svc-4fflr [101.707744ms]
Sep 22 08:55:44.639: INFO: Created: latency-svc-5fqtk
Sep 22 08:55:44.639: INFO: Created: latency-svc-8c72d
Sep 22 08:55:44.639: INFO: Created: latency-svc-mgv8s
Sep 22 08:55:44.669: INFO: Created: latency-svc-ctg28
Sep 22 08:55:44.672: INFO: Got endpoints: latency-svc-mgv8s [141.943872ms]
Sep 22 08:55:44.672: INFO: Got endpoints: latency-svc-8c72d [130.272186ms]
Sep 22 08:55:44.672: INFO: Got endpoints: latency-svc-5fqtk [128.161983ms]
Sep 22 08:55:44.691: INFO: Created: latency-svc-whkzg
Sep 22 08:55:44.692: INFO: Got endpoints: latency-svc-ctg28 [145.073194ms]
Sep 22 08:55:44.702: INFO: Created: latency-svc-wv5js
Sep 22 08:55:44.725: INFO: Got endpoints: latency-svc-wv5js [139.285568ms]
Sep 22 08:55:44.726: INFO: Got endpoints: latency-svc-whkzg [140.763217ms]
Sep 22 08:55:44.731: INFO: Created: latency-svc-c8wkv
Sep 22 08:55:44.737: INFO: Got endpoints: latency-svc-c8wkv [149.756188ms]
Sep 22 08:55:44.747: INFO: Created: latency-svc-wn4j4
Sep 22 08:55:44.779: INFO: Created: latency-svc-fzwfn
Sep 22 08:55:44.787: INFO: Created: latency-svc-4ggb4
Sep 22 08:55:44.788: INFO: Got endpoints: latency-svc-wn4j4 [200.977756ms]
Sep 22 08:55:44.793: INFO: Got endpoints: latency-svc-fzwfn [205.567902ms]
Sep 22 08:55:44.805: INFO: Created: latency-svc-q98d4
Sep 22 08:55:44.818: INFO: Created: latency-svc-66k99
Sep 22 08:55:44.820: INFO: Got endpoints: latency-svc-4ggb4 [232.887766ms]
Sep 22 08:55:44.822: INFO: Got endpoints: latency-svc-q98d4 [226.932661ms]
Sep 22 08:55:44.826: INFO: Got endpoints: latency-svc-66k99 [221.936478ms]
Sep 22 08:55:44.832: INFO: Created: latency-svc-mz4pd
Sep 22 08:55:44.843: INFO: Got endpoints: latency-svc-mz4pd [228.986977ms]
Sep 22 08:55:44.844: INFO: Created: latency-svc-q89hv
Sep 22 08:55:44.863: INFO: Got endpoints: latency-svc-q89hv [248.495276ms]
Sep 22 08:55:44.868: INFO: Created: latency-svc-5r7rd
Sep 22 08:55:44.868: INFO: Created: latency-svc-hh8n9
Sep 22 08:55:44.870: INFO: Got endpoints: latency-svc-hh8n9 [243.582977ms]
Sep 22 08:55:44.874: INFO: Created: latency-svc-94sj6
Sep 22 08:55:44.877: INFO: Got endpoints: latency-svc-5r7rd [204.182033ms]
Sep 22 08:55:44.879: INFO: Got endpoints: latency-svc-94sj6 [200.279554ms]
Sep 22 08:55:44.880: INFO: Created: latency-svc-jtpqr
Sep 22 08:55:44.882: INFO: Created: latency-svc-5v59f
Sep 22 08:55:44.891: INFO: Got endpoints: latency-svc-jtpqr [217.189482ms]
Sep 22 08:55:44.898: INFO: Created: latency-svc-tv96z
Sep 22 08:55:44.901: INFO: Got endpoints: latency-svc-5v59f [208.185647ms]
Sep 22 08:55:44.912: INFO: Created: latency-svc-cg9jc
Sep 22 08:55:44.932: INFO: Created: latency-svc-mpw9r
Sep 22 08:55:44.933: INFO: Created: latency-svc-pd8pp
Sep 22 08:55:44.933: INFO: Created: latency-svc-mrl7p
Sep 22 08:55:44.935: INFO: Got endpoints: latency-svc-tv96z [210.244289ms]
Sep 22 08:55:44.947: INFO: Created: latency-svc-qn6n7
Sep 22 08:55:44.958: INFO: Got endpoints: latency-svc-cg9jc [231.93871ms]
Sep 22 08:55:44.963: INFO: Created: latency-svc-22vdl
Sep 22 08:55:44.969: INFO: Created: latency-svc-ljwdr
Sep 22 08:55:44.974: INFO: Created: latency-svc-bwp9l
Sep 22 08:55:44.987: INFO: Created: latency-svc-9b4cq
Sep 22 08:55:44.998: INFO: Created: latency-svc-llrsv
Sep 22 08:55:45.017: INFO: Created: latency-svc-bsx99
Sep 22 08:55:45.030: INFO: Got endpoints: latency-svc-pd8pp [241.595919ms]
Sep 22 08:55:45.030: INFO: Created: latency-svc-tsqlh
Sep 22 08:55:45.055: INFO: Created: latency-svc-87l6m
Sep 22 08:55:45.062: INFO: Got endpoints: latency-svc-mpw9r [325.538378ms]
Sep 22 08:55:45.073: INFO: Created: latency-svc-697w5
Sep 22 08:55:45.085: INFO: Created: latency-svc-9wl5t
Sep 22 08:55:45.099: INFO: Created: latency-svc-d44s9
Sep 22 08:55:45.103: INFO: Created: latency-svc-dvlrg
Sep 22 08:55:45.108: INFO: Created: latency-svc-4xgnb
Sep 22 08:55:45.109: INFO: Got endpoints: latency-svc-mrl7p [315.375124ms]
Sep 22 08:55:45.117: INFO: Created: latency-svc-hrlk6
Sep 22 08:55:45.154: INFO: Got endpoints: latency-svc-qn6n7 [331.964124ms]
Sep 22 08:55:45.165: INFO: Created: latency-svc-4bd8p
Sep 22 08:55:45.206: INFO: Got endpoints: latency-svc-22vdl [385.464739ms]
Sep 22 08:55:45.217: INFO: Created: latency-svc-qb5bn
Sep 22 08:55:45.257: INFO: Got endpoints: latency-svc-ljwdr [430.741934ms]
Sep 22 08:55:45.267: INFO: Created: latency-svc-45rl7
Sep 22 08:55:45.307: INFO: Got endpoints: latency-svc-bwp9l [464.346364ms]
Sep 22 08:55:45.319: INFO: Created: latency-svc-v84nn
Sep 22 08:55:45.363: INFO: Got endpoints: latency-svc-9b4cq [499.79456ms]
Sep 22 08:55:45.371: INFO: Created: latency-svc-wncbk
Sep 22 08:55:45.405: INFO: Got endpoints: latency-svc-llrsv [535.519795ms]
Sep 22 08:55:45.418: INFO: Created: latency-svc-7jqgz
Sep 22 08:55:45.456: INFO: Got endpoints: latency-svc-bsx99 [578.478778ms]
Sep 22 08:55:45.471: INFO: Created: latency-svc-rtpxq
Sep 22 08:55:45.510: INFO: Got endpoints: latency-svc-tsqlh [630.884979ms]
Sep 22 08:55:45.519: INFO: Created: latency-svc-hpk4k
Sep 22 08:55:45.562: INFO: Got endpoints: latency-svc-87l6m [670.919023ms]
Sep 22 08:55:45.579: INFO: Created: latency-svc-f4glt
Sep 22 08:55:45.608: INFO: Got endpoints: latency-svc-697w5 [707.689942ms]
Sep 22 08:55:45.615: INFO: Created: latency-svc-vhp48
Sep 22 08:55:45.656: INFO: Got endpoints: latency-svc-9wl5t [720.58874ms]
Sep 22 08:55:45.662: INFO: Created: latency-svc-6q8m6
Sep 22 08:55:45.704: INFO: Got endpoints: latency-svc-d44s9 [745.89911ms]
Sep 22 08:55:45.712: INFO: Created: latency-svc-7kvlk
Sep 22 08:55:45.756: INFO: Got endpoints: latency-svc-dvlrg [725.754685ms]
Sep 22 08:55:45.763: INFO: Created: latency-svc-rdbjs
Sep 22 08:55:45.805: INFO: Got endpoints: latency-svc-4xgnb [742.517737ms]
Sep 22 08:55:45.812: INFO: Created: latency-svc-rgqxm
Sep 22 08:55:45.855: INFO: Got endpoints: latency-svc-hrlk6 [746.89233ms]
Sep 22 08:55:45.862: INFO: Created: latency-svc-q9nws
Sep 22 08:55:45.908: INFO: Got endpoints: latency-svc-4bd8p [753.382382ms]
Sep 22 08:55:45.914: INFO: Created: latency-svc-qhvnp
Sep 22 08:55:45.956: INFO: Got endpoints: latency-svc-qb5bn [749.764731ms]
Sep 22 08:55:45.962: INFO: Created: latency-svc-pss7m
Sep 22 08:55:46.007: INFO: Got endpoints: latency-svc-45rl7 [749.582493ms]
Sep 22 08:55:46.013: INFO: Created: latency-svc-59dtc
Sep 22 08:55:46.057: INFO: Got endpoints: latency-svc-v84nn [750.017655ms]
Sep 22 08:55:46.067: INFO: Created: latency-svc-vqjjt
Sep 22 08:55:46.108: INFO: Got endpoints: latency-svc-wncbk [744.024891ms]
Sep 22 08:55:46.116: INFO: Created: latency-svc-9vvr5
Sep 22 08:55:46.155: INFO: Got endpoints: latency-svc-7jqgz [749.684306ms]
Sep 22 08:55:46.164: INFO: Created: latency-svc-t8df9
Sep 22 08:55:46.205: INFO: Got endpoints: latency-svc-rtpxq [749.123797ms]
Sep 22 08:55:46.214: INFO: Created: latency-svc-lj72h
Sep 22 08:55:46.255: INFO: Got endpoints: latency-svc-hpk4k [744.719936ms]
Sep 22 08:55:46.261: INFO: Created: latency-svc-lt5fh
Sep 22 08:55:46.305: INFO: Got endpoints: latency-svc-f4glt [742.457779ms]
Sep 22 08:55:46.315: INFO: Created: latency-svc-9j9mh
Sep 22 08:55:46.354: INFO: Got endpoints: latency-svc-vhp48 [745.800929ms]
Sep 22 08:55:46.360: INFO: Created: latency-svc-8vsqw
Sep 22 08:55:46.405: INFO: Got endpoints: latency-svc-6q8m6 [749.270636ms]
Sep 22 08:55:46.412: INFO: Created: latency-svc-xjjrq
Sep 22 08:55:46.455: INFO: Got endpoints: latency-svc-7kvlk [750.37052ms]
Sep 22 08:55:46.464: INFO: Created: latency-svc-7tjxc
Sep 22 08:55:46.505: INFO: Got endpoints: latency-svc-rdbjs [749.437308ms]
Sep 22 08:55:46.516: INFO: Created: latency-svc-wvqkb
Sep 22 08:55:46.555: INFO: Got endpoints: latency-svc-rgqxm [749.70186ms]
Sep 22 08:55:46.562: INFO: Created: latency-svc-zz6nw
Sep 22 08:55:46.605: INFO: Got endpoints: latency-svc-q9nws [749.511958ms]
Sep 22 08:55:46.612: INFO: Created: latency-svc-nwnzw
Sep 22 08:55:46.655: INFO: Got endpoints: latency-svc-qhvnp [747.407739ms]
Sep 22 08:55:46.667: INFO: Created: latency-svc-cfqbl
Sep 22 08:55:46.704: INFO: Got endpoints: latency-svc-pss7m [748.40573ms]
Sep 22 08:55:46.714: INFO: Created: latency-svc-zsghr
Sep 22 08:55:46.755: INFO: Got endpoints: latency-svc-59dtc [748.513236ms]
Sep 22 08:55:46.763: INFO: Created: latency-svc-hg7v2
Sep 22 08:55:46.805: INFO: Got endpoints: latency-svc-vqjjt [747.487272ms]
Sep 22 08:55:46.812: INFO: Created: latency-svc-nk5rf
Sep 22 08:55:46.855: INFO: Got endpoints: latency-svc-9vvr5 [747.876583ms]
Sep 22 08:55:46.862: INFO: Created: latency-svc-lm2cr
Sep 22 08:55:46.904: INFO: Got endpoints: latency-svc-t8df9 [745.755195ms]
Sep 22 08:55:46.911: INFO: Created: latency-svc-vj8f2
Sep 22 08:55:46.955: INFO: Got endpoints: latency-svc-lj72h [749.036317ms]
Sep 22 08:55:46.962: INFO: Created: latency-svc-qgxwp
Sep 22 08:55:47.005: INFO: Got endpoints: latency-svc-lt5fh [750.349677ms]
Sep 22 08:55:47.012: INFO: Created: latency-svc-rd9sr
Sep 22 08:55:47.059: INFO: Got endpoints: latency-svc-9j9mh [754.03866ms]
Sep 22 08:55:47.072: INFO: Created: latency-svc-99p7g
Sep 22 08:55:47.106: INFO: Got endpoints: latency-svc-8vsqw [751.356684ms]
Sep 22 08:55:47.114: INFO: Created: latency-svc-9fctp
Sep 22 08:55:47.156: INFO: Got endpoints: latency-svc-xjjrq [750.714605ms]
Sep 22 08:55:47.164: INFO: Created: latency-svc-zs6wc
Sep 22 08:55:47.206: INFO: Got endpoints: latency-svc-7tjxc [748.192263ms]
Sep 22 08:55:47.214: INFO: Created: latency-svc-9bfch
Sep 22 08:55:47.257: INFO: Got endpoints: latency-svc-wvqkb [751.078524ms]
Sep 22 08:55:47.265: INFO: Created: latency-svc-hxlf9
Sep 22 08:55:47.308: INFO: Got endpoints: latency-svc-zz6nw [752.630032ms]
Sep 22 08:55:47.314: INFO: Created: latency-svc-g9j55
Sep 22 08:55:47.355: INFO: Got endpoints: latency-svc-nwnzw [749.821347ms]
Sep 22 08:55:47.363: INFO: Created: latency-svc-5gm89
Sep 22 08:55:47.406: INFO: Got endpoints: latency-svc-cfqbl [746.610615ms]
Sep 22 08:55:47.413: INFO: Created: latency-svc-7np5h
Sep 22 08:55:47.455: INFO: Got endpoints: latency-svc-zsghr [749.499018ms]
Sep 22 08:55:47.462: INFO: Created: latency-svc-dl4tj
Sep 22 08:55:47.505: INFO: Got endpoints: latency-svc-hg7v2 [749.608616ms]
Sep 22 08:55:47.514: INFO: Created: latency-svc-7d9zq
Sep 22 08:55:47.555: INFO: Got endpoints: latency-svc-nk5rf [750.029213ms]
Sep 22 08:55:47.562: INFO: Created: latency-svc-wrh5m
Sep 22 08:55:47.604: INFO: Got endpoints: latency-svc-lm2cr [748.85122ms]
Sep 22 08:55:47.614: INFO: Created: latency-svc-klt8h
Sep 22 08:55:47.655: INFO: Got endpoints: latency-svc-vj8f2 [751.253002ms]
Sep 22 08:55:47.667: INFO: Created: latency-svc-8wkr6
Sep 22 08:55:47.705: INFO: Got endpoints: latency-svc-qgxwp [750.07079ms]
Sep 22 08:55:47.712: INFO: Created: latency-svc-jgggs
Sep 22 08:55:47.755: INFO: Got endpoints: latency-svc-rd9sr [749.715538ms]
Sep 22 08:55:47.763: INFO: Created: latency-svc-v9kxk
Sep 22 08:55:47.804: INFO: Got endpoints: latency-svc-99p7g [745.388204ms]
Sep 22 08:55:47.815: INFO: Created: latency-svc-lnbst
Sep 22 08:55:47.856: INFO: Got endpoints: latency-svc-9fctp [750.111909ms]
Sep 22 08:55:47.864: INFO: Created: latency-svc-7hzhb
Sep 22 08:55:47.905: INFO: Got endpoints: latency-svc-zs6wc [749.029933ms]
Sep 22 08:55:47.916: INFO: Created: latency-svc-zxb9w
Sep 22 08:55:47.958: INFO: Got endpoints: latency-svc-9bfch [752.098109ms]
Sep 22 08:55:47.966: INFO: Created: latency-svc-mwh2v
Sep 22 08:55:48.006: INFO: Got endpoints: latency-svc-hxlf9 [749.188032ms]
Sep 22 08:55:48.016: INFO: Created: latency-svc-8t2bn
Sep 22 08:55:48.055: INFO: Got endpoints: latency-svc-g9j55 [747.346935ms]
Sep 22 08:55:48.063: INFO: Created: latency-svc-lffn9
Sep 22 08:55:48.106: INFO: Got endpoints: latency-svc-5gm89 [750.633377ms]
Sep 22 08:55:48.115: INFO: Created: latency-svc-j8smp
Sep 22 08:55:48.155: INFO: Got endpoints: latency-svc-7np5h [748.703817ms]
Sep 22 08:55:48.165: INFO: Created: latency-svc-8jhjw
Sep 22 08:55:48.207: INFO: Got endpoints: latency-svc-dl4tj [751.378634ms]
Sep 22 08:55:48.214: INFO: Created: latency-svc-xh9qn
Sep 22 08:55:48.255: INFO: Got endpoints: latency-svc-7d9zq [749.605969ms]
Sep 22 08:55:48.261: INFO: Created: latency-svc-mrfrv
Sep 22 08:55:48.305: INFO: Got endpoints: latency-svc-wrh5m [749.260932ms]
Sep 22 08:55:48.316: INFO: Created: latency-svc-t5mk4
Sep 22 08:55:48.360: INFO: Got endpoints: latency-svc-klt8h [755.650338ms]
Sep 22 08:55:48.383: INFO: Created: latency-svc-qflkk
Sep 22 08:55:48.405: INFO: Got endpoints: latency-svc-8wkr6 [744.927947ms]
Sep 22 08:55:48.412: INFO: Created: latency-svc-5mxkr
Sep 22 08:55:48.455: INFO: Got endpoints: latency-svc-jgggs [749.72091ms]
Sep 22 08:55:48.463: INFO: Created: latency-svc-l65jn
Sep 22 08:55:48.505: INFO: Got endpoints: latency-svc-v9kxk [750.243442ms]
Sep 22 08:55:48.513: INFO: Created: latency-svc-nrwlj
Sep 22 08:55:48.555: INFO: Got endpoints: latency-svc-lnbst [747.665098ms]
Sep 22 08:55:48.563: INFO: Created: latency-svc-m7n6q
Sep 22 08:55:48.607: INFO: Got endpoints: latency-svc-7hzhb [750.848267ms]
Sep 22 08:55:48.616: INFO: Created: latency-svc-th7wf
Sep 22 08:55:48.655: INFO: Got endpoints: latency-svc-zxb9w [746.378928ms]
Sep 22 08:55:48.664: INFO: Created: latency-svc-qnxv9
Sep 22 08:55:48.705: INFO: Got endpoints: latency-svc-mwh2v [747.005786ms]
Sep 22 08:55:48.714: INFO: Created: latency-svc-wq8vj
Sep 22 08:55:48.755: INFO: Got endpoints: latency-svc-8t2bn [745.056842ms]
Sep 22 08:55:48.766: INFO: Created: latency-svc-blspj
Sep 22 08:55:48.805: INFO: Got endpoints: latency-svc-lffn9 [749.170458ms]
Sep 22 08:55:48.817: INFO: Created: latency-svc-dxhpz
Sep 22 08:55:48.854: INFO: Got endpoints: latency-svc-j8smp [748.188491ms]
Sep 22 08:55:48.864: INFO: Created: latency-svc-fpmh5
Sep 22 08:55:48.905: INFO: Got endpoints: latency-svc-8jhjw [746.623372ms]
Sep 22 08:55:48.914: INFO: Created: latency-svc-mp9mz
Sep 22 08:55:48.956: INFO: Got endpoints: latency-svc-xh9qn [749.114299ms]
Sep 22 08:55:48.967: INFO: Created: latency-svc-wv4xh
Sep 22 08:55:49.005: INFO: Got endpoints: latency-svc-mrfrv [750.378289ms]
Sep 22 08:55:49.013: INFO: Created: latency-svc-nrrnt
Sep 22 08:55:49.056: INFO: Got endpoints: latency-svc-t5mk4 [751.585672ms]
Sep 22 08:55:49.063: INFO: Created: latency-svc-2vf2z
Sep 22 08:55:49.105: INFO: Got endpoints: latency-svc-qflkk [744.720771ms]
Sep 22 08:55:49.111: INFO: Created: latency-svc-ks87w
Sep 22 08:55:49.156: INFO: Got endpoints: latency-svc-5mxkr [750.95633ms]
Sep 22 08:55:49.167: INFO: Created: latency-svc-2gmf9
Sep 22 08:55:49.205: INFO: Got endpoints: latency-svc-l65jn [749.817575ms]
Sep 22 08:55:49.215: INFO: Created: latency-svc-24ghf
Sep 22 08:55:49.256: INFO: Got endpoints: latency-svc-nrwlj [750.322379ms]
Sep 22 08:55:49.263: INFO: Created: latency-svc-sltxf
Sep 22 08:55:49.307: INFO: Got endpoints: latency-svc-m7n6q [751.670358ms]
Sep 22 08:55:49.316: INFO: Created: latency-svc-svtlj
Sep 22 08:55:49.355: INFO: Got endpoints: latency-svc-th7wf [745.023377ms]
Sep 22 08:55:49.361: INFO: Created: latency-svc-xpkcp
Sep 22 08:55:49.406: INFO: Got endpoints: latency-svc-qnxv9 [747.353452ms]
Sep 22 08:55:49.413: INFO: Created: latency-svc-jplp2
Sep 22 08:55:49.455: INFO: Got endpoints: latency-svc-wq8vj [748.297034ms]
Sep 22 08:55:49.462: INFO: Created: latency-svc-zt9hw
Sep 22 08:55:49.505: INFO: Got endpoints: latency-svc-blspj [749.661334ms]
Sep 22 08:55:49.513: INFO: Created: latency-svc-sg456
Sep 22 08:55:49.556: INFO: Got endpoints: latency-svc-dxhpz [746.723796ms]
Sep 22 08:55:49.565: INFO: Created: latency-svc-2vvb9
Sep 22 08:55:49.607: INFO: Got endpoints: latency-svc-fpmh5 [749.090009ms]
Sep 22 08:55:49.620: INFO: Created: latency-svc-wzs6f
Sep 22 08:55:49.657: INFO: Got endpoints: latency-svc-mp9mz [750.85309ms]
Sep 22 08:55:49.666: INFO: Created: latency-svc-8r7mg
Sep 22 08:55:49.705: INFO: Got endpoints: latency-svc-wv4xh [745.543793ms]
Sep 22 08:55:49.713: INFO: Created: latency-svc-knfb4
Sep 22 08:55:49.756: INFO: Got endpoints: latency-svc-nrrnt [750.293462ms]
Sep 22 08:55:49.763: INFO: Created: latency-svc-5fnvj
Sep 22 08:55:49.805: INFO: Got endpoints: latency-svc-2vf2z [748.37844ms]
Sep 22 08:55:49.813: INFO: Created: latency-svc-mmdhr
Sep 22 08:55:49.855: INFO: Got endpoints: latency-svc-ks87w [749.760854ms]
Sep 22 08:55:49.865: INFO: Created: latency-svc-zd9xw
Sep 22 08:55:49.905: INFO: Got endpoints: latency-svc-2gmf9 [749.169908ms]
Sep 22 08:55:49.916: INFO: Created: latency-svc-fsq4l
Sep 22 08:55:49.960: INFO: Got endpoints: latency-svc-24ghf [754.35892ms]
Sep 22 08:55:49.970: INFO: Created: latency-svc-l2dlz
Sep 22 08:55:50.005: INFO: Got endpoints: latency-svc-sltxf [748.64795ms]
Sep 22 08:55:50.013: INFO: Created: latency-svc-59kll
Sep 22 08:55:50.055: INFO: Got endpoints: latency-svc-svtlj [748.307829ms]
Sep 22 08:55:50.063: INFO: Created: latency-svc-f8fdb
Sep 22 08:55:50.105: INFO: Got endpoints: latency-svc-xpkcp [749.092062ms]
Sep 22 08:55:50.113: INFO: Created: latency-svc-v5xpq
Sep 22 08:55:50.154: INFO: Got endpoints: latency-svc-jplp2 [748.756886ms]
Sep 22 08:55:50.164: INFO: Created: latency-svc-s22s9
Sep 22 08:55:50.205: INFO: Got endpoints: latency-svc-zt9hw [749.420187ms]
Sep 22 08:55:50.212: INFO: Created: latency-svc-tqjgd
Sep 22 08:55:50.255: INFO: Got endpoints: latency-svc-sg456 [749.854956ms]
Sep 22 08:55:50.263: INFO: Created: latency-svc-vgn2g
Sep 22 08:55:50.306: INFO: Got endpoints: latency-svc-2vvb9 [750.416201ms]
Sep 22 08:55:50.313: INFO: Created: latency-svc-n525j
Sep 22 08:55:50.355: INFO: Got endpoints: latency-svc-wzs6f [745.090239ms]
Sep 22 08:55:50.365: INFO: Created: latency-svc-kg9fm
Sep 22 08:55:50.405: INFO: Got endpoints: latency-svc-8r7mg [747.630778ms]
Sep 22 08:55:50.415: INFO: Created: latency-svc-w55ng
Sep 22 08:55:50.455: INFO: Got endpoints: latency-svc-knfb4 [750.272906ms]
Sep 22 08:55:50.467: INFO: Created: latency-svc-ncwwj
Sep 22 08:55:50.505: INFO: Got endpoints: latency-svc-5fnvj [748.859442ms]
Sep 22 08:55:50.513: INFO: Created: latency-svc-d5x6b
Sep 22 08:55:50.555: INFO: Got endpoints: latency-svc-mmdhr [749.999725ms]
Sep 22 08:55:50.562: INFO: Created: latency-svc-mthk8
Sep 22 08:55:50.606: INFO: Got endpoints: latency-svc-zd9xw [747.310296ms]
Sep 22 08:55:50.617: INFO: Created: latency-svc-xxzd5
Sep 22 08:55:50.656: INFO: Got endpoints: latency-svc-fsq4l [746.550238ms]
Sep 22 08:55:50.663: INFO: Created: latency-svc-7vbq5
Sep 22 08:55:50.706: INFO: Got endpoints: latency-svc-l2dlz [746.454368ms]
Sep 22 08:55:50.715: INFO: Created: latency-svc-6crh2
Sep 22 08:55:50.757: INFO: Got endpoints: latency-svc-59kll [752.354633ms]
Sep 22 08:55:50.764: INFO: Created: latency-svc-6526b
Sep 22 08:55:50.812: INFO: Got endpoints: latency-svc-f8fdb [757.1182ms]
Sep 22 08:55:50.830: INFO: Created: latency-svc-2rtvr
Sep 22 08:55:50.858: INFO: Got endpoints: latency-svc-v5xpq [753.39552ms]
Sep 22 08:55:50.888: INFO: Created: latency-svc-zxnp2
Sep 22 08:55:50.906: INFO: Got endpoints: latency-svc-s22s9 [751.279896ms]
Sep 22 08:55:50.913: INFO: Created: latency-svc-zrl4g
Sep 22 08:55:50.956: INFO: Got endpoints: latency-svc-tqjgd [750.885342ms]
Sep 22 08:55:50.967: INFO: Created: latency-svc-9d2nn
Sep 22 08:55:51.005: INFO: Got endpoints: latency-svc-vgn2g [749.602543ms]
Sep 22 08:55:51.012: INFO: Created: latency-svc-js8p6
Sep 22 08:55:51.055: INFO: Got endpoints: latency-svc-n525j [748.964824ms]
Sep 22 08:55:51.062: INFO: Created: latency-svc-ht5vh
Sep 22 08:55:51.105: INFO: Got endpoints: latency-svc-kg9fm [747.552853ms]
Sep 22 08:55:51.112: INFO: Created: latency-svc-wmvqd
Sep 22 08:55:51.155: INFO: Got endpoints: latency-svc-w55ng [747.424827ms]
Sep 22 08:55:51.163: INFO: Created: latency-svc-jhq2r
Sep 22 08:55:51.206: INFO: Got endpoints: latency-svc-ncwwj [746.230602ms]
Sep 22 08:55:51.213: INFO: Created: latency-svc-c48s7
Sep 22 08:55:51.255: INFO: Got endpoints: latency-svc-d5x6b [750.339486ms]
Sep 22 08:55:51.262: INFO: Created: latency-svc-vl6ks
Sep 22 08:55:51.306: INFO: Got endpoints: latency-svc-mthk8 [751.306809ms]
Sep 22 08:55:51.314: INFO: Created: latency-svc-r6xs2
Sep 22 08:55:51.355: INFO: Got endpoints: latency-svc-xxzd5 [747.110369ms]
Sep 22 08:55:51.363: INFO: Created: latency-svc-rw2rl
Sep 22 08:55:51.405: INFO: Got endpoints: latency-svc-7vbq5 [749.608825ms]
Sep 22 08:55:51.413: INFO: Created: latency-svc-sglxw
Sep 22 08:55:51.456: INFO: Got endpoints: latency-svc-6crh2 [749.632193ms]
Sep 22 08:55:51.467: INFO: Created: latency-svc-pczsv
Sep 22 08:55:51.507: INFO: Got endpoints: latency-svc-6526b [749.542104ms]
Sep 22 08:55:51.515: INFO: Created: latency-svc-54hfh
Sep 22 08:55:51.555: INFO: Got endpoints: latency-svc-2rtvr [742.856129ms]
Sep 22 08:55:51.564: INFO: Created: latency-svc-hjmzr
Sep 22 08:55:51.605: INFO: Got endpoints: latency-svc-zxnp2 [747.229148ms]
Sep 22 08:55:51.615: INFO: Created: latency-svc-8nwgs
Sep 22 08:55:51.654: INFO: Got endpoints: latency-svc-zrl4g [748.328469ms]
Sep 22 08:55:51.664: INFO: Created: latency-svc-qrz75
Sep 22 08:55:51.705: INFO: Got endpoints: latency-svc-9d2nn [749.248679ms]
Sep 22 08:55:51.712: INFO: Created: latency-svc-nwlww
Sep 22 08:55:51.755: INFO: Got endpoints: latency-svc-js8p6 [750.334818ms]
Sep 22 08:55:51.766: INFO: Created: latency-svc-kz5wr
Sep 22 08:55:51.806: INFO: Got endpoints: latency-svc-ht5vh [750.490138ms]
Sep 22 08:55:51.817: INFO: Created: latency-svc-vjft2
Sep 22 08:55:51.855: INFO: Got endpoints: latency-svc-wmvqd [749.948568ms]
Sep 22 08:55:51.865: INFO: Created: latency-svc-pdrhm
Sep 22 08:55:51.905: INFO: Got endpoints: latency-svc-jhq2r [749.300526ms]
Sep 22 08:55:51.917: INFO: Created: latency-svc-c8xn4
Sep 22 08:55:51.955: INFO: Got endpoints: latency-svc-c48s7 [748.507098ms]
Sep 22 08:55:51.963: INFO: Created: latency-svc-szq4x
Sep 22 08:55:52.007: INFO: Got endpoints: latency-svc-vl6ks [752.074242ms]
Sep 22 08:55:52.016: INFO: Created: latency-svc-wm25p
Sep 22 08:55:52.055: INFO: Got endpoints: latency-svc-r6xs2 [748.839209ms]
Sep 22 08:55:52.063: INFO: Created: latency-svc-77dh7
Sep 22 08:55:52.107: INFO: Got endpoints: latency-svc-rw2rl [752.291449ms]
Sep 22 08:55:52.118: INFO: Created: latency-svc-g95cq
Sep 22 08:55:52.155: INFO: Got endpoints: latency-svc-sglxw [750.105027ms]
Sep 22 08:55:52.166: INFO: Created: latency-svc-dg9hl
Sep 22 08:55:52.206: INFO: Got endpoints: latency-svc-pczsv [749.783398ms]
Sep 22 08:55:52.216: INFO: Created: latency-svc-qqwb9
Sep 22 08:55:52.255: INFO: Got endpoints: latency-svc-54hfh [747.559041ms]
Sep 22 08:55:52.261: INFO: Created: latency-svc-dggss
Sep 22 08:55:52.305: INFO: Got endpoints: latency-svc-hjmzr [747.982553ms]
Sep 22 08:55:52.315: INFO: Created: latency-svc-zxb6x
Sep 22 08:55:52.358: INFO: Got endpoints: latency-svc-8nwgs [749.739702ms]
Sep 22 08:55:52.406: INFO: Got endpoints: latency-svc-qrz75 [751.395229ms]
Sep 22 08:55:52.455: INFO: Got endpoints: latency-svc-nwlww [749.383387ms]
Sep 22 08:55:52.506: INFO: Got endpoints: latency-svc-kz5wr [751.21678ms]
Sep 22 08:55:52.556: INFO: Got endpoints: latency-svc-vjft2 [746.528307ms]
Sep 22 08:55:52.605: INFO: Got endpoints: latency-svc-pdrhm [747.048243ms]
Sep 22 08:55:52.655: INFO: Got endpoints: latency-svc-c8xn4 [746.170315ms]
Sep 22 08:55:52.706: INFO: Got endpoints: latency-svc-szq4x [750.680364ms]
Sep 22 08:55:52.758: INFO: Got endpoints: latency-svc-wm25p [750.453709ms]
Sep 22 08:55:52.806: INFO: Got endpoints: latency-svc-77dh7 [750.547927ms]
Sep 22 08:55:52.855: INFO: Got endpoints: latency-svc-g95cq [747.042682ms]
Sep 22 08:55:52.904: INFO: Got endpoints: latency-svc-dg9hl [745.393203ms]
Sep 22 08:55:52.955: INFO: Got endpoints: latency-svc-qqwb9 [745.85175ms]
Sep 22 08:55:53.005: INFO: Got endpoints: latency-svc-dggss [750.449223ms]
Sep 22 08:55:53.055: INFO: Got endpoints: latency-svc-zxb6x [749.649895ms]
Sep 22 08:55:53.058: INFO: Latencies: [15.269665ms 20.433558ms 31.709777ms 32.143185ms 32.819436ms 35.627851ms 43.761391ms 72.172982ms 72.916784ms 74.031136ms 74.406927ms 74.682301ms 85.561758ms 92.860183ms 101.423138ms 101.707744ms 106.157437ms 128.161983ms 130.272186ms 139.285568ms 140.763217ms 141.943872ms 145.073194ms 149.756188ms 200.279554ms 200.977756ms 204.182033ms 205.567902ms 208.185647ms 210.244289ms 217.189482ms 221.936478ms 226.932661ms 228.986977ms 231.93871ms 232.887766ms 241.595919ms 243.582977ms 248.495276ms 315.375124ms 325.538378ms 331.964124ms 385.464739ms 430.741934ms 464.346364ms 499.79456ms 535.519795ms 578.478778ms 630.884979ms 670.919023ms 707.689942ms 720.58874ms 725.754685ms 742.457779ms 742.517737ms 742.856129ms 744.024891ms 744.719936ms 744.720771ms 744.927947ms 745.023377ms 745.056842ms 745.090239ms 745.388204ms 745.393203ms 745.543793ms 745.755195ms 745.800929ms 745.85175ms 745.89911ms 746.170315ms 746.230602ms 746.378928ms 746.454368ms 746.528307ms 746.550238ms 746.610615ms 746.623372ms 746.723796ms 746.89233ms 747.005786ms 747.042682ms 747.048243ms 747.110369ms 747.229148ms 747.310296ms 747.346935ms 747.353452ms 747.407739ms 747.424827ms 747.487272ms 747.552853ms 747.559041ms 747.630778ms 747.665098ms 747.876583ms 747.982553ms 748.188491ms 748.192263ms 748.297034ms 748.307829ms 748.328469ms 748.37844ms 748.40573ms 748.507098ms 748.513236ms 748.64795ms 748.703817ms 748.756886ms 748.839209ms 748.85122ms 748.859442ms 748.964824ms 749.029933ms 749.036317ms 749.090009ms 749.092062ms 749.114299ms 749.123797ms 749.169908ms 749.170458ms 749.188032ms 749.248679ms 749.260932ms 749.270636ms 749.300526ms 749.383387ms 749.420187ms 749.437308ms 749.499018ms 749.511958ms 749.542104ms 749.582493ms 749.602543ms 749.605969ms 749.608616ms 749.608825ms 749.632193ms 749.649895ms 749.661334ms 749.684306ms 749.70186ms 749.715538ms 749.72091ms 749.739702ms 749.760854ms 749.764731ms 749.783398ms 749.817575ms 749.821347ms 749.854956ms 749.948568ms 749.999725ms 750.017655ms 750.029213ms 750.07079ms 750.105027ms 750.111909ms 750.243442ms 750.272906ms 750.293462ms 750.322379ms 750.334818ms 750.339486ms 750.349677ms 750.37052ms 750.378289ms 750.416201ms 750.449223ms 750.453709ms 750.490138ms 750.547927ms 750.633377ms 750.680364ms 750.714605ms 750.848267ms 750.85309ms 750.885342ms 750.95633ms 751.078524ms 751.21678ms 751.253002ms 751.279896ms 751.306809ms 751.356684ms 751.378634ms 751.395229ms 751.585672ms 751.670358ms 752.074242ms 752.098109ms 752.291449ms 752.354633ms 752.630032ms 753.382382ms 753.39552ms 754.03866ms 754.35892ms 755.650338ms 757.1182ms]
Sep 22 08:55:53.061: INFO: 50 %ile: 748.307829ms
Sep 22 08:55:53.061: INFO: 90 %ile: 751.21678ms
Sep 22 08:55:53.061: INFO: 99 %ile: 755.650338ms
Sep 22 08:55:53.061: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:55:53.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-8617" for this suite.
Sep 22 08:56:07.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:56:07.150: INFO: namespace svc-latency-8617 deletion completed in 14.082870849s

• [SLOW TEST:24.848 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:56:07.150: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 22 08:56:08.195: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:56:08.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1267" for this suite.
Sep 22 08:56:14.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:56:14.309: INFO: namespace container-runtime-1267 deletion completed in 6.101225365s

• [SLOW TEST:7.159 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:56:14.311: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6b782c53-b764-4146-9e9b-69321f4565cf
STEP: Creating a pod to test consume configMaps
Sep 22 08:56:14.364: INFO: Waiting up to 5m0s for pod "pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128" in namespace "configmap-9604" to be "success or failure"
Sep 22 08:56:14.369: INFO: Pod "pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128": Phase="Pending", Reason="", readiness=false. Elapsed: 4.656542ms
Sep 22 08:56:16.373: INFO: Pod "pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009171059s
STEP: Saw pod success
Sep 22 08:56:16.373: INFO: Pod "pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128" satisfied condition "success or failure"
Sep 22 08:56:16.379: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 08:56:16.406: INFO: Waiting for pod pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128 to disappear
Sep 22 08:56:16.410: INFO: Pod pod-configmaps-c79b9642-bf73-4cb2-98c7-fdfd248db128 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:56:16.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9604" for this suite.
Sep 22 08:56:22.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:56:22.528: INFO: namespace configmap-9604 deletion completed in 6.110206594s

• [SLOW TEST:8.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:56:22.529: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 08:56:22.557: INFO: Creating deployment "webserver-deployment"
Sep 22 08:56:22.561: INFO: Waiting for observed generation 1
Sep 22 08:56:24.566: INFO: Waiting for all required pods to come up
Sep 22 08:56:24.569: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 22 08:56:26.582: INFO: Waiting for deployment "webserver-deployment" to complete
Sep 22 08:56:26.586: INFO: Updating deployment "webserver-deployment" with a non-existent image
Sep 22 08:56:26.592: INFO: Updating deployment webserver-deployment
Sep 22 08:56:26.592: INFO: Waiting for observed generation 2
Sep 22 08:56:28.597: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 22 08:56:28.600: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 22 08:56:28.602: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 22 08:56:28.609: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 22 08:56:28.609: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 22 08:56:28.611: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Sep 22 08:56:28.616: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Sep 22 08:56:28.616: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Sep 22 08:56:28.621: INFO: Updating deployment webserver-deployment
Sep 22 08:56:28.621: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Sep 22 08:56:28.628: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 22 08:56:28.633: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 22 08:56:28.656: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9427 /apis/apps/v1/namespaces/deployment-9427/deployments/webserver-deployment 77e50d65-76da-4718-b065-ec156344a70c 334830 3 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0003a1db8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-09-22 08:56:26 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-09-22 08:56:28 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Sep 22 08:56:28.667: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9427 /apis/apps/v1/namespaces/deployment-9427/replicasets/webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 334826 3 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 77e50d65-76da-4718-b065-ec156344a70c 0xc000db8fe7 0xc000db8fe8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000db9058 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:56:28.667: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Sep 22 08:56:28.667: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9427 /apis/apps/v1/namespaces/deployment-9427/replicasets/webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 334825 3 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 77e50d65-76da-4718-b065-ec156344a70c 0xc000db8f27 0xc000db8f28}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000db8f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Sep 22 08:56:28.693: INFO: Pod "webserver-deployment-595b5b9587-c4lsd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-c4lsd webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-c4lsd 9ca78929-b15f-4c45-af00-4e43dcd1b5ff 334691 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.212.131/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc0032903c7 0xc0032903c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.131,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e4cd0816732dba3684c60829a2b956b6952d87d4b977e671caf56fcade1bb124,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-czcjr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-czcjr webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-czcjr a8374083-2d04-42e6-a580-1d3013e36ebd 334697 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.212.130/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003290557 0xc003290558}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.130,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://88b05d650582621156ae3e09d8c3593f629ac4d725fc0996db35872dabd2d410,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-ddrfs" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ddrfs webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-ddrfs 5026ea6d-6707-4581-8771-0ab4d7a7a8c3 334848 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc0032906e7 0xc0032906e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-fwmdz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fwmdz webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-fwmdz 45137fa7-4f86-46fc-a2a5-fc547e9f89a0 334849 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003290800 0xc003290801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-g2mq9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-g2mq9 webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-g2mq9 ee5ef064-b7cf-44db-8c6b-98858970ee54 334701 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.212.127/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003290900 0xc003290901}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.127,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8e74691d97640dd9f5901b4dc3ee3eff20624cfbbb98f4107fa663aaabc11887,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.127,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-g5zvn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-g5zvn webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-g5zvn df4046e2-0e65-4aab-bf39-085bb8da4b02 334840 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003290cc7 0xc003290cc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:,StartTime:2019-09-22 08:56:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-hz66w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hz66w webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-hz66w b0ea84d3-c389-4a9a-9108-d91d719d6351 334845 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003290eb0 0xc003290eb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.694: INFO: Pod "webserver-deployment-595b5b9587-jmzwm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jmzwm webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-jmzwm 22245e99-fc70-42ea-9de5-85686d579aa5 334711 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.56.183/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003291120 0xc003291121}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:10.2.56.183,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://794ba232e99b749cdbc1709548a0af618779f63f1bb5c378f7a877f6163c0ef6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.56.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.695: INFO: Pod "webserver-deployment-595b5b9587-jsk8m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jsk8m webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-jsk8m 53b08593-2bc9-48d4-a6ce-63d91492e777 334846 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003291440 0xc003291441}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.695: INFO: Pod "webserver-deployment-595b5b9587-ncg4l" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ncg4l webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-ncg4l 89418d72-6347-4cfc-a2ec-f6e31af094a4 334694 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.212.129/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003291660 0xc003291661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.129,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d54bd22ee906719760ee325513ce12543dc3e8bd16e596dac05f7b452acb83fa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.129,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.696: INFO: Pod "webserver-deployment-595b5b9587-p7qjq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-p7qjq webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-p7qjq 475c204c-f361-4d0d-91d9-93e159e60ca1 334847 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003291c47 0xc003291c48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.696: INFO: Pod "webserver-deployment-595b5b9587-q5mrj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-q5mrj webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-q5mrj b22050d0-7c06-4feb-a580-5f36037cacf7 334842 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc003291e20 0xc003291e21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.696: INFO: Pod "webserver-deployment-595b5b9587-r9j6d" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r9j6d webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-r9j6d 1b1454be-925e-4435-ab0d-760af5729ba1 334709 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.56.182/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc001728030 0xc001728031}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:10.2.56.182,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://bacaeb7f17eacaf120d6627c9161592bfa6cc6b2a1a0bd1d5dc2a803a09fb79b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.56.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.696: INFO: Pod "webserver-deployment-595b5b9587-w5phc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-w5phc webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-w5phc 2e3c4bd6-0073-45ae-97bf-a10a1cc9fb77 334704 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.212.128/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc0017281b0 0xc0017281b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.128,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9f7f34a325fc7290f49ff8238c4fd89354f8790e896208ecbf998943bc0ab47e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.128,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.696: INFO: Pod "webserver-deployment-595b5b9587-zw5w7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zw5w7 webserver-deployment-595b5b9587- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-595b5b9587-zw5w7 cde4bc3b-cc7a-4d97-bff0-9cbef07b9b65 334719 0 2019-09-22 08:56:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.56.181/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 a717d50b-59bd-42d4-923d-57dd545943ec 0xc001728337 0xc001728338}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:10.2.56.181,StartTime:2019-09-22 08:56:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 08:56:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://093ea9cf208201df70a75c8c1875324d2427689c93c64542712d3ebdc96b0179,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.56.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-8c4nv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8c4nv webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-8c4nv 427c2864-df98-44b5-bee7-90c07a9f4a69 334810 0 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.212.132/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc0017284c0 0xc0017284c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.132,StartTime:2019-09-22 08:56:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.132,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-b8zq8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-b8zq8 webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-b8zq8 828bcdb1-1ed4-40fb-9f92-17f75802a10d 334797 0 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.56.186/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc001728670 0xc001728671}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:,StartTime:2019-09-22 08:56:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-bb44x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bb44x webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-bb44x 557cf342-f1fe-4b0e-b768-376737a476b0 334841 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc0017287e0 0xc0017287e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-cdh9f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cdh9f webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-cdh9f 24702fd5-163c-46d6-b223-7993b673aa96 334832 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc0017288e0 0xc0017288e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-kchnt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kchnt webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-kchnt ae6f290e-31b2-42dc-a370-979b6bc8bc3f 334803 0 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.212.133/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc001728a10 0xc001728a11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:,StartTime:2019-09-22 08:56:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.697: INFO: Pod "webserver-deployment-c7997dcc8-nmcps" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nmcps webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-nmcps 00ba0665-013a-43cf-b326-f77a888d6f92 334844 0 2019-09-22 08:56:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc001728b80 0xc001728b81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.698: INFO: Pod "webserver-deployment-c7997dcc8-qgpsz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qgpsz webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-qgpsz 2f5439a3-f6e4-47a9-99d8-c0db29040283 334820 0 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.56.185/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc001728c90 0xc001728c91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-30-60,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.30.60,PodIP:10.2.56.185,StartTime:2019-09-22 08:56:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.56.185,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 08:56:28.699: INFO: Pod "webserver-deployment-c7997dcc8-tk8pb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tk8pb webserver-deployment-c7997dcc8- deployment-9427 /api/v1/namespaces/deployment-9427/pods/webserver-deployment-c7997dcc8-tk8pb c9b82921-f282-437f-824f-be3925e0b535 334796 0 2019-09-22 08:56:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.212.134/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 1500066c-3fd1-463a-951e-d84df2435a2d 0xc001728e40 0xc001728e41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9s8x2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9s8x2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9s8x2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 08:56:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:,StartTime:2019-09-22 08:56:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 08:56:28.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9427" for this suite.
Sep 22 08:56:34.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 08:56:34.826: INFO: namespace deployment-9427 deletion completed in 6.116614849s

• [SLOW TEST:12.298 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 08:56:34.827: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-8113a228-8c86-4b8d-9525-926fa2494dfc in namespace container-probe-4290
Sep 22 08:56:40.874: INFO: Started pod test-webserver-8113a228-8c86-4b8d-9525-926fa2494dfc in namespace container-probe-4290
STEP: checking the pod's current state and verifying that restartCount is present
Sep 22 08:56:40.876: INFO: Initial restart count of pod test-webserver-8113a228-8c86-4b8d-9525-926fa2494dfc is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:00:41.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4290" for this suite.
Sep 22 09:00:47.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:00:47.455: INFO: namespace container-probe-4290 deletion completed in 6.075794545s

• [SLOW TEST:252.629 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:00:47.457: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Sep 22 09:00:52.011: INFO: Successfully updated pod "adopt-release-sx2cf"
STEP: Checking that the Job readopts the Pod
Sep 22 09:00:52.011: INFO: Waiting up to 15m0s for pod "adopt-release-sx2cf" in namespace "job-2853" to be "adopted"
Sep 22 09:00:52.017: INFO: Pod "adopt-release-sx2cf": Phase="Running", Reason="", readiness=true. Elapsed: 6.058171ms
Sep 22 09:00:54.022: INFO: Pod "adopt-release-sx2cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.01064809s
Sep 22 09:00:54.022: INFO: Pod "adopt-release-sx2cf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Sep 22 09:00:54.530: INFO: Successfully updated pod "adopt-release-sx2cf"
STEP: Checking that the Job releases the Pod
Sep 22 09:00:54.531: INFO: Waiting up to 15m0s for pod "adopt-release-sx2cf" in namespace "job-2853" to be "released"
Sep 22 09:00:54.535: INFO: Pod "adopt-release-sx2cf": Phase="Running", Reason="", readiness=true. Elapsed: 3.98435ms
Sep 22 09:00:56.538: INFO: Pod "adopt-release-sx2cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.007188134s
Sep 22 09:00:56.538: INFO: Pod "adopt-release-sx2cf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:00:56.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2853" for this suite.
Sep 22 09:01:40.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:01:40.635: INFO: namespace job-2853 deletion completed in 44.093748002s

• [SLOW TEST:53.178 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:01:40.636: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Sep 22 09:01:40.682: INFO: Waiting up to 5m0s for pod "client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3" in namespace "containers-8763" to be "success or failure"
Sep 22 09:01:40.686: INFO: Pod "client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.120636ms
Sep 22 09:01:42.689: INFO: Pod "client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006192331s
STEP: Saw pod success
Sep 22 09:01:42.689: INFO: Pod "client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3" satisfied condition "success or failure"
Sep 22 09:01:42.691: INFO: Trying to get logs from node ip-10-0-14-205 pod client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3 container test-container: <nil>
STEP: delete the pod
Sep 22 09:01:42.714: INFO: Waiting for pod client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3 to disappear
Sep 22 09:01:42.716: INFO: Pod client-containers-6787f706-5914-4774-9d00-9a7c4fafcbc3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:01:42.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8763" for this suite.
Sep 22 09:01:48.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:01:48.813: INFO: namespace containers-8763 deletion completed in 6.095285531s

• [SLOW TEST:8.177 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:01:48.813: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 22 09:01:52.912: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:01:52.914: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:01:54.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:01:54.919: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:01:56.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:01:56.918: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:01:58.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:01:58.918: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:02:00.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:02:00.923: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:02:02.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:02:02.919: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:02:04.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:02:04.919: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 22 09:02:06.915: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 22 09:02:06.918: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:02:06.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4334" for this suite.
Sep 22 09:02:34.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:02:35.065: INFO: namespace container-lifecycle-hook-4334 deletion completed in 28.142596145s

• [SLOW TEST:46.252 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:02:35.067: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:02:46.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7261" for this suite.
Sep 22 09:02:52.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:02:52.236: INFO: namespace resourcequota-7261 deletion completed in 6.078812012s

• [SLOW TEST:17.169 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:02:52.237: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 22 09:02:54.300: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:02:54.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4672" for this suite.
Sep 22 09:03:00.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:03:00.410: INFO: namespace container-runtime-4672 deletion completed in 6.093030246s

• [SLOW TEST:8.173 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:03:00.411: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8bd20284-4884-429a-b9bc-4c75eb9b06e5
STEP: Creating a pod to test consume configMaps
Sep 22 09:03:00.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973" in namespace "configmap-4471" to be "success or failure"
Sep 22 09:03:00.458: INFO: Pod "pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28683ms
Sep 22 09:03:02.462: INFO: Pod "pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00804908s
STEP: Saw pod success
Sep 22 09:03:02.462: INFO: Pod "pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973" satisfied condition "success or failure"
Sep 22 09:03:02.464: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 09:03:02.479: INFO: Waiting for pod pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973 to disappear
Sep 22 09:03:02.481: INFO: Pod pod-configmaps-c1293a38-285e-4066-a312-9c3c90aaf973 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:03:02.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4471" for this suite.
Sep 22 09:03:08.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:03:08.559: INFO: namespace configmap-4471 deletion completed in 6.074501933s

• [SLOW TEST:8.148 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:03:08.561: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 22 09:03:11.120: INFO: Successfully updated pod "pod-update-d3774135-9608-4f95-b23a-df05663320b9"
STEP: verifying the updated pod is in kubernetes
Sep 22 09:03:11.125: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:03:11.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2976" for this suite.
Sep 22 09:03:39.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:03:39.215: INFO: namespace pods-2976 deletion completed in 28.086210595s

• [SLOW TEST:30.654 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:03:39.217: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 22 09:03:39.251: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 22 09:03:39.264: INFO: Waiting for terminating namespaces to be deleted...
Sep 22 09:03:39.267: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-14-205 before test
Sep 22 09:03:39.273: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:03:39.273: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 22 09:03:39.273: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 22 09:03:39.273: INFO: calico-node-kfxhb from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.273: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 09:03:39.273: INFO: sonobuoy from sonobuoy started at 2019-09-22 07:56:45 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.273: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 22 09:03:39.273: INFO: kube-proxy-gxhtr from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.273: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 09:03:39.273: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-60 before test
Sep 22 09:03:39.289: INFO: kube-proxy-mrm99 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.289: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 09:03:39.289: INFO: coredns-fffcf5449-vn775 from kube-system started at 2019-09-20 01:40:55 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.289: INFO: 	Container coredns ready: true, restart count 0
Sep 22 09:03:39.289: INFO: sonobuoy-e2e-job-df839470c40a489c from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:03:39.289: INFO: 	Container e2e ready: true, restart count 0
Sep 22 09:03:39.289: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 09:03:39.289: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:03:39.289: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 22 09:03:39.289: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 22 09:03:39.289: INFO: calico-node-nzh59 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 09:03:39.289: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3dacf630-c4d0-4e2f-802a-41e5826b9a92 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-3dacf630-c4d0-4e2f-802a-41e5826b9a92 off the node ip-10-0-14-205
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3dacf630-c4d0-4e2f-802a-41e5826b9a92
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:08:43.368: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7011" for this suite.
Sep 22 09:08:57.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:08:57.461: INFO: namespace sched-pred-7011 deletion completed in 14.086977047s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:318.245 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:08:57.462: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
I0922 09:08:57.462330      18 request.go:706] Error in request: resource name may not be empty
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 22 09:09:00.067: INFO: Successfully updated pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2"
Sep 22 09:09:00.067: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2" in namespace "pods-6713" to be "terminated due to deadline exceeded"
Sep 22 09:09:00.089: INFO: Pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2": Phase="Running", Reason="", readiness=true. Elapsed: 21.292975ms
Sep 22 09:09:02.095: INFO: Pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2": Phase="Running", Reason="", readiness=true. Elapsed: 2.027303174s
Sep 22 09:09:04.098: INFO: Pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.030781312s
Sep 22 09:09:04.098: INFO: Pod "pod-update-activedeadlineseconds-98880624-c3f8-4b5d-9f45-bfca0ea074d2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:04.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6713" for this suite.
Sep 22 09:09:10.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:09:10.238: INFO: namespace pods-6713 deletion completed in 6.135547899s

• [SLOW TEST:12.776 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:09:10.241: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:09:10.293: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-b170f15d-0d42-45a7-84b1-c9c140e0705c" in namespace "security-context-test-6730" to be "success or failure"
Sep 22 09:09:10.300: INFO: Pod "busybox-readonly-false-b170f15d-0d42-45a7-84b1-c9c140e0705c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736445ms
Sep 22 09:09:12.303: INFO: Pod "busybox-readonly-false-b170f15d-0d42-45a7-84b1-c9c140e0705c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009772021s
Sep 22 09:09:12.303: INFO: Pod "busybox-readonly-false-b170f15d-0d42-45a7-84b1-c9c140e0705c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:12.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6730" for this suite.
Sep 22 09:09:18.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:09:18.388: INFO: namespace security-context-test-6730 deletion completed in 6.08122282s

• [SLOW TEST:8.147 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:09:18.388: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-b7f0d39c-0f52-4d35-8e0c-2132482a7198
STEP: Creating a pod to test consume configMaps
Sep 22 09:09:18.427: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd" in namespace "configmap-3844" to be "success or failure"
Sep 22 09:09:18.429: INFO: Pod "pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.96609ms
Sep 22 09:09:20.434: INFO: Pod "pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006061928s
Sep 22 09:09:22.437: INFO: Pod "pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009218453s
STEP: Saw pod success
Sep 22 09:09:22.437: INFO: Pod "pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd" satisfied condition "success or failure"
Sep 22 09:09:22.439: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 09:09:22.467: INFO: Waiting for pod pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd to disappear
Sep 22 09:09:22.471: INFO: Pod pod-configmaps-fe3a7503-ea18-4f80-a646-32361ec276fd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:22.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3844" for this suite.
Sep 22 09:09:28.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:09:28.560: INFO: namespace configmap-3844 deletion completed in 6.083525484s

• [SLOW TEST:10.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:09:28.560: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-d458b488-0e33-4774-a59b-7bd7a95da0fb
STEP: Creating a pod to test consume secrets
Sep 22 09:09:28.596: INFO: Waiting up to 5m0s for pod "pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc" in namespace "secrets-328" to be "success or failure"
Sep 22 09:09:28.599: INFO: Pod "pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.316488ms
Sep 22 09:09:30.604: INFO: Pod "pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00788199s
STEP: Saw pod success
Sep 22 09:09:30.604: INFO: Pod "pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc" satisfied condition "success or failure"
Sep 22 09:09:30.611: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:09:30.649: INFO: Waiting for pod pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc to disappear
Sep 22 09:09:30.657: INFO: Pod pod-secrets-b4813539-9850-4668-93a9-2bc47d91efdc no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:30.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-328" for this suite.
Sep 22 09:09:36.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:09:36.767: INFO: namespace secrets-328 deletion completed in 6.099288442s

• [SLOW TEST:8.207 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:09:36.768: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-58adc35b-be69-495a-a29d-67f04b204265
STEP: Creating a pod to test consume configMaps
Sep 22 09:09:36.830: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4" in namespace "projected-5415" to be "success or failure"
Sep 22 09:09:36.833: INFO: Pod "pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.543709ms
Sep 22 09:09:38.837: INFO: Pod "pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007107675s
STEP: Saw pod success
Sep 22 09:09:38.837: INFO: Pod "pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4" satisfied condition "success or failure"
Sep 22 09:09:38.840: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 09:09:38.857: INFO: Waiting for pod pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4 to disappear
Sep 22 09:09:38.859: INFO: Pod pod-projected-configmaps-b11b9552-dddd-4338-b3d5-0a9789ab6bd4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:38.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5415" for this suite.
Sep 22 09:09:44.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:09:44.975: INFO: namespace projected-5415 deletion completed in 6.113044439s

• [SLOW TEST:8.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:09:44.976: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3110.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3110.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3110.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3110.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 10.37.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.37.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.37.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.37.10_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3110.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3110.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3110.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3110.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3110.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3110.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 10.37.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.37.10_udp@PTR;check="$$(dig +tcp +noall +answer +search 10.37.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.37.10_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 09:09:49.138: INFO: Unable to read wheezy_udp@dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.141: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.143: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.146: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.171: INFO: Unable to read jessie_udp@dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.176: INFO: Unable to read jessie_tcp@dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.179: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.182: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local from pod dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f: the server could not find the requested resource (get pods dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f)
Sep 22 09:09:49.204: INFO: Lookups using dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f failed for: [wheezy_udp@dns-test-service.dns-3110.svc.cluster.local wheezy_tcp@dns-test-service.dns-3110.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local jessie_udp@dns-test-service.dns-3110.svc.cluster.local jessie_tcp@dns-test-service.dns-3110.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3110.svc.cluster.local]

Sep 22 09:09:54.263: INFO: DNS probes using dns-3110/dns-test-14a9180a-e307-45ff-8dbf-368ca0e1bf3f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:09:54.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3110" for this suite.
Sep 22 09:10:00.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:10:00.458: INFO: namespace dns-3110 deletion completed in 6.141907979s

• [SLOW TEST:15.482 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:10:00.459: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 22 09:10:00.497: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337065 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 22 09:10:00.497: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337065 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 22 09:10:10.511: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337081 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 22 09:10:10.511: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337081 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 22 09:10:20.518: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337096 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 22 09:10:20.518: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337096 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 22 09:10:30.524: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337111 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 22 09:10:30.524: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-a b82cfc71-bbe1-4145-938f-81ace29139cb 337111 0 2019-09-22 09:10:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 22 09:10:40.530: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-b bb551391-f26f-43f5-8dc0-4dcec1a7b21f 337126 0 2019-09-22 09:10:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 22 09:10:40.531: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-b bb551391-f26f-43f5-8dc0-4dcec1a7b21f 337126 0 2019-09-22 09:10:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 22 09:10:50.536: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-b bb551391-f26f-43f5-8dc0-4dcec1a7b21f 337142 0 2019-09-22 09:10:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 22 09:10:50.536: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1999 /api/v1/namespaces/watch-1999/configmaps/e2e-watch-test-configmap-b bb551391-f26f-43f5-8dc0-4dcec1a7b21f 337142 0 2019-09-22 09:10:40 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:11:00.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1999" for this suite.
Sep 22 09:11:06.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:11:06.623: INFO: namespace watch-1999 deletion completed in 6.08264524s

• [SLOW TEST:66.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:11:06.624: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:11:06.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5591" for this suite.
Sep 22 09:11:12.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:11:12.736: INFO: namespace services-5591 deletion completed in 6.077892282s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.112 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:11:12.737: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 09:11:12.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9770'
Sep 22 09:11:13.042: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 22 09:11:13.042: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Sep 22 09:11:13.054: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Sep 22 09:11:13.057: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 22 09:11:13.075: INFO: scanned /root for discovery docs: <nil>
Sep 22 09:11:13.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9770'
Sep 22 09:11:28.853: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 22 09:11:28.854: INFO: stdout: "Created e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71\nScaling up e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Sep 22 09:11:28.854: INFO: stdout: "Created e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71\nScaling up e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Sep 22 09:11:28.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9770'
Sep 22 09:11:28.953: INFO: stderr: ""
Sep 22 09:11:28.953: INFO: stdout: "e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71-cfklf "
Sep 22 09:11:28.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71-cfklf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9770'
Sep 22 09:11:29.059: INFO: stderr: ""
Sep 22 09:11:29.059: INFO: stdout: "true"
Sep 22 09:11:29.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71-cfklf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9770'
Sep 22 09:11:29.176: INFO: stderr: ""
Sep 22 09:11:29.176: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Sep 22 09:11:29.176: INFO: e2e-test-httpd-rc-f36eb188757d0edd59ab7060f0ec5a71-cfklf is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Sep 22 09:11:29.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete rc e2e-test-httpd-rc --namespace=kubectl-9770'
Sep 22 09:11:29.297: INFO: stderr: ""
Sep 22 09:11:29.297: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:11:29.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9770" for this suite.
Sep 22 09:11:41.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:11:41.410: INFO: namespace kubectl-9770 deletion completed in 12.101089572s

• [SLOW TEST:28.673 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:11:41.411: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Sep 22 09:11:41.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-3961'
Sep 22 09:11:41.672: INFO: stderr: ""
Sep 22 09:11:41.672: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 22 09:11:42.675: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 09:11:42.675: INFO: Found 0 / 1
Sep 22 09:11:43.676: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 09:11:43.676: INFO: Found 1 / 1
Sep 22 09:11:43.676: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 22 09:11:43.680: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 09:11:43.680: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 22 09:11:43.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 patch pod redis-master-9wlmv --namespace=kubectl-3961 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 22 09:11:43.782: INFO: stderr: ""
Sep 22 09:11:43.782: INFO: stdout: "pod/redis-master-9wlmv patched\n"
STEP: checking annotations
Sep 22 09:11:43.787: INFO: Selector matched 1 pods for map[app:redis]
Sep 22 09:11:43.787: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:11:43.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3961" for this suite.
Sep 22 09:12:11.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:12:11.947: INFO: namespace kubectl-3961 deletion completed in 28.156191291s

• [SLOW TEST:30.536 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:12:11.947: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1697
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 22 09:12:11.984: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 22 09:12:34.087: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.212.161:8080/dial?request=hostName&protocol=udp&host=10.2.56.196&port=8081&tries=1'] Namespace:pod-network-test-1697 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:12:34.087: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:12:34.178: INFO: Waiting for endpoints: map[]
Sep 22 09:12:34.180: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.212.161:8080/dial?request=hostName&protocol=udp&host=10.2.212.160&port=8081&tries=1'] Namespace:pod-network-test-1697 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:12:34.180: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:12:34.279: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:12:34.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1697" for this suite.
Sep 22 09:12:46.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:12:46.362: INFO: namespace pod-network-test-1697 deletion completed in 12.078736655s

• [SLOW TEST:34.415 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:12:46.363: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 09:12:48.415: INFO: DNS probes using dns-test-7bac481e-9e32-465b-ada6-809bc9949a4e succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 09:12:50.449: INFO: File wheezy_udp@dns-test-service-3.dns-9607.svc.cluster.local from pod  dns-9607/dns-test-4e7d457d-ef52-4508-8403-c4493db477a8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 22 09:12:50.452: INFO: File jessie_udp@dns-test-service-3.dns-9607.svc.cluster.local from pod  dns-9607/dns-test-4e7d457d-ef52-4508-8403-c4493db477a8 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 22 09:12:50.452: INFO: Lookups using dns-9607/dns-test-4e7d457d-ef52-4508-8403-c4493db477a8 failed for: [wheezy_udp@dns-test-service-3.dns-9607.svc.cluster.local jessie_udp@dns-test-service-3.dns-9607.svc.cluster.local]

Sep 22 09:12:55.459: INFO: DNS probes using dns-test-4e7d457d-ef52-4508-8403-c4493db477a8 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9607.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9607.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 09:12:57.535: INFO: DNS probes using dns-test-38c5532e-6784-4c58-924b-bebf782cb0ad succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:12:57.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9607" for this suite.
Sep 22 09:13:03.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:13:03.690: INFO: namespace dns-9607 deletion completed in 6.098001858s

• [SLOW TEST:17.328 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:13:03.690: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Sep 22 09:13:03.724: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9601" to be "success or failure"
Sep 22 09:13:03.726: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.796111ms
Sep 22 09:13:05.730: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006046391s
STEP: Saw pod success
Sep 22 09:13:05.730: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 22 09:13:05.732: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 22 09:13:05.754: INFO: Waiting for pod pod-host-path-test to disappear
Sep 22 09:13:05.757: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:13:05.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9601" for this suite.
Sep 22 09:13:11.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:13:11.836: INFO: namespace hostpath-9601 deletion completed in 6.075818898s

• [SLOW TEST:8.146 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:13:11.836: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 22 09:13:11.871: INFO: Waiting up to 5m0s for pod "downward-api-fca17b14-724e-4415-9c75-dde33030b357" in namespace "downward-api-4262" to be "success or failure"
Sep 22 09:13:11.874: INFO: Pod "downward-api-fca17b14-724e-4415-9c75-dde33030b357": Phase="Pending", Reason="", readiness=false. Elapsed: 2.846128ms
Sep 22 09:13:13.877: INFO: Pod "downward-api-fca17b14-724e-4415-9c75-dde33030b357": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005902061s
STEP: Saw pod success
Sep 22 09:13:13.877: INFO: Pod "downward-api-fca17b14-724e-4415-9c75-dde33030b357" satisfied condition "success or failure"
Sep 22 09:13:13.880: INFO: Trying to get logs from node ip-10-0-14-205 pod downward-api-fca17b14-724e-4415-9c75-dde33030b357 container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:13:13.896: INFO: Waiting for pod downward-api-fca17b14-724e-4415-9c75-dde33030b357 to disappear
Sep 22 09:13:13.899: INFO: Pod downward-api-fca17b14-724e-4415-9c75-dde33030b357 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:13:13.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4262" for this suite.
Sep 22 09:13:19.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:13:19.982: INFO: namespace downward-api-4262 deletion completed in 6.078575916s

• [SLOW TEST:8.146 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:13:19.984: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2104
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2104
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2104
Sep 22 09:13:20.030: INFO: Found 0 stateful pods, waiting for 1
Sep 22 09:13:30.035: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 22 09:13:30.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:13:30.367: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:13:30.367: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:13:30.367: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:13:30.369: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 22 09:13:40.373: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:13:40.373: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:13:40.382: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999965s
Sep 22 09:13:41.386: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997185355s
Sep 22 09:13:42.390: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99314249s
Sep 22 09:13:43.393: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989929242s
Sep 22 09:13:44.397: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.985525495s
Sep 22 09:13:45.400: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982172371s
Sep 22 09:13:46.404: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.979044411s
Sep 22 09:13:47.407: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.975762981s
Sep 22 09:13:48.410: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.972501091s
Sep 22 09:13:49.414: INFO: Verifying statefulset ss doesn't scale past 1 for another 969.467219ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2104
Sep 22 09:13:50.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:13:50.628: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 09:13:50.628: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:13:50.628: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:13:50.631: INFO: Found 1 stateful pods, waiting for 3
Sep 22 09:14:00.635: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 09:14:00.635: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 09:14:00.635: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 22 09:14:00.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:14:00.829: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:14:00.829: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:14:00.829: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:14:00.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:14:01.085: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:14:01.085: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:14:01.085: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:14:01.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:14:01.363: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:14:01.363: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:14:01.363: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:14:01.363: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:14:01.366: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 22 09:14:11.380: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:14:11.380: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:14:11.380: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:14:11.392: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999665s
Sep 22 09:14:12.409: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995922333s
Sep 22 09:14:13.412: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.979181771s
Sep 22 09:14:14.416: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.976057654s
Sep 22 09:14:15.421: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.971722258s
Sep 22 09:14:16.425: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.967323434s
Sep 22 09:14:17.428: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.963374434s
Sep 22 09:14:18.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.959981323s
Sep 22 09:14:19.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.956159401s
Sep 22 09:14:20.439: INFO: Verifying statefulset ss doesn't scale past 3 for another 952.820594ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2104
Sep 22 09:14:21.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:14:21.654: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 09:14:21.654: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:14:21.654: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:14:21.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:14:21.873: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 09:14:21.873: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:14:21.873: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:14:21.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-2104 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:14:22.067: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 09:14:22.067: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:14:22.067: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:14:22.067: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 09:14:52.080: INFO: Deleting all statefulset in ns statefulset-2104
Sep 22 09:14:52.092: INFO: Scaling statefulset ss to 0
Sep 22 09:14:52.107: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:14:52.109: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:14:52.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2104" for this suite.
Sep 22 09:14:58.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:14:58.229: INFO: namespace statefulset-2104 deletion completed in 6.108444775s

• [SLOW TEST:98.245 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:14:58.230: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-da807f82-e13d-412c-a488-7b2b58269e39
STEP: Creating secret with name s-test-opt-upd-499394a6-7430-44f7-b3bc-3eff9ac5d553
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-da807f82-e13d-412c-a488-7b2b58269e39
STEP: Updating secret s-test-opt-upd-499394a6-7430-44f7-b3bc-3eff9ac5d553
STEP: Creating secret with name s-test-opt-create-f5b66458-788c-41ea-9b37-041e7ddbe1a5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:15:02.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-528" for this suite.
Sep 22 09:15:14.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:15:14.650: INFO: namespace projected-528 deletion completed in 12.085490821s

• [SLOW TEST:16.420 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:15:14.650: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 22 09:15:18.708: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 22 09:15:18.710: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 22 09:15:20.710: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 22 09:15:20.715: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 22 09:15:22.711: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 22 09:15:22.714: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 22 09:15:24.710: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 22 09:15:24.715: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 22 09:15:26.711: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 22 09:15:26.720: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:15:26.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8560" for this suite.
Sep 22 09:15:38.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:15:38.848: INFO: namespace container-lifecycle-hook-8560 deletion completed in 12.116844305s

• [SLOW TEST:24.198 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:15:38.849: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Sep 22 09:15:38.934: INFO: Waiting up to 5m0s for pod "var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139" in namespace "var-expansion-4781" to be "success or failure"
Sep 22 09:15:38.938: INFO: Pod "var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139": Phase="Pending", Reason="", readiness=false. Elapsed: 3.787673ms
Sep 22 09:15:40.942: INFO: Pod "var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007628379s
STEP: Saw pod success
Sep 22 09:15:40.942: INFO: Pod "var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139" satisfied condition "success or failure"
Sep 22 09:15:40.944: INFO: Trying to get logs from node ip-10-0-14-205 pod var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139 container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:15:40.960: INFO: Waiting for pod var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139 to disappear
Sep 22 09:15:40.963: INFO: Pod var-expansion-b31cec20-2bac-4139-8fc4-3b61c4c1f139 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:15:40.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4781" for this suite.
Sep 22 09:15:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:15:47.048: INFO: namespace var-expansion-4781 deletion completed in 6.081791748s

• [SLOW TEST:8.199 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:15:47.050: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Sep 22 09:15:47.083: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-153516655 proxy --unix-socket=/tmp/kubectl-proxy-unix097041094/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:15:47.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6337" for this suite.
Sep 22 09:15:53.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:15:53.265: INFO: namespace kubectl-6337 deletion completed in 6.088756339s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:15:53.266: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Sep 22 09:15:53.296: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 22 09:15:53.308: INFO: Waiting for terminating namespaces to be deleted...
Sep 22 09:15:53.312: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-14-205 before test
Sep 22 09:15:53.317: INFO: kube-proxy-gxhtr from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.317: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 09:15:53.317: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:15:53.317: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 22 09:15:53.317: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 22 09:15:53.317: INFO: calico-node-kfxhb from kube-system started at 2019-09-20 01:40:39 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.317: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 09:15:53.317: INFO: sonobuoy from sonobuoy started at 2019-09-22 07:56:45 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.317: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 22 09:15:53.317: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-30-60 before test
Sep 22 09:15:53.336: INFO: sonobuoy-e2e-job-df839470c40a489c from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:15:53.336: INFO: 	Container e2e ready: true, restart count 0
Sep 22 09:15:53.336: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 22 09:15:53.336: INFO: sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 from sonobuoy started at 2019-09-22 07:56:46 +0000 UTC (2 container statuses recorded)
Sep 22 09:15:53.336: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 22 09:15:53.336: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 22 09:15:53.336: INFO: calico-node-nzh59 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.336: INFO: 	Container calico-node ready: true, restart count 0
Sep 22 09:15:53.336: INFO: kube-proxy-mrm99 from kube-system started at 2019-09-20 01:40:42 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.336: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 22 09:15:53.336: INFO: coredns-fffcf5449-vn775 from kube-system started at 2019-09-20 01:40:55 +0000 UTC (1 container statuses recorded)
Sep 22 09:15:53.336: INFO: 	Container coredns ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node ip-10-0-14-205
STEP: verifying the node has the label node ip-10-0-30-60
Sep 22 09:15:53.368: INFO: Pod calico-node-kfxhb requesting resource cpu=150m on Node ip-10-0-14-205
Sep 22 09:15:53.368: INFO: Pod calico-node-nzh59 requesting resource cpu=150m on Node ip-10-0-30-60
Sep 22 09:15:53.368: INFO: Pod coredns-fffcf5449-vn775 requesting resource cpu=100m on Node ip-10-0-30-60
Sep 22 09:15:53.368: INFO: Pod kube-proxy-gxhtr requesting resource cpu=0m on Node ip-10-0-14-205
Sep 22 09:15:53.368: INFO: Pod kube-proxy-mrm99 requesting resource cpu=0m on Node ip-10-0-30-60
Sep 22 09:15:53.368: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-14-205
Sep 22 09:15:53.368: INFO: Pod sonobuoy-e2e-job-df839470c40a489c requesting resource cpu=0m on Node ip-10-0-30-60
Sep 22 09:15:53.368: INFO: Pod sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-f74ql requesting resource cpu=0m on Node ip-10-0-14-205
Sep 22 09:15:53.368: INFO: Pod sonobuoy-systemd-logs-daemon-set-3740a81b09dc47be-hndn8 requesting resource cpu=0m on Node ip-10-0-30-60
STEP: Starting Pods to consume most of the cluster CPU.
Sep 22 09:15:53.368: INFO: Creating a pod which consumes cpu=1295m on Node ip-10-0-14-205
Sep 22 09:15:53.373: INFO: Creating a pod which consumes cpu=1225m on Node ip-10-0-30-60
STEP: Creating another pod that requires unavailable amount of CPU.
I0922 09:15:55.400456      18 reflector.go:120] Starting reflector *v1.Event (0s) from k8s.io/kubernetes/test/e2e/common/events.go:136
I0922 09:15:55.400596      18 reflector.go:158] Listing and watching *v1.Event from k8s.io/kubernetes/test/e2e/common/events.go:136
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9.15c6b7ee15ff51d6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2723/filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9 to ip-10-0-14-205]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9.15c6b7ee413e78ea], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9.15c6b7ee499cebbb], Reason = [Created], Message = [Created container filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9.15c6b7ee50c4715d], Reason = [Started], Message = [Started container filler-pod-e6ca473d-9faf-494a-a48f-9f1ca60ce6d9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d.15c6b7ee162ee760], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2723/filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d to ip-10-0-30-60]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d.15c6b7ee4c5963d5], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d.15c6b7ee516034c2], Reason = [Created], Message = [Created container filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d.15c6b7ee590bd17f], Reason = [Started], Message = [Started container filler-pod-ebcb38f8-8596-4d82-ad40-05903e94401d]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c6b7ee8ea8d4d5], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c6b7ee8fdc0225], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-14-205
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-30-60
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:15:56.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2723" for this suite.
Sep 22 09:16:02.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:16:02.560: INFO: namespace sched-pred-2723 deletion completed in 6.106329872s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
I0922 09:16:02.561106      18 request.go:706] Error in request: resource name may not be empty

• [SLOW TEST:9.295 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:16:02.561: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
I0922 09:16:04.419365      18 request.go:538] Throttling request took 52.190822ms, request: PUT:https://10.3.0.1:443/api/v1/namespaces/watch-6454/configmaps/cm-22
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:16:07.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6454" for this suite.
Sep 22 09:16:13.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:16:13.989: INFO: namespace watch-6454 deletion completed in 6.171242465s

• [SLOW TEST:11.428 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:16:13.989: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 22 09:16:14.025: INFO: Waiting up to 5m0s for pod "pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e" in namespace "emptydir-6394" to be "success or failure"
Sep 22 09:16:14.030: INFO: Pod "pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.438575ms
Sep 22 09:16:16.036: INFO: Pod "pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01118072s
STEP: Saw pod success
Sep 22 09:16:16.036: INFO: Pod "pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e" satisfied condition "success or failure"
Sep 22 09:16:16.041: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e container test-container: <nil>
STEP: delete the pod
Sep 22 09:16:16.064: INFO: Waiting for pod pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e to disappear
Sep 22 09:16:16.069: INFO: Pod pod-b851d5a7-d2a1-4c44-9bc9-898b6c0b9c2e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:16:16.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6394" for this suite.
Sep 22 09:16:22.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:16:22.153: INFO: namespace emptydir-6394 deletion completed in 6.080080555s

• [SLOW TEST:8.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:16:22.154: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:16:22.192: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cfa3a4fb-63fc-4b60-9eb7-16ceaf291fb6" in namespace "security-context-test-561" to be "success or failure"
Sep 22 09:16:22.197: INFO: Pod "busybox-privileged-false-cfa3a4fb-63fc-4b60-9eb7-16ceaf291fb6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154458ms
Sep 22 09:16:24.199: INFO: Pod "busybox-privileged-false-cfa3a4fb-63fc-4b60-9eb7-16ceaf291fb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006676552s
Sep 22 09:16:24.199: INFO: Pod "busybox-privileged-false-cfa3a4fb-63fc-4b60-9eb7-16ceaf291fb6" satisfied condition "success or failure"
Sep 22 09:16:24.205: INFO: Got logs for pod "busybox-privileged-false-cfa3a4fb-63fc-4b60-9eb7-16ceaf291fb6": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:16:24.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-561" for this suite.
Sep 22 09:16:30.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:16:30.286: INFO: namespace security-context-test-561 deletion completed in 6.077145557s

• [SLOW TEST:8.132 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:16:30.287: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:16:46.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5114" for this suite.
Sep 22 09:16:52.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:16:52.450: INFO: namespace resourcequota-5114 deletion completed in 6.096316211s

• [SLOW TEST:22.163 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:16:52.450: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-f9cd15da-5f4c-4640-bb83-fd336ed25aff
STEP: Creating a pod to test consume secrets
Sep 22 09:16:52.487: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4" in namespace "projected-8284" to be "success or failure"
Sep 22 09:16:52.490: INFO: Pod "pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.756565ms
Sep 22 09:16:54.494: INFO: Pod "pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006084201s
STEP: Saw pod success
Sep 22 09:16:54.494: INFO: Pod "pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4" satisfied condition "success or failure"
Sep 22 09:16:54.496: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4 container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:16:54.510: INFO: Waiting for pod pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4 to disappear
Sep 22 09:16:54.512: INFO: Pod pod-projected-secrets-f9a12888-c8a3-4009-a00f-d3a411f347d4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:16:54.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8284" for this suite.
Sep 22 09:17:00.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:17:00.611: INFO: namespace projected-8284 deletion completed in 6.095871233s

• [SLOW TEST:8.160 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:17:00.617: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-b2b6d407-8848-4cbc-b27e-db14e43514ae
STEP: Creating a pod to test consume secrets
Sep 22 09:17:00.686: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b" in namespace "projected-334" to be "success or failure"
Sep 22 09:17:00.691: INFO: Pod "pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.328041ms
Sep 22 09:17:02.696: INFO: Pod "pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009787449s
STEP: Saw pod success
Sep 22 09:17:02.696: INFO: Pod "pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b" satisfied condition "success or failure"
Sep 22 09:17:02.700: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:17:02.750: INFO: Waiting for pod pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b to disappear
Sep 22 09:17:02.754: INFO: Pod pod-projected-secrets-4b7c6ab5-3c98-4e61-b1d3-f7bfb54e685b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:17:02.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-334" for this suite.
Sep 22 09:17:08.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:17:08.843: INFO: namespace projected-334 deletion completed in 6.084276197s

• [SLOW TEST:8.227 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:17:08.853: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 22 09:17:08.890: INFO: Waiting up to 5m0s for pod "downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f" in namespace "downward-api-2484" to be "success or failure"
Sep 22 09:17:08.898: INFO: Pod "downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.675116ms
Sep 22 09:17:10.904: INFO: Pod "downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013873984s
STEP: Saw pod success
Sep 22 09:17:10.904: INFO: Pod "downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f" satisfied condition "success or failure"
Sep 22 09:17:10.914: INFO: Trying to get logs from node ip-10-0-14-205 pod downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:17:10.947: INFO: Waiting for pod downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f to disappear
Sep 22 09:17:10.951: INFO: Pod downward-api-84327414-1c61-40ce-9ac8-9542707d8e0f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:17:10.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2484" for this suite.
Sep 22 09:17:16.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:17:17.047: INFO: namespace downward-api-2484 deletion completed in 6.091020558s

• [SLOW TEST:8.194 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:17:17.048: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2109
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 22 09:17:17.091: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 22 09:17:37.158: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.212.177:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2109 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:17:37.158: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:17:37.343: INFO: Found all expected endpoints: [netserver-0]
Sep 22 09:17:37.346: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.56.199:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2109 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:17:37.346: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:17:37.470: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:17:37.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2109" for this suite.
Sep 22 09:17:49.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:17:49.553: INFO: namespace pod-network-test-2109 deletion completed in 12.077548701s

• [SLOW TEST:32.505 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:17:49.554: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5947
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-5947
Sep 22 09:17:49.594: INFO: Found 0 stateful pods, waiting for 1
Sep 22 09:17:59.597: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 09:17:59.616: INFO: Deleting all statefulset in ns statefulset-5947
Sep 22 09:17:59.622: INFO: Scaling statefulset ss to 0
Sep 22 09:18:19.647: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:18:19.649: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:18:19.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5947" for this suite.
Sep 22 09:18:25.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:18:25.742: INFO: namespace statefulset-5947 deletion completed in 6.075679323s

• [SLOW TEST:36.189 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:18:25.742: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 22 09:18:25.778: INFO: Waiting up to 5m0s for pod "pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e" in namespace "emptydir-6774" to be "success or failure"
Sep 22 09:18:25.782: INFO: Pod "pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.455999ms
Sep 22 09:18:27.788: INFO: Pod "pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009993383s
STEP: Saw pod success
Sep 22 09:18:27.788: INFO: Pod "pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e" satisfied condition "success or failure"
Sep 22 09:18:27.791: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e container test-container: <nil>
STEP: delete the pod
Sep 22 09:18:27.815: INFO: Waiting for pod pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e to disappear
Sep 22 09:18:27.817: INFO: Pod pod-28a6d7cc-85c7-40c3-8f90-8f780e6cce0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:18:27.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6774" for this suite.
Sep 22 09:18:33.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:18:33.899: INFO: namespace emptydir-6774 deletion completed in 6.077946434s

• [SLOW TEST:8.157 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:18:33.900: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1022
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-1022
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1022
Sep 22 09:18:33.961: INFO: Found 0 stateful pods, waiting for 1
Sep 22 09:18:43.964: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 22 09:18:43.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:18:44.270: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:18:44.270: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:18:44.270: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:18:44.277: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 22 09:18:54.281: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:18:54.281: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:18:54.294: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Sep 22 09:18:54.294: INFO: ss-0  ip-10-0-14-205  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  }]
Sep 22 09:18:54.294: INFO: 
Sep 22 09:18:54.294: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 22 09:18:55.297: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997008201s
Sep 22 09:18:56.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993526553s
Sep 22 09:18:57.312: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982567491s
Sep 22 09:18:58.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978194786s
Sep 22 09:18:59.319: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974930077s
Sep 22 09:19:00.323: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971654898s
Sep 22 09:19:01.341: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967638146s
Sep 22 09:19:02.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.949465783s
Sep 22 09:19:03.354: INFO: Verifying statefulset ss doesn't scale past 3 for another 945.693115ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1022
Sep 22 09:19:04.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:19:04.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Sep 22 09:19:04.554: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:19:04.554: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:19:04.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:19:04.776: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 22 09:19:04.776: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:19:04.776: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:19:04.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Sep 22 09:19:04.965: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 22 09:19:04.965: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Sep 22 09:19:04.965: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Sep 22 09:19:04.972: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 22 09:19:14.975: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 09:19:14.975: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 22 09:19:14.975: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 22 09:19:14.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:19:15.289: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:19:15.289: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:19:15.289: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:19:15.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:19:15.637: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:19:15.637: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:19:15.637: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:19:15.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=statefulset-1022 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Sep 22 09:19:15.822: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Sep 22 09:19:15.822: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Sep 22 09:19:15.822: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Sep 22 09:19:15.822: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:19:15.826: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 22 09:19:25.831: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:19:25.831: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:19:25.831: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 22 09:19:25.839: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Sep 22 09:19:25.839: INFO: ss-0  ip-10-0-14-205  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  }]
Sep 22 09:19:25.839: INFO: ss-1  ip-10-0-30-60   Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:25.839: INFO: ss-2  ip-10-0-14-205  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:25.839: INFO: 
Sep 22 09:19:25.839: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 22 09:19:26.842: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Sep 22 09:19:26.843: INFO: ss-0  ip-10-0-14-205  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  }]
Sep 22 09:19:26.843: INFO: ss-1  ip-10-0-30-60   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:26.843: INFO: ss-2  ip-10-0-14-205  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:26.843: INFO: 
Sep 22 09:19:26.843: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 22 09:19:27.846: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Sep 22 09:19:27.846: INFO: ss-0  ip-10-0-14-205  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  }]
Sep 22 09:19:27.846: INFO: ss-1  ip-10-0-30-60   Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:27.846: INFO: ss-2  ip-10-0-14-205  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:54 +0000 UTC  }]
Sep 22 09:19:27.846: INFO: 
Sep 22 09:19:27.846: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 22 09:19:28.850: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Sep 22 09:19:28.850: INFO: ss-0  ip-10-0-14-205  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:19:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-22 09:18:33 +0000 UTC  }]
Sep 22 09:19:28.850: INFO: 
Sep 22 09:19:28.850: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 22 09:19:29.853: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.98627422s
Sep 22 09:19:30.859: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.983256454s
Sep 22 09:19:31.861: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.97734678s
Sep 22 09:19:32.865: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974547623s
Sep 22 09:19:33.868: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971580852s
Sep 22 09:19:34.871: INFO: Verifying statefulset ss doesn't scale past 0 for another 968.435481ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1022
Sep 22 09:19:35.874: INFO: Scaling statefulset ss to 0
Sep 22 09:19:35.886: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Sep 22 09:19:35.890: INFO: Deleting all statefulset in ns statefulset-1022
Sep 22 09:19:35.893: INFO: Scaling statefulset ss to 0
Sep 22 09:19:35.900: INFO: Waiting for statefulset status.replicas updated to 0
Sep 22 09:19:35.902: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:19:35.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1022" for this suite.
Sep 22 09:19:41.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:19:41.992: INFO: namespace statefulset-1022 deletion completed in 6.077439964s

• [SLOW TEST:68.091 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:19:41.992: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep 22 09:19:44.042: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-153516655 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 22 09:19:49.159: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:19:49.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9933" for this suite.
Sep 22 09:19:55.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:19:55.262: INFO: namespace pods-9933 deletion completed in 6.088731293s

• [SLOW TEST:13.270 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:19:55.262: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-57b09f65-7da1-4268-a7d2-38f86f85b244
STEP: Creating a pod to test consume secrets
Sep 22 09:19:55.303: INFO: Waiting up to 5m0s for pod "pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21" in namespace "secrets-1055" to be "success or failure"
Sep 22 09:19:55.307: INFO: Pod "pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21": Phase="Pending", Reason="", readiness=false. Elapsed: 3.633598ms
Sep 22 09:19:57.310: INFO: Pod "pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006739686s
STEP: Saw pod success
Sep 22 09:19:57.310: INFO: Pod "pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21" satisfied condition "success or failure"
Sep 22 09:19:57.313: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21 container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:19:57.337: INFO: Waiting for pod pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21 to disappear
Sep 22 09:19:57.348: INFO: Pod pod-secrets-7b2de21c-8230-4ec6-9d51-6b3d5b19cb21 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:19:57.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1055" for this suite.
Sep 22 09:20:03.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:20:03.450: INFO: namespace secrets-1055 deletion completed in 6.090949237s

• [SLOW TEST:8.189 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:20:03.451: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-465801fe-bf5a-4c8a-a784-2c03d803dcd5
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-465801fe-bf5a-4c8a-a784-2c03d803dcd5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:21:11.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9612" for this suite.
Sep 22 09:21:27.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:21:28.046: INFO: namespace projected-9612 deletion completed in 16.104875134s

• [SLOW TEST:84.596 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:21:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-5848.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5848.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-5848.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-5848.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-5848.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5848.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 22 09:21:32.113: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-5848.svc.cluster.local from pod dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137: the server could not find the requested resource (get pods dns-test-89af7b95-c003-457b-bd19-070fc4a4a137)
Sep 22 09:21:32.116: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-5848.svc.cluster.local from pod dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137: the server could not find the requested resource (get pods dns-test-89af7b95-c003-457b-bd19-070fc4a4a137)
Sep 22 09:21:32.143: INFO: Unable to read jessie_udp@dns-test-service-2.dns-5848.svc.cluster.local from pod dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137: the server could not find the requested resource (get pods dns-test-89af7b95-c003-457b-bd19-070fc4a4a137)
Sep 22 09:21:32.147: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-5848.svc.cluster.local from pod dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137: the server could not find the requested resource (get pods dns-test-89af7b95-c003-457b-bd19-070fc4a4a137)
Sep 22 09:21:32.153: INFO: Lookups using dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137 failed for: [wheezy_udp@dns-test-service-2.dns-5848.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-5848.svc.cluster.local jessie_udp@dns-test-service-2.dns-5848.svc.cluster.local jessie_tcp@dns-test-service-2.dns-5848.svc.cluster.local]

Sep 22 09:21:37.185: INFO: DNS probes using dns-5848/dns-test-89af7b95-c003-457b-bd19-070fc4a4a137 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:21:37.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5848" for this suite.
Sep 22 09:21:43.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:21:43.293: INFO: namespace dns-5848 deletion completed in 6.083542942s

• [SLOW TEST:15.247 seconds]
[sig-network] DNS
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:21:43.294: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:21:43.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5" in namespace "downward-api-2432" to be "success or failure"
Sep 22 09:21:43.330: INFO: Pod "downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.655672ms
Sep 22 09:21:45.332: INFO: Pod "downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005387541s
STEP: Saw pod success
Sep 22 09:21:45.333: INFO: Pod "downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5" satisfied condition "success or failure"
Sep 22 09:21:45.336: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5 container client-container: <nil>
STEP: delete the pod
Sep 22 09:21:45.351: INFO: Waiting for pod downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5 to disappear
Sep 22 09:21:45.353: INFO: Pod downwardapi-volume-a0f8a1e3-16c8-4294-b1fa-c9217495b9e5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:21:45.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2432" for this suite.
Sep 22 09:21:51.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:21:51.466: INFO: namespace downward-api-2432 deletion completed in 6.110110604s

• [SLOW TEST:8.172 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:21:51.466: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:21:51.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4182" for this suite.
Sep 22 09:21:57.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:21:57.588: INFO: namespace resourcequota-4182 deletion completed in 6.075734723s

• [SLOW TEST:6.122 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:21:57.588: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Sep 22 09:21:57.621: INFO: Waiting up to 5m0s for pod "downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0" in namespace "downward-api-3548" to be "success or failure"
Sep 22 09:21:57.623: INFO: Pod "downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121358ms
Sep 22 09:21:59.628: INFO: Pod "downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006810072s
STEP: Saw pod success
Sep 22 09:21:59.628: INFO: Pod "downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0" satisfied condition "success or failure"
Sep 22 09:21:59.630: INFO: Trying to get logs from node ip-10-0-14-205 pod downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0 container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:21:59.647: INFO: Waiting for pod downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0 to disappear
Sep 22 09:21:59.650: INFO: Pod downward-api-4d3673a9-9b8f-463d-aa8a-9cc4e14329a0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:21:59.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3548" for this suite.
Sep 22 09:22:05.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:05.735: INFO: namespace downward-api-3548 deletion completed in 6.081638422s

• [SLOW TEST:8.147 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:05.735: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:22:05.770: INFO: Waiting up to 5m0s for pod "downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285" in namespace "downward-api-6511" to be "success or failure"
Sep 22 09:22:05.779: INFO: Pod "downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285": Phase="Pending", Reason="", readiness=false. Elapsed: 9.034896ms
Sep 22 09:22:07.783: INFO: Pod "downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012223677s
STEP: Saw pod success
Sep 22 09:22:07.783: INFO: Pod "downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285" satisfied condition "success or failure"
Sep 22 09:22:07.785: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285 container client-container: <nil>
STEP: delete the pod
Sep 22 09:22:07.832: INFO: Waiting for pod downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285 to disappear
Sep 22 09:22:07.839: INFO: Pod downwardapi-volume-87a064dd-7064-4dd9-8990-1cf8bd8bd285 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:07.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6511" for this suite.
Sep 22 09:22:13.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:13.925: INFO: namespace downward-api-6511 deletion completed in 6.080107253s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:13.927: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-007dac20-10c3-4683-ab1d-1e429b583091
STEP: Creating a pod to test consume secrets
Sep 22 09:22:13.963: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51" in namespace "projected-631" to be "success or failure"
Sep 22 09:22:13.965: INFO: Pod "pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51": Phase="Pending", Reason="", readiness=false. Elapsed: 2.2257ms
Sep 22 09:22:15.969: INFO: Pod "pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005589057s
STEP: Saw pod success
Sep 22 09:22:15.969: INFO: Pod "pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51" satisfied condition "success or failure"
Sep 22 09:22:15.972: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:22:15.989: INFO: Waiting for pod pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51 to disappear
Sep 22 09:22:15.993: INFO: Pod pod-projected-secrets-329fe0c7-4ad5-4569-b7e9-6fa1cdea3d51 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:15.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-631" for this suite.
Sep 22 09:22:22.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:22.095: INFO: namespace projected-631 deletion completed in 6.078238041s

• [SLOW TEST:8.169 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:22.100: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:22:23.191: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 09:22:25.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704740943, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704740943, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704740943, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704740943, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:22:28.208: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Sep 22 09:22:28.221: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:28.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-866" for this suite.
Sep 22 09:22:34.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:34.323: INFO: namespace webhook-866 deletion completed in 6.089908703s
STEP: Destroying namespace "webhook-866-markers" for this suite.
Sep 22 09:22:40.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:40.407: INFO: namespace webhook-866-markers deletion completed in 6.083409688s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.319 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:40.419: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:22:40.452: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd" in namespace "downward-api-9677" to be "success or failure"
Sep 22 09:22:40.456: INFO: Pod "downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.979303ms
Sep 22 09:22:42.460: INFO: Pod "downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007274305s
STEP: Saw pod success
Sep 22 09:22:42.460: INFO: Pod "downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd" satisfied condition "success or failure"
Sep 22 09:22:42.463: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd container client-container: <nil>
STEP: delete the pod
Sep 22 09:22:42.487: INFO: Waiting for pod downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd to disappear
Sep 22 09:22:42.493: INFO: Pod downwardapi-volume-a754dad6-3def-4c5f-8d01-bcf50dfdf8cd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:42.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9677" for this suite.
Sep 22 09:22:48.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:48.578: INFO: namespace downward-api-9677 deletion completed in 6.080077162s

• [SLOW TEST:8.159 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:48.578: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Sep 22 09:22:49.125: INFO: created pod pod-service-account-defaultsa
Sep 22 09:22:49.125: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 22 09:22:49.128: INFO: created pod pod-service-account-mountsa
Sep 22 09:22:49.128: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 22 09:22:49.138: INFO: created pod pod-service-account-nomountsa
Sep 22 09:22:49.138: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 22 09:22:49.143: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 22 09:22:49.143: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 22 09:22:49.149: INFO: created pod pod-service-account-mountsa-mountspec
Sep 22 09:22:49.149: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 22 09:22:49.166: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 22 09:22:49.166: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 22 09:22:49.174: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 22 09:22:49.174: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 22 09:22:49.193: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 22 09:22:49.194: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 22 09:22:49.246: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 22 09:22:49.246: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:49.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-699" for this suite.
Sep 22 09:22:55.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:22:55.332: INFO: namespace svcaccounts-699 deletion completed in 6.079944167s

• [SLOW TEST:6.754 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:22:55.333: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:22:55.359: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:22:58.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7432" for this suite.
Sep 22 09:23:04.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:23:04.296: INFO: namespace custom-resource-definition-7432 deletion completed in 6.150977376s

• [SLOW TEST:8.963 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:23:04.296: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-2222efee-f59a-455f-90b7-c6c1f30ffb1b in namespace container-probe-8375
Sep 22 09:23:06.343: INFO: Started pod busybox-2222efee-f59a-455f-90b7-c6c1f30ffb1b in namespace container-probe-8375
STEP: checking the pod's current state and verifying that restartCount is present
Sep 22 09:23:06.347: INFO: Initial restart count of pod busybox-2222efee-f59a-455f-90b7-c6c1f30ffb1b is 0
Sep 22 09:23:56.429: INFO: Restart count of pod container-probe-8375/busybox-2222efee-f59a-455f-90b7-c6c1f30ffb1b is now 1 (50.082244307s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:23:56.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8375" for this suite.
Sep 22 09:24:02.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:24:02.549: INFO: namespace container-probe-8375 deletion completed in 6.10151792s

• [SLOW TEST:58.253 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:24:02.550: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-4941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4941 to expose endpoints map[]
Sep 22 09:24:02.601: INFO: successfully validated that service endpoint-test2 in namespace services-4941 exposes endpoints map[] (9.051967ms elapsed)
STEP: Creating pod pod1 in namespace services-4941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4941 to expose endpoints map[pod1:[80]]
Sep 22 09:24:04.629: INFO: successfully validated that service endpoint-test2 in namespace services-4941 exposes endpoints map[pod1:[80]] (2.019950017s elapsed)
STEP: Creating pod pod2 in namespace services-4941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4941 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 22 09:24:06.667: INFO: successfully validated that service endpoint-test2 in namespace services-4941 exposes endpoints map[pod1:[80] pod2:[80]] (2.033225996s elapsed)
STEP: Deleting pod pod1 in namespace services-4941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4941 to expose endpoints map[pod2:[80]]
Sep 22 09:24:06.683: INFO: successfully validated that service endpoint-test2 in namespace services-4941 exposes endpoints map[pod2:[80]] (11.990809ms elapsed)
STEP: Deleting pod pod2 in namespace services-4941
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4941 to expose endpoints map[]
Sep 22 09:24:06.696: INFO: successfully validated that service endpoint-test2 in namespace services-4941 exposes endpoints map[] (4.630001ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:24:06.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4941" for this suite.
Sep 22 09:24:18.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:24:18.801: INFO: namespace services-4941 deletion completed in 12.079670223s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.251 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:24:18.804: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:24:25.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1147" for this suite.
Sep 22 09:24:31.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:24:31.928: INFO: namespace resourcequota-1147 deletion completed in 6.084311532s

• [SLOW TEST:13.124 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:24:31.930: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:24:31.969: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 22 09:24:31.978: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:31.980: INFO: Number of nodes with available pods: 0
Sep 22 09:24:31.980: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:24:32.983: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:32.986: INFO: Number of nodes with available pods: 0
Sep 22 09:24:32.986: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:24:33.989: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:34.070: INFO: Number of nodes with available pods: 2
Sep 22 09:24:34.070: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 22 09:24:34.118: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:34.118: INFO: Wrong image for pod: daemon-set-wntm6. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:34.127: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:35.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:35.131: INFO: Wrong image for pod: daemon-set-wntm6. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:35.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:36.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:36.131: INFO: Wrong image for pod: daemon-set-wntm6. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:36.133: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:37.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:37.130: INFO: Wrong image for pod: daemon-set-wntm6. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:37.130: INFO: Pod daemon-set-wntm6 is not available
Sep 22 09:24:37.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:38.131: INFO: Pod daemon-set-6jb42 is not available
Sep 22 09:24:38.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:38.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:39.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:39.133: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:40.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:40.130: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:40.133: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:41.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:41.130: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:41.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:42.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:42.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:42.133: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:43.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:43.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:43.135: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:44.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:44.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:44.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:45.139: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:45.140: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:45.147: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:46.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:46.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:46.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:47.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:47.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:47.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:48.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:48.130: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:48.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:49.131: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:49.131: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:49.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:50.130: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:50.137: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:50.141: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:51.142: INFO: Wrong image for pod: daemon-set-q4mrb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Sep 22 09:24:51.142: INFO: Pod daemon-set-q4mrb is not available
Sep 22 09:24:51.150: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:52.131: INFO: Pod daemon-set-xxn69 is not available
Sep 22 09:24:52.134: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 22 09:24:52.137: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:52.139: INFO: Number of nodes with available pods: 1
Sep 22 09:24:52.139: INFO: Node ip-10-0-30-60 is running more than one daemon pod
Sep 22 09:24:53.143: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:24:53.146: INFO: Number of nodes with available pods: 2
Sep 22 09:24:53.146: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8861, will wait for the garbage collector to delete the pods
I0922 09:24:53.161386      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:24:53.161458      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:24:53.216: INFO: Deleting DaemonSet.extensions daemon-set took: 4.852678ms
I0922 09:24:53.516544      18 controller_utils.go:810] Ignoring inactive pod daemonsets-8861/daemon-set-6jb42 in state Running, deletion time 2019-09-22 09:25:23 +0000 UTC
I0922 09:24:53.516695      18 controller_utils.go:810] Ignoring inactive pod daemonsets-8861/daemon-set-xxn69 in state Running, deletion time 2019-09-22 09:25:23 +0000 UTC
Sep 22 09:24:53.517: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.788855ms
Sep 22 09:25:01.721: INFO: Number of nodes with available pods: 0
Sep 22 09:25:01.721: INFO: Number of running nodes: 0, number of available pods: 0
Sep 22 09:25:01.725: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8861/daemonsets","resourceVersion":"340736"},"items":null}

Sep 22 09:25:01.728: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8861/pods","resourceVersion":"340736"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:01.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8861" for this suite.
Sep 22 09:25:07.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:25:07.854: INFO: namespace daemonsets-8861 deletion completed in 6.08605737s

• [SLOW TEST:35.924 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:25:07.854: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5047
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5047
I0922 09:25:07.904674      18 runners.go:184] Created replication controller with name: externalname-service, namespace: services-5047, replica count: 2
I0922 09:25:07.904852      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:25:07.904893      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:25:10.956: INFO: Creating new exec pod
I0922 09:25:10.956839      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 09:25:12.988847      18 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I0922 09:25:12.988947      18 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Sep 22 09:25:13.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-5047 execpodvz27f -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 22 09:25:14.381: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 22 09:25:14.381: INFO: stdout: ""
Sep 22 09:25:14.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-5047 execpodvz27f -- /bin/sh -x -c nc -zv -t -w 2 10.3.209.233 80'
Sep 22 09:25:14.595: INFO: stderr: "+ nc -zv -t -w 2 10.3.209.233 80\nConnection to 10.3.209.233 80 port [tcp/http] succeeded!\n"
Sep 22 09:25:14.595: INFO: stdout: ""
Sep 22 09:25:14.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-5047 execpodvz27f -- /bin/sh -x -c nc -zv -t -w 2 10.0.14.205 32381'
Sep 22 09:25:14.796: INFO: stderr: "+ nc -zv -t -w 2 10.0.14.205 32381\nConnection to 10.0.14.205 32381 port [tcp/32381] succeeded!\n"
Sep 22 09:25:14.796: INFO: stdout: ""
Sep 22 09:25:14.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-5047 execpodvz27f -- /bin/sh -x -c nc -zv -t -w 2 10.0.30.60 32381'
Sep 22 09:25:14.968: INFO: stderr: "+ nc -zv -t -w 2 10.0.30.60 32381\nConnection to 10.0.30.60 32381 port [tcp/32381] succeeded!\n"
Sep 22 09:25:14.968: INFO: stdout: ""
Sep 22 09:25:14.968: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:14.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5047" for this suite.
Sep 22 09:25:20.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:25:21.079: INFO: namespace services-5047 deletion completed in 6.090858647s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.225 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:25:21.080: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8073/configmap-test-62da5bc9-cf68-469d-a1ac-a1c508153fa0
STEP: Creating a pod to test consume configMaps
Sep 22 09:25:21.115: INFO: Waiting up to 5m0s for pod "pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05" in namespace "configmap-8073" to be "success or failure"
Sep 22 09:25:21.119: INFO: Pod "pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05": Phase="Pending", Reason="", readiness=false. Elapsed: 3.325145ms
Sep 22 09:25:23.122: INFO: Pod "pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006393472s
STEP: Saw pod success
Sep 22 09:25:23.122: INFO: Pod "pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05" satisfied condition "success or failure"
Sep 22 09:25:23.124: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05 container env-test: <nil>
STEP: delete the pod
Sep 22 09:25:23.150: INFO: Waiting for pod pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05 to disappear
Sep 22 09:25:23.152: INFO: Pod pod-configmaps-89d0cb46-e1d1-4597-958a-796aae71cf05 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:23.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8073" for this suite.
Sep 22 09:25:29.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:25:29.250: INFO: namespace configmap-8073 deletion completed in 6.094400538s

• [SLOW TEST:8.170 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:25:29.250: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7976
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7976
STEP: creating replication controller externalsvc in namespace services-7976
I0922 09:25:29.316135      18 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7976, replica count: 2
I0922 09:25:29.316396      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:25:29.316478      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:25:32.368562      18 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Sep 22 09:25:32.379: INFO: Creating new exec pod
Sep 22 09:25:34.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-7976 execpod9p584 -- /bin/sh -x -c nslookup clusterip-service'
Sep 22 09:25:34.631: INFO: stderr: "+ nslookup clusterip-service\n"
Sep 22 09:25:34.631: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-7976.svc.cluster.local\tcanonical name = externalsvc.services-7976.svc.cluster.local.\nName:\texternalsvc.services-7976.svc.cluster.local\nAddress: 10.3.98.153\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7976, will wait for the garbage collector to delete the pods
I0922 09:25:34.637573      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:25:34.637831      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:25:34.692: INFO: Deleting ReplicationController externalsvc took: 4.936329ms
Sep 22 09:25:34.992: INFO: Terminating ReplicationController externalsvc pods took: 300.224727ms
I0922 09:25:34.992788      18 controller_utils.go:810] Ignoring inactive pod services-7976/externalsvc-m2kc8 in state Running, deletion time 2019-09-22 09:25:35 +0000 UTC
I0922 09:25:34.992824      18 controller_utils.go:810] Ignoring inactive pod services-7976/externalsvc-8pkhw in state Running, deletion time 2019-09-22 09:25:35 +0000 UTC
Sep 22 09:25:41.723: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:41.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7976" for this suite.
Sep 22 09:25:47.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:25:47.838: INFO: namespace services-7976 deletion completed in 6.089007117s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.588 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:25:47.838: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5fb40646-baae-4855-9b5b-2eb6d479d743
STEP: Creating a pod to test consume secrets
Sep 22 09:25:47.871: INFO: Waiting up to 5m0s for pod "pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b" in namespace "secrets-5747" to be "success or failure"
Sep 22 09:25:47.881: INFO: Pod "pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.747258ms
Sep 22 09:25:49.884: INFO: Pod "pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012720945s
STEP: Saw pod success
Sep 22 09:25:49.884: INFO: Pod "pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b" satisfied condition "success or failure"
Sep 22 09:25:49.886: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:25:49.905: INFO: Waiting for pod pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b to disappear
Sep 22 09:25:49.908: INFO: Pod pod-secrets-31f7cc30-41b3-4633-ade3-5f1316838c6b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:49.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5747" for this suite.
Sep 22 09:25:55.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:25:56.012: INFO: namespace secrets-5747 deletion completed in 6.101791635s

• [SLOW TEST:8.174 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:25:56.012: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-7efd9109-1631-4885-9da4-7a1dcadc592c
STEP: Creating a pod to test consume configMaps
Sep 22 09:25:56.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275" in namespace "configmap-106" to be "success or failure"
Sep 22 09:25:56.066: INFO: Pod "pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275": Phase="Pending", Reason="", readiness=false. Elapsed: 7.052775ms
Sep 22 09:25:58.069: INFO: Pod "pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010341281s
STEP: Saw pod success
Sep 22 09:25:58.069: INFO: Pod "pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275" satisfied condition "success or failure"
Sep 22 09:25:58.074: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 22 09:25:58.097: INFO: Waiting for pod pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275 to disappear
Sep 22 09:25:58.102: INFO: Pod pod-configmaps-07c0cdf2-40f8-4082-8b57-22f5b47aa275 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:25:58.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-106" for this suite.
Sep 22 09:26:04.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:26:04.184: INFO: namespace configmap-106 deletion completed in 6.078288949s

• [SLOW TEST:8.172 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:26:04.189: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:26:08.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5470" for this suite.
Sep 22 09:26:14.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:26:14.318: INFO: namespace kubelet-test-5470 deletion completed in 6.080737551s

• [SLOW TEST:10.129 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:26:14.318: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:26:25.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9548" for this suite.
Sep 22 09:26:31.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:26:31.491: INFO: namespace resourcequota-9548 deletion completed in 6.079369119s

• [SLOW TEST:17.173 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:26:31.492: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Sep 22 09:26:31.541: INFO: Waiting up to 5m0s for pod "var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213" in namespace "var-expansion-5543" to be "success or failure"
Sep 22 09:26:31.546: INFO: Pod "var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213": Phase="Pending", Reason="", readiness=false. Elapsed: 4.167077ms
Sep 22 09:26:33.549: INFO: Pod "var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007893977s
STEP: Saw pod success
Sep 22 09:26:33.549: INFO: Pod "var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213" satisfied condition "success or failure"
Sep 22 09:26:33.553: INFO: Trying to get logs from node ip-10-0-14-205 pod var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213 container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:26:33.570: INFO: Waiting for pod var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213 to disappear
Sep 22 09:26:33.573: INFO: Pod var-expansion-0e54e793-2cb8-4ff3-b05a-4d34998b4213 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:26:33.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5543" for this suite.
Sep 22 09:26:39.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:26:39.689: INFO: namespace var-expansion-5543 deletion completed in 6.109509423s

• [SLOW TEST:8.198 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:26:39.690: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Sep 22 09:26:39.731: INFO: Waiting up to 5m0s for pod "var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4" in namespace "var-expansion-4075" to be "success or failure"
Sep 22 09:26:39.737: INFO: Pod "var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.990957ms
Sep 22 09:26:41.740: INFO: Pod "var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008076175s
STEP: Saw pod success
Sep 22 09:26:41.740: INFO: Pod "var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4" satisfied condition "success or failure"
Sep 22 09:26:41.743: INFO: Trying to get logs from node ip-10-0-14-205 pod var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4 container dapi-container: <nil>
STEP: delete the pod
Sep 22 09:26:41.757: INFO: Waiting for pod var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4 to disappear
Sep 22 09:26:41.759: INFO: Pod var-expansion-997ac3a9-5474-4d5d-bd82-68239c2b48f4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:26:41.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4075" for this suite.
Sep 22 09:26:47.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:26:47.928: INFO: namespace var-expansion-4075 deletion completed in 6.166092284s

• [SLOW TEST:8.238 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:26:47.929: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 22 09:27:17.996: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:27:17.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0922 09:27:17.996432      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2940" for this suite.
Sep 22 09:27:24.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:27:24.117: INFO: namespace gc-2940 deletion completed in 6.101757345s

• [SLOW TEST:36.188 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:27:24.118: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:27:24.148: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 22 09:27:29.151: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 22 09:27:29.152: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Sep 22 09:27:29.172: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9210 /apis/apps/v1/namespaces/deployment-9210/deployments/test-cleanup-deployment d83cf33a-f577-4156-9a53-b890457ccea0 341469 1 2019-09-22 09:27:29 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008b64f28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Sep 22 09:27:29.191: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-9210 /apis/apps/v1/namespaces/deployment-9210/replicasets/test-cleanup-deployment-65db99849b 385fda1b-d3e5-4493-a313-be5be5e21296 341471 1 2019-09-22 09:27:29 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment d83cf33a-f577-4156-9a53-b890457ccea0 0xc0089ae547 0xc0089ae548}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0089ae5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Sep 22 09:27:29.191: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 22 09:27:29.192: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9210 /apis/apps/v1/namespaces/deployment-9210/replicasets/test-cleanup-controller 530815a9-39e4-48b9-87ea-09230ff6f270 341470 1 2019-09-22 09:27:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment d83cf33a-f577-4156-9a53-b890457ccea0 0xc0089ae477 0xc0089ae478}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0089ae4d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Sep 22 09:27:29.201: INFO: Pod "test-cleanup-controller-f5hrm" is available:
&Pod{ObjectMeta:{test-cleanup-controller-f5hrm test-cleanup-controller- deployment-9210 /api/v1/namespaces/deployment-9210/pods/test-cleanup-controller-f5hrm c1aec5f2-dddd-4a5c-8e24-bacc6e07de4e 341463 0 2019-09-22 09:27:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:10.2.212.214/32] [{apps/v1 ReplicaSet test-cleanup-controller 530815a9-39e4-48b9-87ea-09230ff6f270 0xc0089aec87 0xc0089aec88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2z44h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2z44h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2z44h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 09:27:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 09:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 09:27:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 09:27:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.14.205,PodIP:10.2.212.214,StartTime:2019-09-22 09:27:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-09-22 09:27:24 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://05f80c3a54daea63621b0a045cde428e084c9da99899d57fc27f932e73ec6e7c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.212.214,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Sep 22 09:27:29.201: INFO: Pod "test-cleanup-deployment-65db99849b-n8p7w" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-n8p7w test-cleanup-deployment-65db99849b- deployment-9210 /api/v1/namespaces/deployment-9210/pods/test-cleanup-deployment-65db99849b-n8p7w 4bd3d94e-b670-439b-9f2f-9c9f08ed7fd7 341474 0 2019-09-22 09:27:29 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 385fda1b-d3e5-4493-a313-be5be5e21296 0xc0089aee97 0xc0089aee98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2z44h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2z44h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2z44h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-14-205,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-09-22 09:27:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:27:29.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9210" for this suite.
Sep 22 09:27:35.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:27:35.296: INFO: namespace deployment-9210 deletion completed in 6.089693847s

• [SLOW TEST:11.179 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:27:35.297: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:27:35.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6718" for this suite.
Sep 22 09:27:47.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:27:47.426: INFO: namespace pods-6718 deletion completed in 12.077592632s

• [SLOW TEST:12.129 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:27:47.427: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:27:47.472: INFO: Create a RollingUpdate DaemonSet
Sep 22 09:27:47.475: INFO: Check that daemon pods launch on every node of the cluster
Sep 22 09:27:47.482: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:27:47.485: INFO: Number of nodes with available pods: 0
Sep 22 09:27:47.485: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:27:48.493: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:27:48.498: INFO: Number of nodes with available pods: 1
Sep 22 09:27:48.498: INFO: Node ip-10-0-30-60 is running more than one daemon pod
Sep 22 09:27:49.488: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:27:49.491: INFO: Number of nodes with available pods: 2
Sep 22 09:27:49.491: INFO: Number of running nodes: 2, number of available pods: 2
Sep 22 09:27:49.491: INFO: Update the DaemonSet to trigger a rollout
Sep 22 09:27:49.497: INFO: Updating DaemonSet daemon-set
Sep 22 09:27:55.509: INFO: Roll back the DaemonSet before rollout is complete
Sep 22 09:27:55.514: INFO: Updating DaemonSet daemon-set
Sep 22 09:27:55.514: INFO: Make sure DaemonSet rollback is complete
Sep 22 09:27:55.517: INFO: Wrong image for pod: daemon-set-dfzxd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 22 09:27:55.517: INFO: Pod daemon-set-dfzxd is not available
Sep 22 09:27:55.520: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:27:56.524: INFO: Wrong image for pod: daemon-set-dfzxd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Sep 22 09:27:56.524: INFO: Pod daemon-set-dfzxd is not available
Sep 22 09:27:56.527: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:27:57.523: INFO: Pod daemon-set-g5th6 is not available
Sep 22 09:27:57.526: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2198, will wait for the garbage collector to delete the pods
I0922 09:27:57.534704      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:27:57.535191      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:27:57.589: INFO: Deleting DaemonSet.extensions daemon-set took: 5.03088ms
I0922 09:27:57.890086      18 controller_utils.go:810] Ignoring inactive pod daemonsets-2198/daemon-set-pbh4x in state Running, deletion time 2019-09-22 09:28:27 +0000 UTC
I0922 09:27:57.890387      18 controller_utils.go:810] Ignoring inactive pod daemonsets-2198/daemon-set-g5th6 in state Pending, deletion time 2019-09-22 09:28:27 +0000 UTC
Sep 22 09:27:57.890: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.601519ms
Sep 22 09:27:59.793: INFO: Number of nodes with available pods: 0
Sep 22 09:27:59.794: INFO: Number of running nodes: 0, number of available pods: 0
Sep 22 09:27:59.798: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2198/daemonsets","resourceVersion":"341682"},"items":null}

Sep 22 09:27:59.801: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2198/pods","resourceVersion":"341682"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:27:59.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2198" for this suite.
Sep 22 09:28:05.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:28:05.896: INFO: namespace daemonsets-2198 deletion completed in 6.0799282s

• [SLOW TEST:18.469 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:28:05.897: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
I0922 09:28:05.926715      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/client-go/tools/watch/informerwatcher.go:146
I0922 09:28:05.927157      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/client-go/tools/watch/informerwatcher.go:146
Sep 22 09:28:05.929: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 22 09:28:12.961: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:28:12.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1428" for this suite.
Sep 22 09:28:18.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:28:19.075: INFO: namespace pods-1428 deletion completed in 6.107397549s

• [SLOW TEST:13.178 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:28:19.077: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-ff898f68-26b5-4482-8978-904fd8361dd1
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:28:19.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-112" for this suite.
Sep 22 09:28:25.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:28:25.208: INFO: namespace configmap-112 deletion completed in 6.090964841s

• [SLOW TEST:6.131 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:28:25.208: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 22 09:28:25.236: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:28:29.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3822" for this suite.
Sep 22 09:28:41.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:28:41.150: INFO: namespace init-container-3822 deletion completed in 12.099022618s

• [SLOW TEST:15.942 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:28:41.151: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:29:03.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1851" for this suite.
Sep 22 09:29:09.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:29:09.457: INFO: namespace container-runtime-1851 deletion completed in 6.081372535s

• [SLOW TEST:28.306 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:29:09.457: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 22 09:29:09.494: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7544 /api/v1/namespaces/watch-7544/configmaps/e2e-watch-test-watch-closed 292856b9-f9ad-451f-b124-018a42b18e18 342003 0 2019-09-22 09:29:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 22 09:29:09.494: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7544 /api/v1/namespaces/watch-7544/configmaps/e2e-watch-test-watch-closed 292856b9-f9ad-451f-b124-018a42b18e18 342004 0 2019-09-22 09:29:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 22 09:29:09.505: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7544 /api/v1/namespaces/watch-7544/configmaps/e2e-watch-test-watch-closed 292856b9-f9ad-451f-b124-018a42b18e18 342005 0 2019-09-22 09:29:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 22 09:29:09.505: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7544 /api/v1/namespaces/watch-7544/configmaps/e2e-watch-test-watch-closed 292856b9-f9ad-451f-b124-018a42b18e18 342006 0 2019-09-22 09:29:09 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:29:09.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7544" for this suite.
Sep 22 09:29:15.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:29:15.590: INFO: namespace watch-7544 deletion completed in 6.082752735s

• [SLOW TEST:6.134 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:29:15.590: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-7616
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7616
STEP: Deleting pre-stop pod
Sep 22 09:29:24.659: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:29:24.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7616" for this suite.
Sep 22 09:30:02.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:30:02.809: INFO: namespace prestop-7616 deletion completed in 38.136085492s

• [SLOW TEST:47.219 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:30:02.810: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-071d2393-a2bc-478b-9a83-d5c482d5a307
STEP: Creating configMap with name cm-test-opt-upd-f135d920-d798-4c74-b767-507afe6d3317
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-071d2393-a2bc-478b-9a83-d5c482d5a307
STEP: Updating configmap cm-test-opt-upd-f135d920-d798-4c74-b767-507afe6d3317
STEP: Creating configMap with name cm-test-opt-create-91f27156-9ce6-40fe-8376-4a4381f75fa9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:30:06.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7846" for this suite.
Sep 22 09:30:35.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:30:35.161: INFO: namespace projected-7846 deletion completed in 28.15819258s

• [SLOW TEST:32.351 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:30:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:30:37.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7484" for this suite.
Sep 22 09:30:43.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:30:43.314: INFO: namespace emptydir-wrapper-7484 deletion completed in 6.073443442s

• [SLOW TEST:8.151 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:30:43.314: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Sep 22 09:30:43.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-5208'
Sep 22 09:30:43.580: INFO: stderr: ""
Sep 22 09:30:43.580: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:30:43.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5208'
Sep 22 09:30:43.710: INFO: stderr: ""
Sep 22 09:30:43.710: INFO: stdout: "update-demo-nautilus-5fmv8 update-demo-nautilus-zqbxd "
Sep 22 09:30:43.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-5fmv8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:30:43.791: INFO: stderr: ""
Sep 22 09:30:43.791: INFO: stdout: ""
Sep 22 09:30:43.791: INFO: update-demo-nautilus-5fmv8 is created but not running
Sep 22 09:30:48.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5208'
Sep 22 09:30:48.880: INFO: stderr: ""
Sep 22 09:30:48.880: INFO: stdout: "update-demo-nautilus-5fmv8 update-demo-nautilus-zqbxd "
Sep 22 09:30:48.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-5fmv8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:30:48.967: INFO: stderr: ""
Sep 22 09:30:48.967: INFO: stdout: "true"
Sep 22 09:30:48.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-5fmv8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:30:49.100: INFO: stderr: ""
Sep 22 09:30:49.100: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:30:49.100: INFO: validating pod update-demo-nautilus-5fmv8
Sep 22 09:30:49.111: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:30:49.112: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:30:49.112: INFO: update-demo-nautilus-5fmv8 is verified up and running
Sep 22 09:30:49.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-zqbxd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:30:49.212: INFO: stderr: ""
Sep 22 09:30:49.212: INFO: stdout: "true"
Sep 22 09:30:49.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-zqbxd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:30:49.310: INFO: stderr: ""
Sep 22 09:30:49.310: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:30:49.310: INFO: validating pod update-demo-nautilus-zqbxd
Sep 22 09:30:49.317: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:30:49.317: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:30:49.317: INFO: update-demo-nautilus-zqbxd is verified up and running
STEP: rolling-update to new replication controller
Sep 22 09:30:49.322: INFO: scanned /root for discovery docs: <nil>
Sep 22 09:30:49.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-5208'
Sep 22 09:31:06.801: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 22 09:31:06.801: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:31:06.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-5208'
Sep 22 09:31:06.912: INFO: stderr: ""
Sep 22 09:31:06.912: INFO: stdout: "update-demo-kitten-nrwlg update-demo-kitten-zhgnd "
Sep 22 09:31:06.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-kitten-nrwlg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:31:07.010: INFO: stderr: ""
Sep 22 09:31:07.011: INFO: stdout: "true"
Sep 22 09:31:07.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-kitten-nrwlg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:31:07.103: INFO: stderr: ""
Sep 22 09:31:07.103: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 22 09:31:07.103: INFO: validating pod update-demo-kitten-nrwlg
Sep 22 09:31:07.110: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 22 09:31:07.111: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 22 09:31:07.111: INFO: update-demo-kitten-nrwlg is verified up and running
Sep 22 09:31:07.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-kitten-zhgnd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:31:07.199: INFO: stderr: ""
Sep 22 09:31:07.199: INFO: stdout: "true"
Sep 22 09:31:07.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-kitten-zhgnd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5208'
Sep 22 09:31:07.284: INFO: stderr: ""
Sep 22 09:31:07.284: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 22 09:31:07.284: INFO: validating pod update-demo-kitten-zhgnd
Sep 22 09:31:07.288: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 22 09:31:07.288: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 22 09:31:07.288: INFO: update-demo-kitten-zhgnd is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:31:07.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5208" for this suite.
Sep 22 09:31:35.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:31:35.386: INFO: namespace kubectl-5208 deletion completed in 28.094675198s

• [SLOW TEST:52.072 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:31:35.386: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-d5101adf-8713-465b-94cd-8950475a69ba
STEP: Creating secret with name secret-projected-all-test-volume-64121f5f-a040-4f68-ba3b-f336d83e5c2d
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 22 09:31:35.435: INFO: Waiting up to 5m0s for pod "projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc" in namespace "projected-8386" to be "success or failure"
Sep 22 09:31:35.444: INFO: Pod "projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.142786ms
Sep 22 09:31:37.447: INFO: Pod "projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012090898s
STEP: Saw pod success
Sep 22 09:31:37.447: INFO: Pod "projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc" satisfied condition "success or failure"
Sep 22 09:31:37.450: INFO: Trying to get logs from node ip-10-0-14-205 pod projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 22 09:31:37.535: INFO: Waiting for pod projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc to disappear
Sep 22 09:31:37.538: INFO: Pod projected-volume-bceb812b-fdec-4c9c-a6d1-69812d03cccc no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:31:37.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8386" for this suite.
Sep 22 09:31:43.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:31:43.633: INFO: namespace projected-8386 deletion completed in 6.093071425s

• [SLOW TEST:8.247 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:31:43.644: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-45c75bc1-81c1-4e40-a828-081aa8be4c54
STEP: Creating a pod to test consume secrets
Sep 22 09:31:43.716: INFO: Waiting up to 5m0s for pod "pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8" in namespace "secrets-7853" to be "success or failure"
Sep 22 09:31:43.721: INFO: Pod "pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.910184ms
Sep 22 09:31:45.725: INFO: Pod "pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008336443s
STEP: Saw pod success
Sep 22 09:31:45.725: INFO: Pod "pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8" satisfied condition "success or failure"
Sep 22 09:31:45.729: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8 container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:31:45.757: INFO: Waiting for pod pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8 to disappear
Sep 22 09:31:45.759: INFO: Pod pod-secrets-5b1951d1-0bee-45fe-a7c0-315c248bdda8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:31:45.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7853" for this suite.
Sep 22 09:31:51.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:31:51.847: INFO: namespace secrets-7853 deletion completed in 6.085091911s
STEP: Destroying namespace "secret-namespace-936" for this suite.
Sep 22 09:31:57.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:31:57.935: INFO: namespace secret-namespace-936 deletion completed in 6.088019314s

• [SLOW TEST:14.291 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:31:57.935: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1574
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1574
I0922 09:31:57.988397      18 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1574, replica count: 2
I0922 09:31:57.988648      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:31:57.988716      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:32:01.038: INFO: Creating new exec pod
I0922 09:32:01.038949      18 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 09:32:03.054009      18 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I0922 09:32:03.054211      18 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Sep 22 09:32:04.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1574 execpodv6x6g -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Sep 22 09:32:04.268: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Sep 22 09:32:04.268: INFO: stdout: ""
Sep 22 09:32:04.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1574 execpodv6x6g -- /bin/sh -x -c nc -zv -t -w 2 10.3.140.190 80'
Sep 22 09:32:04.634: INFO: stderr: "+ nc -zv -t -w 2 10.3.140.190 80\nConnection to 10.3.140.190 80 port [tcp/http] succeeded!\n"
Sep 22 09:32:04.634: INFO: stdout: ""
Sep 22 09:32:04.634: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:32:04.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1574" for this suite.
Sep 22 09:32:10.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:32:10.729: INFO: namespace services-1574 deletion completed in 6.07703166s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.794 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:32:10.735: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6930
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 22 09:32:10.770: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 22 09:32:28.829: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.212.234 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6930 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:32:28.829: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:32:29.944: INFO: Found all expected endpoints: [netserver-0]
Sep 22 09:32:29.947: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.56.216 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6930 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 22 09:32:29.947: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
Sep 22 09:32:31.134: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:32:31.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6930" for this suite.
Sep 22 09:32:43.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:32:43.216: INFO: namespace pod-network-test-6930 deletion completed in 12.078121052s

• [SLOW TEST:32.481 seconds]
[sig-network] Networking
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:32:43.217: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:32:43.274: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"ca2cec8e-0cef-4ff9-b473-9b98aafab057", Controller:(*bool)(0xc0045871d2), BlockOwnerDeletion:(*bool)(0xc0045871d3)}}
Sep 22 09:32:43.280: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0b5f7ee4-f4e8-4af6-a2d3-7b6f5d57eb7b", Controller:(*bool)(0xc0045873da), BlockOwnerDeletion:(*bool)(0xc0045873db)}}
Sep 22 09:32:43.287: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"92512086-1b30-441b-bf93-0b00121d1a5d", Controller:(*bool)(0xc0038dab62), BlockOwnerDeletion:(*bool)(0xc0038dab63)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:32:48.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6416" for this suite.
Sep 22 09:32:54.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:32:54.389: INFO: namespace gc-6416 deletion completed in 6.084147689s

• [SLOW TEST:11.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:32:54.390: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:33:11.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3644" for this suite.
Sep 22 09:33:17.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:33:17.547: INFO: namespace resourcequota-3644 deletion completed in 6.084782663s

• [SLOW TEST:23.157 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:33:17.548: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Sep 22 09:33:17.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-8687'
Sep 22 09:33:17.797: INFO: stderr: ""
Sep 22 09:33:17.797: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:33:17.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8687'
Sep 22 09:33:17.907: INFO: stderr: ""
Sep 22 09:33:17.907: INFO: stdout: "update-demo-nautilus-v7dbl update-demo-nautilus-vk7cg "
Sep 22 09:33:17.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:18.035: INFO: stderr: ""
Sep 22 09:33:18.035: INFO: stdout: ""
Sep 22 09:33:18.035: INFO: update-demo-nautilus-v7dbl is created but not running
Sep 22 09:33:23.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8687'
Sep 22 09:33:23.126: INFO: stderr: ""
Sep 22 09:33:23.126: INFO: stdout: "update-demo-nautilus-v7dbl update-demo-nautilus-vk7cg "
Sep 22 09:33:23.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:23.224: INFO: stderr: ""
Sep 22 09:33:23.224: INFO: stdout: "true"
Sep 22 09:33:23.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:23.319: INFO: stderr: ""
Sep 22 09:33:23.319: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:33:23.320: INFO: validating pod update-demo-nautilus-v7dbl
Sep 22 09:33:23.324: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:33:23.325: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:33:23.325: INFO: update-demo-nautilus-v7dbl is verified up and running
Sep 22 09:33:23.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-vk7cg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:23.410: INFO: stderr: ""
Sep 22 09:33:23.410: INFO: stdout: "true"
Sep 22 09:33:23.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-vk7cg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:23.564: INFO: stderr: ""
Sep 22 09:33:23.564: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:33:23.564: INFO: validating pod update-demo-nautilus-vk7cg
Sep 22 09:33:23.569: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:33:23.569: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:33:23.569: INFO: update-demo-nautilus-vk7cg is verified up and running
STEP: scaling down the replication controller
Sep 22 09:33:23.579: INFO: scanned /root for discovery docs: <nil>
Sep 22 09:33:23.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8687'
Sep 22 09:33:23.836: INFO: stderr: ""
Sep 22 09:33:23.836: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:33:23.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8687'
Sep 22 09:33:23.918: INFO: stderr: ""
Sep 22 09:33:23.918: INFO: stdout: "update-demo-nautilus-v7dbl update-demo-nautilus-vk7cg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 22 09:33:28.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8687'
Sep 22 09:33:29.033: INFO: stderr: ""
Sep 22 09:33:29.033: INFO: stdout: "update-demo-nautilus-v7dbl "
Sep 22 09:33:29.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:29.128: INFO: stderr: ""
Sep 22 09:33:29.128: INFO: stdout: "true"
Sep 22 09:33:29.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:29.217: INFO: stderr: ""
Sep 22 09:33:29.217: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:33:29.217: INFO: validating pod update-demo-nautilus-v7dbl
Sep 22 09:33:29.223: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:33:29.223: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:33:29.223: INFO: update-demo-nautilus-v7dbl is verified up and running
STEP: scaling up the replication controller
Sep 22 09:33:29.226: INFO: scanned /root for discovery docs: <nil>
Sep 22 09:33:29.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8687'
Sep 22 09:33:30.341: INFO: stderr: ""
Sep 22 09:33:30.341: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:33:30.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8687'
Sep 22 09:33:30.433: INFO: stderr: ""
Sep 22 09:33:30.433: INFO: stdout: "update-demo-nautilus-gkvwk update-demo-nautilus-v7dbl "
Sep 22 09:33:30.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-gkvwk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:30.519: INFO: stderr: ""
Sep 22 09:33:30.519: INFO: stdout: "true"
Sep 22 09:33:30.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-gkvwk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:30.614: INFO: stderr: ""
Sep 22 09:33:30.614: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:33:30.614: INFO: validating pod update-demo-nautilus-gkvwk
Sep 22 09:33:30.620: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:33:30.620: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:33:30.620: INFO: update-demo-nautilus-gkvwk is verified up and running
Sep 22 09:33:30.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:30.725: INFO: stderr: ""
Sep 22 09:33:30.725: INFO: stdout: "true"
Sep 22 09:33:30.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-v7dbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8687'
Sep 22 09:33:30.918: INFO: stderr: ""
Sep 22 09:33:30.918: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:33:30.918: INFO: validating pod update-demo-nautilus-v7dbl
Sep 22 09:33:30.929: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:33:30.929: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:33:30.929: INFO: update-demo-nautilus-v7dbl is verified up and running
STEP: using delete to clean up resources
Sep 22 09:33:30.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-8687'
Sep 22 09:33:31.067: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 09:33:31.067: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 22 09:33:31.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8687'
Sep 22 09:33:31.153: INFO: stderr: "No resources found in kubectl-8687 namespace.\n"
Sep 22 09:33:31.153: INFO: stdout: ""
Sep 22 09:33:31.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -l name=update-demo --namespace=kubectl-8687 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 22 09:33:31.234: INFO: stderr: ""
Sep 22 09:33:31.234: INFO: stdout: "update-demo-nautilus-gkvwk\nupdate-demo-nautilus-v7dbl\n"
Sep 22 09:33:31.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8687'
Sep 22 09:33:31.860: INFO: stderr: "No resources found in kubectl-8687 namespace.\n"
Sep 22 09:33:31.860: INFO: stdout: ""
Sep 22 09:33:31.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -l name=update-demo --namespace=kubectl-8687 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 22 09:33:31.957: INFO: stderr: ""
Sep 22 09:33:31.957: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:33:31.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8687" for this suite.
Sep 22 09:33:59.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:34:00.095: INFO: namespace kubectl-8687 deletion completed in 28.133873029s

• [SLOW TEST:42.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:34:00.096: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Sep 22 09:34:00.130: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:34:02.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7909" for this suite.
Sep 22 09:34:08.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:34:08.925: INFO: namespace init-container-7909 deletion completed in 6.104461423s

• [SLOW TEST:8.829 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:34:08.925: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 22 09:34:13.018: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:13.021: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:15.023: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:15.027: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:17.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:17.025: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:19.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:19.026: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:21.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:21.025: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:23.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:23.025: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:25.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:25.027: INFO: Pod pod-with-prestop-http-hook still exists
Sep 22 09:34:27.022: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 22 09:34:27.025: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:34:27.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8802" for this suite.
Sep 22 09:34:55.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:34:55.167: INFO: namespace container-lifecycle-hook-8802 deletion completed in 28.085247161s

• [SLOW TEST:46.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:34:55.170: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 22 09:34:59.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec pod-sharedvolume-f4461088-ecde-4172-b9c9-1c7eac6e5b0c -c busybox-main-container --namespace=emptydir-6618 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 22 09:34:59.416: INFO: stderr: ""
Sep 22 09:34:59.416: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:34:59.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6618" for this suite.
Sep 22 09:35:05.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:35:05.495: INFO: namespace emptydir-6618 deletion completed in 6.075594135s

• [SLOW TEST:10.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:35:05.496: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:35:11.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5536" for this suite.
Sep 22 09:35:17.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:35:17.684: INFO: namespace namespaces-5536 deletion completed in 6.077138401s
STEP: Destroying namespace "nsdeletetest-8725" for this suite.
Sep 22 09:35:17.686: INFO: Namespace nsdeletetest-8725 was already deleted
STEP: Destroying namespace "nsdeletetest-9614" for this suite.
Sep 22 09:35:23.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:35:23.764: INFO: namespace nsdeletetest-9614 deletion completed in 6.078286883s

• [SLOW TEST:18.268 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:35:23.764: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:35:39.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4583" for this suite.
Sep 22 09:35:45.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:35:45.974: INFO: namespace resourcequota-4583 deletion completed in 6.091063228s

• [SLOW TEST:22.210 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:35:45.975: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Sep 22 09:35:46.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 api-versions'
Sep 22 09:35:46.261: INFO: stderr: ""
Sep 22 09:35:46.261: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:35:46.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6600" for this suite.
Sep 22 09:35:52.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:35:52.354: INFO: namespace kubectl-6600 deletion completed in 6.089634929s

• [SLOW TEST:6.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:35:52.355: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Sep 22 09:35:52.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9434'
Sep 22 09:35:52.659: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 22 09:35:52.659: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Sep 22 09:35:54.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9434'
Sep 22 09:35:54.766: INFO: stderr: ""
Sep 22 09:35:54.766: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:35:54.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9434" for this suite.
Sep 22 09:36:00.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:00.879: INFO: namespace kubectl-9434 deletion completed in 6.108411689s

• [SLOW TEST:8.525 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:36:00.880: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0922 09:36:02.013664      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 22 09:36:02.013: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:36:02.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5906" for this suite.
Sep 22 09:36:08.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:08.116: INFO: namespace gc-5906 deletion completed in 6.095791373s

• [SLOW TEST:7.236 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:36:08.116: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:36:08.589: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:36:11.605: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:36:11.607: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:36:12.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1910" for this suite.
Sep 22 09:36:18.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:18.329: INFO: namespace webhook-1910 deletion completed in 6.085901204s
STEP: Destroying namespace "webhook-1910-markers" for this suite.
Sep 22 09:36:24.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:24.411: INFO: namespace webhook-1910-markers deletion completed in 6.082514934s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.307 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:36:24.430: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-ebdf08d7-cd94-4718-ac6c-27271808032c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:36:24.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1295" for this suite.
Sep 22 09:36:30.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:30.546: INFO: namespace secrets-1295 deletion completed in 6.083707944s

• [SLOW TEST:6.116 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:36:30.547: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Sep 22 09:36:30.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 create -f - --namespace=kubectl-6055'
Sep 22 09:36:30.764: INFO: stderr: ""
Sep 22 09:36:30.764: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 22 09:36:30.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6055'
Sep 22 09:36:30.876: INFO: stderr: ""
Sep 22 09:36:30.876: INFO: stdout: "update-demo-nautilus-h5lnq update-demo-nautilus-m5659 "
Sep 22 09:36:30.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-h5lnq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6055'
Sep 22 09:36:31.012: INFO: stderr: ""
Sep 22 09:36:31.012: INFO: stdout: ""
Sep 22 09:36:31.012: INFO: update-demo-nautilus-h5lnq is created but not running
Sep 22 09:36:36.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6055'
Sep 22 09:36:36.215: INFO: stderr: ""
Sep 22 09:36:36.215: INFO: stdout: "update-demo-nautilus-h5lnq update-demo-nautilus-m5659 "
Sep 22 09:36:36.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-h5lnq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6055'
Sep 22 09:36:36.295: INFO: stderr: ""
Sep 22 09:36:36.295: INFO: stdout: "true"
Sep 22 09:36:36.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-h5lnq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6055'
Sep 22 09:36:36.389: INFO: stderr: ""
Sep 22 09:36:36.389: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:36:36.389: INFO: validating pod update-demo-nautilus-h5lnq
Sep 22 09:36:36.394: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:36:36.394: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:36:36.394: INFO: update-demo-nautilus-h5lnq is verified up and running
Sep 22 09:36:36.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-m5659 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6055'
Sep 22 09:36:36.474: INFO: stderr: ""
Sep 22 09:36:36.474: INFO: stdout: "true"
Sep 22 09:36:36.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods update-demo-nautilus-m5659 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6055'
Sep 22 09:36:36.569: INFO: stderr: ""
Sep 22 09:36:36.569: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 22 09:36:36.569: INFO: validating pod update-demo-nautilus-m5659
Sep 22 09:36:36.573: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 22 09:36:36.573: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 22 09:36:36.573: INFO: update-demo-nautilus-m5659 is verified up and running
STEP: using delete to clean up resources
Sep 22 09:36:36.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 delete --grace-period=0 --force -f - --namespace=kubectl-6055'
Sep 22 09:36:36.666: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 22 09:36:36.666: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 22 09:36:36.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6055'
Sep 22 09:36:36.841: INFO: stderr: "No resources found in kubectl-6055 namespace.\n"
Sep 22 09:36:36.841: INFO: stdout: ""
Sep 22 09:36:36.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 get pods -l name=update-demo --namespace=kubectl-6055 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 22 09:36:37.075: INFO: stderr: ""
Sep 22 09:36:37.075: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:36:37.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6055" for this suite.
Sep 22 09:36:49.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:49.207: INFO: namespace kubectl-6055 deletion completed in 12.126867404s

• [SLOW TEST:18.660 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:36:49.207: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:36:49.952: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:36:52.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:36:53.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7269" for this suite.
Sep 22 09:36:59.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:36:59.130: INFO: namespace webhook-7269 deletion completed in 6.106662456s
STEP: Destroying namespace "webhook-7269-markers" for this suite.
Sep 22 09:37:05.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:37:05.275: INFO: namespace webhook-7269-markers deletion completed in 6.145632279s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.091 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:37:05.298: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:37:06.474: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Sep 22 09:37:08.483: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704741826, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704741826, loc:(*time.Location)(0x84be2c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63704741826, loc:(*time.Location)(0x84be2c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63704741826, loc:(*time.Location)(0x84be2c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:37:11.492: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:37:11.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2896" for this suite.
Sep 22 09:37:17.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:37:17.697: INFO: namespace webhook-2896 deletion completed in 6.07642433s
STEP: Destroying namespace "webhook-2896-markers" for this suite.
Sep 22 09:37:23.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:37:23.775: INFO: namespace webhook-2896-markers deletion completed in 6.078002029s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.487 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:37:23.786: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 22 09:37:23.838: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:23.841: INFO: Number of nodes with available pods: 0
Sep 22 09:37:23.841: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:37:24.857: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:24.861: INFO: Number of nodes with available pods: 0
Sep 22 09:37:24.861: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:37:25.844: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:25.847: INFO: Number of nodes with available pods: 2
Sep 22 09:37:25.847: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 22 09:37:25.859: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:25.866: INFO: Number of nodes with available pods: 1
Sep 22 09:37:25.866: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:37:26.869: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:26.873: INFO: Number of nodes with available pods: 1
Sep 22 09:37:26.873: INFO: Node ip-10-0-14-205 is running more than one daemon pod
Sep 22 09:37:27.870: INFO: DaemonSet pods can't tolerate node ip-10-0-13-176 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 22 09:37:27.873: INFO: Number of nodes with available pods: 2
Sep 22 09:37:27.873: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8540, will wait for the garbage collector to delete the pods
I0922 09:37:27.880729      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:37:27.880751      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:37:27.935: INFO: Deleting DaemonSet.extensions daemon-set took: 4.809818ms
I0922 09:37:28.041566      18 controller_utils.go:810] Ignoring inactive pod daemonsets-8540/daemon-set-mfrsf in state Running, deletion time 2019-09-22 09:37:57 +0000 UTC
I0922 09:37:28.045579      18 controller_utils.go:810] Ignoring inactive pod daemonsets-8540/daemon-set-2xtqx in state Running, deletion time 2019-09-22 09:37:57 +0000 UTC
Sep 22 09:37:28.045: INFO: Terminating DaemonSet.extensions daemon-set pods took: 109.919954ms
Sep 22 09:37:41.649: INFO: Number of nodes with available pods: 0
Sep 22 09:37:41.649: INFO: Number of running nodes: 0, number of available pods: 0
Sep 22 09:37:41.651: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8540/daemonsets","resourceVersion":"344166"},"items":null}

Sep 22 09:37:41.654: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8540/pods","resourceVersion":"344166"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:37:41.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8540" for this suite.
Sep 22 09:37:47.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:37:47.746: INFO: namespace daemonsets-8540 deletion completed in 6.081086565s

• [SLOW TEST:23.960 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:37:47.753: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:37:47.795: INFO: Waiting up to 5m0s for pod "downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c" in namespace "downward-api-3114" to be "success or failure"
Sep 22 09:37:47.812: INFO: Pod "downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.909178ms
Sep 22 09:37:49.815: INFO: Pod "downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020336682s
STEP: Saw pod success
Sep 22 09:37:49.815: INFO: Pod "downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c" satisfied condition "success or failure"
Sep 22 09:37:49.820: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c container client-container: <nil>
STEP: delete the pod
Sep 22 09:37:49.843: INFO: Waiting for pod downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c to disappear
Sep 22 09:37:49.845: INFO: Pod downwardapi-volume-85d2451a-013f-424c-8848-3cfed0ee788c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:37:49.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3114" for this suite.
Sep 22 09:37:55.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:37:55.944: INFO: namespace downward-api-3114 deletion completed in 6.095427342s

• [SLOW TEST:8.196 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:37:55.955: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 22 09:38:00.134: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 22 09:38:00.146: INFO: Pod pod-with-poststart-http-hook still exists
Sep 22 09:38:02.147: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 22 09:38:02.151: INFO: Pod pod-with-poststart-http-hook still exists
Sep 22 09:38:04.147: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 22 09:38:04.150: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:38:04.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-133" for this suite.
Sep 22 09:38:32.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:38:32.229: INFO: namespace container-lifecycle-hook-133 deletion completed in 28.075426507s

• [SLOW TEST:36.274 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:38:32.229: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:38:33.166: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:38:36.198: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:38:36.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6812" for this suite.
Sep 22 09:38:42.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:38:42.288: INFO: namespace webhook-6812 deletion completed in 6.080800565s
STEP: Destroying namespace "webhook-6812-markers" for this suite.
Sep 22 09:38:48.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:38:48.365: INFO: namespace webhook-6812-markers deletion completed in 6.074753019s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.147 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:38:48.376: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:38:49.236: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:38:52.250: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:38:52.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-728" for this suite.
Sep 22 09:38:58.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:38:58.452: INFO: namespace webhook-728 deletion completed in 6.074897015s
STEP: Destroying namespace "webhook-728-markers" for this suite.
Sep 22 09:39:04.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:39:04.537: INFO: namespace webhook-728-markers deletion completed in 6.085181094s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.172 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:39:04.548: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3a919d05-b0f4-4491-ab71-ee722343b41e
STEP: Creating a pod to test consume secrets
Sep 22 09:39:04.584: INFO: Waiting up to 5m0s for pod "pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688" in namespace "secrets-2171" to be "success or failure"
Sep 22 09:39:04.587: INFO: Pod "pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688": Phase="Pending", Reason="", readiness=false. Elapsed: 3.571076ms
Sep 22 09:39:06.589: INFO: Pod "pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00591371s
STEP: Saw pod success
Sep 22 09:39:06.590: INFO: Pod "pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688" satisfied condition "success or failure"
Sep 22 09:39:06.592: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688 container secret-volume-test: <nil>
STEP: delete the pod
Sep 22 09:39:06.606: INFO: Waiting for pod pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688 to disappear
Sep 22 09:39:06.608: INFO: Pod pod-secrets-205114c8-eb46-4551-b735-5c54e67f3688 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:39:06.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2171" for this suite.
Sep 22 09:39:12.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:39:12.684: INFO: namespace secrets-2171 deletion completed in 6.07162077s

• [SLOW TEST:8.136 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:39:12.684: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-1677
STEP: creating replication controller nodeport-test in namespace services-1677
I0922 09:39:12.723156      18 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-1677, replica count: 2
I0922 09:39:12.723396      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:39:12.723435      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:39:15.773: INFO: Creating new exec pod
I0922 09:39:15.773905      18 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0922 09:39:17.802985      18 reflector.go:120] Starting reflector *v1.Endpoints (0s) from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
I0922 09:39:17.803076      18 reflector.go:158] Listing and watching *v1.Endpoints from k8s.io/kubernetes/test/e2e/framework/service/jig.go:389
Sep 22 09:39:18.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1677 execpodcb5jx -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Sep 22 09:39:18.979: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Sep 22 09:39:18.979: INFO: stdout: ""
Sep 22 09:39:18.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1677 execpodcb5jx -- /bin/sh -x -c nc -zv -t -w 2 10.3.89.102 80'
Sep 22 09:39:19.285: INFO: stderr: "+ nc -zv -t -w 2 10.3.89.102 80\nConnection to 10.3.89.102 80 port [tcp/http] succeeded!\n"
Sep 22 09:39:19.285: INFO: stdout: ""
Sep 22 09:39:19.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1677 execpodcb5jx -- /bin/sh -x -c nc -zv -t -w 2 10.0.14.205 30995'
Sep 22 09:39:19.493: INFO: stderr: "+ nc -zv -t -w 2 10.0.14.205 30995\nConnection to 10.0.14.205 30995 port [tcp/30995] succeeded!\n"
Sep 22 09:39:19.493: INFO: stdout: ""
Sep 22 09:39:19.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-153516655 exec --namespace=services-1677 execpodcb5jx -- /bin/sh -x -c nc -zv -t -w 2 10.0.30.60 30995'
Sep 22 09:39:19.725: INFO: stderr: "+ nc -zv -t -w 2 10.0.30.60 30995\nConnection to 10.0.30.60 30995 port [tcp/30995] succeeded!\n"
Sep 22 09:39:19.725: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:39:19.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1677" for this suite.
Sep 22 09:39:25.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:39:25.810: INFO: namespace services-1677 deletion completed in 6.08186409s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.127 seconds]
[sig-network] Services
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:39:25.811: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:39:28.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8376" for this suite.
Sep 22 09:39:40.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:39:40.966: INFO: namespace replication-controller-8376 deletion completed in 12.104047463s

• [SLOW TEST:15.155 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:39:40.966: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:39:40.996: INFO: Creating ReplicaSet my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67
Sep 22 09:39:41.006: INFO: Pod name my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67: Found 0 pods out of 1
Sep 22 09:39:46.012: INFO: Pod name my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67: Found 1 pods out of 1
Sep 22 09:39:46.013: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67" is running
Sep 22 09:39:46.016: INFO: Pod "my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67-lcmwx" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 09:39:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 09:39:42 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 09:39:42 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-22 09:39:41 +0000 UTC Reason: Message:}])
Sep 22 09:39:46.016: INFO: Trying to dial the pod
Sep 22 09:39:51.035: INFO: Controller my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67: Got expected result from replica 1 [my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67-lcmwx]: "my-hostname-basic-183b0b27-507d-4160-9cd6-8969e0f03b67-lcmwx", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:39:51.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8963" for this suite.
Sep 22 09:39:57.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:39:57.125: INFO: namespace replicaset-8963 deletion completed in 6.08089971s

• [SLOW TEST:16.159 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:39:57.125: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:39:57.157: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4" in namespace "downward-api-9414" to be "success or failure"
Sep 22 09:39:57.159: INFO: Pod "downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.087397ms
Sep 22 09:39:59.162: INFO: Pod "downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005320404s
STEP: Saw pod success
Sep 22 09:39:59.162: INFO: Pod "downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4" satisfied condition "success or failure"
Sep 22 09:39:59.173: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4 container client-container: <nil>
STEP: delete the pod
Sep 22 09:39:59.192: INFO: Waiting for pod downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4 to disappear
Sep 22 09:39:59.199: INFO: Pod downwardapi-volume-bc0bbe5d-f3d1-4cb6-b68b-43f974b913a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:39:59.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9414" for this suite.
Sep 22 09:40:05.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:40:05.286: INFO: namespace downward-api-9414 deletion completed in 6.084192816s

• [SLOW TEST:8.161 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:40:05.286: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 22 09:40:05.325: INFO: Waiting up to 5m0s for pod "pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2" in namespace "emptydir-6321" to be "success or failure"
Sep 22 09:40:05.329: INFO: Pod "pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028992ms
Sep 22 09:40:07.332: INFO: Pod "pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007178402s
STEP: Saw pod success
Sep 22 09:40:07.332: INFO: Pod "pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2" satisfied condition "success or failure"
Sep 22 09:40:07.335: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2 container test-container: <nil>
STEP: delete the pod
Sep 22 09:40:07.349: INFO: Waiting for pod pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2 to disappear
Sep 22 09:40:07.356: INFO: Pod pod-fa69c7ed-48b1-4012-8b6b-2b9100ff37b2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:40:07.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6321" for this suite.
Sep 22 09:40:13.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:40:13.435: INFO: namespace emptydir-6321 deletion completed in 6.075334007s

• [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:40:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:40:13.484: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:40:14.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8714" for this suite.
Sep 22 09:40:20.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:40:20.121: INFO: namespace custom-resource-definition-8714 deletion completed in 6.093625025s

• [SLOW TEST:6.686 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:40:20.122: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Sep 22 09:40:20.154: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674" in namespace "projected-9713" to be "success or failure"
Sep 22 09:40:20.158: INFO: Pod "downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674": Phase="Pending", Reason="", readiness=false. Elapsed: 3.642311ms
Sep 22 09:40:22.161: INFO: Pod "downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006483107s
STEP: Saw pod success
Sep 22 09:40:22.161: INFO: Pod "downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674" satisfied condition "success or failure"
Sep 22 09:40:22.164: INFO: Trying to get logs from node ip-10-0-14-205 pod downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674 container client-container: <nil>
STEP: delete the pod
Sep 22 09:40:22.177: INFO: Waiting for pod downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674 to disappear
Sep 22 09:40:22.179: INFO: Pod downwardapi-volume-24ae94b3-5ac2-477a-beb7-a7f40611c674 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:40:22.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9713" for this suite.
Sep 22 09:40:28.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:40:28.263: INFO: namespace projected-9713 deletion completed in 6.082376814s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:40:28.264: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 22 09:40:28.295: INFO: Waiting up to 5m0s for pod "pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da" in namespace "emptydir-1080" to be "success or failure"
Sep 22 09:40:28.298: INFO: Pod "pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da": Phase="Pending", Reason="", readiness=false. Elapsed: 3.026789ms
Sep 22 09:40:30.301: INFO: Pod "pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006164258s
STEP: Saw pod success
Sep 22 09:40:30.301: INFO: Pod "pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da" satisfied condition "success or failure"
Sep 22 09:40:30.303: INFO: Trying to get logs from node ip-10-0-14-205 pod pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da container test-container: <nil>
STEP: delete the pod
Sep 22 09:40:30.318: INFO: Waiting for pod pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da to disappear
Sep 22 09:40:30.323: INFO: Pod pod-178a1d18-a5a2-41ce-a960-8ee1733fe4da no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:40:30.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1080" for this suite.
Sep 22 09:40:36.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:40:36.412: INFO: namespace emptydir-1080 deletion completed in 6.086739896s

• [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:40:36.414: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1601, will wait for the garbage collector to delete the pods
I0922 09:40:40.464647      18 reflector.go:120] Starting reflector *v1.Pod (0s) from k8s.io/kubernetes/test/utils/pod_store.go:56
I0922 09:40:40.464765      18 reflector.go:158] Listing and watching *v1.Pod from k8s.io/kubernetes/test/utils/pod_store.go:56
Sep 22 09:40:40.520: INFO: Deleting Job.batch foo took: 5.797979ms
I0922 09:40:40.820943      18 controller_utils.go:810] Ignoring inactive pod job-1601/foo-h9tlv in state Running, deletion time 2019-09-22 09:41:10 +0000 UTC
I0922 09:40:40.821074      18 controller_utils.go:810] Ignoring inactive pod job-1601/foo-s89bw in state Running, deletion time 2019-09-22 09:41:10 +0000 UTC
Sep 22 09:40:40.821: INFO: Terminating Job.batch foo pods took: 300.463346ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:41:25.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1601" for this suite.
Sep 22 09:41:31.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:41:31.303: INFO: namespace job-1601 deletion completed in 6.075584717s

• [SLOW TEST:54.889 seconds]
[sig-apps] Job
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:41:31.304: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Sep 22 09:41:33.870: INFO: Successfully updated pod "annotationupdatee55c83ba-68e3-4a61-b573-6ec145c65c8a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:41:37.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1982" for this suite.
Sep 22 09:41:49.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:41:50.026: INFO: namespace projected-1982 deletion completed in 12.128924186s

• [SLOW TEST:18.722 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:41:50.027: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Sep 22 09:41:50.551: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Sep 22 09:41:53.567: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Sep 22 09:41:53.576: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:41:54.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2099" for this suite.
Sep 22 09:42:00.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:42:01.000: INFO: namespace crd-webhook-2099 deletion completed in 6.123334237s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.988 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Sep 22 09:42:01.025: INFO: >>> kubeConfig: /tmp/kubeconfig-153516655
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Sep 22 09:42:12.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7626" for this suite.
Sep 22 09:42:18.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 22 09:42:18.251: INFO: namespace resourcequota-7626 deletion completed in 6.117411948s

• [SLOW TEST:17.226 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.0-rc.2.1+2bd9643cee5b3b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSep 22 09:42:18.254: INFO: Running AfterSuite actions on all nodes
Sep 22 09:42:18.255: INFO: Running AfterSuite actions on node 1
Sep 22 09:42:18.255: INFO: Skipping dumping logs from cluster

Ran 274 of 4897 Specs in 6328.227 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4623 Skipped
PASS

Ginkgo ran 1 suite in 1h45m29.848576864s
Test Suite Passed
