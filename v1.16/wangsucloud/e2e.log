I0521 02:32:14.897451      20 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-300851385
I0521 02:32:14.897606      20 e2e.go:92] Starting e2e run "eab6f487-5bb5-43fd-9514-9c30ecd0ca7d" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1590028332 - Will randomize all specs
Will run 274 of 4732 specs

May 21 02:32:14.966: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:32:14.971: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
May 21 02:32:14.994: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May 21 02:32:15.104: INFO: 41 / 41 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May 21 02:32:15.104: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May 21 02:32:15.104: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May 21 02:32:15.116: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-flannel' (0 seconds elapsed)
May 21 02:32:15.116: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-master' (0 seconds elapsed)
May 21 02:32:15.116: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker' (0 seconds elapsed)
May 21 02:32:15.116: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
May 21 02:32:15.116: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-device-plugin-daemonset' (0 seconds elapsed)
May 21 02:32:15.116: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'wangsucloud-csi-nodeplugin' (0 seconds elapsed)
May 21 02:32:15.116: INFO: e2e test version: v1.16.9
May 21 02:32:15.117: INFO: kube-apiserver version: v1.16.9
May 21 02:32:15.117: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:32:15.125: INFO: Cluster IP family: ipv4
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:32:15.125: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
May 21 02:32:15.166: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 02:32:15.176: INFO: Waiting up to 5m0s for pod "pod-2c0f4270-0894-415e-83bc-362c3e0ebb04" in namespace "emptydir-5924" to be "success or failure"
May 21 02:32:15.182: INFO: Pod "pod-2c0f4270-0894-415e-83bc-362c3e0ebb04": Phase="Pending", Reason="", readiness=false. Elapsed: 5.484521ms
May 21 02:32:17.185: INFO: Pod "pod-2c0f4270-0894-415e-83bc-362c3e0ebb04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008657515s
STEP: Saw pod success
May 21 02:32:17.185: INFO: Pod "pod-2c0f4270-0894-415e-83bc-362c3e0ebb04" satisfied condition "success or failure"
May 21 02:32:17.187: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-2c0f4270-0894-415e-83bc-362c3e0ebb04 container test-container: <nil>
STEP: delete the pod
May 21 02:32:17.215: INFO: Waiting for pod pod-2c0f4270-0894-415e-83bc-362c3e0ebb04 to disappear
May 21 02:32:17.218: INFO: Pod pod-2c0f4270-0894-415e-83bc-362c3e0ebb04 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:32:17.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5924" for this suite.
May 21 02:32:23.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:32:23.313: INFO: namespace emptydir-5924 deletion completed in 6.090035239s

• [SLOW TEST:8.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:32:23.313: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:32:23.350: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 21 02:32:32.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3452 create -f -'
May 21 02:32:33.854: INFO: stderr: ""
May 21 02:32:33.854: INFO: stdout: "e2e-test-crd-publish-openapi-9451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 21 02:32:33.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3452 delete e2e-test-crd-publish-openapi-9451-crds test-cr'
May 21 02:32:34.157: INFO: stderr: ""
May 21 02:32:34.157: INFO: stdout: "e2e-test-crd-publish-openapi-9451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May 21 02:32:34.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3452 apply -f -'
May 21 02:32:34.652: INFO: stderr: ""
May 21 02:32:34.652: INFO: stdout: "e2e-test-crd-publish-openapi-9451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May 21 02:32:34.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3452 delete e2e-test-crd-publish-openapi-9451-crds test-cr'
May 21 02:32:34.767: INFO: stderr: ""
May 21 02:32:34.767: INFO: stdout: "e2e-test-crd-publish-openapi-9451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 21 02:32:34.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-9451-crds'
May 21 02:32:35.057: INFO: stderr: ""
May 21 02:32:35.057: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9451-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:32:38.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3452" for this suite.
May 21 02:32:44.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:32:44.964: INFO: namespace crd-publish-openapi-3452 deletion completed in 6.099120941s

• [SLOW TEST:21.650 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:32:44.964: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
May 21 02:32:47.544: INFO: Successfully updated pod "adopt-release-5jvhp"
STEP: Checking that the Job readopts the Pod
May 21 02:32:47.544: INFO: Waiting up to 15m0s for pod "adopt-release-5jvhp" in namespace "job-3500" to be "adopted"
May 21 02:32:47.547: INFO: Pod "adopt-release-5jvhp": Phase="Running", Reason="", readiness=true. Elapsed: 2.910731ms
May 21 02:32:49.552: INFO: Pod "adopt-release-5jvhp": Phase="Running", Reason="", readiness=true. Elapsed: 2.007204016s
May 21 02:32:49.552: INFO: Pod "adopt-release-5jvhp" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
May 21 02:32:50.065: INFO: Successfully updated pod "adopt-release-5jvhp"
STEP: Checking that the Job releases the Pod
May 21 02:32:50.065: INFO: Waiting up to 15m0s for pod "adopt-release-5jvhp" in namespace "job-3500" to be "released"
May 21 02:32:50.079: INFO: Pod "adopt-release-5jvhp": Phase="Running", Reason="", readiness=true. Elapsed: 13.687131ms
May 21 02:32:52.082: INFO: Pod "adopt-release-5jvhp": Phase="Running", Reason="", readiness=true. Elapsed: 2.017250161s
May 21 02:32:52.082: INFO: Pod "adopt-release-5jvhp" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:32:52.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3500" for this suite.
May 21 02:33:40.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:33:40.195: INFO: namespace job-3500 deletion completed in 48.106793901s

• [SLOW TEST:55.231 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:33:40.195: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 02:33:40.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --namespace=kubectl-5607'
May 21 02:33:40.401: INFO: stderr: ""
May 21 02:33:40.401: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
May 21 02:33:40.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete pods e2e-test-httpd-pod --namespace=kubectl-5607'
May 21 02:33:47.297: INFO: stderr: ""
May 21 02:33:47.297: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:33:47.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5607" for this suite.
May 21 02:33:53.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:33:53.414: INFO: namespace kubectl-5607 deletion completed in 6.111597902s

• [SLOW TEST:13.218 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:33:53.414: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 02:34:01.512: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 02:34:01.517: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 02:34:03.517: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 02:34:03.523: INFO: Pod pod-with-prestop-exec-hook still exists
May 21 02:34:05.518: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May 21 02:34:05.521: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:34:05.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5245" for this suite.
May 21 02:34:33.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:34:33.652: INFO: namespace container-lifecycle-hook-5245 deletion completed in 28.107071212s

• [SLOW TEST:40.238 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:34:33.652: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:34:33.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed" in namespace "downward-api-9820" to be "success or failure"
May 21 02:34:33.768: INFO: Pod "downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed": Phase="Pending", Reason="", readiness=false. Elapsed: 9.324198ms
May 21 02:34:35.772: INFO: Pod "downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013852564s
May 21 02:34:37.776: INFO: Pod "downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017614265s
STEP: Saw pod success
May 21 02:34:37.776: INFO: Pod "downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed" satisfied condition "success or failure"
May 21 02:34:37.778: INFO: Trying to get logs from node 9990-w-ax-1-1 pod downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed container client-container: <nil>
STEP: delete the pod
May 21 02:34:37.809: INFO: Waiting for pod downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed to disappear
May 21 02:34:37.814: INFO: Pod downwardapi-volume-da929283-8983-411d-8f5c-151534f6bfed no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:34:37.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9820" for this suite.
May 21 02:34:43.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:34:43.929: INFO: namespace downward-api-9820 deletion completed in 6.109697951s

• [SLOW TEST:10.277 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:34:43.929: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 02:34:44.373: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 02:34:46.384: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625284, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625284, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625284, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625284, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 02:34:49.404: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:34:49.407: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6584-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:34:55.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1629" for this suite.
May 21 02:35:01.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:01.875: INFO: namespace webhook-1629 deletion completed in 6.274884889s
STEP: Destroying namespace "webhook-1629-markers" for this suite.
May 21 02:35:07.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:07.985: INFO: namespace webhook-1629-markers deletion completed in 6.110122907s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.071 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:08.001: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a5729e80-8897-4186-b963-3d965550d9ea
STEP: Creating a pod to test consume configMaps
May 21 02:35:08.055: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436" in namespace "projected-6225" to be "success or failure"
May 21 02:35:08.062: INFO: Pod "pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436": Phase="Pending", Reason="", readiness=false. Elapsed: 6.674767ms
May 21 02:35:10.065: INFO: Pod "pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010054778s
May 21 02:35:12.068: INFO: Pod "pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013299793s
STEP: Saw pod success
May 21 02:35:12.068: INFO: Pod "pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436" satisfied condition "success or failure"
May 21 02:35:12.071: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 02:35:12.097: INFO: Waiting for pod pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436 to disappear
May 21 02:35:12.100: INFO: Pod pod-projected-configmaps-c2f0ce3b-80c6-4552-acb5-2469ec932436 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:12.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6225" for this suite.
May 21 02:35:18.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:18.190: INFO: namespace projected-6225 deletion completed in 6.082981473s

• [SLOW TEST:10.189 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:18.190: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-38e81398-5651-45ae-9996-a0d3c5615700
STEP: Creating a pod to test consume secrets
May 21 02:35:18.247: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66" in namespace "projected-9419" to be "success or failure"
May 21 02:35:18.251: INFO: Pod "pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176188ms
May 21 02:35:20.254: INFO: Pod "pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007610331s
May 21 02:35:22.258: INFO: Pod "pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011354609s
STEP: Saw pod success
May 21 02:35:22.258: INFO: Pod "pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66" satisfied condition "success or failure"
May 21 02:35:22.261: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 02:35:22.286: INFO: Waiting for pod pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66 to disappear
May 21 02:35:22.288: INFO: Pod pod-projected-secrets-315398ff-b281-41b1-8988-c17cec01ea66 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:22.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9419" for this suite.
May 21 02:35:28.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:28.384: INFO: namespace projected-9419 deletion completed in 6.08995591s

• [SLOW TEST:10.194 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:28.384: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:35:28.423: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May 21 02:35:30.466: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:31.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2482" for this suite.
May 21 02:35:37.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:37.673: INFO: namespace replication-controller-2482 deletion completed in 6.194823608s

• [SLOW TEST:9.288 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:37.673: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:35:37.795: INFO: (0) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.550967ms)
May 21 02:35:37.799: INFO: (1) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.355345ms)
May 21 02:35:37.813: INFO: (2) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 13.965307ms)
May 21 02:35:37.816: INFO: (3) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.017382ms)
May 21 02:35:37.820: INFO: (4) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.329849ms)
May 21 02:35:37.824: INFO: (5) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.805058ms)
May 21 02:35:37.826: INFO: (6) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.787062ms)
May 21 02:35:37.829: INFO: (7) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.87755ms)
May 21 02:35:37.833: INFO: (8) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.521563ms)
May 21 02:35:37.844: INFO: (9) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.980676ms)
May 21 02:35:37.847: INFO: (10) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.377528ms)
May 21 02:35:37.850: INFO: (11) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.111137ms)
May 21 02:35:37.854: INFO: (12) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.130362ms)
May 21 02:35:37.859: INFO: (13) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.235075ms)
May 21 02:35:37.862: INFO: (14) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.965901ms)
May 21 02:35:37.868: INFO: (15) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.316997ms)
May 21 02:35:37.878: INFO: (16) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.517469ms)
May 21 02:35:37.884: INFO: (17) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.327321ms)
May 21 02:35:37.887: INFO: (18) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.715891ms)
May 21 02:35:37.890: INFO: (19) /api/v1/nodes/9990-w-ax-1-1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.949339ms)
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:37.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3852" for this suite.
May 21 02:35:43.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:44.038: INFO: namespace proxy-3852 deletion completed in 6.142794698s

• [SLOW TEST:6.365 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:44.038: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-89980fd9-0abc-4736-ad17-40a098f8c09c
STEP: Creating a pod to test consume configMaps
May 21 02:35:44.093: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965" in namespace "projected-7087" to be "success or failure"
May 21 02:35:44.097: INFO: Pod "pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965": Phase="Pending", Reason="", readiness=false. Elapsed: 3.912912ms
May 21 02:35:46.101: INFO: Pod "pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007898786s
May 21 02:35:48.104: INFO: Pod "pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011201857s
STEP: Saw pod success
May 21 02:35:48.104: INFO: Pod "pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965" satisfied condition "success or failure"
May 21 02:35:48.107: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 02:35:48.133: INFO: Waiting for pod pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965 to disappear
May 21 02:35:48.137: INFO: Pod pod-projected-configmaps-95242501-df8b-4246-979c-db9bb3c57965 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:48.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7087" for this suite.
May 21 02:35:54.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:35:54.229: INFO: namespace projected-7087 deletion completed in 6.088035763s

• [SLOW TEST:10.191 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:35:54.239: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-edd0124a-7dde-435e-a3e6-5b076342e7e0
STEP: Creating configMap with name cm-test-opt-upd-19bf1a52-f949-41e7-9756-c0229fb4061c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-edd0124a-7dde-435e-a3e6-5b076342e7e0
STEP: Updating configmap cm-test-opt-upd-19bf1a52-f949-41e7-9756-c0229fb4061c
STEP: Creating configMap with name cm-test-opt-create-11bf2802-4de1-49da-82d5-0a806ff695a9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:35:58.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4215" for this suite.
May 21 02:36:10.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:36:10.496: INFO: namespace projected-4215 deletion completed in 12.087212579s

• [SLOW TEST:16.257 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:36:10.496: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 02:36:10.539: INFO: Waiting up to 5m0s for pod "pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76" in namespace "emptydir-5724" to be "success or failure"
May 21 02:36:10.541: INFO: Pod "pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00557ms
May 21 02:36:12.545: INFO: Pod "pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005383788s
May 21 02:36:14.548: INFO: Pod "pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008860362s
STEP: Saw pod success
May 21 02:36:14.548: INFO: Pod "pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76" satisfied condition "success or failure"
May 21 02:36:14.551: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76 container test-container: <nil>
STEP: delete the pod
May 21 02:36:14.573: INFO: Waiting for pod pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76 to disappear
May 21 02:36:14.576: INFO: Pod pod-66c6a8cf-7298-452a-b0f5-b0592e3b2b76 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:36:14.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5724" for this suite.
May 21 02:36:20.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:36:20.678: INFO: namespace emptydir-5724 deletion completed in 6.097638418s

• [SLOW TEST:10.182 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:36:20.679: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
May 21 02:36:23.248: INFO: Successfully updated pod "labelsupdatefeac02fc-2dde-4ba5-9d22-e5860ab48974"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:36:25.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1708" for this suite.
May 21 02:36:39.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:36:39.364: INFO: namespace downward-api-1708 deletion completed in 14.094595548s

• [SLOW TEST:18.686 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:36:39.365: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:36:39.411: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-d104cae8-8b7e-4a7f-80c7-fe47d7ed58e7" in namespace "security-context-test-3370" to be "success or failure"
May 21 02:36:39.418: INFO: Pod "busybox-privileged-false-d104cae8-8b7e-4a7f-80c7-fe47d7ed58e7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.018137ms
May 21 02:36:41.424: INFO: Pod "busybox-privileged-false-d104cae8-8b7e-4a7f-80c7-fe47d7ed58e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012857538s
May 21 02:36:41.424: INFO: Pod "busybox-privileged-false-d104cae8-8b7e-4a7f-80c7-fe47d7ed58e7" satisfied condition "success or failure"
May 21 02:36:41.434: INFO: Got logs for pod "busybox-privileged-false-d104cae8-8b7e-4a7f-80c7-fe47d7ed58e7": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:36:41.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3370" for this suite.
May 21 02:36:47.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:36:47.547: INFO: namespace security-context-test-3370 deletion completed in 6.100937102s

• [SLOW TEST:8.182 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:36:47.547: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
May 21 02:36:47.591: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:37:14.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8282" for this suite.
May 21 02:37:20.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:37:20.353: INFO: namespace crd-publish-openapi-8282 deletion completed in 6.158934587s

• [SLOW TEST:32.807 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:37:20.355: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:37:33.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6270" for this suite.
May 21 02:37:39.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:37:39.611: INFO: namespace resourcequota-6270 deletion completed in 6.098288618s

• [SLOW TEST:19.256 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:37:39.611: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3389
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 02:37:39.654: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 02:37:59.744: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.240.4.18:8080/dial?request=hostName&protocol=http&host=10.240.4.17&port=8080&tries=1'] Namespace:pod-network-test-3389 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 02:37:59.744: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:38:00.334: INFO: Waiting for endpoints: map[]
May 21 02:38:00.337: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.240.4.18:8080/dial?request=hostName&protocol=http&host=10.240.3.16&port=8080&tries=1'] Namespace:pod-network-test-3389 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 02:38:00.337: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:38:00.768: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:38:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3389" for this suite.
May 21 02:38:12.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:38:12.892: INFO: namespace pod-network-test-3389 deletion completed in 12.116088528s

• [SLOW TEST:33.282 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:38:12.893: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:38:12.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 version'
May 21 02:38:13.120: INFO: stderr: ""
May 21 02:38:13.120: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.9\", GitCommit:\"a17149e1a189050796ced469dbd78d380f2ed5ef\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:44:51Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.9\", GitCommit:\"a17149e1a189050796ced469dbd78d380f2ed5ef\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:36:15Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:38:13.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1874" for this suite.
May 21 02:38:19.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:38:19.227: INFO: namespace kubectl-1874 deletion completed in 6.100569643s

• [SLOW TEST:6.334 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:38:19.227: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 02:38:19.291: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:19.291: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:19.291: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:19.295: INFO: Number of nodes with available pods: 0
May 21 02:38:19.295: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:38:20.300: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:20.300: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:20.301: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:20.303: INFO: Number of nodes with available pods: 0
May 21 02:38:20.303: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:38:21.300: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:21.300: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:21.300: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:21.304: INFO: Number of nodes with available pods: 1
May 21 02:38:21.304: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:22.304: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.304: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.304: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.307: INFO: Number of nodes with available pods: 2
May 21 02:38:22.307: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
May 21 02:38:22.321: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.321: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.321: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:22.323: INFO: Number of nodes with available pods: 1
May 21 02:38:22.323: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:23.329: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:23.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:23.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:23.333: INFO: Number of nodes with available pods: 1
May 21 02:38:23.333: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:24.335: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:24.335: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:24.335: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:24.339: INFO: Number of nodes with available pods: 1
May 21 02:38:24.339: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:25.331: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:25.331: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:25.331: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:25.334: INFO: Number of nodes with available pods: 1
May 21 02:38:25.334: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:26.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:26.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:26.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:26.336: INFO: Number of nodes with available pods: 1
May 21 02:38:26.336: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:27.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:27.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:27.330: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:27.333: INFO: Number of nodes with available pods: 1
May 21 02:38:27.333: INFO: Node 9990-w-ax-1-2 is running more than one daemon pod
May 21 02:38:28.328: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:28.328: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:28.328: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 02:38:28.331: INFO: Number of nodes with available pods: 2
May 21 02:38:28.331: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9077, will wait for the garbage collector to delete the pods
May 21 02:38:28.394: INFO: Deleting DaemonSet.extensions daemon-set took: 7.858569ms
May 21 02:38:28.696: INFO: Terminating DaemonSet.extensions daemon-set pods took: 302.744021ms
May 21 02:38:37.601: INFO: Number of nodes with available pods: 0
May 21 02:38:37.602: INFO: Number of running nodes: 0, number of available pods: 0
May 21 02:38:37.610: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9077/daemonsets","resourceVersion":"13730"},"items":null}

May 21 02:38:37.613: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9077/pods","resourceVersion":"13730"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:38:37.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9077" for this suite.
May 21 02:38:43.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:38:43.731: INFO: namespace daemonsets-9077 deletion completed in 6.102140022s

• [SLOW TEST:24.504 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:38:43.732: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4827
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 02:38:43.777: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 02:39:07.875: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.240.3.18 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 02:39:07.875: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:39:09.113: INFO: Found all expected endpoints: [netserver-0]
May 21 02:39:09.116: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.240.4.21 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 02:39:09.116: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:39:10.350: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:39:10.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4827" for this suite.
May 21 02:39:22.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:39:22.443: INFO: namespace pod-network-test-4827 deletion completed in 12.08640964s

• [SLOW TEST:38.711 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:39:22.443: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:39:22.482: INFO: Creating deployment "test-recreate-deployment"
May 21 02:39:22.491: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May 21 02:39:22.503: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May 21 02:39:24.509: INFO: Waiting deployment "test-recreate-deployment" to complete
May 21 02:39:24.512: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625562, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625562, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625562, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625562, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-579d66f65f\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 02:39:26.515: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May 21 02:39:26.522: INFO: Updating deployment test-recreate-deployment
May 21 02:39:26.522: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
May 21 02:39:26.637: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-743 /apis/apps/v1/namespaces/deployment-743/deployments/test-recreate-deployment 4b0f17b0-3ae8-4f0e-bf43-4c75722dbcf3 14055 2 2020-05-21 02:39:22 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001da2748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-21 02:39:26 +0000 UTC,LastTransitionTime:2020-05-21 02:39:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-68bffb8c8" is progressing.,LastUpdateTime:2020-05-21 02:39:26 +0000 UTC,LastTransitionTime:2020-05-21 02:39:22 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May 21 02:39:26.639: INFO: New ReplicaSet "test-recreate-deployment-68bffb8c8" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-68bffb8c8  deployment-743 /apis/apps/v1/namespaces/deployment-743/replicasets/test-recreate-deployment-68bffb8c8 b14b083a-106e-41c9-a7b4-ead2b73eaa26 14053 1 2020-05-21 02:39:26 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68bffb8c8] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 4b0f17b0-3ae8-4f0e-bf43-4c75722dbcf3 0xc001e183d0 0xc001e183d1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68bffb8c8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68bffb8c8] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001e18438 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 02:39:26.639: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May 21 02:39:26.639: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-579d66f65f  deployment-743 /apis/apps/v1/namespaces/deployment-743/replicasets/test-recreate-deployment-579d66f65f 3857aa2a-b4dc-4f54-876d-c033a45e5a26 14043 2 2020-05-21 02:39:22 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:579d66f65f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 4b0f17b0-3ae8-4f0e-bf43-4c75722dbcf3 0xc001e18307 0xc001e18308}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 579d66f65f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:579d66f65f] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001e18368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 02:39:26.642: INFO: Pod "test-recreate-deployment-68bffb8c8-5spl7" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-68bffb8c8-5spl7 test-recreate-deployment-68bffb8c8- deployment-743 /api/v1/namespaces/deployment-743/pods/test-recreate-deployment-68bffb8c8-5spl7 82475826-7a3c-4b9c-a38a-6ec2d0476607 14054 0 2020-05-21 02:39:26 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68bffb8c8] map[] [{apps/v1 ReplicaSet test-recreate-deployment-68bffb8c8 b14b083a-106e-41c9-a7b4-ead2b73eaa26 0xc001da2b10 0xc001da2b11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wrgs5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wrgs5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wrgs5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 02:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:39:26.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-743" for this suite.
May 21 02:39:32.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:39:32.736: INFO: namespace deployment-743 deletion completed in 6.088535188s

• [SLOW TEST:10.293 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:39:32.736: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:39:37.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-228" for this suite.
May 21 02:39:43.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:39:43.642: INFO: namespace watch-228 deletion completed in 6.198890085s

• [SLOW TEST:10.906 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:39:43.643: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May 21 02:39:53.765: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0521 02:39:53.765520      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May 21 02:39:53.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9803" for this suite.
May 21 02:39:59.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:39:59.926: INFO: namespace gc-9803 deletion completed in 6.15558098s

• [SLOW TEST:16.284 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:39:59.927: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 02:40:02.493: INFO: Successfully updated pod "pod-update-412d736c-b877-4038-bbd9-4bb88e8fb236"
STEP: verifying the updated pod is in kubernetes
May 21 02:40:02.499: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:40:02.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3420" for this suite.
May 21 02:40:14.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:40:14.618: INFO: namespace pods-3420 deletion completed in 12.114018157s

• [SLOW TEST:14.691 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:40:14.618: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:40:14.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3964" for this suite.
May 21 02:40:20.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:40:20.763: INFO: namespace custom-resource-definition-3964 deletion completed in 6.094251015s

• [SLOW TEST:6.145 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:40:20.764: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May 21 02:40:24.828: INFO: &Pod{ObjectMeta:{send-events-9ec89fa7-c1bd-482c-b00f-438cb7eb08d3  events-796 /api/v1/namespaces/events-796/pods/send-events-9ec89fa7-c1bd-482c-b00f-438cb7eb08d3 e1b54779-f673-4f11-be31-2651e4ff8aa2 14684 0 2020-05-21 02:40:20 +0000 UTC <nil> <nil> map[name:foo time:802772003] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-72mn6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-72mn6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:172.16.17.5/sonobuoy/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-72mn6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:40:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:40:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:40:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 02:40:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.23,StartTime:2020-05-21 02:40:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 02:40:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/agnhost:2.6,ImageID:docker-pullable://172.16.17.5/sonobuoy/agnhost@sha256:4273341f784390e3fd568bee1bf86efe6ef4ad4a7a1a75c0dcd01776683d669a,ContainerID:docker://f2d5b779f4f8e6781988b712ebc1abb8a35a5ee714f5d843a07f3445dc9ae850,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
May 21 02:40:26.833: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May 21 02:40:28.846: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:40:28.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-796" for this suite.
May 21 02:41:12.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:41:12.986: INFO: namespace events-796 deletion completed in 44.123157968s

• [SLOW TEST:52.222 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:41:12.987: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:41:13.037: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f" in namespace "projected-3931" to be "success or failure"
May 21 02:41:13.040: INFO: Pod "downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634004ms
May 21 02:41:15.044: INFO: Pod "downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006487775s
STEP: Saw pod success
May 21 02:41:15.044: INFO: Pod "downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f" satisfied condition "success or failure"
May 21 02:41:15.046: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f container client-container: <nil>
STEP: delete the pod
May 21 02:41:15.073: INFO: Waiting for pod downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f to disappear
May 21 02:41:15.076: INFO: Pod downwardapi-volume-edceaa64-6057-4339-9fd7-31a27afda19f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:41:15.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3931" for this suite.
May 21 02:41:21.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:41:21.180: INFO: namespace projected-3931 deletion completed in 6.098776372s

• [SLOW TEST:8.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:41:21.180: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-29c47404-00cb-49dc-82b2-76733a68ec90
STEP: Creating a pod to test consume secrets
May 21 02:41:21.229: INFO: Waiting up to 5m0s for pod "pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494" in namespace "secrets-5019" to be "success or failure"
May 21 02:41:21.234: INFO: Pod "pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494": Phase="Pending", Reason="", readiness=false. Elapsed: 4.647179ms
May 21 02:41:23.240: INFO: Pod "pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010871506s
May 21 02:41:25.246: INFO: Pod "pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016744146s
STEP: Saw pod success
May 21 02:41:25.246: INFO: Pod "pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494" satisfied condition "success or failure"
May 21 02:41:25.248: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494 container secret-volume-test: <nil>
STEP: delete the pod
May 21 02:41:25.270: INFO: Waiting for pod pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494 to disappear
May 21 02:41:25.274: INFO: Pod pod-secrets-4613b75a-0ae5-4e7c-8595-8bf6588bd494 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:41:25.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5019" for this suite.
May 21 02:41:31.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:41:31.368: INFO: namespace secrets-5019 deletion completed in 6.088170934s

• [SLOW TEST:10.188 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:41:31.368: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-722dab2c-481c-4416-858c-c4e3058b8e82
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:41:35.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1224" for this suite.
May 21 02:41:47.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:41:47.570: INFO: namespace configmap-1224 deletion completed in 12.104221277s

• [SLOW TEST:16.203 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:41:47.571: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 02:41:47.621: INFO: Waiting up to 5m0s for pod "pod-989f50de-032d-4eca-8197-ced4ee3f9659" in namespace "emptydir-2183" to be "success or failure"
May 21 02:41:47.626: INFO: Pod "pod-989f50de-032d-4eca-8197-ced4ee3f9659": Phase="Pending", Reason="", readiness=false. Elapsed: 4.527384ms
May 21 02:41:49.631: INFO: Pod "pod-989f50de-032d-4eca-8197-ced4ee3f9659": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0097576s
May 21 02:41:51.635: INFO: Pod "pod-989f50de-032d-4eca-8197-ced4ee3f9659": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013580868s
STEP: Saw pod success
May 21 02:41:51.635: INFO: Pod "pod-989f50de-032d-4eca-8197-ced4ee3f9659" satisfied condition "success or failure"
May 21 02:41:51.637: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-989f50de-032d-4eca-8197-ced4ee3f9659 container test-container: <nil>
STEP: delete the pod
May 21 02:41:51.674: INFO: Waiting for pod pod-989f50de-032d-4eca-8197-ced4ee3f9659 to disappear
May 21 02:41:51.677: INFO: Pod pod-989f50de-032d-4eca-8197-ced4ee3f9659 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:41:51.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2183" for this suite.
May 21 02:41:57.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:41:57.796: INFO: namespace emptydir-2183 deletion completed in 6.113183719s

• [SLOW TEST:10.225 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:41:57.796: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May 21 02:42:03.878: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 02:42:03.880: INFO: Pod pod-with-prestop-http-hook still exists
May 21 02:42:05.880: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 02:42:05.884: INFO: Pod pod-with-prestop-http-hook still exists
May 21 02:42:07.880: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May 21 02:42:07.883: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:42:07.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9588" for this suite.
May 21 02:42:19.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:42:19.987: INFO: namespace container-lifecycle-hook-9588 deletion completed in 12.090999517s

• [SLOW TEST:22.191 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:42:19.987: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 02:42:20.909: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 02:42:22.919: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625740, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625740, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625740, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725625740, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 02:42:25.940: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:42:36.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6309" for this suite.
May 21 02:42:42.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:42:42.254: INFO: namespace webhook-6309 deletion completed in 6.134164245s
STEP: Destroying namespace "webhook-6309-markers" for this suite.
May 21 02:42:48.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:42:48.334: INFO: namespace webhook-6309-markers deletion completed in 6.079885365s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.360 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:42:48.348: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:43:04.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-134" for this suite.
May 21 02:43:10.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:43:10.585: INFO: namespace resourcequota-134 deletion completed in 6.111011668s

• [SLOW TEST:22.237 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:43:10.585: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:43:14.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4450" for this suite.
May 21 02:43:58.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:43:58.750: INFO: namespace kubelet-test-4450 deletion completed in 44.089829185s

• [SLOW TEST:48.165 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:43:58.754: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3953
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-3953
May 21 02:43:58.809: INFO: Found 0 stateful pods, waiting for 1
May 21 02:44:08.813: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 02:44:08.876: INFO: Deleting all statefulset in ns statefulset-3953
May 21 02:44:08.891: INFO: Scaling statefulset ss to 0
May 21 02:44:28.920: INFO: Waiting for statefulset status.replicas updated to 0
May 21 02:44:28.922: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:44:28.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3953" for this suite.
May 21 02:44:34.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:44:35.048: INFO: namespace statefulset-3953 deletion completed in 6.0992447s

• [SLOW TEST:36.294 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:44:35.048: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
May 21 02:44:35.080: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-547'
May 21 02:44:36.570: INFO: stderr: ""
May 21 02:44:36.571: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 02:44:36.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-547'
May 21 02:44:36.708: INFO: stderr: ""
May 21 02:44:36.708: INFO: stdout: "update-demo-nautilus-dvcfj update-demo-nautilus-ztnrp "
May 21 02:44:36.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-dvcfj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:44:36.838: INFO: stderr: ""
May 21 02:44:36.838: INFO: stdout: ""
May 21 02:44:36.839: INFO: update-demo-nautilus-dvcfj is created but not running
May 21 02:44:41.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-547'
May 21 02:44:41.970: INFO: stderr: ""
May 21 02:44:41.970: INFO: stdout: "update-demo-nautilus-dvcfj update-demo-nautilus-ztnrp "
May 21 02:44:41.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-dvcfj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:44:42.112: INFO: stderr: ""
May 21 02:44:42.112: INFO: stdout: "true"
May 21 02:44:42.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-dvcfj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:44:42.355: INFO: stderr: ""
May 21 02:44:42.355: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 02:44:42.355: INFO: validating pod update-demo-nautilus-dvcfj
May 21 02:44:42.360: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 02:44:42.360: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 02:44:42.360: INFO: update-demo-nautilus-dvcfj is verified up and running
May 21 02:44:42.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-ztnrp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:44:42.571: INFO: stderr: ""
May 21 02:44:42.571: INFO: stdout: "true"
May 21 02:44:42.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-ztnrp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:44:42.688: INFO: stderr: ""
May 21 02:44:42.688: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 02:44:42.688: INFO: validating pod update-demo-nautilus-ztnrp
May 21 02:44:42.693: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 02:44:42.693: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 02:44:42.693: INFO: update-demo-nautilus-ztnrp is verified up and running
STEP: rolling-update to new replication controller
May 21 02:44:42.697: INFO: scanned /root for discovery docs: <nil>
May 21 02:44:42.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-547'
May 21 02:45:05.327: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 02:45:05.327: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 02:45:05.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-547'
May 21 02:45:05.519: INFO: stderr: ""
May 21 02:45:05.519: INFO: stdout: "update-demo-kitten-2x6fm update-demo-kitten-8292w "
May 21 02:45:05.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-kitten-2x6fm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:45:05.634: INFO: stderr: ""
May 21 02:45:05.634: INFO: stdout: "true"
May 21 02:45:05.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-kitten-2x6fm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:45:05.836: INFO: stderr: ""
May 21 02:45:05.836: INFO: stdout: "172.16.17.5/sonobuoy/kitten:1.0"
May 21 02:45:05.836: INFO: validating pod update-demo-kitten-2x6fm
May 21 02:45:05.840: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 02:45:05.840: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 02:45:05.840: INFO: update-demo-kitten-2x6fm is verified up and running
May 21 02:45:05.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-kitten-8292w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:45:06.037: INFO: stderr: ""
May 21 02:45:06.037: INFO: stdout: "true"
May 21 02:45:06.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-kitten-8292w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-547'
May 21 02:45:06.182: INFO: stderr: ""
May 21 02:45:06.182: INFO: stdout: "172.16.17.5/sonobuoy/kitten:1.0"
May 21 02:45:06.182: INFO: validating pod update-demo-kitten-8292w
May 21 02:45:06.187: INFO: got data: {
  "image": "kitten.jpg"
}

May 21 02:45:06.187: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May 21 02:45:06.187: INFO: update-demo-kitten-8292w is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:45:06.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-547" for this suite.
May 21 02:45:34.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:45:34.283: INFO: namespace kubectl-547 deletion completed in 28.090937458s

• [SLOW TEST:59.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:45:34.283: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:45:34.322: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:45:39.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-682" for this suite.
May 21 02:45:45.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:45:45.518: INFO: namespace custom-resource-definition-682 deletion completed in 6.092724545s

• [SLOW TEST:11.235 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:45:45.519: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
May 21 02:45:45.568: INFO: Waiting up to 5m0s for pod "client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2" in namespace "containers-6922" to be "success or failure"
May 21 02:45:45.576: INFO: Pod "client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.437489ms
May 21 02:45:47.581: INFO: Pod "client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012393295s
May 21 02:45:49.585: INFO: Pod "client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016158068s
STEP: Saw pod success
May 21 02:45:49.585: INFO: Pod "client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2" satisfied condition "success or failure"
May 21 02:45:49.587: INFO: Trying to get logs from node 9990-w-ax-1-1 pod client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2 container test-container: <nil>
STEP: delete the pod
May 21 02:45:49.633: INFO: Waiting for pod client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2 to disappear
May 21 02:45:49.639: INFO: Pod client-containers-efc0fb60-c9a1-45ae-8ee0-83ab0de189b2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:45:49.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6922" for this suite.
May 21 02:45:55.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:45:55.740: INFO: namespace containers-6922 deletion completed in 6.09543924s

• [SLOW TEST:10.221 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:45:55.740: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:45:55.818: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May 21 02:45:55.831: INFO: Number of nodes with available pods: 0
May 21 02:45:55.832: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May 21 02:45:55.860: INFO: Number of nodes with available pods: 0
May 21 02:45:55.860: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:45:56.871: INFO: Number of nodes with available pods: 0
May 21 02:45:56.871: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:45:57.863: INFO: Number of nodes with available pods: 0
May 21 02:45:57.863: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:45:58.864: INFO: Number of nodes with available pods: 1
May 21 02:45:58.864: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May 21 02:45:58.883: INFO: Number of nodes with available pods: 1
May 21 02:45:58.883: INFO: Number of running nodes: 0, number of available pods: 1
May 21 02:45:59.886: INFO: Number of nodes with available pods: 0
May 21 02:45:59.886: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May 21 02:45:59.898: INFO: Number of nodes with available pods: 0
May 21 02:45:59.898: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:46:00.901: INFO: Number of nodes with available pods: 0
May 21 02:46:00.901: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:46:01.901: INFO: Number of nodes with available pods: 0
May 21 02:46:01.901: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:46:02.902: INFO: Number of nodes with available pods: 0
May 21 02:46:02.902: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:46:03.901: INFO: Number of nodes with available pods: 0
May 21 02:46:03.901: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 02:46:04.902: INFO: Number of nodes with available pods: 1
May 21 02:46:04.902: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5773, will wait for the garbage collector to delete the pods
May 21 02:46:04.969: INFO: Deleting DaemonSet.extensions daemon-set took: 10.245636ms
May 21 02:46:05.269: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.225311ms
May 21 02:46:08.272: INFO: Number of nodes with available pods: 0
May 21 02:46:08.272: INFO: Number of running nodes: 0, number of available pods: 0
May 21 02:46:08.275: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5773/daemonsets","resourceVersion":"16625"},"items":null}

May 21 02:46:08.277: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5773/pods","resourceVersion":"16625"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:46:08.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5773" for this suite.
May 21 02:46:14.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:46:14.387: INFO: namespace daemonsets-5773 deletion completed in 6.083158771s

• [SLOW TEST:18.647 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:46:14.387: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:46:14.426: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487" in namespace "downward-api-3363" to be "success or failure"
May 21 02:46:14.429: INFO: Pod "downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487": Phase="Pending", Reason="", readiness=false. Elapsed: 2.382137ms
May 21 02:46:16.436: INFO: Pod "downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010073645s
STEP: Saw pod success
May 21 02:46:16.436: INFO: Pod "downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487" satisfied condition "success or failure"
May 21 02:46:16.439: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487 container client-container: <nil>
STEP: delete the pod
May 21 02:46:16.475: INFO: Waiting for pod downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487 to disappear
May 21 02:46:16.478: INFO: Pod downwardapi-volume-8acb3a80-763d-4dec-911d-0a23de85a487 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:46:16.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3363" for this suite.
May 21 02:46:22.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:46:22.574: INFO: namespace downward-api-3363 deletion completed in 6.084015949s

• [SLOW TEST:8.188 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:46:22.575: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9043
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-9043
I0521 02:46:22.649257      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9043, replica count: 2
May 21 02:46:25.699: INFO: Creating new exec pod
I0521 02:46:25.699851      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 02:46:28.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-9043 execpodjkb2w -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May 21 02:46:29.067: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 21 02:46:29.067: INFO: stdout: ""
May 21 02:46:29.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-9043 execpodjkb2w -- /bin/sh -x -c nc -zv -t -w 2 10.97.22.53 80'
May 21 02:46:29.365: INFO: stderr: "+ nc -zv -t -w 2 10.97.22.53 80\nConnection to 10.97.22.53 80 port [tcp/http] succeeded!\n"
May 21 02:46:29.365: INFO: stdout: ""
May 21 02:46:29.365: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:46:29.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9043" for this suite.
May 21 02:46:35.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:46:35.507: INFO: namespace services-9043 deletion completed in 6.096473133s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.932 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:46:35.507: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7926, will wait for the garbage collector to delete the pods
May 21 02:46:39.624: INFO: Deleting Job.batch foo took: 9.725886ms
May 21 02:46:39.725: INFO: Terminating Job.batch foo pods took: 100.624688ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:47:17.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7926" for this suite.
May 21 02:47:23.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:47:23.633: INFO: namespace job-7926 deletion completed in 6.091974553s

• [SLOW TEST:48.126 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:47:23.633: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:47:23.684: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9" in namespace "downward-api-5361" to be "success or failure"
May 21 02:47:23.692: INFO: Pod "downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.004235ms
May 21 02:47:25.696: INFO: Pod "downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012169042s
STEP: Saw pod success
May 21 02:47:25.696: INFO: Pod "downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9" satisfied condition "success or failure"
May 21 02:47:25.702: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9 container client-container: <nil>
STEP: delete the pod
May 21 02:47:25.722: INFO: Waiting for pod downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9 to disappear
May 21 02:47:25.725: INFO: Pod downwardapi-volume-7f74075e-93be-4083-8442-d5e4a34377f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:47:25.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5361" for this suite.
May 21 02:47:31.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:47:31.811: INFO: namespace downward-api-5361 deletion completed in 6.080476425s

• [SLOW TEST:8.178 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:47:31.811: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:47:31.856: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7" in namespace "downward-api-3630" to be "success or failure"
May 21 02:47:31.858: INFO: Pod "downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.535408ms
May 21 02:47:33.862: INFO: Pod "downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006515297s
STEP: Saw pod success
May 21 02:47:33.862: INFO: Pod "downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7" satisfied condition "success or failure"
May 21 02:47:33.864: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7 container client-container: <nil>
STEP: delete the pod
May 21 02:47:33.884: INFO: Waiting for pod downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7 to disappear
May 21 02:47:33.886: INFO: Pod downwardapi-volume-9edcf106-3c22-4087-89b7-73d2fc1a9dc7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:47:33.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3630" for this suite.
May 21 02:47:39.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:47:39.991: INFO: namespace downward-api-3630 deletion completed in 6.099397009s

• [SLOW TEST:8.180 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:47:39.991: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-fb7b582c-003b-4d7b-8079-65573a07de1b
STEP: Creating a pod to test consume configMaps
May 21 02:47:40.046: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0" in namespace "configmap-4157" to be "success or failure"
May 21 02:47:40.050: INFO: Pod "pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.242308ms
May 21 02:47:42.054: INFO: Pod "pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00809671s
May 21 02:47:44.058: INFO: Pod "pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012034582s
STEP: Saw pod success
May 21 02:47:44.058: INFO: Pod "pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0" satisfied condition "success or failure"
May 21 02:47:44.061: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 02:47:44.104: INFO: Waiting for pod pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0 to disappear
May 21 02:47:44.108: INFO: Pod pod-configmaps-0c11a503-bcb2-41cb-9943-b4158e7fa3a0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:47:44.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4157" for this suite.
May 21 02:47:50.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:47:50.213: INFO: namespace configmap-4157 deletion completed in 6.099967103s

• [SLOW TEST:10.222 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:47:50.214: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 02:47:50.309: INFO: Waiting up to 5m0s for pod "pod-92284077-a41b-4dbd-a703-848c2715db82" in namespace "emptydir-9607" to be "success or failure"
May 21 02:47:50.312: INFO: Pod "pod-92284077-a41b-4dbd-a703-848c2715db82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.672386ms
May 21 02:47:52.315: INFO: Pod "pod-92284077-a41b-4dbd-a703-848c2715db82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00594893s
STEP: Saw pod success
May 21 02:47:52.315: INFO: Pod "pod-92284077-a41b-4dbd-a703-848c2715db82" satisfied condition "success or failure"
May 21 02:47:52.320: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-92284077-a41b-4dbd-a703-848c2715db82 container test-container: <nil>
STEP: delete the pod
May 21 02:47:52.340: INFO: Waiting for pod pod-92284077-a41b-4dbd-a703-848c2715db82 to disappear
May 21 02:47:52.343: INFO: Pod pod-92284077-a41b-4dbd-a703-848c2715db82 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:47:52.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9607" for this suite.
May 21 02:47:58.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:47:58.436: INFO: namespace emptydir-9607 deletion completed in 6.08885802s

• [SLOW TEST:8.223 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:47:58.436: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:47:58.473: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:48:58.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-362" for this suite.
May 21 02:49:04.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:49:04.100: INFO: namespace custom-resource-definition-362 deletion completed in 6.088993919s

• [SLOW TEST:65.664 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:49:04.101: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-107b56da-1547-4fb0-bc95-a6bd9fc47c56
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:49:04.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2127" for this suite.
May 21 02:49:10.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:49:10.236: INFO: namespace secrets-2127 deletion completed in 6.093518176s

• [SLOW TEST:6.136 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:49:10.236: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
May 21 02:49:10.279: INFO: Waiting up to 5m0s for pod "downward-api-e55e8967-91f6-4134-b493-2207f164d982" in namespace "downward-api-5385" to be "success or failure"
May 21 02:49:10.285: INFO: Pod "downward-api-e55e8967-91f6-4134-b493-2207f164d982": Phase="Pending", Reason="", readiness=false. Elapsed: 5.81694ms
May 21 02:49:12.289: INFO: Pod "downward-api-e55e8967-91f6-4134-b493-2207f164d982": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009611482s
May 21 02:49:14.293: INFO: Pod "downward-api-e55e8967-91f6-4134-b493-2207f164d982": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013500716s
STEP: Saw pod success
May 21 02:49:14.293: INFO: Pod "downward-api-e55e8967-91f6-4134-b493-2207f164d982" satisfied condition "success or failure"
May 21 02:49:14.295: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downward-api-e55e8967-91f6-4134-b493-2207f164d982 container dapi-container: <nil>
STEP: delete the pod
May 21 02:49:14.323: INFO: Waiting for pod downward-api-e55e8967-91f6-4134-b493-2207f164d982 to disappear
May 21 02:49:14.326: INFO: Pod downward-api-e55e8967-91f6-4134-b493-2207f164d982 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:49:14.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5385" for this suite.
May 21 02:49:20.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:49:20.419: INFO: namespace downward-api-5385 deletion completed in 6.08893775s

• [SLOW TEST:10.183 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:49:20.420: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 02:49:20.455: INFO: Creating ReplicaSet my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2
May 21 02:49:20.464: INFO: Pod name my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2: Found 0 pods out of 1
May 21 02:49:25.467: INFO: Pod name my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2: Found 1 pods out of 1
May 21 02:49:25.467: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2" is running
May 21 02:49:25.469: INFO: Pod "my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2-fqldm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:49:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:49:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:49:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:49:20 +0000 UTC Reason: Message:}])
May 21 02:49:25.470: INFO: Trying to dial the pod
May 21 02:49:30.479: INFO: Controller my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2: Got expected result from replica 1 [my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2-fqldm]: "my-hostname-basic-46778239-5d57-4fea-83b3-94b5b8b2e7a2-fqldm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:49:30.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8170" for this suite.
May 21 02:49:36.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:49:36.580: INFO: namespace replicaset-8170 deletion completed in 6.09538173s

• [SLOW TEST:16.160 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:49:36.580: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-43000de0-8ab5-4f30-aed0-7791819c5fae
STEP: Creating secret with name s-test-opt-upd-702a0e79-3735-4578-9725-d851dbef453a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-43000de0-8ab5-4f30-aed0-7791819c5fae
STEP: Updating secret s-test-opt-upd-702a0e79-3735-4578-9725-d851dbef453a
STEP: Creating secret with name s-test-opt-create-4e5433a8-c33a-475e-beee-3864b44e4751
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:50:57.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2235" for this suite.
May 21 02:51:09.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:51:09.174: INFO: namespace secrets-2235 deletion completed in 12.107514069s

• [SLOW TEST:92.594 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:51:09.174: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
May 21 02:51:09.221: INFO: Waiting up to 5m0s for pod "var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b" in namespace "var-expansion-2140" to be "success or failure"
May 21 02:51:09.225: INFO: Pod "var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.475573ms
May 21 02:51:11.228: INFO: Pod "var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007191914s
May 21 02:51:13.233: INFO: Pod "var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011616501s
STEP: Saw pod success
May 21 02:51:13.233: INFO: Pod "var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b" satisfied condition "success or failure"
May 21 02:51:13.236: INFO: Trying to get logs from node 9990-w-ax-1-1 pod var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b container dapi-container: <nil>
STEP: delete the pod
May 21 02:51:13.268: INFO: Waiting for pod var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b to disappear
May 21 02:51:13.271: INFO: Pod var-expansion-f4069e33-6c36-4a67-92f2-d66903f73f6b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:51:13.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2140" for this suite.
May 21 02:51:19.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:51:19.360: INFO: namespace var-expansion-2140 deletion completed in 6.084633508s

• [SLOW TEST:10.186 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:51:19.361: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
May 21 02:51:19.406: INFO: Waiting up to 5m0s for pod "var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304" in namespace "var-expansion-237" to be "success or failure"
May 21 02:51:19.412: INFO: Pod "var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304": Phase="Pending", Reason="", readiness=false. Elapsed: 6.315018ms
May 21 02:51:21.416: INFO: Pod "var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01025708s
May 21 02:51:23.420: INFO: Pod "var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013895677s
STEP: Saw pod success
May 21 02:51:23.420: INFO: Pod "var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304" satisfied condition "success or failure"
May 21 02:51:23.422: INFO: Trying to get logs from node 9990-w-ax-1-2 pod var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304 container dapi-container: <nil>
STEP: delete the pod
May 21 02:51:23.444: INFO: Waiting for pod var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304 to disappear
May 21 02:51:23.446: INFO: Pod var-expansion-3919d7aa-e714-49b4-b39f-0eb4edd58304 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:51:23.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-237" for this suite.
May 21 02:51:29.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:51:29.567: INFO: namespace var-expansion-237 deletion completed in 6.115910951s

• [SLOW TEST:10.206 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:51:29.568: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 21 02:51:32.631: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:51:32.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3111" for this suite.
May 21 02:51:38.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:51:38.757: INFO: namespace container-runtime-3111 deletion completed in 6.100324635s

• [SLOW TEST:9.190 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:51:38.758: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-360
STEP: creating replication controller nodeport-test in namespace services-360
I0521 02:51:38.844368      20 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-360, replica count: 2
May 21 02:51:41.895: INFO: Creating new exec pod
I0521 02:51:41.895204      20 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 02:51:44.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-360 execpod5pqq2 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
May 21 02:51:45.310: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May 21 02:51:45.310: INFO: stdout: ""
May 21 02:51:45.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-360 execpod5pqq2 -- /bin/sh -x -c nc -zv -t -w 2 10.100.104.93 80'
May 21 02:51:45.630: INFO: stderr: "+ nc -zv -t -w 2 10.100.104.93 80\nConnection to 10.100.104.93 80 port [tcp/http] succeeded!\n"
May 21 02:51:45.630: INFO: stdout: ""
May 21 02:51:45.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-360 execpod5pqq2 -- /bin/sh -x -c nc -zv -t -w 2 192.168.0.7 31148'
May 21 02:51:45.922: INFO: stderr: "+ nc -zv -t -w 2 192.168.0.7 31148\nConnection to 192.168.0.7 31148 port [tcp/31148] succeeded!\n"
May 21 02:51:45.922: INFO: stdout: ""
May 21 02:51:45.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-360 execpod5pqq2 -- /bin/sh -x -c nc -zv -t -w 2 192.168.0.8 31148'
May 21 02:51:46.466: INFO: stderr: "+ nc -zv -t -w 2 192.168.0.8 31148\nConnection to 192.168.0.8 31148 port [tcp/31148] succeeded!\n"
May 21 02:51:46.466: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:51:46.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-360" for this suite.
May 21 02:51:52.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:51:52.565: INFO: namespace services-360 deletion completed in 6.092684309s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.807 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:51:52.566: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 02:51:53.147: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 02:51:55.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626313, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626313, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626313, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626313, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 02:51:58.184: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:51:58.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-877" for this suite.
May 21 02:52:04.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:04.307: INFO: namespace webhook-877 deletion completed in 6.107925314s
STEP: Destroying namespace "webhook-877-markers" for this suite.
May 21 02:52:10.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:10.399: INFO: namespace webhook-877-markers deletion completed in 6.092401792s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.846 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:52:10.412: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 02:52:11.030: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 02:52:13.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626331, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626331, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626331, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626331, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 02:52:16.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:52:16.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4950" for this suite.
May 21 02:52:22.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:22.404: INFO: namespace webhook-4950 deletion completed in 6.094739693s
STEP: Destroying namespace "webhook-4950-markers" for this suite.
May 21 02:52:28.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:28.493: INFO: namespace webhook-4950-markers deletion completed in 6.088387071s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.097 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:52:28.509: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
May 21 02:52:28.556: INFO: Waiting up to 5m0s for pod "downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17" in namespace "downward-api-9236" to be "success or failure"
May 21 02:52:28.563: INFO: Pod "downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17": Phase="Pending", Reason="", readiness=false. Elapsed: 6.899501ms
May 21 02:52:30.567: INFO: Pod "downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011143712s
STEP: Saw pod success
May 21 02:52:30.567: INFO: Pod "downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17" satisfied condition "success or failure"
May 21 02:52:30.570: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17 container dapi-container: <nil>
STEP: delete the pod
May 21 02:52:30.598: INFO: Waiting for pod downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17 to disappear
May 21 02:52:30.601: INFO: Pod downward-api-6638d80a-2c5f-4fbb-a0c5-1e183a772e17 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:52:30.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9236" for this suite.
May 21 02:52:36.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:36.739: INFO: namespace downward-api-9236 deletion completed in 6.130142108s

• [SLOW TEST:8.230 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:52:36.740: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
May 21 02:52:40.799: INFO: Pod pod-hostip-b72b6efc-4880-4d44-8fe9-faa391088f30 has hostIP: 192.168.0.7
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:52:40.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1649" for this suite.
May 21 02:52:52.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:52:52.938: INFO: namespace pods-1649 deletion completed in 12.133506144s

• [SLOW TEST:16.198 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:52:52.938: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May 21 02:52:53.278: INFO: Pod name wrapped-volume-race-281e213c-9d31-4032-a85e-3e129f377f51: Found 0 pods out of 5
May 21 02:52:58.285: INFO: Pod name wrapped-volume-race-281e213c-9d31-4032-a85e-3e129f377f51: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-281e213c-9d31-4032-a85e-3e129f377f51 in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
May 21 02:53:10.387: INFO: Deleting ReplicationController wrapped-volume-race-281e213c-9d31-4032-a85e-3e129f377f51 took: 11.717029ms
May 21 02:53:10.687: INFO: Terminating ReplicationController wrapped-volume-race-281e213c-9d31-4032-a85e-3e129f377f51 pods took: 300.213083ms
STEP: Creating RC which spawns configmap-volume pods
May 21 02:53:47.614: INFO: Pod name wrapped-volume-race-1074a622-c483-4ddf-95bd-bb914812e5a9: Found 0 pods out of 5
May 21 02:53:52.625: INFO: Pod name wrapped-volume-race-1074a622-c483-4ddf-95bd-bb914812e5a9: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1074a622-c483-4ddf-95bd-bb914812e5a9 in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
May 21 02:54:04.717: INFO: Deleting ReplicationController wrapped-volume-race-1074a622-c483-4ddf-95bd-bb914812e5a9 took: 9.849246ms
May 21 02:54:05.028: INFO: Terminating ReplicationController wrapped-volume-race-1074a622-c483-4ddf-95bd-bb914812e5a9 pods took: 310.384446ms
STEP: Creating RC which spawns configmap-volume pods
May 21 02:54:40.750: INFO: Pod name wrapped-volume-race-b45ec79a-65ca-4916-8527-37d6a728460a: Found 0 pods out of 5
May 21 02:54:45.757: INFO: Pod name wrapped-volume-race-b45ec79a-65ca-4916-8527-37d6a728460a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b45ec79a-65ca-4916-8527-37d6a728460a in namespace emptydir-wrapper-8093, will wait for the garbage collector to delete the pods
May 21 02:54:57.858: INFO: Deleting ReplicationController wrapped-volume-race-b45ec79a-65ca-4916-8527-37d6a728460a took: 26.128801ms
May 21 02:54:58.159: INFO: Terminating ReplicationController wrapped-volume-race-b45ec79a-65ca-4916-8527-37d6a728460a pods took: 300.978562ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:55:34.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8093" for this suite.
May 21 02:55:42.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:55:42.590: INFO: namespace emptydir-wrapper-8093 deletion completed in 8.08351039s

• [SLOW TEST:169.652 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:55:42.591: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
May 21 02:55:42.625: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-300851385 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:55:42.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1673" for this suite.
May 21 02:55:48.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:55:48.864: INFO: namespace kubectl-1673 deletion completed in 6.106922929s

• [SLOW TEST:6.273 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:55:48.864: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-55f69f03-fc71-418b-9238-f7f9812b65ce in namespace container-probe-6598
May 21 02:55:51.117: INFO: Started pod liveness-55f69f03-fc71-418b-9238-f7f9812b65ce in namespace container-probe-6598
STEP: checking the pod's current state and verifying that restartCount is present
May 21 02:55:51.120: INFO: Initial restart count of pod liveness-55f69f03-fc71-418b-9238-f7f9812b65ce is 0
May 21 02:56:13.178: INFO: Restart count of pod container-probe-6598/liveness-55f69f03-fc71-418b-9238-f7f9812b65ce is now 1 (22.05829442s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:56:13.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6598" for this suite.
May 21 02:56:19.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:56:19.300: INFO: namespace container-probe-6598 deletion completed in 6.098641907s

• [SLOW TEST:30.436 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:56:19.300: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
May 21 02:56:19.347: INFO: Waiting up to 5m0s for pod "downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661" in namespace "downward-api-5298" to be "success or failure"
May 21 02:56:19.350: INFO: Pod "downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661": Phase="Pending", Reason="", readiness=false. Elapsed: 2.915123ms
May 21 02:56:21.354: INFO: Pod "downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007196597s
STEP: Saw pod success
May 21 02:56:21.355: INFO: Pod "downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661" satisfied condition "success or failure"
May 21 02:56:21.357: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661 container dapi-container: <nil>
STEP: delete the pod
May 21 02:56:21.389: INFO: Waiting for pod downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661 to disappear
May 21 02:56:21.391: INFO: Pod downward-api-5107acee-2f4d-4e0a-9bca-e8df2ece5661 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:56:21.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5298" for this suite.
May 21 02:56:27.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:56:27.507: INFO: namespace downward-api-5298 deletion completed in 6.104428301s

• [SLOW TEST:8.207 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:56:27.507: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
May 21 02:56:27.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=kubectl-4964 run e2e-test-rm-busybox-job --image=172.16.17.5/sonobuoy/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May 21 02:56:30.111: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May 21 02:56:30.111: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:56:32.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4964" for this suite.
May 21 02:56:38.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:56:38.225: INFO: namespace kubectl-4964 deletion completed in 6.093497115s

• [SLOW TEST:10.719 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:56:38.225: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4262.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4262.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4262.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4262.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4262.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 02:56:42.313: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.316: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.319: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.321: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.329: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.333: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.336: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.339: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4262.svc.cluster.local from pod dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4: the server could not find the requested resource (get pods dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4)
May 21 02:56:42.354: INFO: Lookups using dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4262.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4262.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4262.svc.cluster.local jessie_udp@dns-test-service-2.dns-4262.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4262.svc.cluster.local]

May 21 02:56:47.396: INFO: DNS probes using dns-4262/dns-test-2ff2a7ff-ef5b-4875-9942-8c7a77a591e4 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:56:47.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4262" for this suite.
May 21 02:56:53.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:56:53.590: INFO: namespace dns-4262 deletion completed in 6.141040668s

• [SLOW TEST:15.365 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:56:53.591: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4512.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4512.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4512.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4512.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4512.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4512.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 02:56:55.686: INFO: DNS probes using dns-4512/dns-test-61f04352-57a4-43a3-9dc1-643dae9198c6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:56:55.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4512" for this suite.
May 21 02:57:01.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:57:01.823: INFO: namespace dns-4512 deletion completed in 6.111512977s

• [SLOW TEST:8.233 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:57:01.824: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099
May 21 02:57:01.872: INFO: Pod name my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099: Found 0 pods out of 1
May 21 02:57:06.876: INFO: Pod name my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099: Found 1 pods out of 1
May 21 02:57:06.876: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099" are running
May 21 02:57:06.879: INFO: Pod "my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099-jtx8b" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:57:01 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:57:03 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:57:03 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-21 02:57:01 +0000 UTC Reason: Message:}])
May 21 02:57:06.879: INFO: Trying to dial the pod
May 21 02:57:11.904: INFO: Controller my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099: Got expected result from replica 1 [my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099-jtx8b]: "my-hostname-basic-b25379e5-e8fa-47af-8070-9f9a8ed3b099-jtx8b", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:57:11.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2359" for this suite.
May 21 02:57:17.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:57:17.993: INFO: namespace replication-controller-2359 deletion completed in 6.084754641s

• [SLOW TEST:16.169 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:57:17.994: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
May 21 02:57:20.571: INFO: Successfully updated pod "labelsupdate799ec4f8-83ad-4633-b76c-fb5eb316ca2b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:57:22.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7948" for this suite.
May 21 02:57:34.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:57:34.693: INFO: namespace projected-7948 deletion completed in 12.094374365s

• [SLOW TEST:16.700 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:57:34.694: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2078
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2078
STEP: creating replication controller externalsvc in namespace services-2078
I0521 02:57:34.810214      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2078, replica count: 2
I0521 02:57:37.861520      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
May 21 02:57:37.899: INFO: Creating new exec pod
May 21 02:57:41.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-2078 execpodrq94r -- /bin/sh -x -c nslookup nodeport-service'
May 21 02:57:42.255: INFO: stderr: "+ nslookup nodeport-service\n"
May 21 02:57:42.256: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nnodeport-service.services-2078.svc.cluster.local\tcanonical name = externalsvc.services-2078.svc.cluster.local.\nName:\texternalsvc.services-2078.svc.cluster.local\nAddress: 10.98.193.167\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2078, will wait for the garbage collector to delete the pods
May 21 02:57:42.327: INFO: Deleting ReplicationController externalsvc took: 9.558877ms
May 21 02:57:42.627: INFO: Terminating ReplicationController externalsvc pods took: 300.288279ms
May 21 02:57:57.600: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:57:57.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2078" for this suite.
May 21 02:58:03.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:58:03.733: INFO: namespace services-2078 deletion completed in 6.105802673s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:29.039 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:58:03.733: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:58:09.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4885" for this suite.
May 21 02:58:15.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:58:15.995: INFO: namespace namespaces-4885 deletion completed in 6.105040265s
STEP: Destroying namespace "nsdeletetest-8886" for this suite.
May 21 02:58:15.997: INFO: Namespace nsdeletetest-8886 was already deleted
STEP: Destroying namespace "nsdeletetest-3366" for this suite.
May 21 02:58:22.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:58:22.105: INFO: namespace nsdeletetest-3366 deletion completed in 6.107648432s

• [SLOW TEST:18.373 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:58:22.107: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
May 21 02:58:22.750: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:58:22.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0521 02:58:22.750895      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4764" for this suite.
May 21 02:58:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:58:28.868: INFO: namespace gc-4764 deletion completed in 6.107541629s

• [SLOW TEST:6.761 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:58:28.868: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 02:58:28.913: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add" in namespace "projected-2872" to be "success or failure"
May 21 02:58:28.916: INFO: Pod "downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add": Phase="Pending", Reason="", readiness=false. Elapsed: 3.008456ms
May 21 02:58:30.919: INFO: Pod "downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006774552s
STEP: Saw pod success
May 21 02:58:30.920: INFO: Pod "downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add" satisfied condition "success or failure"
May 21 02:58:30.923: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add container client-container: <nil>
STEP: delete the pod
May 21 02:58:30.945: INFO: Waiting for pod downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add to disappear
May 21 02:58:30.947: INFO: Pod downwardapi-volume-4c1bfc07-903b-4114-afff-a860b1898add no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:58:30.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2872" for this suite.
May 21 02:58:36.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:58:37.061: INFO: namespace projected-2872 deletion completed in 6.108467805s

• [SLOW TEST:8.193 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:58:37.061: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
May 21 02:58:37.116: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
May 21 02:58:56.204: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 02:59:04.958: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:59:23.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8232" for this suite.
May 21 02:59:29.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:59:29.319: INFO: namespace crd-publish-openapi-8232 deletion completed in 6.11164167s

• [SLOW TEST:52.258 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:59:29.319: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-6506da54-4a2a-421b-8d18-6ab2d9b5f4a5
STEP: Creating secret with name s-test-opt-upd-be3d925c-1052-426e-8ee9-3b9fd909ac6d
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6506da54-4a2a-421b-8d18-6ab2d9b5f4a5
STEP: Updating secret s-test-opt-upd-be3d925c-1052-426e-8ee9-3b9fd909ac6d
STEP: Creating secret with name s-test-opt-create-8a764ee8-abc9-4e48-a3b0-dc25b8ac2474
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:59:33.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6092" for this suite.
May 21 02:59:49.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:59:49.632: INFO: namespace projected-6092 deletion completed in 16.120539082s

• [SLOW TEST:20.313 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:59:49.632: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-108daf52-8beb-4037-9fa1-ec6204f91be5
STEP: Creating a pod to test consume configMaps
May 21 02:59:49.684: INFO: Waiting up to 5m0s for pod "pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1" in namespace "configmap-7032" to be "success or failure"
May 21 02:59:49.688: INFO: Pod "pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.108539ms
May 21 02:59:51.694: INFO: Pod "pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009760868s
STEP: Saw pod success
May 21 02:59:51.694: INFO: Pod "pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1" satisfied condition "success or failure"
May 21 02:59:51.697: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 02:59:51.723: INFO: Waiting for pod pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1 to disappear
May 21 02:59:51.726: INFO: Pod pod-configmaps-bfbb2269-c0ca-4358-8be9-f5b069966fd1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 02:59:51.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7032" for this suite.
May 21 02:59:57.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 02:59:57.831: INFO: namespace configmap-7032 deletion completed in 6.099492987s

• [SLOW TEST:8.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 02:59:57.831: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
May 21 03:00:07.942: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:00:07.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0521 03:00:07.942783      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9239" for this suite.
May 21 03:00:13.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:00:14.054: INFO: namespace gc-9239 deletion completed in 6.107046585s

• [SLOW TEST:16.223 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:00:14.056: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:00:16.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5946" for this suite.
May 21 03:01:00.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:01:00.240: INFO: namespace kubelet-test-5946 deletion completed in 44.096665651s

• [SLOW TEST:46.184 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:01:00.240: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-x82l
STEP: Creating a pod to test atomic-volume-subpath
May 21 03:01:00.286: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-x82l" in namespace "subpath-9277" to be "success or failure"
May 21 03:01:00.293: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Pending", Reason="", readiness=false. Elapsed: 6.519269ms
May 21 03:01:02.297: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010456208s
May 21 03:01:04.300: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 4.014069971s
May 21 03:01:06.310: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 6.023892707s
May 21 03:01:08.314: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 8.028013503s
May 21 03:01:10.317: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 10.030742127s
May 21 03:01:12.323: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 12.037069588s
May 21 03:01:14.327: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 14.041041555s
May 21 03:01:16.330: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 16.043927086s
May 21 03:01:18.334: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 18.047320085s
May 21 03:01:20.337: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 20.050943545s
May 21 03:01:22.340: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Running", Reason="", readiness=true. Elapsed: 22.054095205s
May 21 03:01:24.345: INFO: Pod "pod-subpath-test-secret-x82l": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058432712s
STEP: Saw pod success
May 21 03:01:24.345: INFO: Pod "pod-subpath-test-secret-x82l" satisfied condition "success or failure"
May 21 03:01:24.356: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-subpath-test-secret-x82l container test-container-subpath-secret-x82l: <nil>
STEP: delete the pod
May 21 03:01:24.388: INFO: Waiting for pod pod-subpath-test-secret-x82l to disappear
May 21 03:01:24.390: INFO: Pod pod-subpath-test-secret-x82l no longer exists
STEP: Deleting pod pod-subpath-test-secret-x82l
May 21 03:01:24.390: INFO: Deleting pod "pod-subpath-test-secret-x82l" in namespace "subpath-9277"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:01:24.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9277" for this suite.
May 21 03:01:30.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:01:30.485: INFO: namespace subpath-9277 deletion completed in 6.087978152s

• [SLOW TEST:30.245 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:01:30.485: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d60c9bbf-47f2-49ae-ae66-a6debf236e92
STEP: Creating a pod to test consume configMaps
May 21 03:01:30.534: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558" in namespace "projected-3754" to be "success or failure"
May 21 03:01:30.540: INFO: Pod "pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558": Phase="Pending", Reason="", readiness=false. Elapsed: 5.685094ms
May 21 03:01:32.543: INFO: Pod "pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009291173s
May 21 03:01:34.547: INFO: Pod "pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013065058s
STEP: Saw pod success
May 21 03:01:34.547: INFO: Pod "pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558" satisfied condition "success or failure"
May 21 03:01:34.549: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:01:34.580: INFO: Waiting for pod pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558 to disappear
May 21 03:01:34.585: INFO: Pod pod-projected-configmaps-738fda9c-80a1-4212-89ac-61c387b39558 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:01:34.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3754" for this suite.
May 21 03:01:40.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:01:40.693: INFO: namespace projected-3754 deletion completed in 6.102221083s

• [SLOW TEST:10.207 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:01:40.694: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-3e2a4f8e-eefe-405c-8001-64ae1fef9b3f
STEP: Creating a pod to test consume configMaps
May 21 03:01:40.747: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0" in namespace "projected-6060" to be "success or failure"
May 21 03:01:40.754: INFO: Pod "pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.478028ms
May 21 03:01:42.758: INFO: Pod "pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010472828s
STEP: Saw pod success
May 21 03:01:42.758: INFO: Pod "pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0" satisfied condition "success or failure"
May 21 03:01:42.761: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:01:42.787: INFO: Waiting for pod pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0 to disappear
May 21 03:01:42.791: INFO: Pod pod-projected-configmaps-f5256c43-2c34-4196-8871-55bccbb7c7e0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:01:42.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6060" for this suite.
May 21 03:01:48.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:01:48.906: INFO: namespace projected-6060 deletion completed in 6.110033243s

• [SLOW TEST:8.212 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:01:48.906: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:01:48.975: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"8169691a-7415-4b59-b2c9-2121cc85f3c7", Controller:(*bool)(0xc0035705ce), BlockOwnerDeletion:(*bool)(0xc0035705cf)}}
May 21 03:01:48.986: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c4e8415e-8af5-4413-8df4-2596a406180c", Controller:(*bool)(0xc0033efeee), BlockOwnerDeletion:(*bool)(0xc0033efeef)}}
May 21 03:01:48.993: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"290ed9a5-b27b-4dfc-b0e0-397dbf580c75", Controller:(*bool)(0xc003570796), BlockOwnerDeletion:(*bool)(0xc003570797)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:01:54.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9107" for this suite.
May 21 03:02:00.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:02:00.115: INFO: namespace gc-9107 deletion completed in 6.098490203s

• [SLOW TEST:11.209 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:02:00.116: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
May 21 03:02:04.699: INFO: Successfully updated pod "annotationupdatee0527e13-9e0f-4814-a857-c4b85e6c741c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:02:06.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3387" for this suite.
May 21 03:02:34.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:02:34.808: INFO: namespace downward-api-3387 deletion completed in 28.08340857s

• [SLOW TEST:34.693 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:02:34.808: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:02:36.072: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:02:38.080: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626956, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626956, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626956, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725626956, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:02:41.106: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:02:41.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5069" for this suite.
May 21 03:02:47.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:02:47.504: INFO: namespace webhook-5069 deletion completed in 6.153608499s
STEP: Destroying namespace "webhook-5069-markers" for this suite.
May 21 03:02:53.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:02:53.629: INFO: namespace webhook-5069-markers deletion completed in 6.124758566s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.833 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:02:53.642: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-wtrks in namespace proxy-1436
I0521 03:02:53.731406      20 runners.go:184] Created replication controller with name: proxy-service-wtrks, namespace: proxy-1436, replica count: 1
I0521 03:02:54.783318      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 03:02:55.784046      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:02:56.784327      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:02:57.784638      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:02:58.784890      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:02:59.785127      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:03:00.785398      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:03:01.786247      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0521 03:03:02.786917      20 runners.go:184] proxy-service-wtrks Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 03:03:02.794: INFO: setup took 9.105417431s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May 21 03:03:02.811: INFO: (0) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 15.387739ms)
May 21 03:03:02.816: INFO: (0) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 20.65334ms)
May 21 03:03:02.850: INFO: (0) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 55.331121ms)
May 21 03:03:02.850: INFO: (0) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 55.647285ms)
May 21 03:03:02.850: INFO: (0) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 55.222019ms)
May 21 03:03:02.850: INFO: (0) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 55.883946ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 59.099229ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 60.447039ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 59.225604ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 59.416874ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 59.122163ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 59.582333ms)
May 21 03:03:02.855: INFO: (0) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 60.119293ms)
May 21 03:03:02.856: INFO: (0) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 60.396226ms)
May 21 03:03:02.856: INFO: (0) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 59.976744ms)
May 21 03:03:02.856: INFO: (0) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 59.741889ms)
May 21 03:03:02.866: INFO: (1) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 8.493536ms)
May 21 03:03:02.866: INFO: (1) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 9.933555ms)
May 21 03:03:02.866: INFO: (1) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 10.440295ms)
May 21 03:03:02.867: INFO: (1) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 10.608253ms)
May 21 03:03:02.868: INFO: (1) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 10.415843ms)
May 21 03:03:02.868: INFO: (1) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 11.257999ms)
May 21 03:03:02.868: INFO: (1) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 11.773454ms)
May 21 03:03:02.868: INFO: (1) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 12.548963ms)
May 21 03:03:02.869: INFO: (1) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 11.367023ms)
May 21 03:03:02.869: INFO: (1) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 13.196563ms)
May 21 03:03:02.870: INFO: (1) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 12.888377ms)
May 21 03:03:02.873: INFO: (1) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 16.465773ms)
May 21 03:03:02.873: INFO: (1) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 15.475966ms)
May 21 03:03:02.873: INFO: (1) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 16.457811ms)
May 21 03:03:02.873: INFO: (1) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 15.416192ms)
May 21 03:03:02.873: INFO: (1) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 16.017057ms)
May 21 03:03:02.879: INFO: (2) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 5.491621ms)
May 21 03:03:02.879: INFO: (2) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.427135ms)
May 21 03:03:02.880: INFO: (2) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 5.794472ms)
May 21 03:03:02.880: INFO: (2) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 6.412136ms)
May 21 03:03:02.887: INFO: (2) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 13.149567ms)
May 21 03:03:02.887: INFO: (2) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 12.513155ms)
May 21 03:03:02.887: INFO: (2) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 13.59317ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 14.380954ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 15.248191ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 14.630069ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 15.392529ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 14.579272ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 14.993566ms)
May 21 03:03:02.889: INFO: (2) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 15.124246ms)
May 21 03:03:02.894: INFO: (2) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 19.30506ms)
May 21 03:03:02.894: INFO: (2) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 20.950275ms)
May 21 03:03:02.908: INFO: (3) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 13.553555ms)
May 21 03:03:02.914: INFO: (3) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 18.968585ms)
May 21 03:03:02.914: INFO: (3) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 19.176195ms)
May 21 03:03:02.914: INFO: (3) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 19.450954ms)
May 21 03:03:02.916: INFO: (3) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 21.115136ms)
May 21 03:03:02.916: INFO: (3) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 21.426192ms)
May 21 03:03:02.916: INFO: (3) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 21.760161ms)
May 21 03:03:02.916: INFO: (3) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 22.32951ms)
May 21 03:03:02.916: INFO: (3) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 21.706115ms)
May 21 03:03:02.922: INFO: (3) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 26.7941ms)
May 21 03:03:02.922: INFO: (3) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 26.977837ms)
May 21 03:03:02.922: INFO: (3) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 26.911136ms)
May 21 03:03:02.922: INFO: (3) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 26.784249ms)
May 21 03:03:02.922: INFO: (3) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 26.853531ms)
May 21 03:03:02.927: INFO: (3) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 32.327899ms)
May 21 03:03:02.927: INFO: (3) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 32.298471ms)
May 21 03:03:02.934: INFO: (4) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.518309ms)
May 21 03:03:02.939: INFO: (4) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 8.543119ms)
May 21 03:03:02.939: INFO: (4) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 10.196813ms)
May 21 03:03:02.947: INFO: (4) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 17.17452ms)
May 21 03:03:02.947: INFO: (4) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 18.005489ms)
May 21 03:03:02.947: INFO: (4) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 19.161103ms)
May 21 03:03:02.947: INFO: (4) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 17.640357ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 19.354761ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 19.523609ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 19.710293ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 17.494915ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 18.377553ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 17.365759ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 17.31825ms)
May 21 03:03:02.948: INFO: (4) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 18.370993ms)
May 21 03:03:02.949: INFO: (4) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 20.181663ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 9.461511ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 11.590069ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 10.651074ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 11.108207ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 11.282709ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 11.013046ms)
May 21 03:03:02.961: INFO: (5) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 10.304434ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 11.417059ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 13.252639ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 11.733279ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 12.451757ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 11.625743ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 12.987647ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 12.133324ms)
May 21 03:03:02.963: INFO: (5) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 12.7648ms)
May 21 03:03:02.964: INFO: (5) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 12.563919ms)
May 21 03:03:02.970: INFO: (6) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 5.960561ms)
May 21 03:03:02.970: INFO: (6) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.243469ms)
May 21 03:03:02.971: INFO: (6) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 7.019104ms)
May 21 03:03:02.972: INFO: (6) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 7.773006ms)
May 21 03:03:02.972: INFO: (6) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.899336ms)
May 21 03:03:02.972: INFO: (6) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 7.20764ms)
May 21 03:03:02.972: INFO: (6) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 7.470491ms)
May 21 03:03:02.973: INFO: (6) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 8.426591ms)
May 21 03:03:02.973: INFO: (6) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 8.204786ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 9.873944ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 10.445256ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 10.352974ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 11.097496ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 11.34271ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 11.485876ms)
May 21 03:03:02.975: INFO: (6) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 11.04846ms)
May 21 03:03:02.986: INFO: (7) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 11.13375ms)
May 21 03:03:02.988: INFO: (7) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 12.644994ms)
May 21 03:03:02.989: INFO: (7) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 12.854777ms)
May 21 03:03:02.989: INFO: (7) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 12.992568ms)
May 21 03:03:02.989: INFO: (7) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 13.057592ms)
May 21 03:03:02.991: INFO: (7) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 14.778383ms)
May 21 03:03:02.991: INFO: (7) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 14.961281ms)
May 21 03:03:02.992: INFO: (7) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 16.09264ms)
May 21 03:03:02.992: INFO: (7) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 16.238925ms)
May 21 03:03:02.992: INFO: (7) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 16.134023ms)
May 21 03:03:02.992: INFO: (7) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 16.47565ms)
May 21 03:03:02.994: INFO: (7) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 18.781681ms)
May 21 03:03:02.994: INFO: (7) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 18.443393ms)
May 21 03:03:02.996: INFO: (7) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 20.162745ms)
May 21 03:03:02.996: INFO: (7) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 20.086731ms)
May 21 03:03:02.996: INFO: (7) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 19.935695ms)
May 21 03:03:03.002: INFO: (8) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 5.956882ms)
May 21 03:03:03.014: INFO: (8) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 16.245245ms)
May 21 03:03:03.014: INFO: (8) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 17.683066ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 26.137343ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 25.682856ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 26.890964ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 27.439787ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 26.570291ms)
May 21 03:03:03.023: INFO: (8) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 25.984222ms)
May 21 03:03:03.034: INFO: (8) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 37.625314ms)
May 21 03:03:03.034: INFO: (8) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 38.028105ms)
May 21 03:03:03.034: INFO: (8) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 36.770034ms)
May 21 03:03:03.034: INFO: (8) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 37.960461ms)
May 21 03:03:03.034: INFO: (8) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 37.478892ms)
May 21 03:03:03.035: INFO: (8) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 37.412742ms)
May 21 03:03:03.035: INFO: (8) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 38.56589ms)
May 21 03:03:03.065: INFO: (9) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 29.869836ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 41.190531ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 41.39313ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 40.8473ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 41.606708ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 41.139817ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 41.28518ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 40.763742ms)
May 21 03:03:03.076: INFO: (9) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 40.915003ms)
May 21 03:03:03.092: INFO: (9) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 56.547436ms)
May 21 03:03:03.092: INFO: (9) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 56.336763ms)
May 21 03:03:03.092: INFO: (9) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 56.774203ms)
May 21 03:03:03.093: INFO: (9) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 57.129339ms)
May 21 03:03:03.093: INFO: (9) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 56.826111ms)
May 21 03:03:03.093: INFO: (9) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 56.921819ms)
May 21 03:03:03.102: INFO: (9) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 66.190919ms)
May 21 03:03:03.118: INFO: (10) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 15.54708ms)
May 21 03:03:03.118: INFO: (10) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 15.710583ms)
May 21 03:03:03.118: INFO: (10) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 16.21467ms)
May 21 03:03:03.118: INFO: (10) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 15.350698ms)
May 21 03:03:03.118: INFO: (10) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 15.99032ms)
May 21 03:03:03.122: INFO: (10) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 19.307675ms)
May 21 03:03:03.122: INFO: (10) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 18.987573ms)
May 21 03:03:03.123: INFO: (10) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 19.809989ms)
May 21 03:03:03.123: INFO: (10) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 19.593519ms)
May 21 03:03:03.123: INFO: (10) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 19.713229ms)
May 21 03:03:03.123: INFO: (10) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 20.599292ms)
May 21 03:03:03.124: INFO: (10) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 21.614287ms)
May 21 03:03:03.124: INFO: (10) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 21.035819ms)
May 21 03:03:03.124: INFO: (10) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 22.168951ms)
May 21 03:03:03.124: INFO: (10) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 20.817506ms)
May 21 03:03:03.124: INFO: (10) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 21.229876ms)
May 21 03:03:03.131: INFO: (11) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 6.221842ms)
May 21 03:03:03.131: INFO: (11) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 6.341059ms)
May 21 03:03:03.131: INFO: (11) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 6.515056ms)
May 21 03:03:03.134: INFO: (11) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 8.968399ms)
May 21 03:03:03.134: INFO: (11) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 8.443157ms)
May 21 03:03:03.134: INFO: (11) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 9.396906ms)
May 21 03:03:03.136: INFO: (11) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 9.880802ms)
May 21 03:03:03.136: INFO: (11) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 11.042276ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 15.041087ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 15.248853ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 15.173781ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 14.998102ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 14.97881ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 15.748794ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 15.270457ms)
May 21 03:03:03.141: INFO: (11) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 16.379637ms)
May 21 03:03:03.148: INFO: (12) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.24332ms)
May 21 03:03:03.148: INFO: (12) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 6.43795ms)
May 21 03:03:03.148: INFO: (12) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 6.180821ms)
May 21 03:03:03.149: INFO: (12) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 7.731171ms)
May 21 03:03:03.149: INFO: (12) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 7.532355ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 15.943815ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 15.720123ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 16.267788ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 15.634609ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 15.404308ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 15.586834ms)
May 21 03:03:03.158: INFO: (12) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 15.372146ms)
May 21 03:03:03.160: INFO: (12) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 18.024524ms)
May 21 03:03:03.160: INFO: (12) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 17.533379ms)
May 21 03:03:03.160: INFO: (12) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 17.045875ms)
May 21 03:03:03.160: INFO: (12) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 18.695721ms)
May 21 03:03:03.164: INFO: (13) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 4.483176ms)
May 21 03:03:03.174: INFO: (13) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 12.904136ms)
May 21 03:03:03.174: INFO: (13) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 13.661253ms)
May 21 03:03:03.175: INFO: (13) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 13.426948ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 22.599916ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 22.765046ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 22.019095ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 22.571466ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 21.976458ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 21.21478ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 22.526948ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 21.499451ms)
May 21 03:03:03.183: INFO: (13) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 21.631957ms)
May 21 03:03:03.185: INFO: (13) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 23.361366ms)
May 21 03:03:03.191: INFO: (13) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 30.740427ms)
May 21 03:03:03.192: INFO: (13) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 29.900762ms)
May 21 03:03:03.202: INFO: (14) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 9.10785ms)
May 21 03:03:03.202: INFO: (14) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 9.663831ms)
May 21 03:03:03.203: INFO: (14) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 10.644715ms)
May 21 03:03:03.203: INFO: (14) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 11.020555ms)
May 21 03:03:03.204: INFO: (14) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 11.971202ms)
May 21 03:03:03.204: INFO: (14) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 11.743952ms)
May 21 03:03:03.204: INFO: (14) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 11.515168ms)
May 21 03:03:03.212: INFO: (14) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 18.895215ms)
May 21 03:03:03.212: INFO: (14) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 19.478353ms)
May 21 03:03:03.212: INFO: (14) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 19.922131ms)
May 21 03:03:03.213: INFO: (14) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 20.180997ms)
May 21 03:03:03.213: INFO: (14) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 20.156022ms)
May 21 03:03:03.213: INFO: (14) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 20.13ms)
May 21 03:03:03.213: INFO: (14) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 20.025353ms)
May 21 03:03:03.213: INFO: (14) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 20.246036ms)
May 21 03:03:03.215: INFO: (14) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 22.806035ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 25.361373ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 25.196015ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 25.598698ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 24.337784ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 24.244538ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 25.200843ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 25.436178ms)
May 21 03:03:03.241: INFO: (15) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 24.72941ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 33.993147ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 34.151077ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 34.741278ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 34.867836ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 34.694764ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 34.326218ms)
May 21 03:03:03.251: INFO: (15) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 34.620192ms)
May 21 03:03:03.261: INFO: (15) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 44.109145ms)
May 21 03:03:03.280: INFO: (16) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 18.832773ms)
May 21 03:03:03.280: INFO: (16) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 19.146126ms)
May 21 03:03:03.281: INFO: (16) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 19.718003ms)
May 21 03:03:03.281: INFO: (16) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 20.147598ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 30.979087ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 30.716196ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 30.60884ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 30.905863ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 30.940207ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 31.004279ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 31.037499ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 30.924651ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 30.751187ms)
May 21 03:03:03.292: INFO: (16) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 31.290985ms)
May 21 03:03:03.298: INFO: (16) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 37.308974ms)
May 21 03:03:03.298: INFO: (16) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 37.09555ms)
May 21 03:03:03.308: INFO: (17) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 9.294381ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 16.010322ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 16.086187ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 16.222988ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 15.816046ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 16.00868ms)
May 21 03:03:03.315: INFO: (17) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 15.892314ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 20.961642ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 20.834374ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 20.833576ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 20.774677ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 21.073603ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 21.17133ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 21.063717ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 21.334245ms)
May 21 03:03:03.320: INFO: (17) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 21.173972ms)
May 21 03:03:03.326: INFO: (18) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 5.814913ms)
May 21 03:03:03.327: INFO: (18) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 6.000858ms)
May 21 03:03:03.327: INFO: (18) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 7.108233ms)
May 21 03:03:03.327: INFO: (18) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 6.400991ms)
May 21 03:03:03.330: INFO: (18) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 9.570203ms)
May 21 03:03:03.331: INFO: (18) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 9.042414ms)
May 21 03:03:03.331: INFO: (18) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 10.008831ms)
May 21 03:03:03.331: INFO: (18) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 10.183158ms)
May 21 03:03:03.332: INFO: (18) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 11.126375ms)
May 21 03:03:03.332: INFO: (18) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 10.130369ms)
May 21 03:03:03.332: INFO: (18) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 11.928618ms)
May 21 03:03:03.337: INFO: (18) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 15.104057ms)
May 21 03:03:03.337: INFO: (18) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 15.387272ms)
May 21 03:03:03.337: INFO: (18) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 16.684912ms)
May 21 03:03:03.337: INFO: (18) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 15.321949ms)
May 21 03:03:03.338: INFO: (18) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 16.188949ms)
May 21 03:03:03.350: INFO: (19) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:162/proxy/: bar (200; 12.366711ms)
May 21 03:03:03.351: INFO: (19) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:443/proxy/tlsrewritem... (200; 12.536335ms)
May 21 03:03:03.352: INFO: (19) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:1080/proxy/rewriteme">... (200; 13.672954ms)
May 21 03:03:03.352: INFO: (19) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:462/proxy/: tls qux (200; 13.619234ms)
May 21 03:03:03.352: INFO: (19) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:1080/proxy/rewriteme">test<... (200; 14.323574ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/: <a href="/api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h/proxy/rewriteme">test</a> (200; 17.124272ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/pods/http:proxy-service-wtrks-c779h:160/proxy/: foo (200; 17.083498ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:160/proxy/: foo (200; 17.606509ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname1/proxy/: tls baz (200; 17.448551ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/pods/https:proxy-service-wtrks-c779h:460/proxy/: tls baz (200; 17.338199ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname2/proxy/: bar (200; 17.508299ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/pods/proxy-service-wtrks-c779h:162/proxy/: bar (200; 17.458034ms)
May 21 03:03:03.356: INFO: (19) /api/v1/namespaces/proxy-1436/services/https:proxy-service-wtrks:tlsportname2/proxy/: tls qux (200; 17.386808ms)
May 21 03:03:03.357: INFO: (19) /api/v1/namespaces/proxy-1436/services/http:proxy-service-wtrks:portname1/proxy/: foo (200; 18.955485ms)
May 21 03:03:03.357: INFO: (19) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname2/proxy/: bar (200; 17.809952ms)
May 21 03:03:03.357: INFO: (19) /api/v1/namespaces/proxy-1436/services/proxy-service-wtrks:portname1/proxy/: foo (200; 18.524135ms)
STEP: deleting ReplicationController proxy-service-wtrks in namespace proxy-1436, will wait for the garbage collector to delete the pods
May 21 03:03:03.418: INFO: Deleting ReplicationController proxy-service-wtrks took: 9.165349ms
May 21 03:03:03.719: INFO: Terminating ReplicationController proxy-service-wtrks pods took: 300.483047ms
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:03:06.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1436" for this suite.
May 21 03:03:12.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:03:12.111: INFO: namespace proxy-1436 deletion completed in 6.086485053s

• [SLOW TEST:18.469 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:03:12.111: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-889
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 03:03:12.145: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 03:03:30.228: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.240.4.68:8080/dial?request=hostName&protocol=udp&host=10.240.4.67&port=8081&tries=1'] Namespace:pod-network-test-889 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 03:03:30.228: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:03:30.535: INFO: Waiting for endpoints: map[]
May 21 03:03:30.538: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.240.4.68:8080/dial?request=hostName&protocol=udp&host=10.240.3.71&port=8081&tries=1'] Namespace:pod-network-test-889 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 03:03:30.538: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:03:30.981: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:03:30.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-889" for this suite.
May 21 03:03:43.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:03:43.113: INFO: namespace pod-network-test-889 deletion completed in 12.114543195s

• [SLOW TEST:31.002 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:03:43.113: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-2431/secret-test-49e748ef-f04e-428a-929b-2b98e8801898
STEP: Creating a pod to test consume secrets
May 21 03:03:43.169: INFO: Waiting up to 5m0s for pod "pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd" in namespace "secrets-2431" to be "success or failure"
May 21 03:03:43.175: INFO: Pod "pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.252459ms
May 21 03:03:45.178: INFO: Pod "pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009019281s
STEP: Saw pod success
May 21 03:03:45.178: INFO: Pod "pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd" satisfied condition "success or failure"
May 21 03:03:45.181: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd container env-test: <nil>
STEP: delete the pod
May 21 03:03:45.212: INFO: Waiting for pod pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd to disappear
May 21 03:03:45.214: INFO: Pod pod-configmaps-3776ae4b-c1a1-45f8-9113-8983e22129cd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:03:45.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2431" for this suite.
May 21 03:03:51.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:03:51.323: INFO: namespace secrets-2431 deletion completed in 6.104035029s

• [SLOW TEST:8.210 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:03:51.323: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:03:51.358: INFO: Creating deployment "webserver-deployment"
May 21 03:03:51.365: INFO: Waiting for observed generation 1
May 21 03:03:53.372: INFO: Waiting for all required pods to come up
May 21 03:03:53.376: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
May 21 03:03:55.396: INFO: Waiting for deployment "webserver-deployment" to complete
May 21 03:03:55.402: INFO: Updating deployment "webserver-deployment" with a non-existent image
May 21 03:03:55.410: INFO: Updating deployment webserver-deployment
May 21 03:03:55.410: INFO: Waiting for observed generation 2
May 21 03:03:57.416: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May 21 03:03:57.419: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May 21 03:03:57.424: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 21 03:03:57.430: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May 21 03:03:57.430: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May 21 03:03:57.434: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May 21 03:03:57.457: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May 21 03:03:57.457: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May 21 03:03:57.486: INFO: Updating deployment webserver-deployment
May 21 03:03:57.486: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May 21 03:03:57.533: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May 21 03:03:59.560: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
May 21 03:03:59.568: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8901 /apis/apps/v1/namespaces/deployment-8901/deployments/webserver-deployment 1842494c-56fb-4bda-b07c-1633e83e2f39 23567 3 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002861d98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-21 03:03:57 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-05-21 03:03:57 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May 21 03:03:59.572: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-8901 /apis/apps/v1/namespaces/deployment-8901/replicasets/webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 23566 3 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 1842494c-56fb-4bda-b07c-1633e83e2f39 0xc002261127 0xc002261128}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0022611d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 03:03:59.572: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May 21 03:03:59.572: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-5774697498  deployment-8901 /apis/apps/v1/namespaces/deployment-8901/replicasets/webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 23557 3 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 1842494c-56fb-4bda-b07c-1633e83e2f39 0xc002260f37 0xc002260f38}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 5774697498,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002261018 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May 21 03:03:59.579: INFO: Pod "webserver-deployment-5774697498-49dlg" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-49dlg webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-49dlg a3ca536b-7d92-4f24-9bcc-2f96d64110bf 23565 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d83c7 0xc0021d83c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.579: INFO: Pod "webserver-deployment-5774697498-4khnj" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-4khnj webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-4khnj e8f7d7a9-73a0-4e96-ba8f-2bf97a6164a1 23405 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d8767 0xc0021d8768}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.74,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://df298566333c6bf443770ba83d7c3016bc0bc7dd65e6bf135b96f8ac6697e3d8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.579: INFO: Pod "webserver-deployment-5774697498-8rqnb" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-8rqnb webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-8rqnb 0f87b5e3-02de-4e67-b496-4c2b53c59849 23587 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d8bb0 0xc0021d8bb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.579: INFO: Pod "webserver-deployment-5774697498-96pwr" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-96pwr webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-96pwr e07a1de3-b653-462d-a9a0-f682c428cc75 23595 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d9027 0xc0021d9028}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-9vfsx" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-9vfsx webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-9vfsx d6199b30-34ff-449b-88cd-1af48e4ca302 23409 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d93b7 0xc0021d93b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.75,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://1ddab346facd458ccc5d643013ca0a39715c084f5f5e073d25cdfb73a1784309,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-bx9zb" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-bx9zb webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-bx9zb 6fd796df-99f6-4d69-8254-9412599dc366 23399 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d9750 0xc0021d9751}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.73,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://b13c25cec12481aaec2bfffd2e79296fe6de281fcae646fa067035c98c4bd99b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-dwc56" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-dwc56 webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-dwc56 2c027cb8-a3f6-4992-9840-0d20928a1789 23598 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d9b10 0xc0021d9b11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-dzn6m" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-dzn6m webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-dzn6m 81773388-1484-49e9-83d1-67dea6e570e0 23539 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021d9e67 0xc0021d9e68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-gj2hz" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-gj2hz webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-gj2hz a5b14c4c-a8db-45b5-bde9-3290e25c9f55 23389 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002154070 0xc002154071}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.71,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://f00c951f6d378503f1ee342360c1e3b20cbffdc6a8ef5083a802bb6697f26d3a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.71,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-gl8z5" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-gl8z5 webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-gl8z5 09b7bf5c-e4f3-4024-837a-96577e2dc3a4 23540 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002154300 0xc002154301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.580: INFO: Pod "webserver-deployment-5774697498-h5rvq" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-h5rvq webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-h5rvq 94e190d6-9ec8-4cbe-b536-9875379b18e7 23568 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc0021544f7 0xc0021544f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-kmwll" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-kmwll webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-kmwll 2159ee88-fb12-449e-9f84-9c7a1f785c33 23413 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002154887 0xc002154888}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.70,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://3bacc092f847b305af12d18be739d2d266d07a727c339131ac8c0e56d8dc040c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-l6hlv" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-l6hlv webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-l6hlv 0104cd70-3fed-4522-a75f-e770b0eb8cc3 23504 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002154b40 0xc002154b41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-n7l4z" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-n7l4z webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-n7l4z be8dfaef-715f-40ac-aa74-bcbdb51c5cb0 23578 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002154f57 0xc002154f58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-rllpd" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-rllpd webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-rllpd b5cf2b8c-4b50-4662-9ebc-916df050f460 23537 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155227 0xc002155228}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-s9hf2" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-s9hf2 webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-s9hf2 7b13a127-f5c2-4b26-817e-757f8259a59c 23528 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155340 0xc002155341}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-srg9j" is not available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-srg9j webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-srg9j 035810e2-7dbb-414f-aa1c-810b5d24c6e1 23536 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155667 0xc002155668}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.581: INFO: Pod "webserver-deployment-5774697498-tmpml" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-tmpml webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-tmpml b4220097-bd6d-4431-b540-9fda4b445325 23387 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155860 0xc002155861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.72,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://d64a274887052a1e0f4e420c23b042a39fc04608f87d82f148ff491edbdc9c75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.72,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.582: INFO: Pod "webserver-deployment-5774697498-wksq8" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-wksq8 webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-wksq8 2400170f-c431-4a67-8698-4287bb232752 23403 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155b60 0xc002155b61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.73,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://2b14800afc1f27e39fcd9c58cab04e79b3bded40a6b4b58b09e118d73c971c61,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.582: INFO: Pod "webserver-deployment-5774697498-xfqzr" is available:
&Pod{ObjectMeta:{webserver-deployment-5774697498-xfqzr webserver-deployment-5774697498- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-5774697498-xfqzr d407e2a0-9a85-426b-9dc0-f4d5d56bf542 23396 0 2020-05-21 03:03:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:5774697498] map[] [{apps/v1 ReplicaSet webserver-deployment-5774697498 5e898803-3bf1-47b6-9017-5d20c94a13dd 0xc002155ed0 0xc002155ed1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.75,StartTime:2020-05-21 03:03:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 03:03:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://dd9bbc968dc533fbec490e0a64e48251cbe771395d91dc0329f6ce998e2fff0c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.582: INFO: Pod "webserver-deployment-c7997dcc8-29wsq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-29wsq webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-29wsq fc639d9c-647d-4b14-b2cf-48fec41b8b50 23597 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e81a0 0xc0020e81a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.582: INFO: Pod "webserver-deployment-c7997dcc8-2gqt7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2gqt7 webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-2gqt7 15e7cf4b-31d0-4175-a062-010fdde15a0f 23581 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e8470 0xc0020e8471}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.582: INFO: Pod "webserver-deployment-c7997dcc8-5cqp6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5cqp6 webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-5cqp6 4f94a78b-78f2-422b-8304-71ca4a3b93e6 23594 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e8800 0xc0020e8801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-5jr9x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5jr9x webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-5jr9x 031536b3-984d-4599-a50c-b86d3ef70a60 23588 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e8a40 0xc0020e8a41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-7lvlr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7lvlr webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-7lvlr c2bc73b4-3a03-461f-9af4-6137582eab37 23551 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e8f90 0xc0020e8f91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-8cvvf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8cvvf webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-8cvvf cae62c72-dd33-4c0f-9b9c-811aeca619d9 23467 0 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e9140 0xc0020e9141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-ds6pk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ds6pk webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-ds6pk 0bbb361c-12b9-4cd7-9474-cc8164c6565c 23559 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e95b0 0xc0020e95b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-k4ds5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-k4ds5 webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-k4ds5 d73810da-8ab8-4d78-a1d3-8018cf6cd350 23446 0 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e98f0 0xc0020e98f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-kxxn4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kxxn4 webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-kxxn4 71d7c4fb-200d-4dab-895d-f2f7ac27906b 23562 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e9a60 0xc0020e9a61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.583: INFO: Pod "webserver-deployment-c7997dcc8-m6jgj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m6jgj webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-m6jgj 443933b9-2e0e-4406-85eb-724099a8de3d 23464 0 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e9bd0 0xc0020e9bd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.584: INFO: Pod "webserver-deployment-c7997dcc8-mgjkr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mgjkr webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-mgjkr b2a231f9-bee1-4caa-92ea-ef6a1035bbda 23436 0 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e9d40 0xc0020e9d41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:,StartTime:2020-05-21 03:03:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.584: INFO: Pod "webserver-deployment-c7997dcc8-pqbwj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pqbwj webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-pqbwj ffd8d726-26f6-471e-9ee2-4e74fb0a935b 23463 0 2020-05-21 03:03:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc0020e9eb0 0xc0020e9eb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May 21 03:03:59.584: INFO: Pod "webserver-deployment-c7997dcc8-tj4v9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tj4v9 webserver-deployment-c7997dcc8- deployment-8901 /api/v1/namespaces/deployment-8901/pods/webserver-deployment-c7997dcc8-tj4v9 94615236-afba-4e10-9208-197e70dc0878 23564 0 2020-05-21 03:03:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0bdae23f-4474-41d8-b65d-08e2983ae55f 0xc001da2020 0xc001da2021}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w8pnc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w8pnc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w8pnc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 03:03:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:,StartTime:2020-05-21 03:03:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:03:59.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8901" for this suite.
May 21 03:04:07.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:04:07.828: INFO: namespace deployment-8901 deletion completed in 8.237724084s

• [SLOW TEST:16.505 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:04:07.828: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May 21 03:04:08.055: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:08.055: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:08.055: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:08.061: INFO: Number of nodes with available pods: 0
May 21 03:04:08.061: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:09.080: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:09.080: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:09.080: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:09.083: INFO: Number of nodes with available pods: 0
May 21 03:04:09.083: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:10.070: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:10.070: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:10.070: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:10.073: INFO: Number of nodes with available pods: 0
May 21 03:04:10.073: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:11.069: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.069: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.069: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.094: INFO: Number of nodes with available pods: 2
May 21 03:04:11.094: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May 21 03:04:11.114: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.114: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.114: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:11.119: INFO: Number of nodes with available pods: 1
May 21 03:04:11.119: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:12.139: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:12.139: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:12.139: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:12.144: INFO: Number of nodes with available pods: 1
May 21 03:04:12.144: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:13.132: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:13.132: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:13.132: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:13.135: INFO: Number of nodes with available pods: 1
May 21 03:04:13.135: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:04:14.126: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:14.126: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:14.126: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:04:14.129: INFO: Number of nodes with available pods: 2
May 21 03:04:14.129: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5549, will wait for the garbage collector to delete the pods
May 21 03:04:14.193: INFO: Deleting DaemonSet.extensions daemon-set took: 8.096003ms
May 21 03:04:14.294: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.279937ms
May 21 03:04:27.297: INFO: Number of nodes with available pods: 0
May 21 03:04:27.297: INFO: Number of running nodes: 0, number of available pods: 0
May 21 03:04:27.299: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5549/daemonsets","resourceVersion":"23981"},"items":null}

May 21 03:04:27.302: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5549/pods","resourceVersion":"23981"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:04:27.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5549" for this suite.
May 21 03:04:33.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:04:33.399: INFO: namespace daemonsets-5549 deletion completed in 6.083931036s

• [SLOW TEST:25.571 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:04:33.400: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-908
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-908 to expose endpoints map[]
May 21 03:04:33.463: INFO: Get endpoints failed (7.126353ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
May 21 03:04:34.466: INFO: successfully validated that service multi-endpoint-test in namespace services-908 exposes endpoints map[] (1.010085758s elapsed)
STEP: Creating pod pod1 in namespace services-908
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-908 to expose endpoints map[pod1:[100]]
May 21 03:04:37.502: INFO: successfully validated that service multi-endpoint-test in namespace services-908 exposes endpoints map[pod1:[100]] (3.027696961s elapsed)
STEP: Creating pod pod2 in namespace services-908
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-908 to expose endpoints map[pod1:[100] pod2:[101]]
May 21 03:04:39.553: INFO: successfully validated that service multi-endpoint-test in namespace services-908 exposes endpoints map[pod1:[100] pod2:[101]] (2.04039065s elapsed)
STEP: Deleting pod pod1 in namespace services-908
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-908 to expose endpoints map[pod2:[101]]
May 21 03:04:40.585: INFO: successfully validated that service multi-endpoint-test in namespace services-908 exposes endpoints map[pod2:[101]] (1.024908062s elapsed)
STEP: Deleting pod pod2 in namespace services-908
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-908 to expose endpoints map[]
May 21 03:04:40.597: INFO: successfully validated that service multi-endpoint-test in namespace services-908 exposes endpoints map[] (3.599028ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:04:40.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-908" for this suite.
May 21 03:04:52.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:04:52.736: INFO: namespace services-908 deletion completed in 12.087664014s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.336 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:04:52.736: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5505
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
May 21 03:04:52.853: INFO: Found 0 stateful pods, waiting for 3
May 21 03:05:02.859: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:05:02.860: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:05:02.860: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:05:02.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-5505 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:05:03.230: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:05:03.230: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:05:03.230: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from 172.16.17.5/sonobuoy/httpd:2.4.38-alpine to 172.16.17.5/sonobuoy/httpd:2.4.39-alpine
May 21 03:05:13.264: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May 21 03:05:23.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-5505 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:05:23.811: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:05:23.811: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:05:23.811: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:05:33.833: INFO: Waiting for StatefulSet statefulset-5505/ss2 to complete update
May 21 03:05:33.833: INFO: Waiting for Pod statefulset-5505/ss2-0 to have revision ss2-9d9677584 update revision ss2-5658755fcf
STEP: Rolling back to a previous revision
May 21 03:05:43.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-5505 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:05:44.182: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:05:44.182: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:05:44.182: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:05:54.216: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May 21 03:06:04.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-5505 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:06:04.563: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:06:04.563: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:06:04.563: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:06:14.594: INFO: Waiting for StatefulSet statefulset-5505/ss2 to complete update
May 21 03:06:14.594: INFO: Waiting for Pod statefulset-5505/ss2-0 to have revision ss2-5658755fcf update revision ss2-9d9677584
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 03:06:24.604: INFO: Deleting all statefulset in ns statefulset-5505
May 21 03:06:24.606: INFO: Scaling statefulset ss2 to 0
May 21 03:06:54.632: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:06:54.634: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:06:54.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5505" for this suite.
May 21 03:07:00.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:07:00.762: INFO: namespace statefulset-5505 deletion completed in 6.105434449s

• [SLOW TEST:128.026 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:07:00.762: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 03:07:00.806: INFO: Waiting up to 5m0s for pod "pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa" in namespace "emptydir-6426" to be "success or failure"
May 21 03:07:00.809: INFO: Pod "pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa": Phase="Pending", Reason="", readiness=false. Elapsed: 3.744073ms
May 21 03:07:02.816: INFO: Pod "pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01046498s
May 21 03:07:04.839: INFO: Pod "pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033816644s
STEP: Saw pod success
May 21 03:07:04.839: INFO: Pod "pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa" satisfied condition "success or failure"
May 21 03:07:04.850: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa container test-container: <nil>
STEP: delete the pod
May 21 03:07:04.903: INFO: Waiting for pod pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa to disappear
May 21 03:07:04.905: INFO: Pod pod-5d199ed3-ade2-4ae8-ad87-3d6e25a9a9aa no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:07:04.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6426" for this suite.
May 21 03:07:10.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:07:11.029: INFO: namespace emptydir-6426 deletion completed in 6.118406943s

• [SLOW TEST:10.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:07:11.029: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:07:11.075: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1919f69c-ac19-4f9f-9a1d-3e79ea121d5e" in namespace "security-context-test-321" to be "success or failure"
May 21 03:07:11.078: INFO: Pod "busybox-user-65534-1919f69c-ac19-4f9f-9a1d-3e79ea121d5e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.572946ms
May 21 03:07:13.083: INFO: Pod "busybox-user-65534-1919f69c-ac19-4f9f-9a1d-3e79ea121d5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008437099s
May 21 03:07:13.083: INFO: Pod "busybox-user-65534-1919f69c-ac19-4f9f-9a1d-3e79ea121d5e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:07:13.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-321" for this suite.
May 21 03:07:19.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:07:19.208: INFO: namespace security-context-test-321 deletion completed in 6.118893313s

• [SLOW TEST:8.179 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:07:19.208: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:07:21.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2240" for this suite.
May 21 03:08:09.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:08:09.373: INFO: namespace kubelet-test-2240 deletion completed in 48.090827455s

• [SLOW TEST:50.165 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:08:09.374: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-9b40c58d-58db-4191-9333-f96d33be34c7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-9b40c58d-58db-4191-9333-f96d33be34c7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:08:13.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3123" for this suite.
May 21 03:08:41.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:08:41.680: INFO: namespace configmap-3123 deletion completed in 28.191544952s

• [SLOW TEST:32.306 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:08:41.680: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-bxb8
STEP: Creating a pod to test atomic-volume-subpath
May 21 03:08:41.738: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-bxb8" in namespace "subpath-5462" to be "success or failure"
May 21 03:08:41.745: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.239488ms
May 21 03:08:43.749: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 2.01022149s
May 21 03:08:45.752: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 4.013550119s
May 21 03:08:47.756: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 6.017236354s
May 21 03:08:49.760: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 8.021007339s
May 21 03:08:51.764: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 10.02543231s
May 21 03:08:53.768: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 12.029223597s
May 21 03:08:55.771: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 14.032834504s
May 21 03:08:57.775: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 16.036749146s
May 21 03:08:59.779: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 18.040593033s
May 21 03:09:01.783: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 20.044314308s
May 21 03:09:03.787: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Running", Reason="", readiness=true. Elapsed: 22.04834166s
May 21 03:09:05.790: INFO: Pod "pod-subpath-test-downwardapi-bxb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051679216s
STEP: Saw pod success
May 21 03:09:05.790: INFO: Pod "pod-subpath-test-downwardapi-bxb8" satisfied condition "success or failure"
May 21 03:09:05.794: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-subpath-test-downwardapi-bxb8 container test-container-subpath-downwardapi-bxb8: <nil>
STEP: delete the pod
May 21 03:09:05.827: INFO: Waiting for pod pod-subpath-test-downwardapi-bxb8 to disappear
May 21 03:09:05.833: INFO: Pod pod-subpath-test-downwardapi-bxb8 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-bxb8
May 21 03:09:05.833: INFO: Deleting pod "pod-subpath-test-downwardapi-bxb8" in namespace "subpath-5462"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:09:05.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5462" for this suite.
May 21 03:09:11.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:09:11.931: INFO: namespace subpath-5462 deletion completed in 6.091659053s

• [SLOW TEST:30.251 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:09:11.932: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-797b3afd-a063-47cc-80db-26abb69bd675
STEP: Creating a pod to test consume configMaps
May 21 03:09:11.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7" in namespace "configmap-9037" to be "success or failure"
May 21 03:09:11.995: INFO: Pod "pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.836699ms
May 21 03:09:14.004: INFO: Pod "pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022551962s
STEP: Saw pod success
May 21 03:09:14.004: INFO: Pod "pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7" satisfied condition "success or failure"
May 21 03:09:14.010: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:09:14.040: INFO: Waiting for pod pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7 to disappear
May 21 03:09:14.045: INFO: Pod pod-configmaps-530be8ee-ad2d-4a11-901f-d6bc81a6eea7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:09:14.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9037" for this suite.
May 21 03:09:20.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:09:20.140: INFO: namespace configmap-9037 deletion completed in 6.089467037s

• [SLOW TEST:8.208 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:09:20.141: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
May 21 03:09:20.174: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
May 21 03:09:20.684: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May 21 03:09:54.561: INFO: Waited 31.806034479s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:09:55.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5311" for this suite.
May 21 03:10:01.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:10:01.421: INFO: namespace aggregator-5311 deletion completed in 6.160125088s

• [SLOW TEST:41.280 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:10:01.421: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:10:01.484: INFO: Create a RollingUpdate DaemonSet
May 21 03:10:01.492: INFO: Check that daemon pods launch on every node of the cluster
May 21 03:10:01.508: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:01.508: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:01.508: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:01.521: INFO: Number of nodes with available pods: 0
May 21 03:10:01.521: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:10:02.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:02.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:02.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:02.532: INFO: Number of nodes with available pods: 0
May 21 03:10:02.532: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:10:03.563: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:03.563: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:03.563: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:03.572: INFO: Number of nodes with available pods: 1
May 21 03:10:03.572: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:10:04.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:04.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:04.528: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:04.533: INFO: Number of nodes with available pods: 2
May 21 03:10:04.534: INFO: Number of running nodes: 2, number of available pods: 2
May 21 03:10:04.536: INFO: Update the DaemonSet to trigger a rollout
May 21 03:10:04.546: INFO: Updating DaemonSet daemon-set
May 21 03:10:08.562: INFO: Roll back the DaemonSet before rollout is complete
May 21 03:10:08.571: INFO: Updating DaemonSet daemon-set
May 21 03:10:08.571: INFO: Make sure DaemonSet rollback is complete
May 21 03:10:08.576: INFO: Wrong image for pod: daemon-set-r6k5b. Expected: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine, got: foo:non-existent.
May 21 03:10:08.576: INFO: Pod daemon-set-r6k5b is not available
May 21 03:10:08.581: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:08.581: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:08.581: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:09.585: INFO: Wrong image for pod: daemon-set-r6k5b. Expected: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine, got: foo:non-existent.
May 21 03:10:09.585: INFO: Pod daemon-set-r6k5b is not available
May 21 03:10:09.591: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:09.591: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:09.591: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:10.586: INFO: Pod daemon-set-mk7j6 is not available
May 21 03:10:10.592: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:10.592: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:10:10.592: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2945, will wait for the garbage collector to delete the pods
May 21 03:10:10.660: INFO: Deleting DaemonSet.extensions daemon-set took: 11.831737ms
May 21 03:10:10.961: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.210695ms
May 21 03:10:17.565: INFO: Number of nodes with available pods: 0
May 21 03:10:17.565: INFO: Number of running nodes: 0, number of available pods: 0
May 21 03:10:17.567: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2945/daemonsets","resourceVersion":"26092"},"items":null}

May 21 03:10:17.569: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2945/pods","resourceVersion":"26092"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:10:17.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2945" for this suite.
May 21 03:10:23.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:10:23.677: INFO: namespace daemonsets-2945 deletion completed in 6.092872804s

• [SLOW TEST:22.256 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:10:23.677: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-e45eca15-2ece-478d-9148-cca4b2ac0e07
STEP: Creating a pod to test consume secrets
May 21 03:10:23.776: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2" in namespace "projected-2565" to be "success or failure"
May 21 03:10:23.778: INFO: Pod "pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.306666ms
May 21 03:10:25.782: INFO: Pod "pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005937486s
STEP: Saw pod success
May 21 03:10:25.782: INFO: Pod "pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2" satisfied condition "success or failure"
May 21 03:10:25.785: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 03:10:25.812: INFO: Waiting for pod pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2 to disappear
May 21 03:10:25.815: INFO: Pod pod-projected-secrets-c55bec86-1453-461a-b6a2-335a67a0baf2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:10:25.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2565" for this suite.
May 21 03:10:31.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:10:31.929: INFO: namespace projected-2565 deletion completed in 6.107182201s

• [SLOW TEST:8.252 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:10:31.929: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
May 21 03:10:31.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2646'
May 21 03:10:32.588: INFO: stderr: ""
May 21 03:10:32.588: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 03:10:33.593: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:10:33.593: INFO: Found 0 / 1
May 21 03:10:34.592: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:10:34.592: INFO: Found 1 / 1
May 21 03:10:34.592: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May 21 03:10:34.594: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:10:34.595: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 03:10:34.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 patch pod redis-master-mtcwk --namespace=kubectl-2646 -p {"metadata":{"annotations":{"x":"y"}}}'
May 21 03:10:34.716: INFO: stderr: ""
May 21 03:10:34.716: INFO: stdout: "pod/redis-master-mtcwk patched\n"
STEP: checking annotations
May 21 03:10:34.719: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:10:34.719: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:10:34.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2646" for this suite.
May 21 03:11:02.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:02.808: INFO: namespace kubectl-2646 deletion completed in 28.083894477s

• [SLOW TEST:30.879 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:11:02.808: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e9a7614f-a8b9-4f50-abf3-5e6e43570361
STEP: Creating a pod to test consume configMaps
May 21 03:11:02.863: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde" in namespace "projected-9957" to be "success or failure"
May 21 03:11:02.867: INFO: Pod "pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982266ms
May 21 03:11:04.872: INFO: Pod "pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008693135s
STEP: Saw pod success
May 21 03:11:04.872: INFO: Pod "pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde" satisfied condition "success or failure"
May 21 03:11:04.874: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:11:04.912: INFO: Waiting for pod pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde to disappear
May 21 03:11:04.914: INFO: Pod pod-projected-configmaps-dc0bf20a-c78a-463d-affb-49f0c2aeefde no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:11:04.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9957" for this suite.
May 21 03:11:10.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:11.036: INFO: namespace projected-9957 deletion completed in 6.115744492s

• [SLOW TEST:8.228 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:11:11.036: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
May 21 03:11:11.079: INFO: Waiting up to 5m0s for pod "downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d" in namespace "downward-api-4465" to be "success or failure"
May 21 03:11:11.085: INFO: Pod "downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.823195ms
May 21 03:11:13.089: INFO: Pod "downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010017795s
STEP: Saw pod success
May 21 03:11:13.089: INFO: Pod "downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d" satisfied condition "success or failure"
May 21 03:11:13.092: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d container dapi-container: <nil>
STEP: delete the pod
May 21 03:11:13.116: INFO: Waiting for pod downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d to disappear
May 21 03:11:13.119: INFO: Pod downward-api-ff9ccd56-a0d4-4192-ae2c-dd45ec00fa9d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:11:13.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4465" for this suite.
May 21 03:11:19.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:19.226: INFO: namespace downward-api-4465 deletion completed in 6.094979791s

• [SLOW TEST:8.190 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:11:19.226: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:11:20.016: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:11:22.024: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627480, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627480, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627480, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627480, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:11:25.043: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:11:25.046: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:11:31.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4670" for this suite.
May 21 03:11:37.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:37.369: INFO: namespace webhook-4670 deletion completed in 6.146642292s
STEP: Destroying namespace "webhook-4670-markers" for this suite.
May 21 03:11:43.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:43.484: INFO: namespace webhook-4670-markers deletion completed in 6.114901006s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.277 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:11:43.503: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e344cb8c-3003-419f-893c-7a2c63935ee3
STEP: Creating a pod to test consume secrets
May 21 03:11:43.565: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1" in namespace "projected-1325" to be "success or failure"
May 21 03:11:43.574: INFO: Pod "pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.865071ms
May 21 03:11:45.605: INFO: Pod "pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039730988s
May 21 03:11:47.608: INFO: Pod "pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043149402s
STEP: Saw pod success
May 21 03:11:47.608: INFO: Pod "pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1" satisfied condition "success or failure"
May 21 03:11:47.611: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 03:11:47.635: INFO: Waiting for pod pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1 to disappear
May 21 03:11:47.640: INFO: Pod pod-projected-secrets-1345d10d-c6ff-4021-b402-75091ed74cd1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:11:47.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1325" for this suite.
May 21 03:11:53.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:11:53.790: INFO: namespace projected-1325 deletion completed in 6.138441013s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:11:53.791: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-24a435fe-e1a7-40be-93fc-985069e8e826
STEP: Creating a pod to test consume secrets
May 21 03:11:53.842: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62" in namespace "projected-6396" to be "success or failure"
May 21 03:11:53.851: INFO: Pod "pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62": Phase="Pending", Reason="", readiness=false. Elapsed: 8.819001ms
May 21 03:11:55.855: INFO: Pod "pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012922021s
May 21 03:11:57.858: INFO: Pod "pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016497812s
STEP: Saw pod success
May 21 03:11:57.858: INFO: Pod "pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62" satisfied condition "success or failure"
May 21 03:11:57.862: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 03:11:57.884: INFO: Waiting for pod pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62 to disappear
May 21 03:11:57.888: INFO: Pod pod-projected-secrets-ac928a7d-33db-4ca8-b821-6ff035315f62 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:11:57.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6396" for this suite.
May 21 03:12:03.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:12:04.011: INFO: namespace projected-6396 deletion completed in 6.117742323s

• [SLOW TEST:10.221 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:12:04.012: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-e1be3a38-b4c7-4b69-8689-28a540f3ae5d in namespace container-probe-7457
May 21 03:12:06.080: INFO: Started pod test-webserver-e1be3a38-b4c7-4b69-8689-28a540f3ae5d in namespace container-probe-7457
STEP: checking the pod's current state and verifying that restartCount is present
May 21 03:12:06.082: INFO: Initial restart count of pod test-webserver-e1be3a38-b4c7-4b69-8689-28a540f3ae5d is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:16:06.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7457" for this suite.
May 21 03:16:12.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:16:12.705: INFO: namespace container-probe-7457 deletion completed in 6.097958851s

• [SLOW TEST:248.693 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:16:12.705: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5734
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May 21 03:16:12.743: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May 21 03:16:36.828: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.240.3.107:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5734 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 03:16:36.828: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:16:37.136: INFO: Found all expected endpoints: [netserver-0]
May 21 03:16:37.140: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.240.4.105:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5734 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 03:16:37.140: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:16:37.484: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:16:37.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5734" for this suite.
May 21 03:16:49.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:16:49.595: INFO: namespace pod-network-test-5734 deletion completed in 12.104341736s

• [SLOW TEST:36.890 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:16:49.595: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-sqhn
STEP: Creating a pod to test atomic-volume-subpath
May 21 03:16:49.669: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sqhn" in namespace "subpath-2689" to be "success or failure"
May 21 03:16:49.672: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.559225ms
May 21 03:16:51.677: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006995402s
May 21 03:16:53.682: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 4.012019947s
May 21 03:16:55.687: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 6.017269602s
May 21 03:16:57.692: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 8.021839652s
May 21 03:16:59.695: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 10.024956749s
May 21 03:17:01.698: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 12.028185107s
May 21 03:17:03.703: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 14.032761272s
May 21 03:17:05.706: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 16.036335188s
May 21 03:17:07.711: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 18.041644584s
May 21 03:17:09.716: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 20.045773016s
May 21 03:17:11.719: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Running", Reason="", readiness=true. Elapsed: 22.049255756s
May 21 03:17:13.729: INFO: Pod "pod-subpath-test-configmap-sqhn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.058808903s
STEP: Saw pod success
May 21 03:17:13.729: INFO: Pod "pod-subpath-test-configmap-sqhn" satisfied condition "success or failure"
May 21 03:17:13.731: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-subpath-test-configmap-sqhn container test-container-subpath-configmap-sqhn: <nil>
STEP: delete the pod
May 21 03:17:13.770: INFO: Waiting for pod pod-subpath-test-configmap-sqhn to disappear
May 21 03:17:13.785: INFO: Pod pod-subpath-test-configmap-sqhn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sqhn
May 21 03:17:13.785: INFO: Deleting pod "pod-subpath-test-configmap-sqhn" in namespace "subpath-2689"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:17:13.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2689" for this suite.
May 21 03:17:19.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:17:19.890: INFO: namespace subpath-2689 deletion completed in 6.095640924s

• [SLOW TEST:30.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:17:19.891: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:17:23.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7121" for this suite.
May 21 03:17:29.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:17:30.041: INFO: namespace kubelet-test-7121 deletion completed in 6.097634607s

• [SLOW TEST:10.150 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:17:30.041: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:17:30.697: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:17:32.705: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627850, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627850, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627850, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627850, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:17:35.726: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:17:47.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4214" for this suite.
May 21 03:17:53.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:17:54.063: INFO: namespace webhook-4214 deletion completed in 6.155896773s
STEP: Destroying namespace "webhook-4214-markers" for this suite.
May 21 03:18:00.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:00.154: INFO: namespace webhook-4214-markers deletion completed in 6.090639709s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.126 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:00.167: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:18:00.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695" in namespace "projected-6444" to be "success or failure"
May 21 03:18:00.212: INFO: Pod "downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.363986ms
May 21 03:18:02.215: INFO: Pod "downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005548787s
May 21 03:18:04.219: INFO: Pod "downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009670472s
STEP: Saw pod success
May 21 03:18:04.219: INFO: Pod "downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695" satisfied condition "success or failure"
May 21 03:18:04.222: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695 container client-container: <nil>
STEP: delete the pod
May 21 03:18:04.251: INFO: Waiting for pod downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695 to disappear
May 21 03:18:04.253: INFO: Pod downwardapi-volume-584f37f5-5a61-4604-8b05-c11b3df1e695 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:04.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6444" for this suite.
May 21 03:18:10.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:10.335: INFO: namespace projected-6444 deletion completed in 6.076495495s

• [SLOW TEST:10.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:10.335: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-ab14ea46-b717-4645-ad7f-53613ecf01a4
STEP: Creating a pod to test consume secrets
May 21 03:18:10.380: INFO: Waiting up to 5m0s for pod "pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4" in namespace "secrets-4935" to be "success or failure"
May 21 03:18:10.383: INFO: Pod "pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.118904ms
May 21 03:18:12.389: INFO: Pod "pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009658235s
May 21 03:18:14.393: INFO: Pod "pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013792255s
STEP: Saw pod success
May 21 03:18:14.393: INFO: Pod "pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4" satisfied condition "success or failure"
May 21 03:18:14.396: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4 container secret-volume-test: <nil>
STEP: delete the pod
May 21 03:18:14.418: INFO: Waiting for pod pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4 to disappear
May 21 03:18:14.421: INFO: Pod pod-secrets-cd1f9605-3e28-4bd6-967a-0b41a354aaf4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:14.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4935" for this suite.
May 21 03:18:20.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:20.522: INFO: namespace secrets-4935 deletion completed in 6.094488982s

• [SLOW TEST:10.187 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:20.522: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-f30fd2b1-e425-4683-a7f8-dfa920a77215
STEP: Creating a pod to test consume secrets
May 21 03:18:20.571: INFO: Waiting up to 5m0s for pod "pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201" in namespace "secrets-6097" to be "success or failure"
May 21 03:18:20.580: INFO: Pod "pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201": Phase="Pending", Reason="", readiness=false. Elapsed: 8.466285ms
May 21 03:18:22.590: INFO: Pod "pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019125396s
STEP: Saw pod success
May 21 03:18:22.590: INFO: Pod "pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201" satisfied condition "success or failure"
May 21 03:18:22.593: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201 container secret-volume-test: <nil>
STEP: delete the pod
May 21 03:18:22.622: INFO: Waiting for pod pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201 to disappear
May 21 03:18:22.625: INFO: Pod pod-secrets-6fc6f61d-5f3d-49c0-9d34-068b00ae8201 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:22.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6097" for this suite.
May 21 03:18:28.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:28.712: INFO: namespace secrets-6097 deletion completed in 6.081237251s

• [SLOW TEST:8.190 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:28.713: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 21 03:18:31.768: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:31.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7560" for this suite.
May 21 03:18:37.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:37.894: INFO: namespace container-runtime-7560 deletion completed in 6.101843366s

• [SLOW TEST:9.181 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:37.894: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:18:37.938: INFO: Waiting up to 5m0s for pod "downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1" in namespace "downward-api-1077" to be "success or failure"
May 21 03:18:37.942: INFO: Pod "downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.405621ms
May 21 03:18:39.946: INFO: Pod "downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007909353s
STEP: Saw pod success
May 21 03:18:39.946: INFO: Pod "downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1" satisfied condition "success or failure"
May 21 03:18:39.948: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1 container client-container: <nil>
STEP: delete the pod
May 21 03:18:39.969: INFO: Waiting for pod downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1 to disappear
May 21 03:18:39.971: INFO: Pod downwardapi-volume-74035b6b-1c7c-44f3-b22c-1768759ad8d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:39.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1077" for this suite.
May 21 03:18:45.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:46.066: INFO: namespace downward-api-1077 deletion completed in 6.089374475s

• [SLOW TEST:8.171 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:46.066: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
May 21 03:18:46.109: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-300851385 proxy --unix-socket=/tmp/kubectl-proxy-unix391321444/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:18:46.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1832" for this suite.
May 21 03:18:52.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:18:52.365: INFO: namespace kubectl-1832 deletion completed in 6.095745418s

• [SLOW TEST:6.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:18:52.365: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
May 21 03:18:52.406: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:19:00.689: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:19:20.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8155" for this suite.
May 21 03:19:26.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:19:27.055: INFO: namespace crd-publish-openapi-8155 deletion completed in 6.095034708s

• [SLOW TEST:34.690 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:19:27.056: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
May 21 03:19:27.615: INFO: created pod pod-service-account-defaultsa
May 21 03:19:27.615: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May 21 03:19:27.630: INFO: created pod pod-service-account-mountsa
May 21 03:19:27.630: INFO: pod pod-service-account-mountsa service account token volume mount: true
May 21 03:19:27.638: INFO: created pod pod-service-account-nomountsa
May 21 03:19:27.638: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May 21 03:19:27.652: INFO: created pod pod-service-account-defaultsa-mountspec
May 21 03:19:27.652: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May 21 03:19:27.660: INFO: created pod pod-service-account-mountsa-mountspec
May 21 03:19:27.660: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May 21 03:19:27.667: INFO: created pod pod-service-account-nomountsa-mountspec
May 21 03:19:27.667: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May 21 03:19:27.682: INFO: created pod pod-service-account-defaultsa-nomountspec
May 21 03:19:27.682: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May 21 03:19:27.703: INFO: created pod pod-service-account-mountsa-nomountspec
May 21 03:19:27.703: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May 21 03:19:27.709: INFO: created pod pod-service-account-nomountsa-nomountspec
May 21 03:19:27.709: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:19:27.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5490" for this suite.
May 21 03:19:33.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:19:33.842: INFO: namespace svcaccounts-5490 deletion completed in 6.1242415s

• [SLOW TEST:6.787 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:19:33.843: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:19:34.927: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:19:36.950: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627974, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627974, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627974, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725627974, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:19:39.972: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
May 21 03:19:39.994: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:19:40.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7975" for this suite.
May 21 03:19:46.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:19:46.104: INFO: namespace webhook-7975 deletion completed in 6.089987766s
STEP: Destroying namespace "webhook-7975-markers" for this suite.
May 21 03:19:52.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:19:52.201: INFO: namespace webhook-7975-markers deletion completed in 6.097288327s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.379 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:19:52.222: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9028
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
May 21 03:19:52.276: INFO: Found 0 stateful pods, waiting for 3
May 21 03:20:02.280: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:20:02.280: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:20:02.280: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from 172.16.17.5/sonobuoy/httpd:2.4.38-alpine to 172.16.17.5/sonobuoy/httpd:2.4.39-alpine
May 21 03:20:02.304: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May 21 03:20:12.349: INFO: Updating stateful set ss2
May 21 03:20:12.357: INFO: Waiting for Pod statefulset-9028/ss2-2 to have revision ss2-9d9677584 update revision ss2-5658755fcf
STEP: Restoring Pods to the correct revision when they are deleted
May 21 03:20:22.408: INFO: Found 2 stateful pods, waiting for 3
May 21 03:20:32.412: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:20:32.412: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:20:32.412: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May 21 03:20:32.437: INFO: Updating stateful set ss2
May 21 03:20:32.453: INFO: Waiting for Pod statefulset-9028/ss2-1 to have revision ss2-9d9677584 update revision ss2-5658755fcf
May 21 03:20:42.478: INFO: Updating stateful set ss2
May 21 03:20:42.486: INFO: Waiting for StatefulSet statefulset-9028/ss2 to complete update
May 21 03:20:42.486: INFO: Waiting for Pod statefulset-9028/ss2-0 to have revision ss2-9d9677584 update revision ss2-5658755fcf
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 03:20:52.493: INFO: Deleting all statefulset in ns statefulset-9028
May 21 03:20:52.496: INFO: Scaling statefulset ss2 to 0
May 21 03:21:02.524: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:21:02.526: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:21:02.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9028" for this suite.
May 21 03:21:08.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:21:08.652: INFO: namespace statefulset-9028 deletion completed in 6.102514984s

• [SLOW TEST:76.430 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:21:08.653: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:21:08.704: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May 21 03:21:08.719: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:08.719: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:08.719: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:08.723: INFO: Number of nodes with available pods: 0
May 21 03:21:08.723: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:21:09.743: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:09.743: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:09.743: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:09.747: INFO: Number of nodes with available pods: 0
May 21 03:21:09.747: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:21:10.731: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:10.731: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:10.731: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:10.734: INFO: Number of nodes with available pods: 2
May 21 03:21:10.734: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May 21 03:21:10.765: INFO: Wrong image for pod: daemon-set-d4vn8. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:10.765: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:10.773: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:10.773: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:10.773: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:11.779: INFO: Wrong image for pod: daemon-set-d4vn8. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:11.779: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:11.784: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:11.784: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:11.784: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:12.778: INFO: Wrong image for pod: daemon-set-d4vn8. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:12.778: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:12.785: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:12.785: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:12.785: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:13.778: INFO: Wrong image for pod: daemon-set-d4vn8. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:13.778: INFO: Pod daemon-set-d4vn8 is not available
May 21 03:21:13.778: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:13.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:13.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:13.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:14.777: INFO: Pod daemon-set-58s6q is not available
May 21 03:21:14.777: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:14.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:14.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:14.782: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:15.778: INFO: Pod daemon-set-58s6q is not available
May 21 03:21:15.778: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:15.783: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:15.783: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:15.783: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:16.780: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:16.780: INFO: Pod daemon-set-fjzjl is not available
May 21 03:21:16.788: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:16.788: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:16.788: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:17.779: INFO: Wrong image for pod: daemon-set-fjzjl. Expected: 172.16.17.5/sonobuoy/redis:5.0.5-alpine, got: 172.16.17.5/sonobuoy/httpd:2.4.38-alpine.
May 21 03:21:17.779: INFO: Pod daemon-set-fjzjl is not available
May 21 03:21:17.801: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:17.801: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:17.801: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.784: INFO: Pod daemon-set-x2zzp is not available
May 21 03:21:18.798: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.798: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.798: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May 21 03:21:18.820: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.820: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.820: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:18.823: INFO: Number of nodes with available pods: 1
May 21 03:21:18.823: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:21:19.829: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:19.829: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:19.829: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:19.831: INFO: Number of nodes with available pods: 1
May 21 03:21:19.831: INFO: Node 9990-w-ax-1-1 is running more than one daemon pod
May 21 03:21:20.845: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:20.845: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:20.845: INFO: DaemonSet pods can't tolerate node 9990-m-5f-1-3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May 21 03:21:20.850: INFO: Number of nodes with available pods: 2
May 21 03:21:20.850: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9549, will wait for the garbage collector to delete the pods
May 21 03:21:20.949: INFO: Deleting DaemonSet.extensions daemon-set took: 8.31658ms
May 21 03:21:21.250: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.203521ms
May 21 03:21:27.354: INFO: Number of nodes with available pods: 0
May 21 03:21:27.360: INFO: Number of running nodes: 0, number of available pods: 0
May 21 03:21:27.370: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9549/daemonsets","resourceVersion":"29785"},"items":null}

May 21 03:21:27.372: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9549/pods","resourceVersion":"29785"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:21:27.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9549" for this suite.
May 21 03:21:33.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:21:33.488: INFO: namespace daemonsets-9549 deletion completed in 6.091259764s

• [SLOW TEST:24.835 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:21:33.488: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:21:44.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6749" for this suite.
May 21 03:21:50.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:21:50.685: INFO: namespace resourcequota-6749 deletion completed in 6.110723462s

• [SLOW TEST:17.197 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:21:50.685: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3066
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-3066
I0521 03:21:50.764196      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3066, replica count: 2
May 21 03:21:53.818: INFO: Creating new exec pod
I0521 03:21:53.818630      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 03:21:56.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-3066 execpodbn24k -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May 21 03:21:57.440: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May 21 03:21:57.440: INFO: stdout: ""
May 21 03:21:57.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-3066 execpodbn24k -- /bin/sh -x -c nc -zv -t -w 2 10.102.17.161 80'
May 21 03:21:57.739: INFO: stderr: "+ nc -zv -t -w 2 10.102.17.161 80\nConnection to 10.102.17.161 80 port [tcp/http] succeeded!\n"
May 21 03:21:57.740: INFO: stdout: ""
May 21 03:21:57.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-3066 execpodbn24k -- /bin/sh -x -c nc -zv -t -w 2 192.168.0.7 31057'
May 21 03:21:58.034: INFO: stderr: "+ nc -zv -t -w 2 192.168.0.7 31057\nConnection to 192.168.0.7 31057 port [tcp/31057] succeeded!\n"
May 21 03:21:58.034: INFO: stdout: ""
May 21 03:21:58.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-3066 execpodbn24k -- /bin/sh -x -c nc -zv -t -w 2 192.168.0.8 31057'
May 21 03:21:58.304: INFO: stderr: "+ nc -zv -t -w 2 192.168.0.8 31057\nConnection to 192.168.0.8 31057 port [tcp/31057] succeeded!\n"
May 21 03:21:58.304: INFO: stdout: ""
May 21 03:21:58.304: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:21:58.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3066" for this suite.
May 21 03:22:04.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:22:04.495: INFO: namespace services-3066 deletion completed in 6.127510865s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.810 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:22:04.495: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:22:08.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6013" for this suite.
May 21 03:22:14.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:22:14.712: INFO: namespace emptydir-wrapper-6013 deletion completed in 6.099866613s

• [SLOW TEST:10.216 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:22:14.712: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
May 21 03:22:14.748: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:22:19.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4246" for this suite.
May 21 03:22:47.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:22:47.163: INFO: namespace init-container-4246 deletion completed in 28.092389258s

• [SLOW TEST:32.451 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:22:47.163: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7d97a965-894d-483d-af01-7123ae471b2a
STEP: Creating a pod to test consume secrets
May 21 03:22:47.216: INFO: Waiting up to 5m0s for pod "pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811" in namespace "secrets-5229" to be "success or failure"
May 21 03:22:47.224: INFO: Pod "pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811": Phase="Pending", Reason="", readiness=false. Elapsed: 8.675146ms
May 21 03:22:49.227: INFO: Pod "pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011841271s
May 21 03:22:51.231: INFO: Pod "pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015569641s
STEP: Saw pod success
May 21 03:22:51.231: INFO: Pod "pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811" satisfied condition "success or failure"
May 21 03:22:51.233: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811 container secret-volume-test: <nil>
STEP: delete the pod
May 21 03:22:51.281: INFO: Waiting for pod pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811 to disappear
May 21 03:22:51.285: INFO: Pod pod-secrets-9ea8eae1-708b-49df-a5f1-258b73cba811 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:22:51.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5229" for this suite.
May 21 03:22:57.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:22:57.380: INFO: namespace secrets-5229 deletion completed in 6.090344754s

• [SLOW TEST:10.217 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:22:57.381: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 03:22:57.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-rc --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7482'
May 21 03:22:57.578: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 03:22:57.578: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
May 21 03:22:57.599: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-7hr9f]
May 21 03:22:57.599: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-7hr9f" in namespace "kubectl-7482" to be "running and ready"
May 21 03:22:57.613: INFO: Pod "e2e-test-httpd-rc-7hr9f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.741579ms
May 21 03:22:59.616: INFO: Pod "e2e-test-httpd-rc-7hr9f": Phase="Running", Reason="", readiness=true. Elapsed: 2.016794711s
May 21 03:22:59.616: INFO: Pod "e2e-test-httpd-rc-7hr9f" satisfied condition "running and ready"
May 21 03:22:59.616: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-7hr9f]
May 21 03:22:59.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs rc/e2e-test-httpd-rc --namespace=kubectl-7482'
May 21 03:22:59.788: INFO: stderr: ""
May 21 03:22:59.788: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.240.3.124. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.240.3.124. Set the 'ServerName' directive globally to suppress this message\n[Thu May 21 03:22:59.182973 2020] [mpm_event:notice] [pid 1:tid 140193957280616] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu May 21 03:22:59.183073 2020] [core:notice] [pid 1:tid 140193957280616] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
May 21 03:22:59.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete rc e2e-test-httpd-rc --namespace=kubectl-7482'
May 21 03:22:59.931: INFO: stderr: ""
May 21 03:22:59.931: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:22:59.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7482" for this suite.
May 21 03:23:05.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:23:06.030: INFO: namespace kubectl-7482 deletion completed in 6.083567463s

• [SLOW TEST:8.649 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:23:06.030: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:23:06.073: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a" in namespace "projected-8618" to be "success or failure"
May 21 03:23:06.081: INFO: Pod "downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.290441ms
May 21 03:23:08.084: INFO: Pod "downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010716589s
May 21 03:23:10.087: INFO: Pod "downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014071012s
STEP: Saw pod success
May 21 03:23:10.087: INFO: Pod "downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a" satisfied condition "success or failure"
May 21 03:23:10.090: INFO: Trying to get logs from node 9990-w-ax-1-1 pod downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a container client-container: <nil>
STEP: delete the pod
May 21 03:23:10.129: INFO: Waiting for pod downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a to disappear
May 21 03:23:10.132: INFO: Pod downwardapi-volume-8df74838-1e77-4fdb-a318-f75679ff8e8a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:23:10.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8618" for this suite.
May 21 03:23:16.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:23:16.232: INFO: namespace projected-8618 deletion completed in 6.095339006s

• [SLOW TEST:10.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:23:16.232: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May 21 03:23:46.826: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:23:46.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0521 03:23:46.826522      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9436" for this suite.
May 21 03:23:52.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:23:52.923: INFO: namespace gc-9436 deletion completed in 6.092249158s

• [SLOW TEST:36.691 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:23:52.923: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:23:53.954: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:23:55.962: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628233, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628233, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628233, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628233, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:23:58.983: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
May 21 03:23:59.013: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
May 21 03:24:01.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 attach --namespace=webhook-544 to-be-attached-pod -i -c=container1'
May 21 03:24:01.327: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:24:01.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-544" for this suite.
May 21 03:24:13.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:24:13.437: INFO: namespace webhook-544 deletion completed in 12.097009247s
STEP: Destroying namespace "webhook-544-markers" for this suite.
May 21 03:24:19.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:24:19.541: INFO: namespace webhook-544-markers deletion completed in 6.104013777s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.641 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:24:19.564: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
May 21 03:24:19.611: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 03:24:28.315: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:24:47.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7268" for this suite.
May 21 03:24:53.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:24:54.003: INFO: namespace crd-publish-openapi-7268 deletion completed in 6.111894579s

• [SLOW TEST:34.439 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:24:54.004: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May 21 03:24:54.051: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31027 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 03:24:54.052: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31027 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May 21 03:25:04.061: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31066 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 03:25:04.062: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31066 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May 21 03:25:14.071: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31105 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 03:25:14.071: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31105 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May 21 03:25:24.080: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31144 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 03:25:24.081: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-a 0e1eb9e6-0d94-4fe1-b174-e02330b1191d 31144 0 2020-05-21 03:24:54 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May 21 03:25:34.089: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-b a1f8b1ea-6251-4b48-80a0-15fd465b3ca0 31183 0 2020-05-21 03:25:34 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 03:25:34.089: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-b a1f8b1ea-6251-4b48-80a0-15fd465b3ca0 31183 0 2020-05-21 03:25:34 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May 21 03:25:44.102: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-b a1f8b1ea-6251-4b48-80a0-15fd465b3ca0 31222 0 2020-05-21 03:25:34 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 03:25:44.102: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-5122 /api/v1/namespaces/watch-5122/configmaps/e2e-watch-test-configmap-b a1f8b1ea-6251-4b48-80a0-15fd465b3ca0 31222 0 2020-05-21 03:25:34 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:25:54.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5122" for this suite.
May 21 03:26:00.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:26:00.202: INFO: namespace watch-5122 deletion completed in 6.091143903s

• [SLOW TEST:66.198 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:26:00.202: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-cbccf50d-f102-46e7-839c-eca48424be02
STEP: Creating a pod to test consume secrets
May 21 03:26:00.262: INFO: Waiting up to 5m0s for pod "pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530" in namespace "secrets-5868" to be "success or failure"
May 21 03:26:00.272: INFO: Pod "pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808224ms
May 21 03:26:02.280: INFO: Pod "pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017631236s
STEP: Saw pod success
May 21 03:26:02.280: INFO: Pod "pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530" satisfied condition "success or failure"
May 21 03:26:02.282: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530 container secret-env-test: <nil>
STEP: delete the pod
May 21 03:26:02.314: INFO: Waiting for pod pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530 to disappear
May 21 03:26:02.324: INFO: Pod pod-secrets-cea74e8a-0a9b-4705-81d1-4ad952f31530 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:26:02.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5868" for this suite.
May 21 03:26:08.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:26:08.426: INFO: namespace secrets-5868 deletion completed in 6.0980826s

• [SLOW TEST:8.224 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:26:08.427: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:26:08.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24" in namespace "downward-api-5874" to be "success or failure"
May 21 03:26:08.469: INFO: Pod "downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.111673ms
May 21 03:26:10.479: INFO: Pod "downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011900859s
STEP: Saw pod success
May 21 03:26:10.479: INFO: Pod "downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24" satisfied condition "success or failure"
May 21 03:26:10.482: INFO: Trying to get logs from node 9990-w-ax-1-1 pod downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24 container client-container: <nil>
STEP: delete the pod
May 21 03:26:10.517: INFO: Waiting for pod downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24 to disappear
May 21 03:26:10.519: INFO: Pod downwardapi-volume-4e9aa761-a87b-41f4-b47d-773dc60dcc24 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:26:10.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5874" for this suite.
May 21 03:26:16.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:26:16.617: INFO: namespace downward-api-5874 deletion completed in 6.091162314s

• [SLOW TEST:8.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:26:16.617: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
May 21 03:26:16.653: INFO: PodSpec: initContainers in spec.initContainers
May 21 03:27:04.143: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a5ca2335-cbc0-429a-b5fc-289c473fd4c4", GenerateName:"", Namespace:"init-container-4352", SelfLink:"/api/v1/namespaces/init-container-4352/pods/pod-init-a5ca2335-cbc0-429a-b5fc-289c473fd4c4", UID:"e6dac77d-861d-4454-9128-20833b7c3056", ResourceVersion:"31613", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63725628376, loc:(*time.Location)(0x78a2900)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"653462524"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gvnj7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00353e000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"172.16.17.5/sonobuoy/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gvnj7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"172.16.17.5/sonobuoy/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gvnj7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"172.16.17.5/sonobuoy/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gvnj7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00608c088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"9990-w-ax-1-1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003870060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00608c110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00608c130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00608c138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00608c13c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628376, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628376, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628376, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725628376, loc:(*time.Location)(0x78a2900)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.0.7", PodIP:"10.240.3.129", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.240.3.129"}}, StartTime:(*v1.Time)(0xc003784060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0008561c0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000856230)}, Ready:false, RestartCount:3, Image:"172.16.17.5/sonobuoy/busybox:1.29", ImageID:"docker-pullable://172.16.17.5/sonobuoy/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://33db8b3b4ebc7d3c2ff116c51ca4ccc0d247555b7382da766212d53f48c78849", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0037840a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.16.17.5/sonobuoy/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003784080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.16.17.5/sonobuoy/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00608c1bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:27:04.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4352" for this suite.
May 21 03:27:32.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:27:32.252: INFO: namespace init-container-4352 deletion completed in 28.098242713s

• [SLOW TEST:75.635 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:27:32.254: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9048
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9048
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9048
May 21 03:27:32.317: INFO: Found 0 stateful pods, waiting for 1
May 21 03:27:42.321: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May 21 03:27:42.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:27:42.648: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:27:42.648: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:27:42.648: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:27:42.652: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May 21 03:27:52.656: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:27:52.656: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:27:52.669: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999553s
May 21 03:27:53.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996473929s
May 21 03:27:54.679: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990850274s
May 21 03:27:55.685: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.986235403s
May 21 03:27:56.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.981625338s
May 21 03:27:57.693: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977163145s
May 21 03:27:58.700: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.970268974s
May 21 03:27:59.704: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96589787s
May 21 03:28:00.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.961866607s
May 21 03:28:01.712: INFO: Verifying statefulset ss doesn't scale past 1 for another 958.004162ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9048
May 21 03:28:02.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:03.037: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:28:03.038: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:28:03.040: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:28:03.044: INFO: Found 1 stateful pods, waiting for 3
May 21 03:28:13.049: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:28:13.049: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:28:13.049: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May 21 03:28:13.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:28:13.398: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:28:13.399: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:28:13.399: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:28:13.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:28:13.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:28:13.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:28:13.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:28:13.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:28:14.202: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:28:14.202: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:28:14.202: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:28:14.202: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:28:14.208: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 21 03:28:24.221: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:28:24.221: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:28:24.221: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:28:24.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.9999996s
May 21 03:28:25.236: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996564007s
May 21 03:28:26.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98356119s
May 21 03:28:27.253: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.979821104s
May 21 03:28:28.258: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.975038307s
May 21 03:28:29.266: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.970904671s
May 21 03:28:30.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.962248942s
May 21 03:28:31.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.957699526s
May 21 03:28:32.278: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954256995s
May 21 03:28:33.284: INFO: Verifying statefulset ss doesn't scale past 3 for another 950.075017ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9048
May 21 03:28:34.288: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:34.662: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:28:34.662: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:28:34.662: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:28:34.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:35.109: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:28:35.109: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:28:35.109: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:28:35.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:35.340: INFO: rc: 126
May 21 03:28:35.340: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:
cannot exec in a stopped state: unknown

stderr:
command terminated with exit code 126

error:
exit status 126
May 21 03:28:45.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:45.485: INFO: rc: 1
May 21 03:28:45.485: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:28:55.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:28:55.586: INFO: rc: 1
May 21 03:28:55.586: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:05.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:05.715: INFO: rc: 1
May 21 03:29:05.715: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:15.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:15.894: INFO: rc: 1
May 21 03:29:15.894: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:25.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:26.021: INFO: rc: 1
May 21 03:29:26.021: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:36.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:36.173: INFO: rc: 1
May 21 03:29:36.173: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:46.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:46.317: INFO: rc: 1
May 21 03:29:46.317: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:29:56.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:29:56.432: INFO: rc: 1
May 21 03:29:56.432: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:06.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:06.589: INFO: rc: 1
May 21 03:30:06.590: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:16.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:16.859: INFO: rc: 1
May 21 03:30:16.859: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:26.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:26.973: INFO: rc: 1
May 21 03:30:26.973: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:36.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:37.258: INFO: rc: 1
May 21 03:30:37.258: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:47.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:47.388: INFO: rc: 1
May 21 03:30:47.388: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:30:57.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:30:57.635: INFO: rc: 1
May 21 03:30:57.635: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:07.635: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:07.776: INFO: rc: 1
May 21 03:31:07.776: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:17.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:17.926: INFO: rc: 1
May 21 03:31:17.926: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:27.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:28.047: INFO: rc: 1
May 21 03:31:28.047: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:38.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:38.158: INFO: rc: 1
May 21 03:31:38.158: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:48.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:48.365: INFO: rc: 1
May 21 03:31:48.365: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:31:58.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:31:58.783: INFO: rc: 1
May 21 03:31:58.783: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:08.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:08.910: INFO: rc: 1
May 21 03:32:08.910: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:18.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:19.030: INFO: rc: 1
May 21 03:32:19.030: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:29.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:29.254: INFO: rc: 1
May 21 03:32:29.255: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:39.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:39.356: INFO: rc: 1
May 21 03:32:39.356: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:49.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:49.457: INFO: rc: 1
May 21 03:32:49.457: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:32:59.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:32:59.616: INFO: rc: 1
May 21 03:32:59.616: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:33:09.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:33:09.935: INFO: rc: 1
May 21 03:33:09.936: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:33:19.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:33:20.123: INFO: rc: 1
May 21 03:33:20.123: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:33:30.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:33:30.233: INFO: rc: 1
May 21 03:33:30.233: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
May 21 03:33:40.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-9048 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:33:40.379: INFO: rc: 1
May 21 03:33:40.379: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
May 21 03:33:40.379: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 03:33:40.392: INFO: Deleting all statefulset in ns statefulset-9048
May 21 03:33:40.395: INFO: Scaling statefulset ss to 0
May 21 03:33:40.403: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:33:40.409: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:33:40.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9048" for this suite.
May 21 03:33:46.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:33:46.529: INFO: namespace statefulset-9048 deletion completed in 6.087710442s

• [SLOW TEST:374.275 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:33:46.529: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 03:33:46.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --namespace=kubectl-4436'
May 21 03:33:46.674: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 03:33:46.674: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
May 21 03:33:46.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete jobs e2e-test-httpd-job --namespace=kubectl-4436'
May 21 03:33:46.802: INFO: stderr: ""
May 21 03:33:46.802: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:33:46.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4436" for this suite.
May 21 03:34:14.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:34:14.922: INFO: namespace kubectl-4436 deletion completed in 28.107308976s

• [SLOW TEST:28.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:34:14.923: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-dbfb2a58-b1b0-4ec5-8924-c8763b37e729
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-dbfb2a58-b1b0-4ec5-8924-c8763b37e729
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:35:31.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3963" for this suite.
May 21 03:35:59.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:35:59.633: INFO: namespace projected-3963 deletion completed in 28.092494065s

• [SLOW TEST:104.710 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:35:59.633: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
May 21 03:35:59.667: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 03:35:59.680: INFO: Waiting for terminating namespaces to be deleted...
May 21 03:35:59.682: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-1 before test
May 21 03:35:59.690: INFO: wangsucloud-csi-nodeplugin-kxzmb from kube-system started at 2020-05-21 01:47:03 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container cinder ready: true, restart count 0
May 21 03:35:59.690: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 03:35:59.690: INFO: kube-proxy-worker-hm48s from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 03:35:59.690: INFO: kube-flannel-qfng7 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container install-cni ready: true, restart count 0
May 21 03:35:59.690: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 03:35:59.690: INFO: ws-swift-79ff4f8c45-wp4s8 from kube-system started at 2020-05-21 01:47:37 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container swift ready: true, restart count 0
May 21 03:35:59.690: INFO: sonobuoy-e2e-job-53ec9ad4c8bc4eba from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container e2e ready: true, restart count 0
May 21 03:35:59.690: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 03:35:59.690: INFO: nodelocaldns-xlwkg from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container node-cache ready: true, restart count 0
May 21 03:35:59.690: INFO: kube-proxy-master-bp8ft from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 03:35:59.690: INFO: tiller-deploy-5c4b5664fc-v5w4x from kube-system started at 2020-05-21 01:47:34 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container tiller ready: true, restart count 0
May 21 03:35:59.690: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.690: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 03:35:59.690: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 03:35:59.690: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-2 before test
May 21 03:35:59.704: INFO: nodelocaldns-ljxj5 from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container node-cache ready: true, restart count 0
May 21 03:35:59.704: INFO: wangsu-cloud-controller-manager-58cd495b6b-vmxbk from kube-system started at 2020-05-21 01:46:33 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container wangsu-cloud-controller-manager ready: true, restart count 0
May 21 03:35:59.704: INFO: kube-proxy-worker-w9vrh from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 03:35:59.704: INFO: sonobuoy from sonobuoy started at 2020-05-21 02:32:09 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 03:35:59.704: INFO: kube-flannel-pxgt2 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container install-cni ready: true, restart count 0
May 21 03:35:59.704: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 03:35:59.704: INFO: wangsucloud-csi-nodeplugin-kmlr5 from kube-system started at 2020-05-21 01:47:09 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container cinder ready: true, restart count 0
May 21 03:35:59.704: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 03:35:59.704: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:35:59.704: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 03:35:59.704: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 03:35:59.704: INFO: kube-proxy-master-bwlfx from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 03:35:59.705: INFO: 	Container kube-proxy-master ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ad9144c9-e282-4053-ae2d-41b0523d426c 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-ad9144c9-e282-4053-ae2d-41b0523d426c off the node 9990-w-ax-1-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ad9144c9-e282-4053-ae2d-41b0523d426c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:41:03.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2704" for this suite.
May 21 03:41:11.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:41:11.933: INFO: namespace sched-pred-2704 deletion completed in 8.097031152s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:312.300 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:41:11.934: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May 21 03:41:18.042: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:41:18.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0521 03:41:18.042737      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-1730" for this suite.
May 21 03:41:24.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:41:24.152: INFO: namespace gc-1730 deletion completed in 6.094159873s

• [SLOW TEST:12.219 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:41:24.153: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2332
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-2332
STEP: Creating statefulset with conflicting port in namespace statefulset-2332
STEP: Waiting until pod test-pod will start running in namespace statefulset-2332
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-2332
May 21 03:41:28.255: INFO: Observed stateful pod in namespace: statefulset-2332, name: ss-0, uid: f80be995-1a39-407f-9322-dd1c26db6654, status phase: Pending. Waiting for statefulset controller to delete.
May 21 03:41:28.441: INFO: Observed stateful pod in namespace: statefulset-2332, name: ss-0, uid: f80be995-1a39-407f-9322-dd1c26db6654, status phase: Failed. Waiting for statefulset controller to delete.
May 21 03:41:28.447: INFO: Observed stateful pod in namespace: statefulset-2332, name: ss-0, uid: f80be995-1a39-407f-9322-dd1c26db6654, status phase: Failed. Waiting for statefulset controller to delete.
May 21 03:41:28.458: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-2332
STEP: Removing pod with conflicting port in namespace statefulset-2332
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-2332 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 03:41:32.486: INFO: Deleting all statefulset in ns statefulset-2332
May 21 03:41:32.488: INFO: Scaling statefulset ss to 0
May 21 03:41:42.501: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:41:42.504: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:41:42.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2332" for this suite.
May 21 03:41:48.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:41:48.612: INFO: namespace statefulset-2332 deletion completed in 6.088716051s

• [SLOW TEST:24.459 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:41:48.613: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
May 21 03:41:48.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 cluster-info'
May 21 03:41:48.793: INFO: stderr: ""
May 21 03:41:48.793: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mmetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:41:48.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-629" for this suite.
May 21 03:41:54.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:41:54.887: INFO: namespace kubectl-629 deletion completed in 6.088161394s

• [SLOW TEST:6.274 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:41:54.887: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:41:54.928: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:41:59.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8820" for this suite.
May 21 03:42:43.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:42:43.134: INFO: namespace pods-8820 deletion completed in 44.107840309s

• [SLOW TEST:48.247 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:42:43.134: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c35a20b8-fb99-4453-afaf-e54d7517d5fe
STEP: Creating a pod to test consume secrets
May 21 03:42:43.188: INFO: Waiting up to 5m0s for pod "pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1" in namespace "secrets-5157" to be "success or failure"
May 21 03:42:43.190: INFO: Pod "pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.079484ms
May 21 03:42:45.193: INFO: Pod "pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005399553s
May 21 03:42:47.201: INFO: Pod "pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012711929s
STEP: Saw pod success
May 21 03:42:47.201: INFO: Pod "pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1" satisfied condition "success or failure"
May 21 03:42:47.204: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1 container secret-volume-test: <nil>
STEP: delete the pod
May 21 03:42:47.243: INFO: Waiting for pod pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1 to disappear
May 21 03:42:47.246: INFO: Pod pod-secrets-743cd61f-23c8-40b1-a445-0e39596e51e1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:42:47.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5157" for this suite.
May 21 03:42:53.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:42:53.361: INFO: namespace secrets-5157 deletion completed in 6.109291664s

• [SLOW TEST:10.227 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:42:53.361: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:42:53.451: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 21 03:43:02.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-7424 create -f -'
May 21 03:43:03.006: INFO: stderr: ""
May 21 03:43:03.006: INFO: stdout: "e2e-test-crd-publish-openapi-8587-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 21 03:43:03.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-7424 delete e2e-test-crd-publish-openapi-8587-crds test-cr'
May 21 03:43:03.181: INFO: stderr: ""
May 21 03:43:03.181: INFO: stdout: "e2e-test-crd-publish-openapi-8587-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May 21 03:43:03.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-7424 apply -f -'
May 21 03:43:03.528: INFO: stderr: ""
May 21 03:43:03.528: INFO: stdout: "e2e-test-crd-publish-openapi-8587-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May 21 03:43:03.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-7424 delete e2e-test-crd-publish-openapi-8587-crds test-cr'
May 21 03:43:03.673: INFO: stderr: ""
May 21 03:43:03.673: INFO: stdout: "e2e-test-crd-publish-openapi-8587-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
May 21 03:43:03.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-8587-crds'
May 21 03:43:03.998: INFO: stderr: ""
May 21 03:43:03.998: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8587-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:43:08.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7424" for this suite.
May 21 03:43:14.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:43:14.246: INFO: namespace crd-publish-openapi-7424 deletion completed in 6.091845871s

• [SLOW TEST:20.885 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:43:14.246: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b181408d-de5d-4d62-8ee7-170f1d156c64 in namespace container-probe-9341
May 21 03:43:16.315: INFO: Started pod busybox-b181408d-de5d-4d62-8ee7-170f1d156c64 in namespace container-probe-9341
STEP: checking the pod's current state and verifying that restartCount is present
May 21 03:43:16.317: INFO: Initial restart count of pod busybox-b181408d-de5d-4d62-8ee7-170f1d156c64 is 0
May 21 03:44:08.422: INFO: Restart count of pod container-probe-9341/busybox-b181408d-de5d-4d62-8ee7-170f1d156c64 is now 1 (52.104423557s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:44:08.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9341" for this suite.
May 21 03:44:14.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:44:14.529: INFO: namespace container-probe-9341 deletion completed in 6.085361537s

• [SLOW TEST:60.283 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:44:14.529: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:44:15.488: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:44:18.511: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:44:18.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6670" for this suite.
May 21 03:44:24.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:44:24.750: INFO: namespace webhook-6670 deletion completed in 6.168421477s
STEP: Destroying namespace "webhook-6670-markers" for this suite.
May 21 03:44:30.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:44:30.848: INFO: namespace webhook-6670-markers deletion completed in 6.098650281s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.335 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:44:30.864: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
May 21 03:44:35.437: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6909 pod-service-account-4c97bc2a-348b-416f-9a4e-fd0142733c41 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May 21 03:44:35.815: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6909 pod-service-account-4c97bc2a-348b-416f-9a4e-fd0142733c41 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May 21 03:44:36.249: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6909 pod-service-account-4c97bc2a-348b-416f-9a4e-fd0142733c41 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:44:36.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6909" for this suite.
May 21 03:44:42.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:44:42.850: INFO: namespace svcaccounts-6909 deletion completed in 6.105138477s

• [SLOW TEST:11.986 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:44:42.851: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 03:44:46.928: INFO: DNS probes using dns-test-7a837741-2754-4745-beed-7832dbc57296 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 03:44:51.001: INFO: DNS probes using dns-test-cf0d77f5-7ca9-4b16-ab15-fcb7c149d053 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8738.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8738.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 03:44:55.093: INFO: DNS probes using dns-test-54481e62-87bf-4b6e-b15b-81c761e9d9a5 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:44:55.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8738" for this suite.
May 21 03:45:01.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:45:01.258: INFO: namespace dns-8738 deletion completed in 6.095429152s

• [SLOW TEST:18.407 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:45:01.258: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
May 21 03:45:01.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-6309'
May 21 03:45:01.674: INFO: stderr: ""
May 21 03:45:01.674: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 03:45:01.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:01.874: INFO: stderr: ""
May 21 03:45:01.875: INFO: stdout: "update-demo-nautilus-24qpj update-demo-nautilus-bxqdf "
May 21 03:45:01.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-24qpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:02.038: INFO: stderr: ""
May 21 03:45:02.038: INFO: stdout: ""
May 21 03:45:02.038: INFO: update-demo-nautilus-24qpj is created but not running
May 21 03:45:07.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:07.171: INFO: stderr: ""
May 21 03:45:07.171: INFO: stdout: "update-demo-nautilus-24qpj update-demo-nautilus-bxqdf "
May 21 03:45:07.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-24qpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:07.292: INFO: stderr: ""
May 21 03:45:07.292: INFO: stdout: "true"
May 21 03:45:07.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-24qpj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:07.432: INFO: stderr: ""
May 21 03:45:07.432: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:07.432: INFO: validating pod update-demo-nautilus-24qpj
May 21 03:45:07.437: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:07.437: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:07.437: INFO: update-demo-nautilus-24qpj is verified up and running
May 21 03:45:07.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:07.551: INFO: stderr: ""
May 21 03:45:07.551: INFO: stdout: "true"
May 21 03:45:07.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:07.672: INFO: stderr: ""
May 21 03:45:07.672: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:07.672: INFO: validating pod update-demo-nautilus-bxqdf
May 21 03:45:07.676: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:07.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:07.676: INFO: update-demo-nautilus-bxqdf is verified up and running
STEP: scaling down the replication controller
May 21 03:45:07.679: INFO: scanned /root for discovery docs: <nil>
May 21 03:45:07.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6309'
May 21 03:45:08.849: INFO: stderr: ""
May 21 03:45:08.849: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 03:45:08.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:08.999: INFO: stderr: ""
May 21 03:45:08.999: INFO: stdout: "update-demo-nautilus-24qpj update-demo-nautilus-bxqdf "
STEP: Replicas for name=update-demo: expected=1 actual=2
May 21 03:45:14.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:14.125: INFO: stderr: ""
May 21 03:45:14.125: INFO: stdout: "update-demo-nautilus-bxqdf "
May 21 03:45:14.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:14.247: INFO: stderr: ""
May 21 03:45:14.247: INFO: stdout: "true"
May 21 03:45:14.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:14.347: INFO: stderr: ""
May 21 03:45:14.347: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:14.347: INFO: validating pod update-demo-nautilus-bxqdf
May 21 03:45:14.356: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:14.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:14.356: INFO: update-demo-nautilus-bxqdf is verified up and running
STEP: scaling up the replication controller
May 21 03:45:14.358: INFO: scanned /root for discovery docs: <nil>
May 21 03:45:14.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6309'
May 21 03:45:15.538: INFO: stderr: ""
May 21 03:45:15.538: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 03:45:15.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:15.660: INFO: stderr: ""
May 21 03:45:15.660: INFO: stdout: "update-demo-nautilus-bxqdf update-demo-nautilus-fbxk2 "
May 21 03:45:15.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:15.772: INFO: stderr: ""
May 21 03:45:15.772: INFO: stdout: "true"
May 21 03:45:15.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:15.863: INFO: stderr: ""
May 21 03:45:15.863: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:15.863: INFO: validating pod update-demo-nautilus-bxqdf
May 21 03:45:15.867: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:15.867: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:15.867: INFO: update-demo-nautilus-bxqdf is verified up and running
May 21 03:45:15.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-fbxk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:15.959: INFO: stderr: ""
May 21 03:45:15.959: INFO: stdout: ""
May 21 03:45:15.959: INFO: update-demo-nautilus-fbxk2 is created but not running
May 21 03:45:20.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6309'
May 21 03:45:21.086: INFO: stderr: ""
May 21 03:45:21.086: INFO: stdout: "update-demo-nautilus-bxqdf update-demo-nautilus-fbxk2 "
May 21 03:45:21.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:21.206: INFO: stderr: ""
May 21 03:45:21.206: INFO: stdout: "true"
May 21 03:45:21.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-bxqdf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:21.298: INFO: stderr: ""
May 21 03:45:21.298: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:21.298: INFO: validating pod update-demo-nautilus-bxqdf
May 21 03:45:21.302: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:21.302: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:21.302: INFO: update-demo-nautilus-bxqdf is verified up and running
May 21 03:45:21.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-fbxk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:21.396: INFO: stderr: ""
May 21 03:45:21.396: INFO: stdout: "true"
May 21 03:45:21.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-fbxk2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6309'
May 21 03:45:21.490: INFO: stderr: ""
May 21 03:45:21.490: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 03:45:21.490: INFO: validating pod update-demo-nautilus-fbxk2
May 21 03:45:21.497: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 03:45:21.497: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 03:45:21.497: INFO: update-demo-nautilus-fbxk2 is verified up and running
STEP: using delete to clean up resources
May 21 03:45:21.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-6309'
May 21 03:45:21.614: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 03:45:21.614: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 03:45:21.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6309'
May 21 03:45:21.939: INFO: stderr: "No resources found in kubectl-6309 namespace.\n"
May 21 03:45:21.939: INFO: stdout: ""
May 21 03:45:21.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -l name=update-demo --namespace=kubectl-6309 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 03:45:22.085: INFO: stderr: ""
May 21 03:45:22.085: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:45:22.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6309" for this suite.
May 21 03:45:28.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:45:28.190: INFO: namespace kubectl-6309 deletion completed in 6.099212047s

• [SLOW TEST:26.932 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:45:28.190: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:45:28.446: INFO: (0) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.143961ms)
May 21 03:45:28.449: INFO: (1) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.2328ms)
May 21 03:45:28.453: INFO: (2) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.200138ms)
May 21 03:45:28.456: INFO: (3) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.278088ms)
May 21 03:45:28.461: INFO: (4) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.65336ms)
May 21 03:45:28.464: INFO: (5) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 2.979041ms)
May 21 03:45:28.468: INFO: (6) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.233038ms)
May 21 03:45:28.471: INFO: (7) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.234616ms)
May 21 03:45:28.475: INFO: (8) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.384488ms)
May 21 03:45:28.484: INFO: (9) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.935081ms)
May 21 03:45:28.487: INFO: (10) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.577899ms)
May 21 03:45:28.490: INFO: (11) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.22447ms)
May 21 03:45:28.494: INFO: (12) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.132087ms)
May 21 03:45:28.497: INFO: (13) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.200685ms)
May 21 03:45:28.501: INFO: (14) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.121849ms)
May 21 03:45:28.504: INFO: (15) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.179577ms)
May 21 03:45:28.507: INFO: (16) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.194156ms)
May 21 03:45:28.511: INFO: (17) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.259686ms)
May 21 03:45:28.516: INFO: (18) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.886832ms)
May 21 03:45:28.520: INFO: (19) /api/v1/nodes/9990-w-ax-1-1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 3.943908ms)
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:45:28.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8944" for this suite.
May 21 03:45:34.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:45:34.608: INFO: namespace proxy-8944 deletion completed in 6.083419482s

• [SLOW TEST:6.417 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:45:34.608: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7684
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-7684
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7684
May 21 03:45:34.662: INFO: Found 0 stateful pods, waiting for 1
May 21 03:45:44.672: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May 21 03:45:44.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:45:45.390: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:45:45.390: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:45:45.390: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:45:45.400: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:45:45.400: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:45:45.428: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
May 21 03:45:45.428: INFO: ss-0  9990-w-ax-1-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  }]
May 21 03:45:45.428: INFO: ss-1                 Pending         []
May 21 03:45:45.428: INFO: 
May 21 03:45:45.428: INFO: StatefulSet ss has not reached scale 3, at 2
May 21 03:45:46.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994299669s
May 21 03:45:47.437: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.9898125s
May 21 03:45:48.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985100173s
May 21 03:45:49.449: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977699871s
May 21 03:45:50.453: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.973301703s
May 21 03:45:51.462: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965377476s
May 21 03:45:52.467: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960570267s
May 21 03:45:53.471: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.95483763s
May 21 03:45:54.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 951.251551ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7684
May 21 03:45:55.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:45:56.009: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May 21 03:45:56.009: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:45:56.009: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:45:56.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:45:56.428: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 21 03:45:56.428: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:45:56.428: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:45:56.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May 21 03:45:56.750: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May 21 03:45:56.750: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May 21 03:45:56.750: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May 21 03:45:56.755: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:45:56.755: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May 21 03:45:56.755: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May 21 03:45:56.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:45:57.158: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:45:57.158: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:45:57.158: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:45:57.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:45:57.508: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:45:57.508: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:45:57.508: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:45:57.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=statefulset-7684 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May 21 03:45:57.813: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May 21 03:45:57.813: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May 21 03:45:57.813: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May 21 03:45:57.813: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:45:57.817: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May 21 03:46:07.825: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:46:07.825: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:46:07.825: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May 21 03:46:07.842: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
May 21 03:46:07.842: INFO: ss-0  9990-w-ax-1-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  }]
May 21 03:46:07.842: INFO: ss-1  9990-w-ax-1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:07.842: INFO: ss-2  9990-w-ax-1-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:07.842: INFO: 
May 21 03:46:07.842: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 03:46:08.850: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
May 21 03:46:08.850: INFO: ss-0  9990-w-ax-1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  }]
May 21 03:46:08.850: INFO: ss-1  9990-w-ax-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:08.850: INFO: ss-2  9990-w-ax-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:08.850: INFO: 
May 21 03:46:08.850: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 03:46:09.854: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
May 21 03:46:09.854: INFO: ss-0  9990-w-ax-1-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:57 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:34 +0000 UTC  }]
May 21 03:46:09.854: INFO: ss-1  9990-w-ax-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:09.854: INFO: ss-2  9990-w-ax-1-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:58 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-21 03:45:45 +0000 UTC  }]
May 21 03:46:09.854: INFO: 
May 21 03:46:09.854: INFO: StatefulSet ss has not reached scale 0, at 3
May 21 03:46:10.858: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.979600364s
May 21 03:46:11.862: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.976113164s
May 21 03:46:12.868: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.969265881s
May 21 03:46:13.872: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.965349325s
May 21 03:46:14.875: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.961933031s
May 21 03:46:15.880: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.957901934s
May 21 03:46:16.884: INFO: Verifying statefulset ss doesn't scale past 0 for another 953.794351ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7684
May 21 03:46:17.887: INFO: Scaling statefulset ss to 0
May 21 03:46:17.895: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
May 21 03:46:17.897: INFO: Deleting all statefulset in ns statefulset-7684
May 21 03:46:17.899: INFO: Scaling statefulset ss to 0
May 21 03:46:17.908: INFO: Waiting for statefulset status.replicas updated to 0
May 21 03:46:17.911: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:46:17.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7684" for this suite.
May 21 03:46:23.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:46:24.050: INFO: namespace statefulset-7684 deletion completed in 6.121243404s

• [SLOW TEST:49.442 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:46:24.050: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
May 21 03:46:24.097: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5544" to be "success or failure"
May 21 03:46:24.103: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.591676ms
May 21 03:46:26.106: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009093065s
May 21 03:46:28.110: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012791761s
STEP: Saw pod success
May 21 03:46:28.110: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May 21 03:46:28.112: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May 21 03:46:28.152: INFO: Waiting for pod pod-host-path-test to disappear
May 21 03:46:28.154: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:46:28.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5544" for this suite.
May 21 03:46:34.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:46:34.244: INFO: namespace hostpath-5544 deletion completed in 6.084571656s

• [SLOW TEST:10.193 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:46:34.244: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:46:34.284: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:46:40.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2165" for this suite.
May 21 03:46:46.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:46:46.419: INFO: namespace custom-resource-definition-2165 deletion completed in 6.098639123s

• [SLOW TEST:12.175 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:46:46.419: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
May 21 03:46:46.466: INFO: Waiting up to 5m0s for pod "client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f" in namespace "containers-6200" to be "success or failure"
May 21 03:46:46.471: INFO: Pod "client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.447253ms
May 21 03:46:48.475: INFO: Pod "client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008644532s
May 21 03:46:50.478: INFO: Pod "client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01199992s
STEP: Saw pod success
May 21 03:46:50.478: INFO: Pod "client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f" satisfied condition "success or failure"
May 21 03:46:50.481: INFO: Trying to get logs from node 9990-w-ax-1-1 pod client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f container test-container: <nil>
STEP: delete the pod
May 21 03:46:50.508: INFO: Waiting for pod client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f to disappear
May 21 03:46:50.512: INFO: Pod client-containers-d22c6f5b-f0a5-41d0-89ed-6770186da93f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:46:50.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6200" for this suite.
May 21 03:46:56.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:46:56.615: INFO: namespace containers-6200 deletion completed in 6.096660554s

• [SLOW TEST:10.196 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:46:56.615: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May 21 03:46:56.664: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:47:07.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8539" for this suite.
May 21 03:47:13.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:47:13.643: INFO: namespace pods-8539 deletion completed in 6.099515347s

• [SLOW TEST:17.028 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:47:13.643: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
May 21 03:47:13.676: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 03:47:13.694: INFO: Waiting for terminating namespaces to be deleted...
May 21 03:47:13.696: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-1 before test
May 21 03:47:13.703: INFO: kube-proxy-master-bp8ft from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 03:47:13.703: INFO: tiller-deploy-5c4b5664fc-v5w4x from kube-system started at 2020-05-21 01:47:34 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container tiller ready: true, restart count 0
May 21 03:47:13.703: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 03:47:13.703: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 03:47:13.703: INFO: wangsucloud-csi-nodeplugin-kxzmb from kube-system started at 2020-05-21 01:47:03 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container cinder ready: true, restart count 0
May 21 03:47:13.703: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 03:47:13.703: INFO: kube-proxy-worker-hm48s from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 03:47:13.703: INFO: kube-flannel-qfng7 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container install-cni ready: true, restart count 0
May 21 03:47:13.703: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 03:47:13.703: INFO: ws-swift-79ff4f8c45-wp4s8 from kube-system started at 2020-05-21 01:47:37 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container swift ready: true, restart count 0
May 21 03:47:13.703: INFO: sonobuoy-e2e-job-53ec9ad4c8bc4eba from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container e2e ready: true, restart count 0
May 21 03:47:13.703: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 03:47:13.703: INFO: nodelocaldns-xlwkg from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.703: INFO: 	Container node-cache ready: true, restart count 0
May 21 03:47:13.703: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-2 before test
May 21 03:47:13.710: INFO: kube-proxy-master-bwlfx from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 03:47:13.710: INFO: wangsucloud-csi-nodeplugin-kmlr5 from kube-system started at 2020-05-21 01:47:09 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container cinder ready: true, restart count 0
May 21 03:47:13.710: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 03:47:13.710: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 03:47:13.710: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 03:47:13.710: INFO: wangsu-cloud-controller-manager-58cd495b6b-vmxbk from kube-system started at 2020-05-21 01:46:33 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container wangsu-cloud-controller-manager ready: true, restart count 0
May 21 03:47:13.710: INFO: nodelocaldns-ljxj5 from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container node-cache ready: true, restart count 0
May 21 03:47:13.710: INFO: kube-proxy-worker-w9vrh from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 03:47:13.710: INFO: kube-flannel-pxgt2 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container install-cni ready: true, restart count 0
May 21 03:47:13.710: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 03:47:13.710: INFO: sonobuoy from sonobuoy started at 2020-05-21 02:32:09 +0000 UTC (1 container statuses recorded)
May 21 03:47:13.710: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3a98a409-20eb-417d-bd23-3ae168f15643 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3a98a409-20eb-417d-bd23-3ae168f15643 off the node 9990-w-ax-1-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3a98a409-20eb-417d-bd23-3ae168f15643
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:47:23.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4384" for this suite.
May 21 03:47:41.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:47:41.916: INFO: namespace sched-pred-4384 deletion completed in 18.085535751s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:28.273 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:47:41.916: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:47:41.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e" in namespace "projected-4053" to be "success or failure"
May 21 03:47:41.979: INFO: Pod "downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.535734ms
May 21 03:47:43.982: INFO: Pod "downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e": Phase="Running", Reason="", readiness=true. Elapsed: 2.022080943s
May 21 03:47:45.986: INFO: Pod "downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025328996s
STEP: Saw pod success
May 21 03:47:45.986: INFO: Pod "downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e" satisfied condition "success or failure"
May 21 03:47:45.988: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e container client-container: <nil>
STEP: delete the pod
May 21 03:47:46.010: INFO: Waiting for pod downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e to disappear
May 21 03:47:46.013: INFO: Pod downwardapi-volume-354bb1b5-47d6-42f3-b8f0-b5740967a31e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:47:46.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4053" for this suite.
May 21 03:47:52.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:47:52.118: INFO: namespace projected-4053 deletion completed in 6.100832729s

• [SLOW TEST:10.202 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:47:52.128: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:48:16.195: INFO: Container started at 2020-05-21 03:47:53 +0000 UTC, pod became ready at 2020-05-21 03:48:14 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:48:16.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9339" for this suite.
May 21 03:48:28.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:48:28.306: INFO: namespace container-probe-9339 deletion completed in 12.106701295s

• [SLOW TEST:36.179 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:48:28.307: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-45ab77fa-3b9b-44d9-851d-43dbccf0e732
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:48:28.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8887" for this suite.
May 21 03:48:34.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:48:34.442: INFO: namespace configmap-8887 deletion completed in 6.093669287s

• [SLOW TEST:6.135 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:48:34.442: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 21 03:48:35.036: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May 21 03:48:37.044: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725629715, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725629715, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725629715, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725629715, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-54b5599975\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:48:40.073: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:48:40.076: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:48:46.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1677" for this suite.
May 21 03:48:52.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:48:52.717: INFO: namespace crd-webhook-1677 deletion completed in 6.220997748s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:18.306 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:48:52.749: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May 21 03:48:57.839: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:48:58.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8502" for this suite.
May 21 03:49:26.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:49:26.954: INFO: namespace replicaset-8502 deletion completed in 28.087115946s

• [SLOW TEST:34.205 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:49:26.954: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6875/configmap-test-a3a66f91-606b-44b4-83bd-9a8ac51efd16
STEP: Creating a pod to test consume configMaps
May 21 03:49:26.998: INFO: Waiting up to 5m0s for pod "pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210" in namespace "configmap-6875" to be "success or failure"
May 21 03:49:27.001: INFO: Pod "pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.622955ms
May 21 03:49:29.004: INFO: Pod "pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005734969s
May 21 03:49:31.008: INFO: Pod "pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009455249s
STEP: Saw pod success
May 21 03:49:31.008: INFO: Pod "pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210" satisfied condition "success or failure"
May 21 03:49:31.010: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210 container env-test: <nil>
STEP: delete the pod
May 21 03:49:31.037: INFO: Waiting for pod pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210 to disappear
May 21 03:49:31.042: INFO: Pod pod-configmaps-ecc0a614-7e6d-498d-bdf4-105a4bc2b210 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:49:31.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6875" for this suite.
May 21 03:49:37.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:49:37.135: INFO: namespace configmap-6875 deletion completed in 6.088452935s

• [SLOW TEST:10.181 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:49:37.136: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 in namespace container-probe-1398
May 21 03:49:41.185: INFO: Started pod liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 in namespace container-probe-1398
STEP: checking the pod's current state and verifying that restartCount is present
May 21 03:49:41.188: INFO: Initial restart count of pod liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is 0
May 21 03:49:53.212: INFO: Restart count of pod container-probe-1398/liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is now 1 (12.024487727s elapsed)
May 21 03:50:13.267: INFO: Restart count of pod container-probe-1398/liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is now 2 (32.079245667s elapsed)
May 21 03:50:33.303: INFO: Restart count of pod container-probe-1398/liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is now 3 (52.115929556s elapsed)
May 21 03:50:53.354: INFO: Restart count of pod container-probe-1398/liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is now 4 (1m12.166896914s elapsed)
May 21 03:52:09.558: INFO: Restart count of pod container-probe-1398/liveness-e1ef35cc-655c-46ac-939a-c286486f76f1 is now 5 (2m28.370882918s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:52:09.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1398" for this suite.
May 21 03:52:15.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:52:15.671: INFO: namespace container-probe-1398 deletion completed in 6.092989708s

• [SLOW TEST:158.535 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:52:15.671: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:52:15.712: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
May 21 03:52:24.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 create -f -'
May 21 03:52:25.179: INFO: stderr: ""
May 21 03:52:25.179: INFO: stdout: "e2e-test-crd-publish-openapi-6360-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 21 03:52:25.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 delete e2e-test-crd-publish-openapi-6360-crds test-foo'
May 21 03:52:25.291: INFO: stderr: ""
May 21 03:52:25.291: INFO: stdout: "e2e-test-crd-publish-openapi-6360-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May 21 03:52:25.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 apply -f -'
May 21 03:52:25.617: INFO: stderr: ""
May 21 03:52:25.617: INFO: stdout: "e2e-test-crd-publish-openapi-6360-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May 21 03:52:25.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 delete e2e-test-crd-publish-openapi-6360-crds test-foo'
May 21 03:52:25.778: INFO: stderr: ""
May 21 03:52:25.778: INFO: stdout: "e2e-test-crd-publish-openapi-6360-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
May 21 03:52:25.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 create -f -'
May 21 03:52:26.077: INFO: rc: 1
May 21 03:52:26.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 apply -f -'
May 21 03:52:26.329: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
May 21 03:52:26.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 create -f -'
May 21 03:52:26.615: INFO: rc: 1
May 21 03:52:26.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-3503 apply -f -'
May 21 03:52:26.863: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
May 21 03:52:26.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-6360-crds'
May 21 03:52:27.139: INFO: stderr: ""
May 21 03:52:27.139: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6360-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
May 21 03:52:27.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-6360-crds.metadata'
May 21 03:52:27.423: INFO: stderr: ""
May 21 03:52:27.423: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6360-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May 21 03:52:27.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-6360-crds.spec'
May 21 03:52:27.707: INFO: stderr: ""
May 21 03:52:27.707: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6360-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May 21 03:52:27.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-6360-crds.spec.bars'
May 21 03:52:27.979: INFO: stderr: ""
May 21 03:52:27.979: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6360-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
May 21 03:52:27.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-6360-crds.spec.bars2'
May 21 03:52:28.283: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:52:31.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3503" for this suite.
May 21 03:52:37.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:52:38.026: INFO: namespace crd-publish-openapi-3503 deletion completed in 6.088623521s

• [SLOW TEST:22.355 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:52:38.026: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
May 21 03:52:38.069: INFO: Waiting up to 5m0s for pod "pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160" in namespace "emptydir-1885" to be "success or failure"
May 21 03:52:38.082: INFO: Pod "pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160": Phase="Pending", Reason="", readiness=false. Elapsed: 12.84025ms
May 21 03:52:40.086: INFO: Pod "pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016706485s
May 21 03:52:42.089: INFO: Pod "pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020395392s
STEP: Saw pod success
May 21 03:52:42.089: INFO: Pod "pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160" satisfied condition "success or failure"
May 21 03:52:42.092: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160 container test-container: <nil>
STEP: delete the pod
May 21 03:52:42.123: INFO: Waiting for pod pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160 to disappear
May 21 03:52:42.126: INFO: Pod pod-da9c3bb4-81b7-431c-b78f-8d9c71f7c160 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:52:42.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1885" for this suite.
May 21 03:52:48.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:52:48.211: INFO: namespace emptydir-1885 deletion completed in 6.080634631s

• [SLOW TEST:10.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:52:48.212: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
May 21 03:52:48.261: INFO: Waiting up to 5m0s for pod "var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0" in namespace "var-expansion-3479" to be "success or failure"
May 21 03:52:48.264: INFO: Pod "var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.55877ms
May 21 03:52:50.268: INFO: Pod "var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007543933s
STEP: Saw pod success
May 21 03:52:50.268: INFO: Pod "var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0" satisfied condition "success or failure"
May 21 03:52:50.272: INFO: Trying to get logs from node 9990-w-ax-1-2 pod var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0 container dapi-container: <nil>
STEP: delete the pod
May 21 03:52:50.301: INFO: Waiting for pod var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0 to disappear
May 21 03:52:50.304: INFO: Pod var-expansion-92e19b4b-2edd-408e-bfb8-7f742b1d97f0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:52:50.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3479" for this suite.
May 21 03:52:56.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:52:56.398: INFO: namespace var-expansion-3479 deletion completed in 6.085926725s

• [SLOW TEST:8.186 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:52:56.398: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
May 21 03:52:56.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run logs-generator --generator=run-pod/v1 --image=172.16.17.5/sonobuoy/agnhost:2.6 --namespace=kubectl-9910 -- logs-generator --log-lines-total 100 --run-duration 20s'
May 21 03:52:56.562: INFO: stderr: ""
May 21 03:52:56.562: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
May 21 03:52:56.562: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May 21 03:52:56.563: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9910" to be "running and ready, or succeeded"
May 21 03:52:56.566: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 3.493829ms
May 21 03:52:58.569: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006692671s
May 21 03:53:00.573: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.010705453s
May 21 03:53:00.573: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May 21 03:53:00.573: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
May 21 03:53:00.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910'
May 21 03:53:00.748: INFO: stderr: ""
May 21 03:53:00.748: INFO: stdout: "I0521 03:52:57.854765       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/5jst 260\nI0521 03:52:58.055051       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/h4mj 494\nI0521 03:52:58.255140       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/cm7 226\nI0521 03:52:58.455077       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/kgq 504\nI0521 03:52:58.654987       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/nsgp 378\nI0521 03:52:58.855001       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/bf2n 358\nI0521 03:52:59.054991       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/hmf 480\nI0521 03:52:59.254944       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/z7zz 538\nI0521 03:52:59.454977       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/np57 595\nI0521 03:52:59.654929       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/t7p 333\nI0521 03:52:59.854909       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/lwts 212\nI0521 03:53:00.054959       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/lnt6 404\nI0521 03:53:00.255206       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/59n 393\nI0521 03:53:00.454928       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/nhq 435\nI0521 03:53:00.655191       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/w8w 470\n"
STEP: limiting log lines
May 21 03:53:00.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910 --tail=1'
May 21 03:53:00.947: INFO: stderr: ""
May 21 03:53:00.947: INFO: stdout: "I0521 03:53:00.855133       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/8lt 443\n"
STEP: limiting log bytes
May 21 03:53:00.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910 --limit-bytes=1'
May 21 03:53:01.137: INFO: stderr: ""
May 21 03:53:01.138: INFO: stdout: "I"
STEP: exposing timestamps
May 21 03:53:01.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910 --tail=1 --timestamps'
May 21 03:53:01.279: INFO: stderr: ""
May 21 03:53:01.279: INFO: stdout: "2020-05-21T03:53:01.255191092Z I0521 03:53:01.254923       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/wvm2 400\n"
STEP: restricting to a time range
May 21 03:53:03.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910 --since=1s'
May 21 03:53:03.909: INFO: stderr: ""
May 21 03:53:03.909: INFO: stdout: "I0521 03:53:03.054989       1 logs_generator.go:76] 26 GET /api/v1/namespaces/ns/pods/bjdf 322\nI0521 03:53:03.254925       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/rrx 357\nI0521 03:53:03.454935       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/jd6h 202\nI0521 03:53:03.654941       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/4bj 285\nI0521 03:53:03.854926       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/4599 272\n"
May 21 03:53:03.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs logs-generator logs-generator --namespace=kubectl-9910 --since=24h'
May 21 03:53:04.023: INFO: stderr: ""
May 21 03:53:04.023: INFO: stdout: "I0521 03:52:57.854765       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/5jst 260\nI0521 03:52:58.055051       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/h4mj 494\nI0521 03:52:58.255140       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/cm7 226\nI0521 03:52:58.455077       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/kgq 504\nI0521 03:52:58.654987       1 logs_generator.go:76] 4 POST /api/v1/namespaces/ns/pods/nsgp 378\nI0521 03:52:58.855001       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/bf2n 358\nI0521 03:52:59.054991       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/hmf 480\nI0521 03:52:59.254944       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/ns/pods/z7zz 538\nI0521 03:52:59.454977       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/np57 595\nI0521 03:52:59.654929       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/t7p 333\nI0521 03:52:59.854909       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/lwts 212\nI0521 03:53:00.054959       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/lnt6 404\nI0521 03:53:00.255206       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/59n 393\nI0521 03:53:00.454928       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/nhq 435\nI0521 03:53:00.655191       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/w8w 470\nI0521 03:53:00.855133       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/8lt 443\nI0521 03:53:01.062717       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/8h27 495\nI0521 03:53:01.254923       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/wvm2 400\nI0521 03:53:01.455042       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/5nkz 481\nI0521 03:53:01.654937       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/5b8 466\nI0521 03:53:01.854959       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/csh 396\nI0521 03:53:02.054929       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/sqkq 328\nI0521 03:53:02.254932       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/ns/pods/qxz9 251\nI0521 03:53:02.459872       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/bdj 266\nI0521 03:53:02.654964       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/qp4 508\nI0521 03:53:02.854902       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/lxvx 537\nI0521 03:53:03.054989       1 logs_generator.go:76] 26 GET /api/v1/namespaces/ns/pods/bjdf 322\nI0521 03:53:03.254925       1 logs_generator.go:76] 27 GET /api/v1/namespaces/kube-system/pods/rrx 357\nI0521 03:53:03.454935       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/default/pods/jd6h 202\nI0521 03:53:03.654941       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/4bj 285\nI0521 03:53:03.854926       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/4599 272\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
May 21 03:53:04.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete pod logs-generator --namespace=kubectl-9910'
May 21 03:53:06.108: INFO: stderr: ""
May 21 03:53:06.108: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:53:06.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9910" for this suite.
May 21 03:53:12.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:53:12.217: INFO: namespace kubectl-9910 deletion completed in 6.103761222s

• [SLOW TEST:15.819 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:53:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:53:12.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4046" for this suite.
May 21 03:53:40.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:53:40.382: INFO: namespace pods-4046 deletion completed in 28.108963747s

• [SLOW TEST:28.164 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:53:40.382: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:53:40.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238" in namespace "downward-api-9871" to be "success or failure"
May 21 03:53:40.440: INFO: Pod "downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238": Phase="Pending", Reason="", readiness=false. Elapsed: 8.801105ms
May 21 03:53:42.445: INFO: Pod "downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013550054s
May 21 03:53:44.449: INFO: Pod "downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017996125s
STEP: Saw pod success
May 21 03:53:44.449: INFO: Pod "downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238" satisfied condition "success or failure"
May 21 03:53:44.452: INFO: Trying to get logs from node 9990-w-ax-1-1 pod downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238 container client-container: <nil>
STEP: delete the pod
May 21 03:53:44.475: INFO: Waiting for pod downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238 to disappear
May 21 03:53:44.478: INFO: Pod downwardapi-volume-44d271ec-5f9d-4f65-872d-5e9cc0e54238 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:53:44.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9871" for this suite.
May 21 03:53:50.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:53:50.571: INFO: namespace downward-api-9871 deletion completed in 6.087954352s

• [SLOW TEST:10.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:53:50.571: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:54:12.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4352" for this suite.
May 21 03:54:18.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:54:18.947: INFO: namespace container-runtime-4352 deletion completed in 6.086237096s

• [SLOW TEST:28.376 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:54:18.948: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:54:18.981: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5535" for this suite.
May 21 03:54:24.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:54:25.065: INFO: namespace tables-5535 deletion completed in 6.080272388s

• [SLOW TEST:6.118 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:54:25.066: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 03:54:25.111: INFO: Waiting up to 5m0s for pod "pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3" in namespace "emptydir-334" to be "success or failure"
May 21 03:54:25.116: INFO: Pod "pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.323135ms
May 21 03:54:27.119: INFO: Pod "pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008557686s
May 21 03:54:29.129: INFO: Pod "pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018417095s
STEP: Saw pod success
May 21 03:54:29.129: INFO: Pod "pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3" satisfied condition "success or failure"
May 21 03:54:29.132: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3 container test-container: <nil>
STEP: delete the pod
May 21 03:54:29.199: INFO: Waiting for pod pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3 to disappear
May 21 03:54:29.202: INFO: Pod pod-ed34989f-bc52-49ab-b7d3-4ec2b349e2c3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:54:29.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-334" for this suite.
May 21 03:54:35.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:54:35.303: INFO: namespace emptydir-334 deletion completed in 6.096428483s

• [SLOW TEST:10.237 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:54:35.303: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 03:54:35.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-deployment --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-557'
May 21 03:54:35.461: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 03:54:35.461: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
May 21 03:54:39.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete deployment e2e-test-httpd-deployment --namespace=kubectl-557'
May 21 03:54:39.633: INFO: stderr: ""
May 21 03:54:39.633: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:54:39.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-557" for this suite.
May 21 03:54:51.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:54:51.745: INFO: namespace kubectl-557 deletion completed in 12.105964338s

• [SLOW TEST:16.442 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:54:51.746: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f694d629-8fa4-43e6-91c4-6f70d850236b
STEP: Creating a pod to test consume secrets
May 21 03:54:51.836: INFO: Waiting up to 5m0s for pod "pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892" in namespace "secrets-31" to be "success or failure"
May 21 03:54:51.838: INFO: Pod "pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892": Phase="Pending", Reason="", readiness=false. Elapsed: 2.148434ms
May 21 03:54:53.844: INFO: Pod "pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007367792s
STEP: Saw pod success
May 21 03:54:53.844: INFO: Pod "pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892" satisfied condition "success or failure"
May 21 03:54:53.847: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892 container secret-volume-test: <nil>
STEP: delete the pod
May 21 03:54:53.887: INFO: Waiting for pod pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892 to disappear
May 21 03:54:53.900: INFO: Pod pod-secrets-f7d2d621-eb3a-4e7e-b921-e164aa962892 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:54:53.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-31" for this suite.
May 21 03:54:59.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:55:00.022: INFO: namespace secrets-31 deletion completed in 6.106130695s
STEP: Destroying namespace "secret-namespace-4107" for this suite.
May 21 03:55:06.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:55:06.115: INFO: namespace secret-namespace-4107 deletion completed in 6.092608215s

• [SLOW TEST:14.369 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:55:06.115: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6958
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6958
STEP: Deleting pre-stop pod
May 21 03:55:15.200: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:55:15.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6958" for this suite.
May 21 03:55:59.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:55:59.306: INFO: namespace prestop-6958 deletion completed in 44.091209102s

• [SLOW TEST:53.191 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:55:59.306: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
May 21 03:55:59.354: INFO: Waiting up to 5m0s for pod "client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b" in namespace "containers-798" to be "success or failure"
May 21 03:55:59.356: INFO: Pod "client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.264332ms
May 21 03:56:01.360: INFO: Pod "client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006617471s
STEP: Saw pod success
May 21 03:56:01.360: INFO: Pod "client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b" satisfied condition "success or failure"
May 21 03:56:01.363: INFO: Trying to get logs from node 9990-w-ax-1-2 pod client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b container test-container: <nil>
STEP: delete the pod
May 21 03:56:01.394: INFO: Waiting for pod client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b to disappear
May 21 03:56:01.400: INFO: Pod client-containers-062c9838-3b0e-4eec-abf7-03438d0cd04b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:56:01.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-798" for this suite.
May 21 03:56:07.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:56:07.505: INFO: namespace containers-798 deletion completed in 6.099189051s

• [SLOW TEST:8.199 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:56:07.505: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
May 21 03:56:07.563: INFO: Waiting up to 5m0s for pod "pod-07c64d51-f421-427d-9586-0765db6036e3" in namespace "emptydir-4906" to be "success or failure"
May 21 03:56:07.565: INFO: Pod "pod-07c64d51-f421-427d-9586-0765db6036e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.481372ms
May 21 03:56:09.569: INFO: Pod "pod-07c64d51-f421-427d-9586-0765db6036e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006540665s
May 21 03:56:11.573: INFO: Pod "pod-07c64d51-f421-427d-9586-0765db6036e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01016177s
STEP: Saw pod success
May 21 03:56:11.573: INFO: Pod "pod-07c64d51-f421-427d-9586-0765db6036e3" satisfied condition "success or failure"
May 21 03:56:11.575: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-07c64d51-f421-427d-9586-0765db6036e3 container test-container: <nil>
STEP: delete the pod
May 21 03:56:11.595: INFO: Waiting for pod pod-07c64d51-f421-427d-9586-0765db6036e3 to disappear
May 21 03:56:11.597: INFO: Pod pod-07c64d51-f421-427d-9586-0765db6036e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:56:11.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4906" for this suite.
May 21 03:56:17.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:56:17.692: INFO: namespace emptydir-4906 deletion completed in 6.084898773s

• [SLOW TEST:10.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:56:17.693: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-402dd5f7-a64b-4ed5-a7a8-9cf4f383896a
STEP: Creating a pod to test consume secrets
May 21 03:56:17.744: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582" in namespace "projected-6210" to be "success or failure"
May 21 03:56:17.747: INFO: Pod "pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582": Phase="Pending", Reason="", readiness=false. Elapsed: 2.294882ms
May 21 03:56:19.750: INFO: Pod "pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005532775s
May 21 03:56:21.755: INFO: Pod "pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01029978s
STEP: Saw pod success
May 21 03:56:21.755: INFO: Pod "pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582" satisfied condition "success or failure"
May 21 03:56:21.757: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582 container projected-secret-volume-test: <nil>
STEP: delete the pod
May 21 03:56:21.794: INFO: Waiting for pod pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582 to disappear
May 21 03:56:21.796: INFO: Pod pod-projected-secrets-6dc6529c-5ff4-49fe-a3fc-a614707cd582 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:56:21.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6210" for this suite.
May 21 03:56:27.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:56:27.887: INFO: namespace projected-6210 deletion completed in 6.086563632s

• [SLOW TEST:10.195 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:56:27.888: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:56:43.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1429" for this suite.
May 21 03:56:50.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:56:50.099: INFO: namespace resourcequota-1429 deletion completed in 6.110048925s

• [SLOW TEST:22.211 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:56:50.099: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 03:56:58.198: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:56:58.201: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 03:57:00.201: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:57:00.204: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 03:57:02.201: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:57:02.205: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 03:57:04.201: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:57:04.207: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 03:57:06.201: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:57:06.205: INFO: Pod pod-with-poststart-exec-hook still exists
May 21 03:57:08.201: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May 21 03:57:08.204: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:57:08.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7424" for this suite.
May 21 03:57:20.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:57:20.318: INFO: namespace container-lifecycle-hook-7424 deletion completed in 12.109169283s

• [SLOW TEST:30.220 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:57:20.319: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 03:57:20.366: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1" in namespace "projected-3084" to be "success or failure"
May 21 03:57:20.373: INFO: Pod "downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.904214ms
May 21 03:57:22.377: INFO: Pod "downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01124594s
May 21 03:57:24.381: INFO: Pod "downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015420598s
STEP: Saw pod success
May 21 03:57:24.381: INFO: Pod "downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1" satisfied condition "success or failure"
May 21 03:57:24.384: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1 container client-container: <nil>
STEP: delete the pod
May 21 03:57:24.406: INFO: Waiting for pod downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1 to disappear
May 21 03:57:24.409: INFO: Pod downwardapi-volume-4e000eec-14a4-4051-a103-5b6ffab0c6f1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:57:24.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3084" for this suite.
May 21 03:57:30.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:57:30.518: INFO: namespace projected-3084 deletion completed in 6.104130064s

• [SLOW TEST:10.199 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:57:30.518: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8dd97b25-c085-46d3-86b1-747a167548de
STEP: Creating a pod to test consume configMaps
May 21 03:57:30.635: INFO: Waiting up to 5m0s for pod "pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3" in namespace "configmap-1584" to be "success or failure"
May 21 03:57:30.638: INFO: Pod "pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.550168ms
May 21 03:57:32.641: INFO: Pod "pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006387066s
STEP: Saw pod success
May 21 03:57:32.642: INFO: Pod "pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3" satisfied condition "success or failure"
May 21 03:57:32.644: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:57:32.665: INFO: Waiting for pod pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3 to disappear
May 21 03:57:32.670: INFO: Pod pod-configmaps-8de6f84e-3a3e-466f-95cd-4b29103735a3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:57:32.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1584" for this suite.
May 21 03:57:38.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:57:38.771: INFO: namespace configmap-1584 deletion completed in 6.095953869s

• [SLOW TEST:8.253 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:57:38.771: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-1726c93d-c76f-485e-81e5-394a91b8a233
STEP: Creating a pod to test consume configMaps
May 21 03:57:38.825: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291" in namespace "configmap-3172" to be "success or failure"
May 21 03:57:38.831: INFO: Pod "pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291": Phase="Pending", Reason="", readiness=false. Elapsed: 6.75428ms
May 21 03:57:40.835: INFO: Pod "pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009880745s
May 21 03:57:42.838: INFO: Pod "pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013733409s
STEP: Saw pod success
May 21 03:57:42.839: INFO: Pod "pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291" satisfied condition "success or failure"
May 21 03:57:42.841: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 03:57:42.866: INFO: Waiting for pod pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291 to disappear
May 21 03:57:42.870: INFO: Pod pod-configmaps-3e3e6f7a-d4ad-4067-99bc-cdfa8a7c0291 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:57:42.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3172" for this suite.
May 21 03:57:48.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:57:48.978: INFO: namespace configmap-3172 deletion completed in 6.098871622s

• [SLOW TEST:10.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:57:48.978: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 03:57:49.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2310'
May 21 03:57:49.300: INFO: stderr: ""
May 21 03:57:49.300: INFO: stdout: "replicationcontroller/redis-master created\n"
May 21 03:57:49.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2310'
May 21 03:57:49.677: INFO: stderr: ""
May 21 03:57:49.677: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 03:57:50.687: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:57:50.687: INFO: Found 0 / 1
May 21 03:57:51.681: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:57:51.681: INFO: Found 1 / 1
May 21 03:57:51.681: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 03:57:51.684: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:57:51.684: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 03:57:51.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 describe pod redis-master-x9vmc --namespace=kubectl-2310'
May 21 03:57:51.894: INFO: stderr: ""
May 21 03:57:51.894: INFO: stdout: "Name:         redis-master-x9vmc\nNamespace:    kubectl-2310\nPriority:     0\nNode:         9990-w-ax-1-1/192.168.0.7\nStart Time:   Thu, 21 May 2020 03:57:49 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.240.3.161\nIPs:\n  IP:           10.240.3.161\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://77871319b4d84cedf882ce07e6dd6bc10413f627fcdca86d2b9145a14baf0b05\n    Image:          172.16.17.5/sonobuoy/redis:5.0.5-alpine\n    Image ID:       docker-pullable://172.16.17.5/sonobuoy/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 21 May 2020 03:57:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-2gksz (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-2gksz:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-2gksz\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                    Message\n  ----    ------     ----       ----                    -------\n  Normal  Scheduled  <unknown>  default-scheduler       Successfully assigned kubectl-2310/redis-master-x9vmc to 9990-w-ax-1-1\n  Normal  Pulled     1s         kubelet, 9990-w-ax-1-1  Container image \"172.16.17.5/sonobuoy/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, 9990-w-ax-1-1  Created container redis-master\n  Normal  Started    1s         kubelet, 9990-w-ax-1-1  Started container redis-master\n"
May 21 03:57:51.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 describe rc redis-master --namespace=kubectl-2310'
May 21 03:57:52.023: INFO: stderr: ""
May 21 03:57:52.023: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2310\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        172.16.17.5/sonobuoy/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-x9vmc\n"
May 21 03:57:52.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 describe service redis-master --namespace=kubectl-2310'
May 21 03:57:52.155: INFO: stderr: ""
May 21 03:57:52.155: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2310\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.108.221.47\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.240.3.161:6379\nSession Affinity:  None\nEvents:            <none>\n"
May 21 03:57:52.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 describe node 9990-m-5f-1-1'
May 21 03:57:52.301: INFO: stderr: ""
May 21 03:57:52.301: INFO: stdout: "Name:               9990-m-5f-1-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ram_type_2_4G_50G\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/zone=nova\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=9990-m-5f-1-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    topology.wangsucloud-csi-plugin/zone=nova\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 192.168.0.4\n                    csi.volume.kubernetes.io/nodeid: {\"wangsucloud-csi-plugin\":\"e663e052-3f7c-4288-af97-047175d6a80e\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ae:4a:ef:8f:5f:6a\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 192.168.0.4\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 21 May 2020 01:44:19 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 21 May 2020 03:57:50 +0000   Thu, 21 May 2020 01:44:14 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 21 May 2020 03:57:50 +0000   Thu, 21 May 2020 01:44:14 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 21 May 2020 03:57:50 +0000   Thu, 21 May 2020 01:44:14 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 21 May 2020 03:57:50 +0000   Thu, 21 May 2020 01:46:25 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.0.4\n  InternalIP:  172.16.24.173\n  Hostname:    9990-m-5f-1-1\nCapacity:\n cpu:                2\n ephemeral-storage:  49750Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3865040Ki\n pods:               110\nAllocatable:\n cpu:                1800m\n ephemeral-storage:  46949990323\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             3057840Ki\n pods:               110\nSystem Info:\n Machine ID:                 38e5eb64540b4c65856aaf78b833c670\n System UUID:                E663E052-3F7C-4288-AF97-047175D6A80E\n Boot ID:                    0a5b7b13-76d7-481a-b952-c5265ec90f5a\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.7\n Kubelet Version:            v1.16.9\n Kube-Proxy Version:         v1.16.9\nPodCIDR:                     10.240.2.0/24\nPodCIDRs:                    10.240.2.0/24\nProviderID:                  wangsu:///e663e052-3f7c-4288-af97-047175d6a80e\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-7889b66978-m2kgg                                   100m (5%)     0 (0%)      70Mi (2%)        170Mi (5%)     130m\n  kube-system                dns-autoscaler-5c9db77c6f-cv5k6                            20m (1%)      0 (0%)      10Mi (0%)        0 (0%)         130m\n  kube-system                kube-apiserver-9990-m-5f-1-1                               250m (13%)    0 (0%)      0 (0%)           0 (0%)         133m\n  kube-system                kube-controller-manager-9990-m-5f-1-1                      200m (11%)    0 (0%)      0 (0%)           0 (0%)         133m\n  kube-system                kube-flannel-gtqdq                                         150m (8%)     300m (16%)  64M (2%)         500M (15%)     131m\n  kube-system                kube-proxy-master-wblhq                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         133m\n  kube-system                kube-scheduler-9990-m-5f-1-1                               100m (5%)     0 (0%)      0 (0%)           0 (0%)         133m\n  kube-system                metrics-server-d9449d98f-hwktm                             5m (0%)       100m (5%)   50Mi (1%)        300Mi (10%)    130m\n  kube-system                nodelocaldns-mg4pf                                         100m (5%)     0 (0%)      70Mi (2%)        170Mi (5%)     130m\n  kube-system                wangsucloud-csi-nodeplugin-c2hjj                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         130m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-496fp    0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                925m (51%)     400m (22%)\n  memory             267300Ki (8%)  1171088640 (37%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
May 21 03:57:52.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 describe namespace kubectl-2310'
May 21 03:57:52.486: INFO: stderr: ""
May 21 03:57:52.486: INFO: stdout: "Name:         kubectl-2310\nLabels:       e2e-framework=kubectl\n              e2e-run=eab6f487-5bb5-43fd-9514-9c30ecd0ca7d\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:57:52.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2310" for this suite.
May 21 03:58:20.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:58:20.596: INFO: namespace kubectl-2310 deletion completed in 28.10394561s

• [SLOW TEST:31.618 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:58:20.597: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 03:58:21.582: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 03:58:23.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630301, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630301, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630301, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630301, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 03:58:26.614: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:58:26.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1297" for this suite.
May 21 03:58:32.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:58:32.840: INFO: namespace webhook-1297 deletion completed in 6.131593762s
STEP: Destroying namespace "webhook-1297-markers" for this suite.
May 21 03:58:38.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:58:39.058: INFO: namespace webhook-1297-markers deletion completed in 6.218534422s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.477 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:58:39.074: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
May 21 03:59:19.170: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:59:19.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0521 03:59:19.170588      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9871" for this suite.
May 21 03:59:25.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:59:25.317: INFO: namespace gc-9871 deletion completed in 6.142529612s

• [SLOW TEST:46.242 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:59:25.318: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
May 21 03:59:25.412: INFO: namespace kubectl-4339
May 21 03:59:25.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-4339'
May 21 03:59:25.807: INFO: stderr: ""
May 21 03:59:25.807: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
May 21 03:59:26.814: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:59:26.814: INFO: Found 0 / 1
May 21 03:59:27.811: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:59:27.811: INFO: Found 1 / 1
May 21 03:59:27.811: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May 21 03:59:27.814: INFO: Selector matched 1 pods for map[app:redis]
May 21 03:59:27.814: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May 21 03:59:27.814: INFO: wait on redis-master startup in kubectl-4339 
May 21 03:59:27.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 logs redis-master-9m9g5 redis-master --namespace=kubectl-4339'
May 21 03:59:27.954: INFO: stderr: ""
May 21 03:59:27.954: INFO: stdout: "1:C 21 May 2020 03:59:26.941 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 21 May 2020 03:59:26.941 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 21 May 2020 03:59:26.941 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 21 May 2020 03:59:26.943 * Running mode=standalone, port=6379.\n1:M 21 May 2020 03:59:26.943 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 May 2020 03:59:26.943 # Server initialized\n1:M 21 May 2020 03:59:26.943 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 May 2020 03:59:26.943 * Ready to accept connections\n"
STEP: exposing RC
May 21 03:59:27.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4339'
May 21 03:59:28.089: INFO: stderr: ""
May 21 03:59:28.089: INFO: stdout: "service/rm2 exposed\n"
May 21 03:59:28.093: INFO: Service rm2 in namespace kubectl-4339 found.
STEP: exposing service
May 21 03:59:30.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4339'
May 21 03:59:30.247: INFO: stderr: ""
May 21 03:59:30.247: INFO: stdout: "service/rm3 exposed\n"
May 21 03:59:30.257: INFO: Service rm3 in namespace kubectl-4339 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:59:32.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4339" for this suite.
May 21 03:59:44.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:59:44.370: INFO: namespace kubectl-4339 deletion completed in 12.102533693s

• [SLOW TEST:19.053 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:59:44.371: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
May 21 03:59:44.456: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-3089'
May 21 03:59:44.996: INFO: stderr: ""
May 21 03:59:44.996: INFO: stdout: "pod/pause created\n"
May 21 03:59:44.996: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May 21 03:59:44.996: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3089" to be "running and ready"
May 21 03:59:45.000: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 3.908309ms
May 21 03:59:47.003: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007462339s
May 21 03:59:49.007: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.010860102s
May 21 03:59:49.007: INFO: Pod "pause" satisfied condition "running and ready"
May 21 03:59:49.007: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
May 21 03:59:49.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 label pods pause testing-label=testing-label-value --namespace=kubectl-3089'
May 21 03:59:49.137: INFO: stderr: ""
May 21 03:59:49.137: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May 21 03:59:49.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pod pause -L testing-label --namespace=kubectl-3089'
May 21 03:59:49.262: INFO: stderr: ""
May 21 03:59:49.262: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May 21 03:59:49.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 label pods pause testing-label- --namespace=kubectl-3089'
May 21 03:59:49.398: INFO: stderr: ""
May 21 03:59:49.398: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May 21 03:59:49.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pod pause -L testing-label --namespace=kubectl-3089'
May 21 03:59:49.529: INFO: stderr: ""
May 21 03:59:49.529: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
May 21 03:59:49.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-3089'
May 21 03:59:49.665: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 03:59:49.665: INFO: stdout: "pod \"pause\" force deleted\n"
May 21 03:59:49.665: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get rc,svc -l name=pause --no-headers --namespace=kubectl-3089'
May 21 03:59:49.890: INFO: stderr: "No resources found in kubectl-3089 namespace.\n"
May 21 03:59:49.890: INFO: stdout: ""
May 21 03:59:49.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -l name=pause --namespace=kubectl-3089 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 03:59:50.014: INFO: stderr: ""
May 21 03:59:50.015: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 03:59:50.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3089" for this suite.
May 21 03:59:56.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 03:59:56.132: INFO: namespace kubectl-3089 deletion completed in 6.100517252s

• [SLOW TEST:11.761 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 03:59:56.133: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7f7ba3b7-251b-43eb-b406-bce4d02cec88
STEP: Creating a pod to test consume configMaps
May 21 03:59:56.186: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d" in namespace "projected-7805" to be "success or failure"
May 21 03:59:56.189: INFO: Pod "pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110935ms
May 21 03:59:58.192: INFO: Pod "pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005495184s
May 21 04:00:00.196: INFO: Pod "pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009550414s
STEP: Saw pod success
May 21 04:00:00.196: INFO: Pod "pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d" satisfied condition "success or failure"
May 21 04:00:00.199: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 04:00:00.234: INFO: Waiting for pod pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d to disappear
May 21 04:00:00.236: INFO: Pod pod-projected-configmaps-8f3cd01b-1554-4a68-a18f-f238e2f26f0d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:00:00.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7805" for this suite.
May 21 04:00:06.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:00:06.323: INFO: namespace projected-7805 deletion completed in 6.080866773s

• [SLOW TEST:10.190 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:00:06.323: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
May 21 04:00:06.358: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:00:30.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7632" for this suite.
May 21 04:00:37.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:00:37.103: INFO: namespace crd-publish-openapi-7632 deletion completed in 6.115079495s

• [SLOW TEST:30.780 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:00:37.103: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May 21 04:00:37.654: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
May 21 04:00:39.664: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630437, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630437, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630437, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630437, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-54b5599975\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:00:42.698: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:00:42.701: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:00:49.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8367" for this suite.
May 21 04:00:55.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:00:55.162: INFO: namespace crd-webhook-8367 deletion completed in 6.149079301s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:18.083 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:00:55.187: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:00:55.240: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-f89493b5-6455-4fc3-bfc5-4a4e15b603d8" in namespace "security-context-test-1331" to be "success or failure"
May 21 04:00:55.249: INFO: Pod "alpine-nnp-false-f89493b5-6455-4fc3-bfc5-4a4e15b603d8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.160718ms
May 21 04:00:57.253: INFO: Pod "alpine-nnp-false-f89493b5-6455-4fc3-bfc5-4a4e15b603d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01316384s
May 21 04:00:57.253: INFO: Pod "alpine-nnp-false-f89493b5-6455-4fc3-bfc5-4a4e15b603d8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:00:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1331" for this suite.
May 21 04:01:03.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:03.364: INFO: namespace security-context-test-1331 deletion completed in 6.091846075s

• [SLOW TEST:8.177 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:03.365: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 04:01:03.415: INFO: Waiting up to 5m0s for pod "downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566" in namespace "downward-api-9112" to be "success or failure"
May 21 04:01:03.418: INFO: Pod "downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566": Phase="Pending", Reason="", readiness=false. Elapsed: 2.520648ms
May 21 04:01:05.422: INFO: Pod "downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006783084s
STEP: Saw pod success
May 21 04:01:05.422: INFO: Pod "downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566" satisfied condition "success or failure"
May 21 04:01:05.424: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566 container client-container: <nil>
STEP: delete the pod
May 21 04:01:05.445: INFO: Waiting for pod downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566 to disappear
May 21 04:01:05.448: INFO: Pod downwardapi-volume-51f099f6-5a9e-4c8f-acc9-df7657c9e566 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:05.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9112" for this suite.
May 21 04:01:11.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:11.542: INFO: namespace downward-api-9112 deletion completed in 6.088934129s

• [SLOW TEST:8.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:11.542: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May 21 04:01:11.604: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1740 /api/v1/namespaces/watch-1740/configmaps/e2e-watch-test-watch-closed 0f450fce-ee29-43d2-987d-7bea6e366d15 42273 0 2020-05-21 04:01:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 04:01:11.604: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1740 /api/v1/namespaces/watch-1740/configmaps/e2e-watch-test-watch-closed 0f450fce-ee29-43d2-987d-7bea6e366d15 42274 0 2020-05-21 04:01:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May 21 04:01:11.620: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1740 /api/v1/namespaces/watch-1740/configmaps/e2e-watch-test-watch-closed 0f450fce-ee29-43d2-987d-7bea6e366d15 42275 0 2020-05-21 04:01:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 04:01:11.621: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1740 /api/v1/namespaces/watch-1740/configmaps/e2e-watch-test-watch-closed 0f450fce-ee29-43d2-987d-7bea6e366d15 42277 0 2020-05-21 04:01:11 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:11.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1740" for this suite.
May 21 04:01:17.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:17.719: INFO: namespace watch-1740 deletion completed in 6.093386247s

• [SLOW TEST:6.176 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
May 21 04:01:17.764: INFO: Waiting up to 5m0s for pod "pod-48af0a9a-01aa-484a-91b0-d68930859251" in namespace "emptydir-4026" to be "success or failure"
May 21 04:01:17.768: INFO: Pod "pod-48af0a9a-01aa-484a-91b0-d68930859251": Phase="Pending", Reason="", readiness=false. Elapsed: 4.728409ms
May 21 04:01:19.775: INFO: Pod "pod-48af0a9a-01aa-484a-91b0-d68930859251": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011592244s
May 21 04:01:21.779: INFO: Pod "pod-48af0a9a-01aa-484a-91b0-d68930859251": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015235591s
STEP: Saw pod success
May 21 04:01:21.779: INFO: Pod "pod-48af0a9a-01aa-484a-91b0-d68930859251" satisfied condition "success or failure"
May 21 04:01:21.781: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-48af0a9a-01aa-484a-91b0-d68930859251 container test-container: <nil>
STEP: delete the pod
May 21 04:01:21.811: INFO: Waiting for pod pod-48af0a9a-01aa-484a-91b0-d68930859251 to disappear
May 21 04:01:21.816: INFO: Pod pod-48af0a9a-01aa-484a-91b0-d68930859251 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:21.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4026" for this suite.
May 21 04:01:27.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:27.915: INFO: namespace emptydir-4026 deletion completed in 6.094574263s

• [SLOW TEST:10.196 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:27.915: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 04:01:27.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956" in namespace "projected-707" to be "success or failure"
May 21 04:01:27.966: INFO: Pod "downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956": Phase="Pending", Reason="", readiness=false. Elapsed: 2.51696ms
May 21 04:01:29.969: INFO: Pod "downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005944356s
STEP: Saw pod success
May 21 04:01:29.969: INFO: Pod "downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956" satisfied condition "success or failure"
May 21 04:01:29.972: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956 container client-container: <nil>
STEP: delete the pod
May 21 04:01:29.992: INFO: Waiting for pod downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956 to disappear
May 21 04:01:29.994: INFO: Pod downwardapi-volume-8788b8ea-3a7f-463e-9fb3-e0e306f6c956 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:29.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-707" for this suite.
May 21 04:01:36.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:36.092: INFO: namespace projected-707 deletion completed in 6.091070415s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:36.092: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3587.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3587.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 04:01:40.186: INFO: DNS probes using dns-3587/dns-test-c7bebfaf-fd3b-48e6-89f5-bc819946ddb0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:40.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3587" for this suite.
May 21 04:01:46.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:01:46.369: INFO: namespace dns-3587 deletion completed in 6.098131328s

• [SLOW TEST:10.277 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:01:46.369: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:01:46.405: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:01:48.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9386" for this suite.
May 21 04:02:32.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:02:32.714: INFO: namespace pods-9386 deletion completed in 44.106247198s

• [SLOW TEST:46.345 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:02:32.715: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7884.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7884.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7884.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7884.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 171.19.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.19.171_udp@PTR;check="$$(dig +tcp +noall +answer +search 171.19.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.19.171_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7884.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7884.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7884.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7884.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7884.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7884.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 171.19.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.19.171_udp@PTR;check="$$(dig +tcp +noall +answer +search 171.19.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.19.171_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 04:02:36.829: INFO: Unable to read wheezy_udp@dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.831: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.834: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.842: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.862: INFO: Unable to read jessie_udp@dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.865: INFO: Unable to read jessie_tcp@dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.867: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.874: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local from pod dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027: the server could not find the requested resource (get pods dns-test-8759a041-4dfc-4738-8302-8a52a5da2027)
May 21 04:02:36.893: INFO: Lookups using dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027 failed for: [wheezy_udp@dns-test-service.dns-7884.svc.cluster.local wheezy_tcp@dns-test-service.dns-7884.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local jessie_udp@dns-test-service.dns-7884.svc.cluster.local jessie_tcp@dns-test-service.dns-7884.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7884.svc.cluster.local]

May 21 04:02:41.955: INFO: DNS probes using dns-7884/dns-test-8759a041-4dfc-4738-8302-8a52a5da2027 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:02:42.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7884" for this suite.
May 21 04:02:48.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:02:48.235: INFO: namespace dns-7884 deletion completed in 6.107307001s

• [SLOW TEST:15.520 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:02:48.235: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
May 21 04:02:48.267: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

May 21 04:02:48.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:48.938: INFO: stderr: ""
May 21 04:02:48.938: INFO: stdout: "service/redis-slave created\n"
May 21 04:02:48.938: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

May 21 04:02:48.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:49.261: INFO: stderr: ""
May 21 04:02:49.261: INFO: stdout: "service/redis-master created\n"
May 21 04:02:49.262: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May 21 04:02:49.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:49.609: INFO: stderr: ""
May 21 04:02:49.609: INFO: stdout: "service/frontend created\n"
May 21 04:02:49.610: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: 172.16.17.5/sonobuoy/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

May 21 04:02:49.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:49.970: INFO: stderr: ""
May 21 04:02:49.970: INFO: stdout: "deployment.apps/frontend created\n"
May 21 04:02:49.970: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: 172.16.17.5/sonobuoy/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May 21 04:02:49.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:50.333: INFO: stderr: ""
May 21 04:02:50.333: INFO: stdout: "deployment.apps/redis-master created\n"
May 21 04:02:50.334: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: 172.16.17.5/sonobuoy/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

May 21 04:02:50.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-2061'
May 21 04:02:50.728: INFO: stderr: ""
May 21 04:02:50.728: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
May 21 04:02:50.728: INFO: Waiting for all frontend pods to be Running.
May 21 04:02:55.778: INFO: Waiting for frontend to serve content.
May 21 04:02:55.798: INFO: Trying to add a new entry to the guestbook.
May 21 04:02:55.814: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
May 21 04:02:55.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:55.984: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:55.984: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
May 21 04:02:55.984: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:56.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:56.210: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 04:02:56.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:56.374: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:56.375: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 04:02:56.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:56.538: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:56.538: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May 21 04:02:56.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:56.683: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:56.683: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
May 21 04:02:56.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-2061'
May 21 04:02:56.829: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:02:56.829: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:02:56.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2061" for this suite.
May 21 04:03:24.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:03:24.961: INFO: namespace kubectl-2061 deletion completed in 28.106550908s

• [SLOW TEST:36.726 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:03:24.961: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May 21 04:03:25.034: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2612 /api/v1/namespaces/watch-2612/configmaps/e2e-watch-test-resource-version e82ccf56-6569-470f-9425-24a731f78add 43166 0 2020-05-21 04:03:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 04:03:25.034: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2612 /api/v1/namespaces/watch-2612/configmaps/e2e-watch-test-resource-version e82ccf56-6569-470f-9425-24a731f78add 43167 0 2020-05-21 04:03:25 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:03:25.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2612" for this suite.
May 21 04:03:31.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:03:31.152: INFO: namespace watch-2612 deletion completed in 6.112596546s

• [SLOW TEST:6.190 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:03:31.152: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-03ad76fa-b7b8-488c-992b-aa8ba2355455
STEP: Creating a pod to test consume configMaps
May 21 04:03:31.218: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271" in namespace "projected-34" to be "success or failure"
May 21 04:03:31.224: INFO: Pod "pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271": Phase="Pending", Reason="", readiness=false. Elapsed: 5.087194ms
May 21 04:03:33.229: INFO: Pod "pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010387811s
May 21 04:03:35.233: INFO: Pod "pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014802874s
STEP: Saw pod success
May 21 04:03:35.233: INFO: Pod "pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271" satisfied condition "success or failure"
May 21 04:03:35.236: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May 21 04:03:35.280: INFO: Waiting for pod pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271 to disappear
May 21 04:03:35.283: INFO: Pod pod-projected-configmaps-1f22eda6-dcc3-4d5d-b384-87e46bbb7271 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:03:35.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-34" for this suite.
May 21 04:03:41.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:03:41.393: INFO: namespace projected-34 deletion completed in 6.104072719s

• [SLOW TEST:10.241 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:03:41.394: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:03:41.983: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
May 21 04:03:43.992: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630622, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630622, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630622, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630621, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:03:47.020: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:03:47.024: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4123-crds.webhook.example.com via the AdmissionRegistration API
May 21 04:03:52.585: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:03:53.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-381" for this suite.
May 21 04:03:59.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:03:59.701: INFO: namespace webhook-381 deletion completed in 6.088467063s
STEP: Destroying namespace "webhook-381-markers" for this suite.
May 21 04:04:05.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:05.797: INFO: namespace webhook-381-markers deletion completed in 6.096059332s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.418 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:05.812: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May 21 04:04:08.387: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf"
May 21 04:04:08.387: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf" in namespace "pods-8492" to be "terminated due to deadline exceeded"
May 21 04:04:08.389: INFO: Pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.295086ms
May 21 04:04:10.393: INFO: Pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.006612662s
May 21 04:04:12.398: INFO: Pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.011110789s
May 21 04:04:12.398: INFO: Pod "pod-update-activedeadlineseconds-0f0df1d9-473c-45c0-9da2-8fc3d3c538cf" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:12.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8492" for this suite.
May 21 04:04:18.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:18.497: INFO: namespace pods-8492 deletion completed in 6.094737258s

• [SLOW TEST:12.685 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:18.497: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
May 21 04:04:22.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec pod-sharedvolume-7909a274-29fa-4f5c-9e83-70eb854f332f -c busybox-main-container --namespace=emptydir-8342 -- cat /usr/share/volumeshare/shareddata.txt'
May 21 04:04:22.884: INFO: stderr: ""
May 21 04:04:22.884: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:22.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8342" for this suite.
May 21 04:04:28.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:29.010: INFO: namespace emptydir-8342 deletion completed in 6.113940148s

• [SLOW TEST:10.513 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:29.010: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-51e6fee2-a0fe-426a-a759-981a3f223716
STEP: Creating a pod to test consume secrets
May 21 04:04:29.074: INFO: Waiting up to 5m0s for pod "pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d" in namespace "secrets-4280" to be "success or failure"
May 21 04:04:29.080: INFO: Pod "pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.440985ms
May 21 04:04:31.085: INFO: Pod "pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011426806s
May 21 04:04:33.094: INFO: Pod "pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020429478s
STEP: Saw pod success
May 21 04:04:33.094: INFO: Pod "pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d" satisfied condition "success or failure"
May 21 04:04:33.097: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d container secret-volume-test: <nil>
STEP: delete the pod
May 21 04:04:33.125: INFO: Waiting for pod pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d to disappear
May 21 04:04:33.128: INFO: Pod pod-secrets-6ad5b736-f1eb-4b1e-9f3c-883860297f2d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:33.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4280" for this suite.
May 21 04:04:39.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:39.228: INFO: namespace secrets-4280 deletion completed in 6.095820054s

• [SLOW TEST:10.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:39.228: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
May 21 04:04:39.279: INFO: Waiting up to 5m0s for pod "pod-507fe588-14eb-46cc-b2a2-01835e6e7623" in namespace "emptydir-8813" to be "success or failure"
May 21 04:04:39.281: INFO: Pod "pod-507fe588-14eb-46cc-b2a2-01835e6e7623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.455642ms
May 21 04:04:41.285: INFO: Pod "pod-507fe588-14eb-46cc-b2a2-01835e6e7623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006429329s
May 21 04:04:43.291: INFO: Pod "pod-507fe588-14eb-46cc-b2a2-01835e6e7623": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012695798s
STEP: Saw pod success
May 21 04:04:43.292: INFO: Pod "pod-507fe588-14eb-46cc-b2a2-01835e6e7623" satisfied condition "success or failure"
May 21 04:04:43.294: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-507fe588-14eb-46cc-b2a2-01835e6e7623 container test-container: <nil>
STEP: delete the pod
May 21 04:04:43.320: INFO: Waiting for pod pod-507fe588-14eb-46cc-b2a2-01835e6e7623 to disappear
May 21 04:04:43.322: INFO: Pod pod-507fe588-14eb-46cc-b2a2-01835e6e7623 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:43.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8813" for this suite.
May 21 04:04:49.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:49.417: INFO: namespace emptydir-8813 deletion completed in 6.088874004s

• [SLOW TEST:10.188 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:49.417: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:49.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6247" for this suite.
May 21 04:04:55.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:04:55.598: INFO: namespace kubelet-test-6247 deletion completed in 6.099733061s

• [SLOW TEST:6.181 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:04:55.598: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:04:57.681: INFO: Waiting up to 5m0s for pod "client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a" in namespace "pods-8029" to be "success or failure"
May 21 04:04:57.685: INFO: Pod "client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.252527ms
May 21 04:04:59.688: INFO: Pod "client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007676642s
STEP: Saw pod success
May 21 04:04:59.689: INFO: Pod "client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a" satisfied condition "success or failure"
May 21 04:04:59.692: INFO: Trying to get logs from node 9990-w-ax-1-2 pod client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a container env3cont: <nil>
STEP: delete the pod
May 21 04:04:59.710: INFO: Waiting for pod client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a to disappear
May 21 04:04:59.715: INFO: Pod client-envvars-5829b613-4d1b-412f-90e2-9117e418d47a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:04:59.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8029" for this suite.
May 21 04:05:11.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:05:11.889: INFO: namespace pods-8029 deletion completed in 12.16861654s

• [SLOW TEST:16.290 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:05:11.889: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:05:12.905: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 04:05:14.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630712, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630712, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630712, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630712, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:05:17.940: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:05:17.944: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1160-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:05:24.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5374" for this suite.
May 21 04:05:30.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:05:30.191: INFO: namespace webhook-5374 deletion completed in 6.097866401s
STEP: Destroying namespace "webhook-5374-markers" for this suite.
May 21 04:05:36.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:05:36.274: INFO: namespace webhook-5374-markers deletion completed in 6.082505959s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.399 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:05:36.288: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:05:44.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9671" for this suite.
May 21 04:05:50.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:05:50.435: INFO: namespace job-9671 deletion completed in 6.088264346s

• [SLOW TEST:14.147 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:05:50.436: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
May 21 04:05:50.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 create -f - --namespace=kubectl-89'
May 21 04:05:50.941: INFO: stderr: ""
May 21 04:05:50.941: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May 21 04:05:50.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-89'
May 21 04:05:51.124: INFO: stderr: ""
May 21 04:05:51.124: INFO: stdout: "update-demo-nautilus-4thrn update-demo-nautilus-kb8pc "
May 21 04:05:51.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-4thrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-89'
May 21 04:05:51.346: INFO: stderr: ""
May 21 04:05:51.346: INFO: stdout: ""
May 21 04:05:51.346: INFO: update-demo-nautilus-4thrn is created but not running
May 21 04:05:56.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-89'
May 21 04:05:56.456: INFO: stderr: ""
May 21 04:05:56.456: INFO: stdout: "update-demo-nautilus-4thrn update-demo-nautilus-kb8pc "
May 21 04:05:56.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-4thrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-89'
May 21 04:05:56.625: INFO: stderr: ""
May 21 04:05:56.626: INFO: stdout: "true"
May 21 04:05:56.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-4thrn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-89'
May 21 04:05:56.750: INFO: stderr: ""
May 21 04:05:56.750: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 04:05:56.750: INFO: validating pod update-demo-nautilus-4thrn
May 21 04:05:56.757: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 04:05:56.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 04:05:56.757: INFO: update-demo-nautilus-4thrn is verified up and running
May 21 04:05:56.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-kb8pc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-89'
May 21 04:05:56.888: INFO: stderr: ""
May 21 04:05:56.889: INFO: stdout: "true"
May 21 04:05:56.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods update-demo-nautilus-kb8pc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-89'
May 21 04:05:56.994: INFO: stderr: ""
May 21 04:05:56.994: INFO: stdout: "172.16.17.5/sonobuoy/nautilus:1.0"
May 21 04:05:56.994: INFO: validating pod update-demo-nautilus-kb8pc
May 21 04:05:56.998: INFO: got data: {
  "image": "nautilus.jpg"
}

May 21 04:05:56.998: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May 21 04:05:56.998: INFO: update-demo-nautilus-kb8pc is verified up and running
STEP: using delete to clean up resources
May 21 04:05:56.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete --grace-period=0 --force -f - --namespace=kubectl-89'
May 21 04:05:57.113: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May 21 04:05:57.113: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May 21 04:05:57.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-89'
May 21 04:05:57.278: INFO: stderr: "No resources found in kubectl-89 namespace.\n"
May 21 04:05:57.278: INFO: stdout: ""
May 21 04:05:57.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -l name=update-demo --namespace=kubectl-89 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May 21 04:05:57.386: INFO: stderr: ""
May 21 04:05:57.386: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:05:57.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-89" for this suite.
May 21 04:06:09.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:06:09.486: INFO: namespace kubectl-89 deletion completed in 12.090541119s

• [SLOW TEST:19.050 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:06:09.486: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May 21 04:06:09.555: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44314 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May 21 04:06:09.555: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44315 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May 21 04:06:09.555: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44317 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May 21 04:06:19.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44356 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May 21 04:06:19.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44357 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May 21 04:06:19.592: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-916 /api/v1/namespaces/watch-916/configmaps/e2e-watch-test-label-changed 2b020be1-6d55-4445-a609-36ce9945f64f 44358 0 2020-05-21 04:06:09 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:06:19.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-916" for this suite.
May 21 04:06:25.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:06:25.708: INFO: namespace watch-916 deletion completed in 6.111689998s

• [SLOW TEST:16.222 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:06:25.709: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May 21 04:06:25.757: INFO: Pod name pod-release: Found 0 pods out of 1
May 21 04:06:30.761: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:06:31.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3666" for this suite.
May 21 04:06:37.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:06:37.890: INFO: namespace replication-controller-3666 deletion completed in 6.100216539s

• [SLOW TEST:12.181 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:06:37.890: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2448
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2448
STEP: creating replication controller externalsvc in namespace services-2448
I0521 04:06:38.161418      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2448, replica count: 2
I0521 04:06:41.213258      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
May 21 04:06:41.234: INFO: Creating new exec pod
May 21 04:06:43.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 exec --namespace=services-2448 execpodw4pjg -- /bin/sh -x -c nslookup clusterip-service'
May 21 04:06:43.587: INFO: stderr: "+ nslookup clusterip-service\n"
May 21 04:06:43.587: INFO: stdout: "Server:\t\t169.254.25.10\nAddress:\t169.254.25.10#53\n\nclusterip-service.services-2448.svc.cluster.local\tcanonical name = externalsvc.services-2448.svc.cluster.local.\nName:\texternalsvc.services-2448.svc.cluster.local\nAddress: 10.108.206.104\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2448, will wait for the garbage collector to delete the pods
May 21 04:06:43.652: INFO: Deleting ReplicationController externalsvc took: 9.959786ms
May 21 04:06:43.952: INFO: Terminating ReplicationController externalsvc pods took: 300.277388ms
May 21 04:06:48.391: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:06:48.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2448" for this suite.
May 21 04:06:54.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:06:54.509: INFO: namespace services-2448 deletion completed in 6.083366626s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.619 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:06:54.509: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:06:54.553: INFO: Pod name rollover-pod: Found 0 pods out of 1
May 21 04:06:59.557: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 04:06:59.557: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May 21 04:07:01.562: INFO: Creating deployment "test-rollover-deployment"
May 21 04:07:01.571: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May 21 04:07:03.582: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May 21 04:07:03.588: INFO: Ensure that both replica sets have 1 created replica
May 21 04:07:03.592: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May 21 04:07:03.601: INFO: Updating deployment test-rollover-deployment
May 21 04:07:03.601: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May 21 04:07:05.611: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May 21 04:07:05.618: INFO: Make sure deployment "test-rollover-deployment" is complete
May 21 04:07:05.622: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:05.622: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630823, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:07.629: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:07.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:09.629: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:09.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:11.629: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:11.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:13.629: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:13.629: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:15.630: INFO: all replica sets need to contain the pod-template-hash label
May 21 04:07:15.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725630821, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-56b986dbbd\" is progressing."}}, CollisionCount:(*int32)(nil)}
May 21 04:07:17.633: INFO: 
May 21 04:07:17.635: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
May 21 04:07:17.642: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1208 /apis/apps/v1/namespaces/deployment-1208/deployments/test-rollover-deployment 40bb0ece-a0b9-4d72-ad23-25d388bd8cf8 44797 2 2020-05-21 04:07:01 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003934cf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-21 04:07:01 +0000 UTC,LastTransitionTime:2020-05-21 04:07:01 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-56b986dbbd" has successfully progressed.,LastUpdateTime:2020-05-21 04:07:15 +0000 UTC,LastTransitionTime:2020-05-21 04:07:01 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 21 04:07:17.647: INFO: New ReplicaSet "test-rollover-deployment-56b986dbbd" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-56b986dbbd  deployment-1208 /apis/apps/v1/namespaces/deployment-1208/replicasets/test-rollover-deployment-56b986dbbd 35df4743-e156-42f0-a06b-13509a94cfe1 44785 2 2020-05-21 04:07:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:56b986dbbd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 40bb0ece-a0b9-4d72-ad23-25d388bd8cf8 0xc003ab0c17 0xc003ab0c18}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 56b986dbbd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:56b986dbbd] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003ab0c78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 21 04:07:17.647: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May 21 04:07:17.648: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1208 /apis/apps/v1/namespaces/deployment-1208/replicasets/test-rollover-controller c2cf950f-aa9b-464d-9bff-435646afab5d 44796 2 2020-05-21 04:06:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 40bb0ece-a0b9-4d72-ad23-25d388bd8cf8 0xc003ab0b47 0xc003ab0b48}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003ab0ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 04:07:17.648: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-1208 /apis/apps/v1/namespaces/deployment-1208/replicasets/test-rollover-deployment-f6c94f66c 0ae71e05-cd7b-447d-ba09-904c605a9250 44730 2 2020-05-21 04:07:01 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 40bb0ece-a0b9-4d72-ad23-25d388bd8cf8 0xc003ab0ce0 0xc003ab0ce1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003ab0d58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 04:07:17.651: INFO: Pod "test-rollover-deployment-56b986dbbd-99988" is available:
&Pod{ObjectMeta:{test-rollover-deployment-56b986dbbd-99988 test-rollover-deployment-56b986dbbd- deployment-1208 /api/v1/namespaces/deployment-1208/pods/test-rollover-deployment-56b986dbbd-99988 9702a275-ce8d-42d1-9e74-420831628ab4 44745 0 2020-05-21 04:07:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:56b986dbbd] map[] [{apps/v1 ReplicaSet test-rollover-deployment-56b986dbbd 35df4743-e156-42f0-a06b-13509a94cfe1 0xc0039350e7 0xc0039350e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jdc6f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jdc6f,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.16.17.5/sonobuoy/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jdc6f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:07:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:07:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:07:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:07:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.188,StartTime:2020-05-21 04:07:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 04:07:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/redis:5.0.5-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://109e62d67584d06ba20088555d48e943004c21868c78928219b7776d925894bc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.188,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:07:17.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1208" for this suite.
May 21 04:07:23.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:07:23.739: INFO: namespace deployment-1208 deletion completed in 6.082324672s

• [SLOW TEST:29.229 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:07:23.739: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 21 04:07:26.816: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:07:26.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-309" for this suite.
May 21 04:07:32.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:07:32.937: INFO: namespace container-runtime-309 deletion completed in 6.09870797s

• [SLOW TEST:9.197 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:07:32.937: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-f2b4786d-ac73-472e-96d7-7edbc3d96c1a
STEP: Creating configMap with name cm-test-opt-upd-64512cc0-6fae-462d-b880-d9209b1d01dd
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f2b4786d-ac73-472e-96d7-7edbc3d96c1a
STEP: Updating configmap cm-test-opt-upd-64512cc0-6fae-462d-b880-d9209b1d01dd
STEP: Creating configMap with name cm-test-opt-create-79fcdc70-7ff3-4283-883d-3139cac735c2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:07:37.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4910" for this suite.
May 21 04:07:49.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:07:49.173: INFO: namespace configmap-4910 deletion completed in 12.084995541s

• [SLOW TEST:16.236 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:07:49.173: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-wchp
STEP: Creating a pod to test atomic-volume-subpath
May 21 04:07:49.233: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-wchp" in namespace "subpath-1299" to be "success or failure"
May 21 04:07:49.236: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.919905ms
May 21 04:07:51.240: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 2.006200956s
May 21 04:07:53.244: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 4.010723627s
May 21 04:07:55.253: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 6.019489015s
May 21 04:07:57.260: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 8.026182001s
May 21 04:07:59.267: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 10.03392126s
May 21 04:08:01.271: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 12.038097967s
May 21 04:08:03.275: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 14.042012861s
May 21 04:08:05.281: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 16.047476736s
May 21 04:08:07.285: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 18.051457551s
May 21 04:08:09.290: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Running", Reason="", readiness=true. Elapsed: 20.057046565s
May 21 04:08:11.294: INFO: Pod "pod-subpath-test-configmap-wchp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.060582684s
STEP: Saw pod success
May 21 04:08:11.294: INFO: Pod "pod-subpath-test-configmap-wchp" satisfied condition "success or failure"
May 21 04:08:11.297: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-subpath-test-configmap-wchp container test-container-subpath-configmap-wchp: <nil>
STEP: delete the pod
May 21 04:08:11.318: INFO: Waiting for pod pod-subpath-test-configmap-wchp to disappear
May 21 04:08:11.321: INFO: Pod pod-subpath-test-configmap-wchp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-wchp
May 21 04:08:11.321: INFO: Deleting pod "pod-subpath-test-configmap-wchp" in namespace "subpath-1299"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:08:11.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1299" for this suite.
May 21 04:08:17.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:08:17.416: INFO: namespace subpath-1299 deletion completed in 6.08787071s

• [SLOW TEST:28.242 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:08:17.416: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 04:08:17.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-pod --generator=run-pod/v1 --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3592'
May 21 04:08:17.585: INFO: stderr: ""
May 21 04:08:17.585: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
May 21 04:08:22.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pod e2e-test-httpd-pod --namespace=kubectl-3592 -o json'
May 21 04:08:22.812: INFO: stderr: ""
May 21 04:08:22.812: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-05-21T04:08:17Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3592\",\n        \"resourceVersion\": \"45179\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3592/pods/e2e-test-httpd-pod\",\n        \"uid\": \"77af6a16-d058-49f1-b2c2-e760b8d561a4\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"172.16.17.5/sonobuoy/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-5h8tp\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"9990-w-ax-1-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-5h8tp\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-5h8tp\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-21T04:08:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-21T04:08:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-21T04:08:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-21T04:08:17Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://2db31103bd5ef244e043adc0916abb9c60a70837f9b70b3afa1e303efd2568a6\",\n                \"image\": \"172.16.17.5/sonobuoy/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-05-21T04:08:19Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.0.7\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.240.3.190\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.240.3.190\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-05-21T04:08:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
May 21 04:08:22.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 replace -f - --namespace=kubectl-3592'
May 21 04:08:23.143: INFO: stderr: ""
May 21 04:08:23.143: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image 172.16.17.5/sonobuoy/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
May 21 04:08:23.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete pods e2e-test-httpd-pod --namespace=kubectl-3592'
May 21 04:08:26.153: INFO: stderr: ""
May 21 04:08:26.153: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:08:26.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3592" for this suite.
May 21 04:08:32.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:08:32.266: INFO: namespace kubectl-3592 deletion completed in 6.107607357s

• [SLOW TEST:14.851 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:08:32.267: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:08:36.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5740" for this suite.
May 21 04:08:44.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:08:44.449: INFO: namespace containers-5740 deletion completed in 8.10930662s

• [SLOW TEST:12.183 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:08:44.450: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May 21 04:08:47.529: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:08:47.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3022" for this suite.
May 21 04:08:53.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:08:53.655: INFO: namespace container-runtime-3022 deletion completed in 6.102971335s

• [SLOW TEST:9.206 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:08:53.656: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
May 21 04:08:53.702: INFO: Waiting up to 5m0s for pod "pod-0872ec8c-256b-404a-b5d6-b46591f648c2" in namespace "emptydir-7281" to be "success or failure"
May 21 04:08:53.704: INFO: Pod "pod-0872ec8c-256b-404a-b5d6-b46591f648c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.802487ms
May 21 04:08:55.708: INFO: Pod "pod-0872ec8c-256b-404a-b5d6-b46591f648c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006335312s
May 21 04:08:57.712: INFO: Pod "pod-0872ec8c-256b-404a-b5d6-b46591f648c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009962365s
STEP: Saw pod success
May 21 04:08:57.712: INFO: Pod "pod-0872ec8c-256b-404a-b5d6-b46591f648c2" satisfied condition "success or failure"
May 21 04:08:57.714: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-0872ec8c-256b-404a-b5d6-b46591f648c2 container test-container: <nil>
STEP: delete the pod
May 21 04:08:57.758: INFO: Waiting for pod pod-0872ec8c-256b-404a-b5d6-b46591f648c2 to disappear
May 21 04:08:57.763: INFO: Pod pod-0872ec8c-256b-404a-b5d6-b46591f648c2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:08:57.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7281" for this suite.
May 21 04:09:03.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:03.867: INFO: namespace emptydir-7281 deletion completed in 6.097942429s

• [SLOW TEST:10.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:09:03.867: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:09:05.168: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:09:08.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:09:08.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5681" for this suite.
May 21 04:09:20.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:20.353: INFO: namespace webhook-5681 deletion completed in 12.094601687s
STEP: Destroying namespace "webhook-5681-markers" for this suite.
May 21 04:09:26.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:26.457: INFO: namespace webhook-5681-markers deletion completed in 6.103478591s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.603 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:09:26.470: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 04:09:26.517: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a" in namespace "projected-466" to be "success or failure"
May 21 04:09:26.523: INFO: Pod "downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.439861ms
May 21 04:09:28.527: INFO: Pod "downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008164103s
STEP: Saw pod success
May 21 04:09:28.527: INFO: Pod "downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a" satisfied condition "success or failure"
May 21 04:09:28.530: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a container client-container: <nil>
STEP: delete the pod
May 21 04:09:28.549: INFO: Waiting for pod downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a to disappear
May 21 04:09:28.552: INFO: Pod downwardapi-volume-8405ae7e-8c25-4ae4-a0c4-411aa365246a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:09:28.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-466" for this suite.
May 21 04:09:34.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:34.655: INFO: namespace projected-466 deletion completed in 6.097873277s

• [SLOW TEST:8.185 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:09:34.655: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-898.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-898.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-898.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-898.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-898.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-898.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May 21 04:09:36.757: INFO: DNS probes using dns-898/dns-test-c7011568-61e7-482e-a4e6-2678407f4048 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:09:36.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-898" for this suite.
May 21 04:09:42.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:42.892: INFO: namespace dns-898 deletion completed in 6.088424836s

• [SLOW TEST:8.237 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:09:42.893: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:09:49.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3624" for this suite.
May 21 04:09:55.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:09:56.039: INFO: namespace resourcequota-3624 deletion completed in 6.091778175s

• [SLOW TEST:13.146 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:09:56.039: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
May 21 04:09:56.079: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 04:09:56.101: INFO: Waiting for terminating namespaces to be deleted...
May 21 04:09:56.103: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-1 before test
May 21 04:09:56.112: INFO: kube-proxy-worker-hm48s from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:09:56.112: INFO: kube-flannel-qfng7 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:09:56.112: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:09:56.112: INFO: ws-swift-79ff4f8c45-wp4s8 from kube-system started at 2020-05-21 01:47:37 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container swift ready: true, restart count 0
May 21 04:09:56.112: INFO: sonobuoy-e2e-job-53ec9ad4c8bc4eba from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container e2e ready: true, restart count 0
May 21 04:09:56.112: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 04:09:56.112: INFO: nodelocaldns-xlwkg from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:09:56.112: INFO: kube-proxy-master-bp8ft from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 04:09:56.112: INFO: tiller-deploy-5c4b5664fc-v5w4x from kube-system started at 2020-05-21 01:47:34 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container tiller ready: true, restart count 0
May 21 04:09:56.112: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:09:56.112: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:09:56.112: INFO: wangsucloud-csi-nodeplugin-kxzmb from kube-system started at 2020-05-21 01:47:03 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.112: INFO: 	Container cinder ready: true, restart count 0
May 21 04:09:56.112: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:09:56.112: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-2 before test
May 21 04:09:56.120: INFO: nodelocaldns-ljxj5 from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:09:56.120: INFO: wangsu-cloud-controller-manager-58cd495b6b-vmxbk from kube-system started at 2020-05-21 01:46:33 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container wangsu-cloud-controller-manager ready: true, restart count 0
May 21 04:09:56.120: INFO: kube-proxy-worker-w9vrh from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:09:56.120: INFO: sonobuoy from sonobuoy started at 2020-05-21 02:32:09 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 04:09:56.120: INFO: kube-flannel-pxgt2 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:09:56.120: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:09:56.120: INFO: wangsucloud-csi-nodeplugin-kmlr5 from kube-system started at 2020-05-21 01:47:09 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container cinder ready: true, restart count 0
May 21 04:09:56.120: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:09:56.120: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:09:56.120: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:09:56.120: INFO: kube-proxy-master-bwlfx from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:09:56.120: INFO: 	Container kube-proxy-master ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 9990-w-ax-1-1
STEP: verifying the node has the label node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod kube-flannel-pxgt2 requesting resource cpu=150m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod kube-flannel-qfng7 requesting resource cpu=150m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod kube-proxy-master-bp8ft requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod kube-proxy-master-bwlfx requesting resource cpu=0m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod kube-proxy-worker-hm48s requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod kube-proxy-worker-w9vrh requesting resource cpu=0m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod nodelocaldns-ljxj5 requesting resource cpu=100m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod nodelocaldns-xlwkg requesting resource cpu=100m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod tiller-deploy-5c4b5664fc-v5w4x requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod wangsu-cloud-controller-manager-58cd495b6b-vmxbk requesting resource cpu=200m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod wangsucloud-csi-nodeplugin-kmlr5 requesting resource cpu=0m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod wangsucloud-csi-nodeplugin-kxzmb requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod ws-swift-79ff4f8c45-wp4s8 requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod sonobuoy requesting resource cpu=0m on Node 9990-w-ax-1-2
May 21 04:09:56.171: INFO: Pod sonobuoy-e2e-job-53ec9ad4c8bc4eba requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb requesting resource cpu=0m on Node 9990-w-ax-1-1
May 21 04:09:56.171: INFO: Pod sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w requesting resource cpu=0m on Node 9990-w-ax-1-2
STEP: Starting Pods to consume most of the cluster CPU.
May 21 04:09:56.171: INFO: Creating a pod which consumes cpu=1155m on Node 9990-w-ax-1-1
May 21 04:09:56.179: INFO: Creating a pod which consumes cpu=1015m on Node 9990-w-ax-1-2
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db.1610efad54785470], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1137/filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db to 9990-w-ax-1-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db.1610efad98348a59], Reason = [Pulled], Message = [Container image "172.16.17.5/sonobuoy/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db.1610efada5773887], Reason = [Created], Message = [Created container filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db.1610efadc20d4363], Reason = [Started], Message = [Started container filler-pod-ca53753e-c07a-4cd0-a3ee-2bc968a9d5db]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0.1610efad5493e2b2], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1137/filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0 to 9990-w-ax-1-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0.1610efad7fb1227e], Reason = [Pulled], Message = [Container image "172.16.17.5/sonobuoy/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0.1610efad827e3dc5], Reason = [Created], Message = [Created container filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0.1610efad9081cdd4], Reason = [Started], Message = [Started container filler-pod-e4b70b73-c9ab-4d69-80a2-10470f20ada0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1610efae4482d175], Reason = [FailedScheduling], Message = [0/5 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 4 Insufficient cpu.]
STEP: removing the label node off the node 9990-w-ax-1-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 9990-w-ax-1-2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:10:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1137" for this suite.
May 21 04:10:07.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:10:07.420: INFO: namespace sched-pred-1137 deletion completed in 6.154373529s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.381 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:10:07.421: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b9bb9088-fc88-438c-a9f4-169d9575a4ab in namespace container-probe-7420
May 21 04:10:09.478: INFO: Started pod busybox-b9bb9088-fc88-438c-a9f4-169d9575a4ab in namespace container-probe-7420
STEP: checking the pod's current state and verifying that restartCount is present
May 21 04:10:09.480: INFO: Initial restart count of pod busybox-b9bb9088-fc88-438c-a9f4-169d9575a4ab is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:14:10.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7420" for this suite.
May 21 04:14:16.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:14:16.133: INFO: namespace container-probe-7420 deletion completed in 6.091865101s

• [SLOW TEST:248.712 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:14:16.134: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:14:16.915: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 04:14:18.927: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631256, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631256, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631256, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631256, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:14:21.945: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:14:22.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7217" for this suite.
May 21 04:14:28.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:14:28.110: INFO: namespace webhook-7217 deletion completed in 6.095062915s
STEP: Destroying namespace "webhook-7217-markers" for this suite.
May 21 04:14:34.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:14:34.212: INFO: namespace webhook-7217-markers deletion completed in 6.102025907s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.094 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:14:34.228: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
May 21 04:14:34.281: INFO: Waiting up to 5m0s for pod "pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289" in namespace "emptydir-3707" to be "success or failure"
May 21 04:14:34.286: INFO: Pod "pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289": Phase="Pending", Reason="", readiness=false. Elapsed: 5.075703ms
May 21 04:14:36.290: INFO: Pod "pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008569123s
STEP: Saw pod success
May 21 04:14:36.290: INFO: Pod "pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289" satisfied condition "success or failure"
May 21 04:14:36.292: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289 container test-container: <nil>
STEP: delete the pod
May 21 04:14:36.325: INFO: Waiting for pod pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289 to disappear
May 21 04:14:36.328: INFO: Pod pod-f8eb4d09-2bb7-4e90-b6f4-523591d33289 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:14:36.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3707" for this suite.
May 21 04:14:42.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:14:42.508: INFO: namespace emptydir-3707 deletion completed in 6.173472979s

• [SLOW TEST:8.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:14:42.509: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:14:42.545: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May 21 04:14:51.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-144 create -f -'
May 21 04:14:52.253: INFO: stderr: ""
May 21 04:14:52.253: INFO: stdout: "e2e-test-crd-publish-openapi-1468-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 21 04:14:52.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-144 delete e2e-test-crd-publish-openapi-1468-crds test-cr'
May 21 04:14:52.434: INFO: stderr: ""
May 21 04:14:52.434: INFO: stdout: "e2e-test-crd-publish-openapi-1468-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May 21 04:14:52.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-144 apply -f -'
May 21 04:14:52.959: INFO: stderr: ""
May 21 04:14:52.959: INFO: stdout: "e2e-test-crd-publish-openapi-1468-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May 21 04:14:52.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 --namespace=crd-publish-openapi-144 delete e2e-test-crd-publish-openapi-1468-crds test-cr'
May 21 04:14:53.078: INFO: stderr: ""
May 21 04:14:53.078: INFO: stdout: "e2e-test-crd-publish-openapi-1468-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May 21 04:14:53.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 explain e2e-test-crd-publish-openapi-1468-crds'
May 21 04:14:53.489: INFO: stderr: ""
May 21 04:14:53.489: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1468-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:14:55.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-144" for this suite.
May 21 04:15:01.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:15:01.789: INFO: namespace crd-publish-openapi-144 deletion completed in 6.152745765s

• [SLOW TEST:19.281 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:15:01.789: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 04:15:01.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477" in namespace "projected-3955" to be "success or failure"
May 21 04:15:01.859: INFO: Pod "downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477": Phase="Pending", Reason="", readiness=false. Elapsed: 19.918937ms
May 21 04:15:03.864: INFO: Pod "downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024276086s
STEP: Saw pod success
May 21 04:15:03.864: INFO: Pod "downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477" satisfied condition "success or failure"
May 21 04:15:03.867: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477 container client-container: <nil>
STEP: delete the pod
May 21 04:15:03.891: INFO: Waiting for pod downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477 to disappear
May 21 04:15:03.894: INFO: Pod downwardapi-volume-50258522-fe19-4162-ab56-17bf4401f477 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:15:03.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3955" for this suite.
May 21 04:15:09.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:15:09.989: INFO: namespace projected-3955 deletion completed in 6.090865559s

• [SLOW TEST:8.200 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:15:09.990: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:15:21.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-226" for this suite.
May 21 04:15:27.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:15:27.255: INFO: namespace resourcequota-226 deletion completed in 6.131718369s

• [SLOW TEST:17.265 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:15:27.255: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 04:15:27.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-rc --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6931'
May 21 04:15:27.552: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 04:15:27.552: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
May 21 04:15:27.564: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May 21 04:15:27.585: INFO: scanned /root for discovery docs: <nil>
May 21 04:15:27.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 rolling-update e2e-test-httpd-rc --update-period=1s --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6931'
May 21 04:15:43.533: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May 21 04:15:43.533: INFO: stdout: "Created e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72\nScaling up e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
May 21 04:15:43.533: INFO: stdout: "Created e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72\nScaling up e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
May 21 04:15:43.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-6931'
May 21 04:15:43.696: INFO: stderr: ""
May 21 04:15:43.696: INFO: stdout: "e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72-t8gsh "
May 21 04:15:43.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72-t8gsh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6931'
May 21 04:15:43.799: INFO: stderr: ""
May 21 04:15:43.799: INFO: stdout: "true"
May 21 04:15:43.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 get pods e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72-t8gsh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6931'
May 21 04:15:43.956: INFO: stderr: ""
May 21 04:15:43.956: INFO: stdout: "172.16.17.5/sonobuoy/httpd:2.4.38-alpine"
May 21 04:15:43.956: INFO: e2e-test-httpd-rc-4ae6e0ac9991671545bbd9ef0bbd2c72-t8gsh is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
May 21 04:15:43.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete rc e2e-test-httpd-rc --namespace=kubectl-6931'
May 21 04:15:44.302: INFO: stderr: ""
May 21 04:15:44.302: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:15:44.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6931" for this suite.
May 21 04:16:12.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:16:12.418: INFO: namespace kubectl-6931 deletion completed in 28.101833365s

• [SLOW TEST:45.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:16:12.419: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:16:29.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-69" for this suite.
May 21 04:16:35.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:16:35.619: INFO: namespace resourcequota-69 deletion completed in 6.101445031s

• [SLOW TEST:23.201 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:16:35.620: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:16:51.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5457" for this suite.
May 21 04:16:57.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:16:57.907: INFO: namespace resourcequota-5457 deletion completed in 6.115561971s

• [SLOW TEST:22.288 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:16:57.908: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
May 21 04:16:59.965: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-300851385 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May 21 04:17:05.131: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:17:05.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8744" for this suite.
May 21 04:17:11.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:17:11.230: INFO: namespace pods-8744 deletion completed in 6.090949743s

• [SLOW TEST:13.323 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:17:11.231: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:17:11.280: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May 21 04:17:11.291: INFO: Pod name sample-pod: Found 0 pods out of 1
May 21 04:17:16.297: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 04:17:16.297: INFO: Creating deployment "test-rolling-update-deployment"
May 21 04:17:16.303: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May 21 04:17:16.311: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May 21 04:17:18.317: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May 21 04:17:18.319: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
May 21 04:17:18.328: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4493 /apis/apps/v1/namespaces/deployment-4493/deployments/test-rolling-update-deployment a1fcac31-8f0a-427e-88ed-7c2284a6ff80 47933 1 2020-05-21 04:17:16 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0059ec8f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-21 04:17:16 +0000 UTC,LastTransitionTime:2020-05-21 04:17:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-5ccd96f979" has successfully progressed.,LastUpdateTime:2020-05-21 04:17:18 +0000 UTC,LastTransitionTime:2020-05-21 04:17:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May 21 04:17:18.334: INFO: New ReplicaSet "test-rolling-update-deployment-5ccd96f979" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-5ccd96f979  deployment-4493 /apis/apps/v1/namespaces/deployment-4493/replicasets/test-rolling-update-deployment-5ccd96f979 066493c0-ece5-4882-803c-ba3615e059a7 47920 1 2020-05-21 04:17:16 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5ccd96f979] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment a1fcac31-8f0a-427e-88ed-7c2284a6ff80 0xc0059ecdd7 0xc0059ecdd8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 5ccd96f979,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5ccd96f979] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0059ece38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 21 04:17:18.334: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May 21 04:17:18.334: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4493 /apis/apps/v1/namespaces/deployment-4493/replicasets/test-rolling-update-controller 8d657659-065d-4720-b108-6362892cc6fe 47932 2 2020-05-21 04:17:11 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment a1fcac31-8f0a-427e-88ed-7c2284a6ff80 0xc0059ecd07 0xc0059ecd08}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0059ecd68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May 21 04:17:18.337: INFO: Pod "test-rolling-update-deployment-5ccd96f979-9z5rs" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-5ccd96f979-9z5rs test-rolling-update-deployment-5ccd96f979- deployment-4493 /api/v1/namespaces/deployment-4493/pods/test-rolling-update-deployment-5ccd96f979-9z5rs 52090346-8b78-4c9c-88d8-eac47ca6e75e 47919 0 2020-05-21 04:17:16 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5ccd96f979] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-5ccd96f979 066493c0-ece5-4882-803c-ba3615e059a7 0xc0029ef0b7 0xc0029ef0b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mnqdx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mnqdx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.16.17.5/sonobuoy/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mnqdx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.8,PodIP:10.240.4.210,StartTime:2020-05-21 04:17:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 04:17:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/redis:5.0.5-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://63c8dc278e4d93f731b47c8c55773c40468c7e318fbf031ff9ebacdd2ee9ed86,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.4.210,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:17:18.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4493" for this suite.
May 21 04:17:24.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:17:24.432: INFO: namespace deployment-4493 deletion completed in 6.08987182s

• [SLOW TEST:13.201 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:17:24.432: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:17:29.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8014" for this suite.
May 21 04:17:57.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:17:57.628: INFO: namespace replication-controller-8014 deletion completed in 28.104025317s

• [SLOW TEST:33.196 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:17:57.629: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:17:57.676: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May 21 04:18:02.680: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May 21 04:18:02.680: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
May 21 04:18:02.701: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3849 /apis/apps/v1/namespaces/deployment-3849/deployments/test-cleanup-deployment 3f2fa7f2-7709-4489-b321-89f3ba7a1849 48177 1 2020-05-21 04:18:02 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis 172.16.17.5/sonobuoy/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029eea98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

May 21 04:18:02.706: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
May 21 04:18:02.706: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
May 21 04:18:02.706: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3849 /apis/apps/v1/namespaces/deployment-3849/replicasets/test-cleanup-controller d75c7ebf-b27a-497a-bab8-575a99548053 48178 1 2020-05-21 04:17:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 3f2fa7f2-7709-4489-b321-89f3ba7a1849 0xc0059edf07 0xc0059edf08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.16.17.5/sonobuoy/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0059edf68 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May 21 04:18:02.715: INFO: Pod "test-cleanup-controller-qn4qs" is available:
&Pod{ObjectMeta:{test-cleanup-controller-qn4qs test-cleanup-controller- deployment-3849 /api/v1/namespaces/deployment-3849/pods/test-cleanup-controller-qn4qs c938185f-30d7-4190-84de-c00ab70ccfde 48161 0 2020-05-21 04:17:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller d75c7ebf-b27a-497a-bab8-575a99548053 0xc002dc23d7 0xc002dc23d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q8gg8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q8gg8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q8gg8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:9990-w-ax-1-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:18:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:18:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-21 04:17:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.0.7,PodIP:10.240.3.200,StartTime:2020-05-21 04:17:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-21 04:17:59 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.16.17.5/sonobuoy/httpd:2.4.38-alpine,ImageID:docker-pullable://172.16.17.5/sonobuoy/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://425ab734760dd819c581af2990b6d8d96c686c3e57a7129cb7961b7b189fbd6e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.240.3.200,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:18:02.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3849" for this suite.
May 21 04:18:08.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:18:08.830: INFO: namespace deployment-3849 deletion completed in 6.10396551s

• [SLOW TEST:11.202 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:18:08.830: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
May 21 04:18:08.900: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502" in namespace "downward-api-4231" to be "success or failure"
May 21 04:18:08.908: INFO: Pod "downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502": Phase="Pending", Reason="", readiness=false. Elapsed: 7.703303ms
May 21 04:18:10.912: INFO: Pod "downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012145458s
STEP: Saw pod success
May 21 04:18:10.912: INFO: Pod "downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502" satisfied condition "success or failure"
May 21 04:18:10.915: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502 container client-container: <nil>
STEP: delete the pod
May 21 04:18:10.941: INFO: Waiting for pod downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502 to disappear
May 21 04:18:10.944: INFO: Pod downwardapi-volume-ec211a27-df01-47bb-858f-8f59f13ca502 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:18:10.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4231" for this suite.
May 21 04:18:16.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:18:17.038: INFO: namespace downward-api-4231 deletion completed in 6.087609463s

• [SLOW TEST:8.208 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:18:17.038: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:18:18.175: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 04:18:20.185: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631498, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631498, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631498, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725631498, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:18:23.216: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
May 21 04:18:23.247: INFO: Waiting for webhook configuration to be ready...
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:18:23.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7380" for this suite.
May 21 04:18:29.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:18:29.600: INFO: namespace webhook-7380 deletion completed in 6.217390793s
STEP: Destroying namespace "webhook-7380-markers" for this suite.
May 21 04:18:35.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:18:35.690: INFO: namespace webhook-7380-markers deletion completed in 6.090381439s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.667 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:18:35.705: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
May 21 04:18:35.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 api-versions'
May 21 04:18:35.878: INFO: stderr: ""
May 21 04:18:35.879: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:18:35.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3713" for this suite.
May 21 04:18:41.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:18:41.986: INFO: namespace kubectl-3713 deletion completed in 6.10069815s

• [SLOW TEST:6.281 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:18:41.987: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:18:42.031: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Creating first CR 
May 21 04:18:47.642: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:47Z generation:1 name:name1 resourceVersion:48496 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:eeaebdd2-e41e-4d77-9b54-eb191c98bc81] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
May 21 04:18:57.649: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:57Z generation:1 name:name2 resourceVersion:48535 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d771d10e-5dcd-4601-b836-9dc5b007c727] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
May 21 04:19:07.658: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:47Z generation:2 name:name1 resourceVersion:48574 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:eeaebdd2-e41e-4d77-9b54-eb191c98bc81] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
May 21 04:19:17.664: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:57Z generation:2 name:name2 resourceVersion:48613 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d771d10e-5dcd-4601-b836-9dc5b007c727] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
May 21 04:19:27.674: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:47Z generation:2 name:name1 resourceVersion:48652 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:eeaebdd2-e41e-4d77-9b54-eb191c98bc81] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
May 21 04:19:37.686: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-21T04:18:57Z generation:2 name:name2 resourceVersion:48691 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d771d10e-5dcd-4601-b836-9dc5b007c727] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:19:48.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4291" for this suite.
May 21 04:19:54.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:19:54.298: INFO: namespace crd-watch-4291 deletion completed in 6.092507474s

• [SLOW TEST:72.311 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:19:54.299: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8396/configmap-test-32428b9a-0af6-4140-b296-c80868bbcd78
STEP: Creating a pod to test consume configMaps
May 21 04:19:54.353: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10" in namespace "configmap-8396" to be "success or failure"
May 21 04:19:54.360: INFO: Pod "pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10": Phase="Pending", Reason="", readiness=false. Elapsed: 7.028867ms
May 21 04:19:56.364: INFO: Pod "pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010994661s
May 21 04:19:58.367: INFO: Pod "pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014594882s
STEP: Saw pod success
May 21 04:19:58.367: INFO: Pod "pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10" satisfied condition "success or failure"
May 21 04:19:58.370: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10 container env-test: <nil>
STEP: delete the pod
May 21 04:19:58.407: INFO: Waiting for pod pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10 to disappear
May 21 04:19:58.409: INFO: Pod pod-configmaps-5c454b5b-c055-4df8-a8b6-29d5cc364a10 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:19:58.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8396" for this suite.
May 21 04:20:04.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:20:04.506: INFO: namespace configmap-8396 deletion completed in 6.084812839s

• [SLOW TEST:10.207 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:20:04.506: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
May 21 04:20:04.559: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:20:09.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4579" for this suite.
May 21 04:20:15.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:20:15.316: INFO: namespace init-container-4579 deletion completed in 6.09304438s

• [SLOW TEST:10.809 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:20:15.316: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-2763e66c-01f5-406e-8075-d024c74f79a9
STEP: Creating secret with name secret-projected-all-test-volume-b4cc3180-d845-4870-bb47-87542b8766c6
STEP: Creating a pod to test Check all projections for projected volume plugin
May 21 04:20:15.382: INFO: Waiting up to 5m0s for pod "projected-volume-98071208-ca06-4332-91cf-e31c6444e815" in namespace "projected-8346" to be "success or failure"
May 21 04:20:15.390: INFO: Pod "projected-volume-98071208-ca06-4332-91cf-e31c6444e815": Phase="Pending", Reason="", readiness=false. Elapsed: 5.557636ms
May 21 04:20:17.394: INFO: Pod "projected-volume-98071208-ca06-4332-91cf-e31c6444e815": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009797387s
May 21 04:20:19.403: INFO: Pod "projected-volume-98071208-ca06-4332-91cf-e31c6444e815": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01943547s
STEP: Saw pod success
May 21 04:20:19.404: INFO: Pod "projected-volume-98071208-ca06-4332-91cf-e31c6444e815" satisfied condition "success or failure"
May 21 04:20:19.406: INFO: Trying to get logs from node 9990-w-ax-1-2 pod projected-volume-98071208-ca06-4332-91cf-e31c6444e815 container projected-all-volume-test: <nil>
STEP: delete the pod
May 21 04:20:19.432: INFO: Waiting for pod projected-volume-98071208-ca06-4332-91cf-e31c6444e815 to disappear
May 21 04:20:19.434: INFO: Pod projected-volume-98071208-ca06-4332-91cf-e31c6444e815 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:20:19.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8346" for this suite.
May 21 04:20:25.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:20:25.586: INFO: namespace projected-8346 deletion completed in 6.144869625s

• [SLOW TEST:10.270 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:20:25.587: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:21:25.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4831" for this suite.
May 21 04:21:53.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:21:53.756: INFO: namespace container-probe-4831 deletion completed in 28.108738378s

• [SLOW TEST:88.169 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:21:53.756: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.16.17.5/sonobuoy/httpd:2.4.38-alpine
May 21 04:21:53.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 run e2e-test-httpd-deployment --image=172.16.17.5/sonobuoy/httpd:2.4.38-alpine --namespace=kubectl-2431'
May 21 04:21:53.984: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May 21 04:21:53.984: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
May 21 04:21:53.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-300851385 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2431'
May 21 04:21:54.136: INFO: stderr: ""
May 21 04:21:54.136: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:21:54.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2431" for this suite.
May 21 04:22:00.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:00.229: INFO: namespace kubectl-2431 deletion completed in 6.086096032s

• [SLOW TEST:6.473 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:00.230: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:00.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9383" for this suite.
May 21 04:22:06.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:06.370: INFO: namespace services-9383 deletion completed in 6.091513576s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.140 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:06.370: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
May 21 04:22:06.414: INFO: Waiting up to 5m0s for pod "pod-eda01a31-08af-4ee8-af3b-71b762093106" in namespace "emptydir-4413" to be "success or failure"
May 21 04:22:06.425: INFO: Pod "pod-eda01a31-08af-4ee8-af3b-71b762093106": Phase="Pending", Reason="", readiness=false. Elapsed: 10.499564ms
May 21 04:22:08.430: INFO: Pod "pod-eda01a31-08af-4ee8-af3b-71b762093106": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016052642s
STEP: Saw pod success
May 21 04:22:08.430: INFO: Pod "pod-eda01a31-08af-4ee8-af3b-71b762093106" satisfied condition "success or failure"
May 21 04:22:08.433: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-eda01a31-08af-4ee8-af3b-71b762093106 container test-container: <nil>
STEP: delete the pod
May 21 04:22:08.466: INFO: Waiting for pod pod-eda01a31-08af-4ee8-af3b-71b762093106 to disappear
May 21 04:22:08.470: INFO: Pod pod-eda01a31-08af-4ee8-af3b-71b762093106 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:08.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4413" for this suite.
May 21 04:22:14.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:14.554: INFO: namespace emptydir-4413 deletion completed in 6.078672468s

• [SLOW TEST:8.184 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:14.554: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-0f9df7c0-a8f5-4925-a160-8542c65df23b
STEP: Creating a pod to test consume configMaps
May 21 04:22:14.619: INFO: Waiting up to 5m0s for pod "pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974" in namespace "configmap-7299" to be "success or failure"
May 21 04:22:14.626: INFO: Pod "pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974": Phase="Pending", Reason="", readiness=false. Elapsed: 6.469149ms
May 21 04:22:16.629: INFO: Pod "pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009734172s
STEP: Saw pod success
May 21 04:22:16.629: INFO: Pod "pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974" satisfied condition "success or failure"
May 21 04:22:16.631: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 04:22:16.665: INFO: Waiting for pod pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974 to disappear
May 21 04:22:16.667: INFO: Pod pod-configmaps-bcaeb28a-c34a-450a-9775-38df39f07974 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:16.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7299" for this suite.
May 21 04:22:22.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:22.761: INFO: namespace configmap-7299 deletion completed in 6.089944633s

• [SLOW TEST:8.207 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:22.762: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
May 21 04:22:22.816: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-93482579-589e-468f-8c61-a7952eb19dbf" in namespace "security-context-test-6901" to be "success or failure"
May 21 04:22:22.820: INFO: Pod "busybox-readonly-false-93482579-589e-468f-8c61-a7952eb19dbf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.67699ms
May 21 04:22:24.824: INFO: Pod "busybox-readonly-false-93482579-589e-468f-8c61-a7952eb19dbf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007958213s
May 21 04:22:24.824: INFO: Pod "busybox-readonly-false-93482579-589e-468f-8c61-a7952eb19dbf" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:24.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6901" for this suite.
May 21 04:22:30.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:30.955: INFO: namespace security-context-test-6901 deletion completed in 6.125493993s

• [SLOW TEST:8.193 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:30.955: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-4255
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4255 to expose endpoints map[]
May 21 04:22:31.022: INFO: Get endpoints failed (8.765472ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
May 21 04:22:32.025: INFO: successfully validated that service endpoint-test2 in namespace services-4255 exposes endpoints map[] (1.011968903s elapsed)
STEP: Creating pod pod1 in namespace services-4255
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4255 to expose endpoints map[pod1:[80]]
May 21 04:22:34.075: INFO: successfully validated that service endpoint-test2 in namespace services-4255 exposes endpoints map[pod1:[80]] (2.035393381s elapsed)
STEP: Creating pod pod2 in namespace services-4255
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4255 to expose endpoints map[pod1:[80] pod2:[80]]
May 21 04:22:36.126: INFO: successfully validated that service endpoint-test2 in namespace services-4255 exposes endpoints map[pod1:[80] pod2:[80]] (2.041901522s elapsed)
STEP: Deleting pod pod1 in namespace services-4255
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4255 to expose endpoints map[pod2:[80]]
May 21 04:22:37.147: INFO: successfully validated that service endpoint-test2 in namespace services-4255 exposes endpoints map[pod2:[80]] (1.014479055s elapsed)
STEP: Deleting pod pod2 in namespace services-4255
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4255 to expose endpoints map[]
May 21 04:22:37.162: INFO: successfully validated that service endpoint-test2 in namespace services-4255 exposes endpoints map[] (6.277181ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:37.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4255" for this suite.
May 21 04:22:43.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:43.336: INFO: namespace services-4255 deletion completed in 6.127408169s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.381 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:43.337: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
May 21 04:22:43.385: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 04:22:43.400: INFO: Waiting for terminating namespaces to be deleted...
May 21 04:22:43.402: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-1 before test
May 21 04:22:43.411: INFO: nodelocaldns-xlwkg from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:22:43.411: INFO: kube-proxy-master-bp8ft from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 04:22:43.411: INFO: tiller-deploy-5c4b5664fc-v5w4x from kube-system started at 2020-05-21 01:47:34 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container tiller ready: true, restart count 0
May 21 04:22:43.411: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:22:43.411: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:22:43.411: INFO: wangsucloud-csi-nodeplugin-kxzmb from kube-system started at 2020-05-21 01:47:03 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container cinder ready: true, restart count 0
May 21 04:22:43.411: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:22:43.411: INFO: kube-proxy-worker-hm48s from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:22:43.411: INFO: kube-flannel-qfng7 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:22:43.411: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:22:43.411: INFO: ws-swift-79ff4f8c45-wp4s8 from kube-system started at 2020-05-21 01:47:37 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container swift ready: true, restart count 0
May 21 04:22:43.411: INFO: sonobuoy-e2e-job-53ec9ad4c8bc4eba from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.411: INFO: 	Container e2e ready: true, restart count 0
May 21 04:22:43.411: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 04:22:43.411: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-2 before test
May 21 04:22:43.417: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:22:43.417: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:22:43.417: INFO: kube-proxy-master-bwlfx from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 04:22:43.417: INFO: wangsucloud-csi-nodeplugin-kmlr5 from kube-system started at 2020-05-21 01:47:09 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container cinder ready: true, restart count 0
May 21 04:22:43.417: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:22:43.417: INFO: wangsu-cloud-controller-manager-58cd495b6b-vmxbk from kube-system started at 2020-05-21 01:46:33 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container wangsu-cloud-controller-manager ready: true, restart count 0
May 21 04:22:43.417: INFO: nodelocaldns-ljxj5 from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:22:43.417: INFO: kube-proxy-worker-w9vrh from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:22:43.417: INFO: kube-flannel-pxgt2 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:22:43.417: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:22:43.417: INFO: sonobuoy from sonobuoy started at 2020-05-21 02:32:09 +0000 UTC (1 container statuses recorded)
May 21 04:22:43.417: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1610f05ff86d7b77], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:44.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8621" for this suite.
May 21 04:22:50.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:22:50.548: INFO: namespace sched-pred-8621 deletion completed in 6.096772701s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.211 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:22:50.548: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
May 21 04:22:55.140: INFO: Successfully updated pod "annotationupdate20063723-ac2a-46d3-9a07-eabc8eeb2674"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:22:57.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9911" for this suite.
May 21 04:23:25.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:23:25.294: INFO: namespace projected-9911 deletion completed in 28.121898395s

• [SLOW TEST:34.746 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:23:25.295: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9506
I0521 04:23:25.356179      20 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9506, replica count: 1
I0521 04:23:26.412986      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 04:23:27.413461      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0521 04:23:28.413774      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May 21 04:23:28.534: INFO: Created: latency-svc-mbp9z
May 21 04:23:28.542: INFO: Got endpoints: latency-svc-mbp9z [28.888111ms]
May 21 04:23:28.576: INFO: Created: latency-svc-ddqjk
May 21 04:23:28.581: INFO: Got endpoints: latency-svc-ddqjk [38.476011ms]
May 21 04:23:28.585: INFO: Created: latency-svc-vl227
May 21 04:23:28.606: INFO: Got endpoints: latency-svc-vl227 [62.372549ms]
May 21 04:23:28.625: INFO: Created: latency-svc-xg57d
May 21 04:23:28.645: INFO: Created: latency-svc-bzqsl
May 21 04:23:28.648: INFO: Got endpoints: latency-svc-xg57d [104.457665ms]
May 21 04:23:28.667: INFO: Got endpoints: latency-svc-bzqsl [122.855403ms]
May 21 04:23:28.667: INFO: Created: latency-svc-bhd9r
May 21 04:23:28.681: INFO: Got endpoints: latency-svc-bhd9r [136.384706ms]
May 21 04:23:28.689: INFO: Created: latency-svc-8msp2
May 21 04:23:28.703: INFO: Got endpoints: latency-svc-8msp2 [158.670913ms]
May 21 04:23:28.705: INFO: Created: latency-svc-vfhsd
May 21 04:23:28.717: INFO: Got endpoints: latency-svc-vfhsd [171.970604ms]
May 21 04:23:28.723: INFO: Created: latency-svc-zk98x
May 21 04:23:28.735: INFO: Got endpoints: latency-svc-zk98x [190.237569ms]
May 21 04:23:28.748: INFO: Created: latency-svc-5wgxr
May 21 04:23:28.767: INFO: Got endpoints: latency-svc-5wgxr [221.665708ms]
May 21 04:23:28.771: INFO: Created: latency-svc-bjkq4
May 21 04:23:28.783: INFO: Got endpoints: latency-svc-bjkq4 [237.082206ms]
May 21 04:23:28.792: INFO: Created: latency-svc-q922d
May 21 04:23:28.807: INFO: Got endpoints: latency-svc-q922d [260.87503ms]
May 21 04:23:28.814: INFO: Created: latency-svc-c7vpf
May 21 04:23:28.825: INFO: Got endpoints: latency-svc-c7vpf [278.713465ms]
May 21 04:23:28.827: INFO: Created: latency-svc-cwrch
May 21 04:23:28.845: INFO: Got endpoints: latency-svc-cwrch [299.221484ms]
May 21 04:23:28.863: INFO: Created: latency-svc-5s4qk
May 21 04:23:28.868: INFO: Got endpoints: latency-svc-5s4qk [321.816905ms]
May 21 04:23:28.904: INFO: Created: latency-svc-qf8pd
May 21 04:23:28.931: INFO: Got endpoints: latency-svc-qf8pd [384.165901ms]
May 21 04:23:28.945: INFO: Created: latency-svc-lvkb7
May 21 04:23:28.975: INFO: Got endpoints: latency-svc-lvkb7 [393.619364ms]
May 21 04:23:28.981: INFO: Created: latency-svc-skgbm
May 21 04:23:29.011: INFO: Got endpoints: latency-svc-skgbm [405.11194ms]
May 21 04:23:29.019: INFO: Created: latency-svc-ddvj2
May 21 04:23:29.041: INFO: Got endpoints: latency-svc-ddvj2 [392.638317ms]
May 21 04:23:29.069: INFO: Created: latency-svc-s5kqc
May 21 04:23:29.092: INFO: Got endpoints: latency-svc-s5kqc [424.688786ms]
May 21 04:23:29.093: INFO: Created: latency-svc-n78q2
May 21 04:23:29.102: INFO: Got endpoints: latency-svc-n78q2 [420.769989ms]
May 21 04:23:29.116: INFO: Created: latency-svc-fjrk6
May 21 04:23:29.137: INFO: Created: latency-svc-xnrfd
May 21 04:23:29.138: INFO: Got endpoints: latency-svc-fjrk6 [434.477785ms]
May 21 04:23:29.146: INFO: Got endpoints: latency-svc-xnrfd [428.805071ms]
May 21 04:23:29.153: INFO: Created: latency-svc-v8rbp
May 21 04:23:29.164: INFO: Got endpoints: latency-svc-v8rbp [428.268455ms]
May 21 04:23:29.176: INFO: Created: latency-svc-4sthz
May 21 04:23:29.190: INFO: Got endpoints: latency-svc-4sthz [422.474453ms]
May 21 04:23:29.196: INFO: Created: latency-svc-rvwfl
May 21 04:23:29.210: INFO: Got endpoints: latency-svc-rvwfl [426.884785ms]
May 21 04:23:29.230: INFO: Created: latency-svc-g2hrw
May 21 04:23:29.240: INFO: Got endpoints: latency-svc-g2hrw [433.066829ms]
May 21 04:23:29.246: INFO: Created: latency-svc-t46qs
May 21 04:23:29.253: INFO: Got endpoints: latency-svc-t46qs [428.156716ms]
May 21 04:23:29.268: INFO: Created: latency-svc-lkbsn
May 21 04:23:29.276: INFO: Got endpoints: latency-svc-lkbsn [430.723441ms]
May 21 04:23:29.283: INFO: Created: latency-svc-9kh7c
May 21 04:23:29.303: INFO: Got endpoints: latency-svc-9kh7c [435.419307ms]
May 21 04:23:29.314: INFO: Created: latency-svc-cd66t
May 21 04:23:29.326: INFO: Got endpoints: latency-svc-cd66t [395.44835ms]
May 21 04:23:29.335: INFO: Created: latency-svc-rdb8c
May 21 04:23:29.362: INFO: Created: latency-svc-z9kxs
May 21 04:23:29.362: INFO: Got endpoints: latency-svc-rdb8c [387.28723ms]
May 21 04:23:29.371: INFO: Got endpoints: latency-svc-z9kxs [359.618971ms]
May 21 04:23:29.395: INFO: Created: latency-svc-mmjqq
May 21 04:23:29.439: INFO: Got endpoints: latency-svc-mmjqq [398.043569ms]
May 21 04:23:29.453: INFO: Created: latency-svc-4s72r
May 21 04:23:29.453: INFO: Got endpoints: latency-svc-4s72r [361.188403ms]
May 21 04:23:29.473: INFO: Created: latency-svc-7ld2w
May 21 04:23:29.486: INFO: Got endpoints: latency-svc-7ld2w [383.891796ms]
May 21 04:23:29.498: INFO: Created: latency-svc-9gl4x
May 21 04:23:29.511: INFO: Got endpoints: latency-svc-9gl4x [373.135482ms]
May 21 04:23:29.529: INFO: Created: latency-svc-hj4nb
May 21 04:23:29.534: INFO: Got endpoints: latency-svc-hj4nb [388.447132ms]
May 21 04:23:29.535: INFO: Created: latency-svc-hw9nf
May 21 04:23:29.550: INFO: Got endpoints: latency-svc-hw9nf [385.780531ms]
May 21 04:23:29.568: INFO: Created: latency-svc-zlpvv
May 21 04:23:29.584: INFO: Got endpoints: latency-svc-zlpvv [394.468155ms]
May 21 04:23:29.595: INFO: Created: latency-svc-c5l2n
May 21 04:23:29.606: INFO: Got endpoints: latency-svc-c5l2n [395.94347ms]
May 21 04:23:29.612: INFO: Created: latency-svc-dm6gl
May 21 04:23:29.629: INFO: Got endpoints: latency-svc-dm6gl [389.344425ms]
May 21 04:23:29.638: INFO: Created: latency-svc-tmjs5
May 21 04:23:29.652: INFO: Got endpoints: latency-svc-tmjs5 [399.012163ms]
May 21 04:23:29.668: INFO: Created: latency-svc-qsd5s
May 21 04:23:29.683: INFO: Got endpoints: latency-svc-qsd5s [406.83329ms]
May 21 04:23:29.711: INFO: Created: latency-svc-49pnc
May 21 04:23:29.721: INFO: Got endpoints: latency-svc-49pnc [418.308503ms]
May 21 04:23:29.730: INFO: Created: latency-svc-w4v4g
May 21 04:23:29.744: INFO: Got endpoints: latency-svc-w4v4g [417.553456ms]
May 21 04:23:29.747: INFO: Created: latency-svc-clm2z
May 21 04:23:29.753: INFO: Got endpoints: latency-svc-clm2z [390.343012ms]
May 21 04:23:29.767: INFO: Created: latency-svc-t8kzw
May 21 04:23:29.788: INFO: Got endpoints: latency-svc-t8kzw [417.845108ms]
May 21 04:23:29.799: INFO: Created: latency-svc-pgkkn
May 21 04:23:29.810: INFO: Got endpoints: latency-svc-pgkkn [371.009361ms]
May 21 04:23:29.829: INFO: Created: latency-svc-zqtkx
May 21 04:23:29.829: INFO: Got endpoints: latency-svc-zqtkx [376.467793ms]
May 21 04:23:29.856: INFO: Created: latency-svc-nbrjl
May 21 04:23:29.868: INFO: Got endpoints: latency-svc-nbrjl [382.313824ms]
May 21 04:23:29.890: INFO: Created: latency-svc-b792r
May 21 04:23:29.901: INFO: Got endpoints: latency-svc-b792r [390.025549ms]
May 21 04:23:29.932: INFO: Created: latency-svc-4766r
May 21 04:23:29.932: INFO: Got endpoints: latency-svc-4766r [398.181066ms]
May 21 04:23:29.956: INFO: Created: latency-svc-mpf8h
May 21 04:23:29.983: INFO: Got endpoints: latency-svc-mpf8h [432.946019ms]
May 21 04:23:30.022: INFO: Created: latency-svc-b84jh
May 21 04:23:30.047: INFO: Got endpoints: latency-svc-b84jh [462.261487ms]
May 21 04:23:30.047: INFO: Created: latency-svc-b865t
May 21 04:23:30.058: INFO: Got endpoints: latency-svc-b865t [452.035547ms]
May 21 04:23:30.068: INFO: Created: latency-svc-rswqd
May 21 04:23:30.087: INFO: Got endpoints: latency-svc-rswqd [457.38662ms]
May 21 04:23:30.101: INFO: Created: latency-svc-85x94
May 21 04:23:30.120: INFO: Got endpoints: latency-svc-85x94 [467.755506ms]
May 21 04:23:30.138: INFO: Created: latency-svc-xmvgc
May 21 04:23:30.138: INFO: Created: latency-svc-jz6sj
May 21 04:23:30.150: INFO: Got endpoints: latency-svc-jz6sj [428.274071ms]
May 21 04:23:30.172: INFO: Got endpoints: latency-svc-xmvgc [488.768344ms]
May 21 04:23:30.183: INFO: Created: latency-svc-4wzt9
May 21 04:23:30.196: INFO: Got endpoints: latency-svc-4wzt9 [451.968603ms]
May 21 04:23:30.201: INFO: Created: latency-svc-mhz77
May 21 04:23:30.213: INFO: Got endpoints: latency-svc-mhz77 [459.82927ms]
May 21 04:23:30.221: INFO: Created: latency-svc-6xwvk
May 21 04:23:30.232: INFO: Got endpoints: latency-svc-6xwvk [443.722704ms]
May 21 04:23:30.242: INFO: Created: latency-svc-qts7t
May 21 04:23:30.250: INFO: Got endpoints: latency-svc-qts7t [439.675322ms]
May 21 04:23:30.260: INFO: Created: latency-svc-ln9mr
May 21 04:23:30.278: INFO: Created: latency-svc-lf64r
May 21 04:23:30.305: INFO: Got endpoints: latency-svc-ln9mr [475.510724ms]
May 21 04:23:30.311: INFO: Created: latency-svc-ljl4v
May 21 04:23:30.330: INFO: Created: latency-svc-9kh6x
May 21 04:23:30.348: INFO: Got endpoints: latency-svc-lf64r [479.749679ms]
May 21 04:23:30.364: INFO: Created: latency-svc-blp9b
May 21 04:23:30.397: INFO: Got endpoints: latency-svc-ljl4v [496.628806ms]
May 21 04:23:30.398: INFO: Created: latency-svc-l2s4l
May 21 04:23:30.417: INFO: Created: latency-svc-m6ldf
May 21 04:23:30.432: INFO: Created: latency-svc-hwp68
May 21 04:23:30.457: INFO: Got endpoints: latency-svc-9kh6x [524.579598ms]
May 21 04:23:30.457: INFO: Created: latency-svc-jgr22
May 21 04:23:30.477: INFO: Created: latency-svc-l59x2
May 21 04:23:30.492: INFO: Got endpoints: latency-svc-blp9b [509.665571ms]
May 21 04:23:30.499: INFO: Created: latency-svc-w7kcg
May 21 04:23:30.521: INFO: Created: latency-svc-pj4cz
May 21 04:23:30.537: INFO: Created: latency-svc-dx55s
May 21 04:23:30.558: INFO: Created: latency-svc-tkttl
May 21 04:23:30.559: INFO: Got endpoints: latency-svc-l2s4l [512.748263ms]
May 21 04:23:30.595: INFO: Got endpoints: latency-svc-m6ldf [536.982246ms]
May 21 04:23:30.614: INFO: Created: latency-svc-lhvvm
May 21 04:23:30.630: INFO: Created: latency-svc-s9rxb
May 21 04:23:30.641: INFO: Created: latency-svc-v7zq9
May 21 04:23:30.642: INFO: Got endpoints: latency-svc-hwp68 [555.320507ms]
May 21 04:23:30.663: INFO: Created: latency-svc-7hkcr
May 21 04:23:30.675: INFO: Created: latency-svc-s7vvt
May 21 04:23:30.693: INFO: Created: latency-svc-bqldv
May 21 04:23:30.706: INFO: Got endpoints: latency-svc-jgr22 [586.048565ms]
May 21 04:23:30.742: INFO: Created: latency-svc-9dv2c
May 21 04:23:30.747: INFO: Got endpoints: latency-svc-l59x2 [596.983876ms]
May 21 04:23:30.763: INFO: Created: latency-svc-gw99m
May 21 04:23:30.778: INFO: Created: latency-svc-94pwf
May 21 04:23:30.795: INFO: Got endpoints: latency-svc-w7kcg [623.465754ms]
May 21 04:23:30.803: INFO: Created: latency-svc-992ht
May 21 04:23:30.835: INFO: Created: latency-svc-bmnq4
May 21 04:23:30.846: INFO: Got endpoints: latency-svc-pj4cz [650.091409ms]
May 21 04:23:30.855: INFO: Created: latency-svc-lvbf9
May 21 04:23:30.883: INFO: Created: latency-svc-x4xdg
May 21 04:23:30.895: INFO: Got endpoints: latency-svc-dx55s [682.582047ms]
May 21 04:23:30.932: INFO: Created: latency-svc-fx57d
May 21 04:23:30.947: INFO: Got endpoints: latency-svc-tkttl [715.240183ms]
May 21 04:23:30.980: INFO: Created: latency-svc-znpbb
May 21 04:23:30.993: INFO: Got endpoints: latency-svc-lhvvm [743.047985ms]
May 21 04:23:31.014: INFO: Created: latency-svc-7mkjc
May 21 04:23:31.042: INFO: Got endpoints: latency-svc-s9rxb [737.290559ms]
May 21 04:23:31.061: INFO: Created: latency-svc-bfbnc
May 21 04:23:31.092: INFO: Got endpoints: latency-svc-v7zq9 [744.049637ms]
May 21 04:23:31.115: INFO: Created: latency-svc-cfg4d
May 21 04:23:31.153: INFO: Got endpoints: latency-svc-7hkcr [755.5157ms]
May 21 04:23:31.178: INFO: Created: latency-svc-rdnkf
May 21 04:23:31.191: INFO: Got endpoints: latency-svc-s7vvt [733.796176ms]
May 21 04:23:31.217: INFO: Created: latency-svc-xzskc
May 21 04:23:31.243: INFO: Got endpoints: latency-svc-bqldv [750.530797ms]
May 21 04:23:31.265: INFO: Created: latency-svc-8xp7t
May 21 04:23:31.291: INFO: Got endpoints: latency-svc-9dv2c [730.821998ms]
May 21 04:23:31.318: INFO: Created: latency-svc-2t8pc
May 21 04:23:31.342: INFO: Got endpoints: latency-svc-gw99m [747.183012ms]
May 21 04:23:31.372: INFO: Created: latency-svc-4ndk8
May 21 04:23:31.410: INFO: Got endpoints: latency-svc-94pwf [767.649228ms]
May 21 04:23:31.448: INFO: Got endpoints: latency-svc-992ht [741.956002ms]
May 21 04:23:31.448: INFO: Created: latency-svc-k5rwm
May 21 04:23:31.478: INFO: Created: latency-svc-bznff
May 21 04:23:31.496: INFO: Got endpoints: latency-svc-bmnq4 [748.906995ms]
May 21 04:23:31.523: INFO: Created: latency-svc-w96sd
May 21 04:23:31.542: INFO: Got endpoints: latency-svc-lvbf9 [746.464987ms]
May 21 04:23:31.566: INFO: Created: latency-svc-d8nrd
May 21 04:23:31.601: INFO: Got endpoints: latency-svc-x4xdg [754.564282ms]
May 21 04:23:31.647: INFO: Got endpoints: latency-svc-fx57d [751.708455ms]
May 21 04:23:31.659: INFO: Created: latency-svc-cbwv2
May 21 04:23:31.672: INFO: Created: latency-svc-2p75s
May 21 04:23:31.695: INFO: Got endpoints: latency-svc-znpbb [747.14328ms]
May 21 04:23:31.726: INFO: Created: latency-svc-fc48s
May 21 04:23:31.741: INFO: Got endpoints: latency-svc-7mkjc [748.017488ms]
May 21 04:23:31.782: INFO: Created: latency-svc-sl9tc
May 21 04:23:31.806: INFO: Got endpoints: latency-svc-bfbnc [763.709506ms]
May 21 04:23:31.843: INFO: Created: latency-svc-mhf6s
May 21 04:23:31.845: INFO: Got endpoints: latency-svc-cfg4d [753.183687ms]
May 21 04:23:31.871: INFO: Created: latency-svc-fnfj8
May 21 04:23:31.913: INFO: Got endpoints: latency-svc-rdnkf [759.760984ms]
May 21 04:23:31.947: INFO: Created: latency-svc-cwjpd
May 21 04:23:31.947: INFO: Got endpoints: latency-svc-xzskc [756.511152ms]
May 21 04:23:31.967: INFO: Created: latency-svc-484ld
May 21 04:23:31.995: INFO: Got endpoints: latency-svc-8xp7t [751.649299ms]
May 21 04:23:32.026: INFO: Created: latency-svc-mlcv9
May 21 04:23:32.042: INFO: Got endpoints: latency-svc-2t8pc [751.281501ms]
May 21 04:23:32.076: INFO: Created: latency-svc-hcr7x
May 21 04:23:32.091: INFO: Got endpoints: latency-svc-4ndk8 [748.641914ms]
May 21 04:23:32.120: INFO: Created: latency-svc-p287g
May 21 04:23:32.143: INFO: Got endpoints: latency-svc-k5rwm [733.047618ms]
May 21 04:23:32.174: INFO: Created: latency-svc-rxxhj
May 21 04:23:32.191: INFO: Got endpoints: latency-svc-bznff [743.369818ms]
May 21 04:23:32.219: INFO: Created: latency-svc-x8rjt
May 21 04:23:32.249: INFO: Got endpoints: latency-svc-w96sd [753.405039ms]
May 21 04:23:32.278: INFO: Created: latency-svc-z7pfh
May 21 04:23:32.293: INFO: Got endpoints: latency-svc-d8nrd [750.992687ms]
May 21 04:23:32.315: INFO: Created: latency-svc-pdcxj
May 21 04:23:32.355: INFO: Got endpoints: latency-svc-cbwv2 [754.016949ms]
May 21 04:23:32.392: INFO: Created: latency-svc-jkk2l
May 21 04:23:32.395: INFO: Got endpoints: latency-svc-2p75s [748.44272ms]
May 21 04:23:32.418: INFO: Created: latency-svc-gf96v
May 21 04:23:32.443: INFO: Got endpoints: latency-svc-fc48s [748.134272ms]
May 21 04:23:32.476: INFO: Created: latency-svc-vmh5b
May 21 04:23:32.491: INFO: Got endpoints: latency-svc-sl9tc [750.192405ms]
May 21 04:23:32.538: INFO: Created: latency-svc-xb8lt
May 21 04:23:32.545: INFO: Got endpoints: latency-svc-mhf6s [739.052908ms]
May 21 04:23:32.566: INFO: Created: latency-svc-k5p87
May 21 04:23:32.592: INFO: Got endpoints: latency-svc-fnfj8 [746.776605ms]
May 21 04:23:32.611: INFO: Created: latency-svc-g9kgl
May 21 04:23:32.641: INFO: Got endpoints: latency-svc-cwjpd [728.083495ms]
May 21 04:23:32.665: INFO: Created: latency-svc-vb4jk
May 21 04:23:32.694: INFO: Got endpoints: latency-svc-484ld [746.31399ms]
May 21 04:23:32.714: INFO: Created: latency-svc-2kt9f
May 21 04:23:32.745: INFO: Got endpoints: latency-svc-mlcv9 [750.059302ms]
May 21 04:23:32.774: INFO: Created: latency-svc-4bdsg
May 21 04:23:32.808: INFO: Got endpoints: latency-svc-hcr7x [766.109184ms]
May 21 04:23:32.847: INFO: Created: latency-svc-4qv89
May 21 04:23:32.850: INFO: Got endpoints: latency-svc-p287g [758.928664ms]
May 21 04:23:32.873: INFO: Created: latency-svc-khc8d
May 21 04:23:32.895: INFO: Got endpoints: latency-svc-rxxhj [752.237566ms]
May 21 04:23:32.950: INFO: Got endpoints: latency-svc-x8rjt [759.083476ms]
May 21 04:23:32.960: INFO: Created: latency-svc-td9jj
May 21 04:23:32.984: INFO: Created: latency-svc-nc9s2
May 21 04:23:32.993: INFO: Got endpoints: latency-svc-z7pfh [743.987574ms]
May 21 04:23:33.058: INFO: Got endpoints: latency-svc-pdcxj [765.173218ms]
May 21 04:23:33.060: INFO: Created: latency-svc-9vpbk
May 21 04:23:33.095: INFO: Created: latency-svc-jgbzv
May 21 04:23:33.096: INFO: Got endpoints: latency-svc-jkk2l [740.748836ms]
May 21 04:23:33.128: INFO: Created: latency-svc-pmjt7
May 21 04:23:33.141: INFO: Got endpoints: latency-svc-gf96v [745.695518ms]
May 21 04:23:33.165: INFO: Created: latency-svc-zv6n8
May 21 04:23:33.197: INFO: Got endpoints: latency-svc-vmh5b [754.280398ms]
May 21 04:23:33.221: INFO: Created: latency-svc-52l8n
May 21 04:23:33.243: INFO: Got endpoints: latency-svc-xb8lt [751.660121ms]
May 21 04:23:33.266: INFO: Created: latency-svc-5kj2c
May 21 04:23:33.299: INFO: Got endpoints: latency-svc-k5p87 [753.669487ms]
May 21 04:23:33.319: INFO: Created: latency-svc-2khfb
May 21 04:23:33.353: INFO: Got endpoints: latency-svc-g9kgl [761.131867ms]
May 21 04:23:33.382: INFO: Created: latency-svc-phhdx
May 21 04:23:33.395: INFO: Got endpoints: latency-svc-vb4jk [753.941603ms]
May 21 04:23:33.422: INFO: Created: latency-svc-n6gpm
May 21 04:23:33.445: INFO: Got endpoints: latency-svc-2kt9f [751.49566ms]
May 21 04:23:33.468: INFO: Created: latency-svc-2dthx
May 21 04:23:33.498: INFO: Got endpoints: latency-svc-4bdsg [753.024485ms]
May 21 04:23:33.529: INFO: Created: latency-svc-55td6
May 21 04:23:33.559: INFO: Got endpoints: latency-svc-4qv89 [750.78056ms]
May 21 04:23:33.596: INFO: Created: latency-svc-zgxvz
May 21 04:23:33.601: INFO: Got endpoints: latency-svc-khc8d [751.447304ms]
May 21 04:23:33.633: INFO: Created: latency-svc-rpkhh
May 21 04:23:33.641: INFO: Got endpoints: latency-svc-td9jj [745.617821ms]
May 21 04:23:33.662: INFO: Created: latency-svc-hhqjc
May 21 04:23:33.695: INFO: Got endpoints: latency-svc-nc9s2 [744.750783ms]
May 21 04:23:33.921: INFO: Got endpoints: latency-svc-jgbzv [862.542511ms]
May 21 04:23:33.921: INFO: Got endpoints: latency-svc-9vpbk [927.870027ms]
May 21 04:23:33.922: INFO: Got endpoints: latency-svc-zv6n8 [780.735852ms]
May 21 04:23:33.922: INFO: Got endpoints: latency-svc-pmjt7 [826.574757ms]
May 21 04:23:33.925: INFO: Created: latency-svc-6ks6v
May 21 04:23:33.949: INFO: Got endpoints: latency-svc-52l8n [751.732819ms]
May 21 04:23:33.957: INFO: Created: latency-svc-6kwn2
May 21 04:23:33.994: INFO: Created: latency-svc-xx5sb
May 21 04:23:33.998: INFO: Got endpoints: latency-svc-5kj2c [755.180708ms]
May 21 04:23:34.014: INFO: Created: latency-svc-q5tl6
May 21 04:23:34.031: INFO: Created: latency-svc-rkjgx
May 21 04:23:34.046: INFO: Got endpoints: latency-svc-2khfb [747.348418ms]
May 21 04:23:34.059: INFO: Created: latency-svc-4lrcg
May 21 04:23:34.086: INFO: Created: latency-svc-2kbrw
May 21 04:23:34.095: INFO: Got endpoints: latency-svc-phhdx [741.754703ms]
May 21 04:23:34.097: INFO: Created: latency-svc-5qmpl
May 21 04:23:34.126: INFO: Created: latency-svc-2czv4
May 21 04:23:34.141: INFO: Got endpoints: latency-svc-n6gpm [745.832478ms]
May 21 04:23:34.164: INFO: Created: latency-svc-sw5rr
May 21 04:23:34.194: INFO: Got endpoints: latency-svc-2dthx [748.63881ms]
May 21 04:23:34.214: INFO: Created: latency-svc-fvpmm
May 21 04:23:34.243: INFO: Got endpoints: latency-svc-55td6 [745.194562ms]
May 21 04:23:34.299: INFO: Got endpoints: latency-svc-zgxvz [739.565507ms]
May 21 04:23:34.335: INFO: Created: latency-svc-k9p8h
May 21 04:23:34.348: INFO: Got endpoints: latency-svc-rpkhh [747.257755ms]
May 21 04:23:34.382: INFO: Created: latency-svc-hh7hj
May 21 04:23:34.402: INFO: Got endpoints: latency-svc-hhqjc [761.073451ms]
May 21 04:23:34.413: INFO: Created: latency-svc-mks8c
May 21 04:23:34.458: INFO: Got endpoints: latency-svc-6ks6v [763.204067ms]
May 21 04:23:34.459: INFO: Created: latency-svc-4fcsd
May 21 04:23:34.496: INFO: Got endpoints: latency-svc-6kwn2 [574.774789ms]
May 21 04:23:34.498: INFO: Created: latency-svc-r8wlc
May 21 04:23:34.523: INFO: Created: latency-svc-tb9dz
May 21 04:23:34.542: INFO: Got endpoints: latency-svc-xx5sb [620.474941ms]
May 21 04:23:34.571: INFO: Created: latency-svc-l975w
May 21 04:23:34.593: INFO: Got endpoints: latency-svc-q5tl6 [670.49882ms]
May 21 04:23:34.619: INFO: Created: latency-svc-7mnq4
May 21 04:23:34.642: INFO: Got endpoints: latency-svc-rkjgx [720.420939ms]
May 21 04:23:34.664: INFO: Created: latency-svc-545wm
May 21 04:23:34.699: INFO: Got endpoints: latency-svc-4lrcg [749.678152ms]
May 21 04:23:34.719: INFO: Created: latency-svc-gtvw6
May 21 04:23:34.741: INFO: Got endpoints: latency-svc-2kbrw [742.643177ms]
May 21 04:23:34.762: INFO: Created: latency-svc-zwn6l
May 21 04:23:34.791: INFO: Got endpoints: latency-svc-5qmpl [744.320293ms]
May 21 04:23:34.819: INFO: Created: latency-svc-z2m6s
May 21 04:23:34.842: INFO: Got endpoints: latency-svc-2czv4 [746.714817ms]
May 21 04:23:34.866: INFO: Created: latency-svc-ljmzs
May 21 04:23:34.896: INFO: Got endpoints: latency-svc-sw5rr [754.952653ms]
May 21 04:23:34.924: INFO: Created: latency-svc-5nrpx
May 21 04:23:34.942: INFO: Got endpoints: latency-svc-fvpmm [748.085183ms]
May 21 04:23:34.962: INFO: Created: latency-svc-d2pt5
May 21 04:23:34.996: INFO: Got endpoints: latency-svc-k9p8h [752.694588ms]
May 21 04:23:35.017: INFO: Created: latency-svc-c4fp4
May 21 04:23:35.044: INFO: Got endpoints: latency-svc-hh7hj [745.255559ms]
May 21 04:23:35.069: INFO: Created: latency-svc-99r4n
May 21 04:23:35.090: INFO: Got endpoints: latency-svc-mks8c [741.343035ms]
May 21 04:23:35.111: INFO: Created: latency-svc-4xjfx
May 21 04:23:35.143: INFO: Got endpoints: latency-svc-4fcsd [740.637689ms]
May 21 04:23:35.165: INFO: Created: latency-svc-czs9h
May 21 04:23:35.193: INFO: Got endpoints: latency-svc-r8wlc [734.943404ms]
May 21 04:23:35.215: INFO: Created: latency-svc-2t9sv
May 21 04:23:35.241: INFO: Got endpoints: latency-svc-tb9dz [745.214504ms]
May 21 04:23:35.263: INFO: Created: latency-svc-rxzdd
May 21 04:23:35.292: INFO: Got endpoints: latency-svc-l975w [750.144899ms]
May 21 04:23:35.314: INFO: Created: latency-svc-56zbg
May 21 04:23:35.342: INFO: Got endpoints: latency-svc-7mnq4 [748.950528ms]
May 21 04:23:35.366: INFO: Created: latency-svc-xkzmt
May 21 04:23:35.397: INFO: Got endpoints: latency-svc-545wm [754.568718ms]
May 21 04:23:35.418: INFO: Created: latency-svc-z4g9g
May 21 04:23:35.444: INFO: Got endpoints: latency-svc-gtvw6 [745.031173ms]
May 21 04:23:35.474: INFO: Created: latency-svc-gc6hr
May 21 04:23:35.491: INFO: Got endpoints: latency-svc-zwn6l [750.047917ms]
May 21 04:23:35.542: INFO: Got endpoints: latency-svc-z2m6s [751.273461ms]
May 21 04:23:35.573: INFO: Created: latency-svc-xrfcl
May 21 04:23:35.584: INFO: Created: latency-svc-vfkht
May 21 04:23:35.593: INFO: Got endpoints: latency-svc-ljmzs [750.735913ms]
May 21 04:23:35.621: INFO: Created: latency-svc-khhj2
May 21 04:23:35.641: INFO: Got endpoints: latency-svc-5nrpx [744.750462ms]
May 21 04:23:35.666: INFO: Created: latency-svc-62lds
May 21 04:23:35.694: INFO: Got endpoints: latency-svc-d2pt5 [752.24993ms]
May 21 04:23:35.715: INFO: Created: latency-svc-lz5lx
May 21 04:23:35.742: INFO: Got endpoints: latency-svc-c4fp4 [745.893621ms]
May 21 04:23:35.770: INFO: Created: latency-svc-hm7p8
May 21 04:23:35.791: INFO: Got endpoints: latency-svc-99r4n [746.909392ms]
May 21 04:23:35.809: INFO: Created: latency-svc-2nd76
May 21 04:23:35.842: INFO: Got endpoints: latency-svc-4xjfx [751.577987ms]
May 21 04:23:35.861: INFO: Created: latency-svc-m6fsq
May 21 04:23:35.896: INFO: Got endpoints: latency-svc-czs9h [753.254827ms]
May 21 04:23:35.927: INFO: Created: latency-svc-r8h2d
May 21 04:23:35.941: INFO: Got endpoints: latency-svc-2t9sv [747.783709ms]
May 21 04:23:35.971: INFO: Created: latency-svc-dskkq
May 21 04:23:35.991: INFO: Got endpoints: latency-svc-rxzdd [749.953282ms]
May 21 04:23:36.010: INFO: Created: latency-svc-ttfcj
May 21 04:23:36.042: INFO: Got endpoints: latency-svc-56zbg [750.080789ms]
May 21 04:23:36.070: INFO: Created: latency-svc-xx5w6
May 21 04:23:36.099: INFO: Got endpoints: latency-svc-xkzmt [756.855292ms]
May 21 04:23:36.119: INFO: Created: latency-svc-wp79l
May 21 04:23:36.144: INFO: Got endpoints: latency-svc-z4g9g [746.733511ms]
May 21 04:23:36.167: INFO: Created: latency-svc-lr66l
May 21 04:23:36.194: INFO: Got endpoints: latency-svc-gc6hr [749.860566ms]
May 21 04:23:36.214: INFO: Created: latency-svc-6w2bm
May 21 04:23:36.241: INFO: Got endpoints: latency-svc-xrfcl [750.315967ms]
May 21 04:23:36.264: INFO: Created: latency-svc-ffmdf
May 21 04:23:36.292: INFO: Got endpoints: latency-svc-vfkht [749.849372ms]
May 21 04:23:36.313: INFO: Created: latency-svc-cr6gf
May 21 04:23:36.343: INFO: Got endpoints: latency-svc-khhj2 [750.39403ms]
May 21 04:23:36.366: INFO: Created: latency-svc-lrwx9
May 21 04:23:36.394: INFO: Got endpoints: latency-svc-62lds [753.413765ms]
May 21 04:23:36.441: INFO: Got endpoints: latency-svc-lz5lx [746.329627ms]
May 21 04:23:36.493: INFO: Got endpoints: latency-svc-hm7p8 [750.957692ms]
May 21 04:23:36.541: INFO: Got endpoints: latency-svc-2nd76 [749.856795ms]
May 21 04:23:36.592: INFO: Got endpoints: latency-svc-m6fsq [750.826707ms]
May 21 04:23:36.643: INFO: Got endpoints: latency-svc-r8h2d [746.987548ms]
May 21 04:23:36.692: INFO: Got endpoints: latency-svc-dskkq [750.902772ms]
May 21 04:23:36.743: INFO: Got endpoints: latency-svc-ttfcj [752.015829ms]
May 21 04:23:36.792: INFO: Got endpoints: latency-svc-xx5w6 [749.602863ms]
May 21 04:23:36.850: INFO: Got endpoints: latency-svc-wp79l [750.989981ms]
May 21 04:23:36.893: INFO: Got endpoints: latency-svc-lr66l [748.970361ms]
May 21 04:23:36.943: INFO: Got endpoints: latency-svc-6w2bm [749.451928ms]
May 21 04:23:36.993: INFO: Got endpoints: latency-svc-ffmdf [752.068337ms]
May 21 04:23:37.046: INFO: Got endpoints: latency-svc-cr6gf [754.16344ms]
May 21 04:23:37.102: INFO: Got endpoints: latency-svc-lrwx9 [758.920829ms]
May 21 04:23:37.102: INFO: Latencies: [38.476011ms 62.372549ms 104.457665ms 122.855403ms 136.384706ms 158.670913ms 171.970604ms 190.237569ms 221.665708ms 237.082206ms 260.87503ms 278.713465ms 299.221484ms 321.816905ms 359.618971ms 361.188403ms 371.009361ms 373.135482ms 376.467793ms 382.313824ms 383.891796ms 384.165901ms 385.780531ms 387.28723ms 388.447132ms 389.344425ms 390.025549ms 390.343012ms 392.638317ms 393.619364ms 394.468155ms 395.44835ms 395.94347ms 398.043569ms 398.181066ms 399.012163ms 405.11194ms 406.83329ms 417.553456ms 417.845108ms 418.308503ms 420.769989ms 422.474453ms 424.688786ms 426.884785ms 428.156716ms 428.268455ms 428.274071ms 428.805071ms 430.723441ms 432.946019ms 433.066829ms 434.477785ms 435.419307ms 439.675322ms 443.722704ms 451.968603ms 452.035547ms 457.38662ms 459.82927ms 462.261487ms 467.755506ms 475.510724ms 479.749679ms 488.768344ms 496.628806ms 509.665571ms 512.748263ms 524.579598ms 536.982246ms 555.320507ms 574.774789ms 586.048565ms 596.983876ms 620.474941ms 623.465754ms 650.091409ms 670.49882ms 682.582047ms 715.240183ms 720.420939ms 728.083495ms 730.821998ms 733.047618ms 733.796176ms 734.943404ms 737.290559ms 739.052908ms 739.565507ms 740.637689ms 740.748836ms 741.343035ms 741.754703ms 741.956002ms 742.643177ms 743.047985ms 743.369818ms 743.987574ms 744.049637ms 744.320293ms 744.750462ms 744.750783ms 745.031173ms 745.194562ms 745.214504ms 745.255559ms 745.617821ms 745.695518ms 745.832478ms 745.893621ms 746.31399ms 746.329627ms 746.464987ms 746.714817ms 746.733511ms 746.776605ms 746.909392ms 746.987548ms 747.14328ms 747.183012ms 747.257755ms 747.348418ms 747.783709ms 748.017488ms 748.085183ms 748.134272ms 748.44272ms 748.63881ms 748.641914ms 748.906995ms 748.950528ms 748.970361ms 749.451928ms 749.602863ms 749.678152ms 749.849372ms 749.856795ms 749.860566ms 749.953282ms 750.047917ms 750.059302ms 750.080789ms 750.144899ms 750.192405ms 750.315967ms 750.39403ms 750.530797ms 750.735913ms 750.78056ms 750.826707ms 750.902772ms 750.957692ms 750.989981ms 750.992687ms 751.273461ms 751.281501ms 751.447304ms 751.49566ms 751.577987ms 751.649299ms 751.660121ms 751.708455ms 751.732819ms 752.015829ms 752.068337ms 752.237566ms 752.24993ms 752.694588ms 753.024485ms 753.183687ms 753.254827ms 753.405039ms 753.413765ms 753.669487ms 753.941603ms 754.016949ms 754.16344ms 754.280398ms 754.564282ms 754.568718ms 754.952653ms 755.180708ms 755.5157ms 756.511152ms 756.855292ms 758.920829ms 758.928664ms 759.083476ms 759.760984ms 761.073451ms 761.131867ms 763.204067ms 763.709506ms 765.173218ms 766.109184ms 767.649228ms 780.735852ms 826.574757ms 862.542511ms 927.870027ms]
May 21 04:23:37.102: INFO: 50 %ile: 744.750462ms
May 21 04:23:37.102: INFO: 90 %ile: 754.952653ms
May 21 04:23:37.102: INFO: 99 %ile: 862.542511ms
May 21 04:23:37.102: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:23:37.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9506" for this suite.
May 21 04:23:53.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:23:53.221: INFO: namespace svc-latency-9506 deletion completed in 16.109671159s

• [SLOW TEST:27.926 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:23:53.221: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-0c0ef499-4102-4f32-a717-f89d1adb0986
STEP: Creating a pod to test consume secrets
May 21 04:23:53.279: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776" in namespace "projected-3451" to be "success or failure"
May 21 04:23:53.281: INFO: Pod "pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776": Phase="Pending", Reason="", readiness=false. Elapsed: 2.766674ms
May 21 04:23:55.292: INFO: Pod "pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013035006s
STEP: Saw pod success
May 21 04:23:55.292: INFO: Pod "pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776" satisfied condition "success or failure"
May 21 04:23:55.295: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776 container secret-volume-test: <nil>
STEP: delete the pod
May 21 04:23:55.324: INFO: Waiting for pod pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776 to disappear
May 21 04:23:55.329: INFO: Pod pod-projected-secrets-34a962f6-75a0-454c-90b6-c72679f7e776 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:23:55.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3451" for this suite.
May 21 04:24:01.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:24:01.431: INFO: namespace projected-3451 deletion completed in 6.095844913s

• [SLOW TEST:8.210 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:24:01.431: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:24:12.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2579" for this suite.
May 21 04:24:18.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:24:18.666: INFO: namespace resourcequota-2579 deletion completed in 6.095934793s

• [SLOW TEST:17.235 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:24:18.667: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
May 21 04:24:18.707: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:24:21.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9110" for this suite.
May 21 04:24:27.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:24:27.684: INFO: namespace init-container-9110 deletion completed in 6.108288746s

• [SLOW TEST:9.018 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:24:27.686: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-7dsp
STEP: Creating a pod to test atomic-volume-subpath
May 21 04:24:27.755: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7dsp" in namespace "subpath-1747" to be "success or failure"
May 21 04:24:27.760: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Pending", Reason="", readiness=false. Elapsed: 5.161471ms
May 21 04:24:29.764: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009161685s
May 21 04:24:31.768: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 4.013202262s
May 21 04:24:33.772: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 6.016847805s
May 21 04:24:35.777: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 8.022404567s
May 21 04:24:37.781: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 10.025831492s
May 21 04:24:39.784: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 12.029241735s
May 21 04:24:41.788: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 14.032853879s
May 21 04:24:43.791: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 16.036063318s
May 21 04:24:45.795: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 18.039923858s
May 21 04:24:47.799: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Running", Reason="", readiness=true. Elapsed: 20.044325867s
May 21 04:24:49.803: INFO: Pod "pod-subpath-test-projected-7dsp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.04847946s
STEP: Saw pod success
May 21 04:24:49.803: INFO: Pod "pod-subpath-test-projected-7dsp" satisfied condition "success or failure"
May 21 04:24:49.806: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-subpath-test-projected-7dsp container test-container-subpath-projected-7dsp: <nil>
STEP: delete the pod
May 21 04:24:49.831: INFO: Waiting for pod pod-subpath-test-projected-7dsp to disappear
May 21 04:24:49.834: INFO: Pod pod-subpath-test-projected-7dsp no longer exists
STEP: Deleting pod pod-subpath-test-projected-7dsp
May 21 04:24:49.834: INFO: Deleting pod "pod-subpath-test-projected-7dsp" in namespace "subpath-1747"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:24:49.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1747" for this suite.
May 21 04:24:55.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:24:55.959: INFO: namespace subpath-1747 deletion completed in 6.117245413s

• [SLOW TEST:28.273 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:24:55.959: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
May 21 04:24:56.005: INFO: Waiting up to 5m0s for pod "pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39" in namespace "emptydir-6343" to be "success or failure"
May 21 04:24:56.008: INFO: Pod "pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.818001ms
May 21 04:24:58.012: INFO: Pod "pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006705436s
May 21 04:25:00.016: INFO: Pod "pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010961997s
STEP: Saw pod success
May 21 04:25:00.016: INFO: Pod "pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39" satisfied condition "success or failure"
May 21 04:25:00.018: INFO: Trying to get logs from node 9990-w-ax-1-1 pod pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39 container test-container: <nil>
STEP: delete the pod
May 21 04:25:00.044: INFO: Waiting for pod pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39 to disappear
May 21 04:25:00.047: INFO: Pod pod-c9758db5-3661-4b8a-8d9c-a5734a6e2e39 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:25:00.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6343" for this suite.
May 21 04:25:06.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:25:06.141: INFO: namespace emptydir-6343 deletion completed in 6.089271822s

• [SLOW TEST:10.182 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:25:06.142: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May 21 04:25:14.219: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:14.219: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:14.395: INFO: Exec stderr: ""
May 21 04:25:14.395: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:14.395: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:14.609: INFO: Exec stderr: ""
May 21 04:25:14.609: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:14.609: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:14.821: INFO: Exec stderr: ""
May 21 04:25:14.822: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:14.822: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:15.059: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May 21 04:25:15.060: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:15.060: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:15.244: INFO: Exec stderr: ""
May 21 04:25:15.244: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:15.244: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:15.455: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May 21 04:25:15.455: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:15.455: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:15.836: INFO: Exec stderr: ""
May 21 04:25:15.837: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:15.837: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:16.355: INFO: Exec stderr: ""
May 21 04:25:16.355: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:16.355: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:16.761: INFO: Exec stderr: ""
May 21 04:25:16.761: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8689 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May 21 04:25:16.761: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
May 21 04:25:17.397: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:25:17.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8689" for this suite.
May 21 04:26:01.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:26:01.491: INFO: namespace e2e-kubelet-etc-hosts-8689 deletion completed in 44.088322565s

• [SLOW TEST:55.349 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:26:01.492: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:26:32.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9621" for this suite.
May 21 04:26:38.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:26:38.797: INFO: namespace namespaces-9621 deletion completed in 6.106913039s
STEP: Destroying namespace "nsdeletetest-6809" for this suite.
May 21 04:26:38.799: INFO: Namespace nsdeletetest-6809 was already deleted
STEP: Destroying namespace "nsdeletetest-8443" for this suite.
May 21 04:26:44.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:26:44.895: INFO: namespace nsdeletetest-8443 deletion completed in 6.096469966s

• [SLOW TEST:43.403 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:26:44.895: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f4772c3e-94ac-466e-a0d4-b855395e202a
STEP: Creating a pod to test consume configMaps
May 21 04:26:44.947: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77" in namespace "configmap-9693" to be "success or failure"
May 21 04:26:44.951: INFO: Pod "pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77": Phase="Pending", Reason="", readiness=false. Elapsed: 4.147283ms
May 21 04:26:46.954: INFO: Pod "pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007638601s
May 21 04:26:48.958: INFO: Pod "pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011069049s
STEP: Saw pod success
May 21 04:26:48.958: INFO: Pod "pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77" satisfied condition "success or failure"
May 21 04:26:48.960: INFO: Trying to get logs from node 9990-w-ax-1-2 pod pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77 container configmap-volume-test: <nil>
STEP: delete the pod
May 21 04:26:48.989: INFO: Waiting for pod pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77 to disappear
May 21 04:26:48.993: INFO: Pod pod-configmaps-8b00cba0-ac94-4fdc-9bab-c6f3b76dbe77 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:26:48.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9693" for this suite.
May 21 04:26:55.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:26:55.091: INFO: namespace configmap-9693 deletion completed in 6.092804109s

• [SLOW TEST:10.196 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:26:55.092: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May 21 04:26:56.207: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May 21 04:26:58.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725632016, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725632016, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63725632016, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63725632016, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5cbd6679b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May 21 04:27:01.238: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:27:01.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5913" for this suite.
May 21 04:27:07.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:27:07.431: INFO: namespace webhook-5913 deletion completed in 6.085789032s
STEP: Destroying namespace "webhook-5913-markers" for this suite.
May 21 04:27:13.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:27:13.590: INFO: namespace webhook-5913-markers deletion completed in 6.158748256s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.512 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:27:13.604: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
May 21 04:27:13.648: INFO: Waiting up to 5m0s for pod "downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b" in namespace "downward-api-7604" to be "success or failure"
May 21 04:27:13.650: INFO: Pod "downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.239208ms
May 21 04:27:15.654: INFO: Pod "downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005946576s
STEP: Saw pod success
May 21 04:27:15.654: INFO: Pod "downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b" satisfied condition "success or failure"
May 21 04:27:15.656: INFO: Trying to get logs from node 9990-w-ax-1-2 pod downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b container dapi-container: <nil>
STEP: delete the pod
May 21 04:27:15.678: INFO: Waiting for pod downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b to disappear
May 21 04:27:15.681: INFO: Pod downward-api-280b18b3-5747-4f9e-bbb2-7d11580cd37b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:27:15.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7604" for this suite.
May 21 04:27:21.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:27:21.780: INFO: namespace downward-api-7604 deletion completed in 6.094536047s

• [SLOW TEST:8.176 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:27:21.780: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:27:21.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-818" for this suite.
May 21 04:27:27.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:27:27.946: INFO: namespace resourcequota-818 deletion completed in 6.096528319s

• [SLOW TEST:6.166 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:27:27.946: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May 21 04:27:32.094: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 04:27:32.097: INFO: Pod pod-with-poststart-http-hook still exists
May 21 04:27:34.097: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 04:27:34.102: INFO: Pod pod-with-poststart-http-hook still exists
May 21 04:27:36.097: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May 21 04:27:36.102: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:27:36.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8217" for this suite.
May 21 04:28:04.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:28:04.220: INFO: namespace container-lifecycle-hook-8217 deletion completed in 28.110047878s

• [SLOW TEST:36.274 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May 21 04:28:04.220: INFO: >>> kubeConfig: /tmp/kubeconfig-300851385
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
May 21 04:28:04.261: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May 21 04:28:04.278: INFO: Waiting for terminating namespaces to be deleted...
May 21 04:28:04.281: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-1 before test
May 21 04:28:04.302: INFO: nodelocaldns-xlwkg from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:28:04.302: INFO: kube-proxy-master-bp8ft from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 04:28:04.302: INFO: tiller-deploy-5c4b5664fc-v5w4x from kube-system started at 2020-05-21 01:47:34 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container tiller ready: true, restart count 0
May 21 04:28:04.302: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-7s9wb from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:28:04.302: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:28:04.302: INFO: wangsucloud-csi-nodeplugin-kxzmb from kube-system started at 2020-05-21 01:47:03 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container cinder ready: true, restart count 0
May 21 04:28:04.302: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:28:04.302: INFO: kube-proxy-worker-hm48s from kube-system started at 2020-05-21 01:45:18 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:28:04.302: INFO: kube-flannel-qfng7 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:28:04.302: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:28:04.302: INFO: ws-swift-79ff4f8c45-wp4s8 from kube-system started at 2020-05-21 01:47:37 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container swift ready: true, restart count 0
May 21 04:28:04.302: INFO: sonobuoy-e2e-job-53ec9ad4c8bc4eba from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.302: INFO: 	Container e2e ready: true, restart count 0
May 21 04:28:04.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May 21 04:28:04.302: INFO: 
Logging pods the kubelet thinks is on node 9990-w-ax-1-2 before test
May 21 04:28:04.312: INFO: kube-proxy-worker-w9vrh from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container kube-proxy-worker ready: true, restart count 0
May 21 04:28:04.312: INFO: sonobuoy from sonobuoy started at 2020-05-21 02:32:09 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May 21 04:28:04.312: INFO: kube-flannel-pxgt2 from kube-system started at 2020-05-21 01:46:20 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container install-cni ready: true, restart count 0
May 21 04:28:04.312: INFO: 	Container kube-flannel ready: true, restart count 0
May 21 04:28:04.312: INFO: wangsucloud-csi-nodeplugin-kmlr5 from kube-system started at 2020-05-21 01:47:09 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container cinder ready: true, restart count 0
May 21 04:28:04.312: INFO: 	Container driver-registrar ready: true, restart count 0
May 21 04:28:04.312: INFO: sonobuoy-systemd-logs-daemon-set-7b4a9471df0b4b01-fmn7w from sonobuoy started at 2020-05-21 02:32:10 +0000 UTC (2 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container sonobuoy-worker ready: true, restart count 1
May 21 04:28:04.312: INFO: 	Container systemd-logs ready: true, restart count 0
May 21 04:28:04.312: INFO: kube-proxy-master-bwlfx from kube-system started at 2020-05-21 01:45:30 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container kube-proxy-master ready: true, restart count 0
May 21 04:28:04.312: INFO: nodelocaldns-ljxj5 from kube-system started at 2020-05-21 01:47:22 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container node-cache ready: true, restart count 0
May 21 04:28:04.312: INFO: wangsu-cloud-controller-manager-58cd495b6b-vmxbk from kube-system started at 2020-05-21 01:46:33 +0000 UTC (1 container statuses recorded)
May 21 04:28:04.312: INFO: 	Container wangsu-cloud-controller-manager ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-95310708-14b8-4a4c-af96-a02a854dbf1f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-95310708-14b8-4a4c-af96-a02a854dbf1f off the node 9990-w-ax-1-2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-95310708-14b8-4a4c-af96-a02a854dbf1f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May 21 04:28:08.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8043" for this suite.
May 21 04:28:18.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
May 21 04:28:18.503: INFO: namespace sched-pred-8043 deletion completed in 10.096186472s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.283 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSMay 21 04:28:18.504: INFO: Running AfterSuite actions on all nodes
May 21 04:28:18.504: INFO: Running AfterSuite actions on node 1
May 21 04:28:18.504: INFO: Skipping dumping logs from cluster

Ran 274 of 4732 Specs in 6963.543 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4458 Skipped
PASS

Ginkgo ran 1 suite in 1h56m5.769402394s
Test Suite Passed
