I0505 11:17:13.713478      21 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-610752675
I0505 11:17:13.713499      21 test_context.go:419] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0505 11:17:13.713590      21 e2e.go:109] Starting e2e run "8d6cecca-6da0-4a1e-95c3-e0070a484aaf" on Ginkgo node 1
{"msg":"Test Suite starting","total":280,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1588677432 - Will randomize all specs
Will run 280 of 4842 specs

May  5 11:17:13.737: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:17:13.739: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
E0505 11:17:13.739773      21 progress.go:119] Failed to post progress update to http://localhost:8099/progress: Post http://localhost:8099/progress: dial tcp 127.0.0.1:8099: connect: connection refused
May  5 11:17:13.761: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
May  5 11:17:13.808: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
May  5 11:17:13.808: INFO: expected 7 pod replicas in namespace 'kube-system', 7 are Running and Ready.
May  5 11:17:13.808: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
May  5 11:17:13.818: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
May  5 11:17:13.818: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
May  5 11:17:13.818: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kubelet' (0 seconds elapsed)
May  5 11:17:13.818: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'pod-checkpointer' (0 seconds elapsed)
May  5 11:17:13.818: INFO: e2e test version: v1.17.4
May  5 11:17:13.820: INFO: kube-apiserver version: v1.17.4
May  5 11:17:13.820: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:17:13.824: INFO: Cluster IP family: ipv4
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:17:13.825: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
May  5 11:17:13.880: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
May  5 11:17:13.890: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-865eb8c1-251e-4358-8486-a2d9c81898cb
STEP: Creating a pod to test consume secrets
May  5 11:17:14.011: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9" in namespace "projected-1578" to be "success or failure"
May  5 11:17:14.014: INFO: Pod "pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.701829ms
May  5 11:17:16.017: INFO: Pod "pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005992201s
May  5 11:17:18.024: INFO: Pod "pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012476213s
STEP: Saw pod success
May  5 11:17:18.024: INFO: Pod "pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9" satisfied condition "success or failure"
May  5 11:17:18.028: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  5 11:17:18.057: INFO: Waiting for pod pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9 to disappear
May  5 11:17:18.061: INFO: Pod pod-projected-secrets-44fd3c30-e141-45ec-8456-889260bd9de9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:17:18.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1578" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":1,"skipped":8,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:17:18.071: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
May  5 11:17:19.244: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0505 11:17:19.244203      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:17:19.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-455" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":280,"completed":2,"skipped":13,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:17:19.251: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
May  5 11:17:21.938: INFO: Successfully updated pod "labelsupdatee3c4e919-7ed1-4d86-913f-c12f9ae94a23"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:17:25.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-474" for this suite.

• [SLOW TEST:6.720 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":3,"skipped":50,"failed":0}
SSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:17:25.972: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service nodeport-test with type=NodePort in namespace services-7439
STEP: creating replication controller nodeport-test in namespace services-7439
I0505 11:17:26.152105      21 runners.go:189] Created replication controller with name: nodeport-test, namespace: services-7439, replica count: 2
I0505 11:17:29.217820      21 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0505 11:17:32.222435      21 runners.go:189] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  5 11:17:32.222: INFO: Creating new exec pod
May  5 11:17:35.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-7439 execpodtwxgc -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
May  5 11:17:35.610: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
May  5 11:17:35.610: INFO: stdout: ""
May  5 11:17:35.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-7439 execpodtwxgc -- /bin/sh -x -c nc -zv -t -w 2 10.3.142.200 80'
May  5 11:17:35.804: INFO: stderr: "+ nc -zv -t -w 2 10.3.142.200 80\nConnection to 10.3.142.200 80 port [tcp/http] succeeded!\n"
May  5 11:17:35.804: INFO: stdout: ""
May  5 11:17:35.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-7439 execpodtwxgc -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.202 31540'
May  5 11:17:36.037: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.202 31540\nConnection to 10.0.27.202 31540 port [tcp/31540] succeeded!\n"
May  5 11:17:36.037: INFO: stdout: ""
May  5 11:17:36.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-7439 execpodtwxgc -- /bin/sh -x -c nc -zv -t -w 2 10.0.33.250 31540'
May  5 11:17:36.236: INFO: stderr: "+ nc -zv -t -w 2 10.0.33.250 31540\nConnection to 10.0.33.250 31540 port [tcp/31540] succeeded!\n"
May  5 11:17:36.236: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:17:36.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7439" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:10.273 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":280,"completed":4,"skipped":54,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:17:36.245: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-9809
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  5 11:17:36.384: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  5 11:18:00.489: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.232.8:8080/dial?request=hostname&protocol=udp&host=10.2.232.7&port=8081&tries=1'] Namespace:pod-network-test-9809 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:18:00.489: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:18:00.593: INFO: Waiting for responses: map[]
May  5 11:18:00.596: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.232.8:8080/dial?request=hostname&protocol=udp&host=10.2.169.5&port=8081&tries=1'] Namespace:pod-network-test-9809 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:18:00.596: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:18:00.699: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:18:00.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9809" for this suite.

• [SLOW TEST:24.462 seconds]
[sig-network] Networking
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":5,"skipped":61,"failed":0}
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:18:00.707: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:18:00.860: INFO: Create a RollingUpdate DaemonSet
May  5 11:18:00.864: INFO: Check that daemon pods launch on every node of the cluster
May  5 11:18:00.867: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:00.872: INFO: Number of nodes with available pods: 0
May  5 11:18:00.872: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:01.876: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:01.890: INFO: Number of nodes with available pods: 0
May  5 11:18:01.890: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:02.877: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:02.880: INFO: Number of nodes with available pods: 0
May  5 11:18:02.880: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:03.876: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:03.880: INFO: Number of nodes with available pods: 0
May  5 11:18:03.880: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:04.878: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:04.883: INFO: Number of nodes with available pods: 0
May  5 11:18:04.883: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:05.883: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:05.891: INFO: Number of nodes with available pods: 0
May  5 11:18:05.891: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:06.882: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:06.887: INFO: Number of nodes with available pods: 0
May  5 11:18:06.890: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:07.876: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:07.879: INFO: Number of nodes with available pods: 0
May  5 11:18:07.879: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:08.876: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:08.879: INFO: Number of nodes with available pods: 0
May  5 11:18:08.879: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:18:09.875: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:09.878: INFO: Number of nodes with available pods: 2
May  5 11:18:09.878: INFO: Number of running nodes: 2, number of available pods: 2
May  5 11:18:09.878: INFO: Update the DaemonSet to trigger a rollout
May  5 11:18:09.885: INFO: Updating DaemonSet daemon-set
May  5 11:18:21.900: INFO: Roll back the DaemonSet before rollout is complete
May  5 11:18:21.907: INFO: Updating DaemonSet daemon-set
May  5 11:18:21.908: INFO: Make sure DaemonSet rollback is complete
May  5 11:18:21.910: INFO: Wrong image for pod: daemon-set-lzlmj. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
May  5 11:18:21.911: INFO: Pod daemon-set-lzlmj is not available
May  5 11:18:21.915: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:22.919: INFO: Wrong image for pod: daemon-set-lzlmj. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
May  5 11:18:22.919: INFO: Pod daemon-set-lzlmj is not available
May  5 11:18:22.922: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:23.919: INFO: Wrong image for pod: daemon-set-lzlmj. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
May  5 11:18:23.919: INFO: Pod daemon-set-lzlmj is not available
May  5 11:18:23.921: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:18:24.919: INFO: Pod daemon-set-drq24 is not available
May  5 11:18:24.923: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3486, will wait for the garbage collector to delete the pods
May  5 11:18:24.987: INFO: Deleting DaemonSet.extensions daemon-set took: 5.175314ms
May  5 11:18:25.387: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.714342ms
May  5 11:18:29.200: INFO: Number of nodes with available pods: 0
May  5 11:18:29.200: INFO: Number of running nodes: 0, number of available pods: 0
May  5 11:18:29.204: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3486/daemonsets","resourceVersion":"3983"},"items":null}

May  5 11:18:29.208: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3486/pods","resourceVersion":"3983"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:18:29.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3486" for this suite.

• [SLOW TEST:28.517 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":280,"completed":6,"skipped":63,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:18:29.226: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
May  5 11:18:29.374: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7747 /api/v1/namespaces/watch-7747/configmaps/e2e-watch-test-watch-closed 6453f20e-6b00-472e-9485-14652e5ae689 3992 0 2020-05-05 11:18:29 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  5 11:18:29.374: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7747 /api/v1/namespaces/watch-7747/configmaps/e2e-watch-test-watch-closed 6453f20e-6b00-472e-9485-14652e5ae689 3993 0 2020-05-05 11:18:29 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
May  5 11:18:29.393: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7747 /api/v1/namespaces/watch-7747/configmaps/e2e-watch-test-watch-closed 6453f20e-6b00-472e-9485-14652e5ae689 3994 0 2020-05-05 11:18:29 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  5 11:18:29.393: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-7747 /api/v1/namespaces/watch-7747/configmaps/e2e-watch-test-watch-closed 6453f20e-6b00-472e-9485-14652e5ae689 3995 0 2020-05-05 11:18:29 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:18:29.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7747" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":280,"completed":7,"skipped":76,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:18:29.402: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-projected-crf9
STEP: Creating a pod to test atomic-volume-subpath
May  5 11:18:29.544: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-crf9" in namespace "subpath-9289" to be "success or failure"
May  5 11:18:29.552: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.378869ms
May  5 11:18:31.555: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.010586749s
May  5 11:18:33.558: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 4.013981739s
May  5 11:18:35.562: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 6.01778013s
May  5 11:18:37.566: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 8.021375225s
May  5 11:18:39.573: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 10.028676842s
May  5 11:18:41.576: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 12.031936918s
May  5 11:18:43.579: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 14.035011812s
May  5 11:18:45.583: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 16.038964629s
May  5 11:18:47.587: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 18.042282954s
May  5 11:18:49.590: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Running", Reason="", readiness=true. Elapsed: 20.045269847s
May  5 11:18:51.594: INFO: Pod "pod-subpath-test-projected-crf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.049496826s
STEP: Saw pod success
May  5 11:18:51.594: INFO: Pod "pod-subpath-test-projected-crf9" satisfied condition "success or failure"
May  5 11:18:51.597: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-subpath-test-projected-crf9 container test-container-subpath-projected-crf9: <nil>
STEP: delete the pod
May  5 11:18:51.618: INFO: Waiting for pod pod-subpath-test-projected-crf9 to disappear
May  5 11:18:51.621: INFO: Pod pod-subpath-test-projected-crf9 no longer exists
STEP: Deleting pod pod-subpath-test-projected-crf9
May  5 11:18:51.621: INFO: Deleting pod "pod-subpath-test-projected-crf9" in namespace "subpath-9289"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:18:51.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9289" for this suite.

• [SLOW TEST:22.229 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":280,"completed":8,"skipped":83,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:18:51.631: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:18:51.783: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40643889-9914-4500-b8b4-97478231e078" in namespace "downward-api-4728" to be "success or failure"
May  5 11:18:51.786: INFO: Pod "downwardapi-volume-40643889-9914-4500-b8b4-97478231e078": Phase="Pending", Reason="", readiness=false. Elapsed: 3.144539ms
May  5 11:18:53.790: INFO: Pod "downwardapi-volume-40643889-9914-4500-b8b4-97478231e078": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007175786s
STEP: Saw pod success
May  5 11:18:53.790: INFO: Pod "downwardapi-volume-40643889-9914-4500-b8b4-97478231e078" satisfied condition "success or failure"
May  5 11:18:53.793: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-40643889-9914-4500-b8b4-97478231e078 container client-container: <nil>
STEP: delete the pod
May  5 11:18:53.815: INFO: Waiting for pod downwardapi-volume-40643889-9914-4500-b8b4-97478231e078 to disappear
May  5 11:18:53.819: INFO: Pod downwardapi-volume-40643889-9914-4500-b8b4-97478231e078 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:18:53.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4728" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":9,"skipped":85,"failed":0}
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:18:53.831: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
May  5 11:18:54.250: INFO: Pod name wrapped-volume-race-b929d064-2786-497b-ae89-1d2968c23361: Found 3 pods out of 5
May  5 11:18:59.295: INFO: Pod name wrapped-volume-race-b929d064-2786-497b-ae89-1d2968c23361: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b929d064-2786-497b-ae89-1d2968c23361 in namespace emptydir-wrapper-6517, will wait for the garbage collector to delete the pods
May  5 11:19:07.382: INFO: Deleting ReplicationController wrapped-volume-race-b929d064-2786-497b-ae89-1d2968c23361 took: 14.954604ms
May  5 11:19:07.786: INFO: Terminating ReplicationController wrapped-volume-race-b929d064-2786-497b-ae89-1d2968c23361 pods took: 404.710354ms
STEP: Creating RC which spawns configmap-volume pods
May  5 11:19:25.683: INFO: Pod name wrapped-volume-race-81bc1fd2-689f-4765-bd9f-21561c5a0001: Found 1 pods out of 5
May  5 11:19:30.689: INFO: Pod name wrapped-volume-race-81bc1fd2-689f-4765-bd9f-21561c5a0001: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-81bc1fd2-689f-4765-bd9f-21561c5a0001 in namespace emptydir-wrapper-6517, will wait for the garbage collector to delete the pods
May  5 11:19:42.764: INFO: Deleting ReplicationController wrapped-volume-race-81bc1fd2-689f-4765-bd9f-21561c5a0001 took: 5.141529ms
May  5 11:19:43.165: INFO: Terminating ReplicationController wrapped-volume-race-81bc1fd2-689f-4765-bd9f-21561c5a0001 pods took: 401.267448ms
STEP: Creating RC which spawns configmap-volume pods
May  5 11:19:56.492: INFO: Pod name wrapped-volume-race-b8eba14b-f8bd-461b-b09b-a58b0425b6ca: Found 0 pods out of 5
May  5 11:20:01.519: INFO: Pod name wrapped-volume-race-b8eba14b-f8bd-461b-b09b-a58b0425b6ca: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b8eba14b-f8bd-461b-b09b-a58b0425b6ca in namespace emptydir-wrapper-6517, will wait for the garbage collector to delete the pods
May  5 11:20:13.611: INFO: Deleting ReplicationController wrapped-volume-race-b8eba14b-f8bd-461b-b09b-a58b0425b6ca took: 8.502738ms
May  5 11:20:14.011: INFO: Terminating ReplicationController wrapped-volume-race-b8eba14b-f8bd-461b-b09b-a58b0425b6ca pods took: 400.380001ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:20:31.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6517" for this suite.

• [SLOW TEST:97.773 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":280,"completed":10,"skipped":86,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:20:31.605: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:20:31.754: INFO: Waiting up to 5m0s for pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c" in namespace "security-context-test-5297" to be "success or failure"
May  5 11:20:31.757: INFO: Pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.800566ms
May  5 11:20:33.761: INFO: Pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006948871s
May  5 11:20:35.768: INFO: Pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014069703s
May  5 11:20:37.772: INFO: Pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018144268s
May  5 11:20:37.772: INFO: Pod "busybox-user-65534-35cb722c-fe59-43c9-9f2a-74c99785348c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:20:37.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5297" for this suite.

• [SLOW TEST:6.174 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  When creating a container with runAsUser
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:43
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":11,"skipped":145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:20:37.780: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service multi-endpoint-test in namespace services-4903
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4903 to expose endpoints map[]
May  5 11:20:37.919: INFO: successfully validated that service multi-endpoint-test in namespace services-4903 exposes endpoints map[] (3.723678ms elapsed)
STEP: Creating pod pod1 in namespace services-4903
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4903 to expose endpoints map[pod1:[100]]
May  5 11:20:40.964: INFO: successfully validated that service multi-endpoint-test in namespace services-4903 exposes endpoints map[pod1:[100]] (3.033340677s elapsed)
STEP: Creating pod pod2 in namespace services-4903
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4903 to expose endpoints map[pod1:[100] pod2:[101]]
May  5 11:20:43.051: INFO: successfully validated that service multi-endpoint-test in namespace services-4903 exposes endpoints map[pod1:[100] pod2:[101]] (2.0707788s elapsed)
STEP: Deleting pod pod1 in namespace services-4903
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4903 to expose endpoints map[pod2:[101]]
May  5 11:20:43.072: INFO: successfully validated that service multi-endpoint-test in namespace services-4903 exposes endpoints map[pod2:[101]] (13.434431ms elapsed)
STEP: Deleting pod pod2 in namespace services-4903
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4903 to expose endpoints map[]
May  5 11:20:44.110: INFO: successfully validated that service multi-endpoint-test in namespace services-4903 exposes endpoints map[] (1.01842842s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:20:44.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4903" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:6.366 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":280,"completed":12,"skipped":178,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:20:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1357
STEP: creating an pod
May  5 11:20:44.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.8 --namespace=kubectl-1267 -- logs-generator --log-lines-total 100 --run-duration 20s'
May  5 11:20:44.399: INFO: stderr: ""
May  5 11:20:44.399: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Waiting for log generator to start.
May  5 11:20:44.399: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
May  5 11:20:44.399: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1267" to be "running and ready, or succeeded"
May  5 11:20:44.404: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.799302ms
May  5 11:20:46.408: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.008781093s
May  5 11:20:46.408: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
May  5 11:20:46.408: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
May  5 11:20:46.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267'
May  5 11:20:46.599: INFO: stderr: ""
May  5 11:20:46.599: INFO: stdout: "I0505 11:20:45.320941       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/skq 541\nI0505 11:20:45.521071       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/6ggt 265\nI0505 11:20:45.721090       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/qn25 264\nI0505 11:20:45.921056       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/7bnx 573\nI0505 11:20:46.121101       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/5mw 399\nI0505 11:20:46.321059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/5th 330\nI0505 11:20:46.521095       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/zcz 349\n"
STEP: limiting log lines
May  5 11:20:46.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267 --tail=1'
May  5 11:20:46.706: INFO: stderr: ""
May  5 11:20:46.706: INFO: stdout: "I0505 11:20:46.521095       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/zcz 349\n"
May  5 11:20:46.706: INFO: got output "I0505 11:20:46.521095       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/zcz 349\n"
STEP: limiting log bytes
May  5 11:20:46.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267 --limit-bytes=1'
May  5 11:20:46.844: INFO: stderr: ""
May  5 11:20:46.844: INFO: stdout: "I"
May  5 11:20:46.844: INFO: got output "I"
STEP: exposing timestamps
May  5 11:20:46.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267 --tail=1 --timestamps'
May  5 11:20:46.968: INFO: stderr: ""
May  5 11:20:46.968: INFO: stdout: "2020-05-05T11:20:46.921229297Z I0505 11:20:46.921100       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/8kw 276\n"
May  5 11:20:46.968: INFO: got output "2020-05-05T11:20:46.921229297Z I0505 11:20:46.921100       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/8kw 276\n"
STEP: restricting to a time range
May  5 11:20:49.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267 --since=1s'
May  5 11:20:49.668: INFO: stderr: ""
May  5 11:20:49.668: INFO: stdout: "I0505 11:20:48.721061       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/sdf 425\nI0505 11:20:48.921096       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/v2br 461\nI0505 11:20:49.121065       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/cqf 420\nI0505 11:20:49.321154       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/gcx 482\nI0505 11:20:49.521068       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/9jwl 256\n"
May  5 11:20:49.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs logs-generator logs-generator --namespace=kubectl-1267 --since=24h'
May  5 11:20:49.761: INFO: stderr: ""
May  5 11:20:49.761: INFO: stdout: "I0505 11:20:45.320941       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/skq 541\nI0505 11:20:45.521071       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/6ggt 265\nI0505 11:20:45.721090       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/qn25 264\nI0505 11:20:45.921056       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/7bnx 573\nI0505 11:20:46.121101       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/5mw 399\nI0505 11:20:46.321059       1 logs_generator.go:76] 5 GET /api/v1/namespaces/ns/pods/5th 330\nI0505 11:20:46.521095       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/zcz 349\nI0505 11:20:46.721059       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/df4 284\nI0505 11:20:46.921100       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/8kw 276\nI0505 11:20:47.121056       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/dhw 453\nI0505 11:20:47.321054       1 logs_generator.go:76] 10 POST /api/v1/namespaces/kube-system/pods/g9wk 390\nI0505 11:20:47.521095       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/kt6 267\nI0505 11:20:47.721094       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/6szl 252\nI0505 11:20:47.921112       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/db2 234\nI0505 11:20:48.121095       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/rdm 284\nI0505 11:20:48.321092       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/n99q 571\nI0505 11:20:48.521085       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/rclx 268\nI0505 11:20:48.721061       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/sdf 425\nI0505 11:20:48.921096       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/v2br 461\nI0505 11:20:49.121065       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/cqf 420\nI0505 11:20:49.321154       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/gcx 482\nI0505 11:20:49.521068       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/9jwl 256\nI0505 11:20:49.721152       1 logs_generator.go:76] 22 GET /api/v1/namespaces/default/pods/scf 218\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1363
May  5 11:20:49.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete pod logs-generator --namespace=kubectl-1267'
May  5 11:21:01.107: INFO: stderr: ""
May  5 11:21:01.107: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:21:01.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1267" for this suite.

• [SLOW TEST:16.964 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1353
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":280,"completed":13,"skipped":184,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:21:01.115: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
May  5 11:21:01.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-2709'
May  5 11:21:01.584: INFO: stderr: ""
May  5 11:21:01.584: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May  5 11:21:02.587: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:21:02.587: INFO: Found 0 / 1
May  5 11:21:03.588: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:21:03.589: INFO: Found 1 / 1
May  5 11:21:03.589: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
May  5 11:21:03.593: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:21:03.593: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  5 11:21:03.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 patch pod agnhost-master-lxwvc --namespace=kubectl-2709 -p {"metadata":{"annotations":{"x":"y"}}}'
May  5 11:21:03.877: INFO: stderr: ""
May  5 11:21:03.877: INFO: stdout: "pod/agnhost-master-lxwvc patched\n"
STEP: checking annotations
May  5 11:21:03.884: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:21:03.884: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:21:03.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2709" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":280,"completed":14,"skipped":197,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:21:03.892: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3527
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-3527
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3527
STEP: Creating statefulset with conflicting port in namespace statefulset-3527
STEP: Waiting until pod test-pod will start running in namespace statefulset-3527
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3527
May  5 11:21:08.067: INFO: Observed stateful pod in namespace: statefulset-3527, name: ss-0, uid: b2e01839-43a5-4921-b518-eb9ce7c59cd5, status phase: Pending. Waiting for statefulset controller to delete.
May  5 11:21:08.261: INFO: Observed stateful pod in namespace: statefulset-3527, name: ss-0, uid: b2e01839-43a5-4921-b518-eb9ce7c59cd5, status phase: Failed. Waiting for statefulset controller to delete.
May  5 11:21:08.273: INFO: Observed stateful pod in namespace: statefulset-3527, name: ss-0, uid: b2e01839-43a5-4921-b518-eb9ce7c59cd5, status phase: Failed. Waiting for statefulset controller to delete.
May  5 11:21:08.273: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3527
STEP: Removing pod with conflicting port in namespace statefulset-3527
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3527 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 11:21:12.392: INFO: Deleting all statefulset in ns statefulset-3527
May  5 11:21:12.395: INFO: Scaling statefulset ss to 0
May  5 11:21:32.409: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:21:32.412: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:21:32.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3527" for this suite.

• [SLOW TEST:28.537 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":280,"completed":15,"skipped":212,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:21:32.431: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:21:39.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8343" for this suite.

• [SLOW TEST:7.209 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":280,"completed":16,"skipped":213,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:21:39.643: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4479
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
May  5 11:21:39.789: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:21:56.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4479" for this suite.

• [SLOW TEST:16.604 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":280,"completed":17,"skipped":238,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:21:56.248: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
May  5 11:21:58.972: INFO: Successfully updated pod "annotationupdatee69b8d06-970e-4e7c-9f20-62982cdc8a1a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:22:01.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8544" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":18,"skipped":243,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:22:01.027: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:22:01.167: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
May  5 11:22:01.174: INFO: Pod name sample-pod: Found 0 pods out of 1
May  5 11:22:06.191: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  5 11:22:06.191: INFO: Creating deployment "test-rolling-update-deployment"
May  5 11:22:06.196: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
May  5 11:22:06.205: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
May  5 11:22:08.217: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
May  5 11:22:08.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274526, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274526, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274526, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274526, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 11:22:10.247: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
May  5 11:22:10.258: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-6102 /apis/apps/v1/namespaces/deployment-6102/deployments/test-rolling-update-deployment 00f14ec8-c04c-48aa-88f4-c6cd24617830 6048 1 2020-05-05 11:22:06 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e744c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-05 11:22:06 +0000 UTC,LastTransitionTime:2020-05-05 11:22:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67cf4f6444" has successfully progressed.,LastUpdateTime:2020-05-05 11:22:08 +0000 UTC,LastTransitionTime:2020-05-05 11:22:06 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  5 11:22:10.261: INFO: New ReplicaSet "test-rolling-update-deployment-67cf4f6444" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67cf4f6444  deployment-6102 /apis/apps/v1/namespaces/deployment-6102/replicasets/test-rolling-update-deployment-67cf4f6444 fdd38954-97c5-44bc-a610-e2417c8793ad 6038 1 2020-05-05 11:22:06 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 00f14ec8-c04c-48aa-88f4-c6cd24617830 0xc002f34757 0xc002f34758}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67cf4f6444,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002f34848 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  5 11:22:10.261: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
May  5 11:22:10.261: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-6102 /apis/apps/v1/namespaces/deployment-6102/replicasets/test-rolling-update-controller 87855a73-57d7-4042-a5ab-6dc9fdd81bc2 6047 2 2020-05-05 11:22:01 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 00f14ec8-c04c-48aa-88f4-c6cd24617830 0xc002f3466f 0xc002f34690}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002f346f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 11:22:10.264: INFO: Pod "test-rolling-update-deployment-67cf4f6444-msbw9" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67cf4f6444-msbw9 test-rolling-update-deployment-67cf4f6444- deployment-6102 /api/v1/namespaces/deployment-6102/pods/test-rolling-update-deployment-67cf4f6444-msbw9 1f376338-3ece-4a7a-ba5a-553d347acdaf 6037 0 2020-05-05 11:22:06 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[cni.projectcalico.org/podIP:10.2.169.20/32 cni.projectcalico.org/podIPs:10.2.169.20/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-67cf4f6444 fdd38954-97c5-44bc-a610-e2417c8793ad 0xc002f350f7 0xc002f350f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-njtx2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-njtx2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-njtx2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:22:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:22:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:22:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:22:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.20,StartTime:2020-05-05 11:22:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:22:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://493cb45071bbe7f6498a8ad13b66c4e5ea8e1576acd056ad57e2906516faedd9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.20,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:22:10.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6102" for this suite.

• [SLOW TEST:9.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":19,"skipped":283,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:22:10.275: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:22:11.496: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:22:13.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274531, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274531, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274531, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274531, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:22:16.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:22:16.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-622" for this suite.
STEP: Destroying namespace "webhook-622-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.465 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":280,"completed":20,"skipped":296,"failed":0}
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:22:16.740: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating secret secrets-6679/secret-test-b567093b-ef4e-4ce2-8571-19a59638c3ad
STEP: Creating a pod to test consume secrets
May  5 11:22:16.914: INFO: Waiting up to 5m0s for pod "pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05" in namespace "secrets-6679" to be "success or failure"
May  5 11:22:16.922: INFO: Pod "pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05": Phase="Pending", Reason="", readiness=false. Elapsed: 7.296822ms
May  5 11:22:18.925: INFO: Pod "pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010507647s
STEP: Saw pod success
May  5 11:22:18.925: INFO: Pod "pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05" satisfied condition "success or failure"
May  5 11:22:18.928: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05 container env-test: <nil>
STEP: delete the pod
May  5 11:22:18.945: INFO: Waiting for pod pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05 to disappear
May  5 11:22:18.948: INFO: Pod pod-configmaps-d3670ee6-fda4-47d0-a4c7-3b9a7d161a05 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:22:18.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6679" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":21,"skipped":298,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:22:18.954: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:22:19.477: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:22:22.493: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
May  5 11:22:22.524: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:22:22.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2648" for this suite.
STEP: Destroying namespace "webhook-2648-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":280,"completed":22,"skipped":314,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:22:22.718: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-121
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-121
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-121
May  5 11:22:22.884: INFO: Found 0 stateful pods, waiting for 1
May  5 11:22:32.889: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
May  5 11:22:32.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:22:33.140: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:22:33.140: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:22:33.140: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:22:33.147: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  5 11:22:43.151: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:22:43.151: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:22:43.166: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999731s
May  5 11:22:44.169: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993731698s
May  5 11:22:45.173: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.989644997s
May  5 11:22:46.179: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.984779772s
May  5 11:22:47.182: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.980821356s
May  5 11:22:48.186: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.977268734s
May  5 11:22:49.191: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.973532046s
May  5 11:22:50.195: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.967406586s
May  5 11:22:51.198: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.963898921s
May  5 11:22:52.202: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.951722ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-121
May  5 11:22:53.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:22:53.438: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:22:53.438: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:22:53.438: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:22:53.442: INFO: Found 1 stateful pods, waiting for 3
May  5 11:23:03.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:23:03.446: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:23:03.446: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
May  5 11:23:03.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:23:03.672: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:23:03.672: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:23:03.672: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:23:03.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:23:03.957: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:23:03.957: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:23:03.957: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:23:03.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:23:04.208: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:23:04.208: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:23:04.208: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:23:04.208: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:23:04.211: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
May  5 11:23:14.217: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:23:14.217: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:23:14.217: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:23:14.232: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999587s
May  5 11:23:15.237: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991966327s
May  5 11:23:16.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.987306115s
May  5 11:23:17.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.983912268s
May  5 11:23:18.247: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980493194s
May  5 11:23:19.251: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976656289s
May  5 11:23:20.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972748503s
May  5 11:23:21.258: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.969118954s
May  5 11:23:22.262: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965423189s
May  5 11:23:23.266: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.816791ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-121
May  5 11:23:24.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:23:24.472: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:23:24.472: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:23:24.472: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:23:24.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:23:24.713: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:23:24.713: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:23:24.713: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:23:24.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-121 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:23:24.908: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:23:24.908: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:23:24.908: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:23:24.908: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 11:23:44.921: INFO: Deleting all statefulset in ns statefulset-121
May  5 11:23:44.924: INFO: Scaling statefulset ss to 0
May  5 11:23:44.934: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:23:44.937: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:23:44.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-121" for this suite.

• [SLOW TEST:82.238 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":280,"completed":23,"skipped":351,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:23:44.956: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5416
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
May  5 11:23:45.100: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
May  5 11:23:57.792: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:24:01.343: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:14.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5416" for this suite.

• [SLOW TEST:29.341 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":280,"completed":24,"skipped":380,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:14.299: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  5 11:24:16.479: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:16.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6580" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":25,"skipped":397,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:16.526: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7156 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7156;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7156 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7156;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7156.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7156.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7156.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7156.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7156.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7156.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7156.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7156.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7156.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.39.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.39.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.39.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.39.183_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7156 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7156;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7156 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7156;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7156.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7156.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7156.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7156.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7156.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7156.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7156.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7156.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7156.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7156.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 183.39.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.39.183_udp@PTR;check="$$(dig +tcp +noall +answer +search 183.39.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.39.183_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 11:24:28.725: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.729: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.732: INFO: Unable to read wheezy_udp@dns-test-service.dns-7156 from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.735: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7156 from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.738: INFO: Unable to read wheezy_udp@dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.742: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.745: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.771: INFO: Unable to read jessie_udp@dns-test-service from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.774: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.778: INFO: Unable to read jessie_udp@dns-test-service.dns-7156 from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.784: INFO: Unable to read jessie_tcp@dns-test-service.dns-7156 from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.787: INFO: Unable to read jessie_udp@dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.791: INFO: Unable to read jessie_tcp@dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.794: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7156.svc from pod dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610: the server could not find the requested resource (get pods dns-test-901728d5-d992-45b7-909c-fc7abc732610)
May  5 11:24:28.818: INFO: Lookups using dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-7156 wheezy_tcp@dns-test-service.dns-7156 wheezy_udp@dns-test-service.dns-7156.svc wheezy_tcp@dns-test-service.dns-7156.svc wheezy_udp@_http._tcp.dns-test-service.dns-7156.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-7156 jessie_tcp@dns-test-service.dns-7156 jessie_udp@dns-test-service.dns-7156.svc jessie_tcp@dns-test-service.dns-7156.svc jessie_udp@_http._tcp.dns-test-service.dns-7156.svc]

May  5 11:24:34.139: INFO: DNS probes using dns-7156/dns-test-901728d5-d992-45b7-909c-fc7abc732610 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:34.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7156" for this suite.

• [SLOW TEST:17.835 seconds]
[sig-network] DNS
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":280,"completed":26,"skipped":406,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:34.361: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
May  5 11:24:34.620: INFO: Waiting up to 5m0s for pod "downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec" in namespace "downward-api-6143" to be "success or failure"
May  5 11:24:34.628: INFO: Pod "downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec": Phase="Pending", Reason="", readiness=false. Elapsed: 8.684422ms
May  5 11:24:36.635: INFO: Pod "downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014845896s
STEP: Saw pod success
May  5 11:24:36.635: INFO: Pod "downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec" satisfied condition "success or failure"
May  5 11:24:36.638: INFO: Trying to get logs from node ip-10-0-27-202 pod downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec container dapi-container: <nil>
STEP: delete the pod
May  5 11:24:36.664: INFO: Waiting for pod downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec to disappear
May  5 11:24:36.666: INFO: Pod downward-api-6a8ee25a-f37a-4a55-8b4a-48ac04ef5cec no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:36.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6143" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":280,"completed":27,"skipped":433,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:36.673: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1754
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 11:24:36.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1808'
May  5 11:24:36.946: INFO: stderr: ""
May  5 11:24:36.946: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1759
May  5 11:24:36.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete pods e2e-test-httpd-pod --namespace=kubectl-1808'
May  5 11:24:51.109: INFO: stderr: ""
May  5 11:24:51.109: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:51.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1808" for this suite.

• [SLOW TEST:14.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1750
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":280,"completed":28,"skipped":444,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:51.118: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7176
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-27159042-8991-424b-a8d6-6ea27291bedb
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-27159042-8991-424b-a8d6-6ea27291bedb
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:55.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7176" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":29,"skipped":490,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:55.333: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
May  5 11:24:55.524: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  5 11:24:55.540: INFO: Waiting for terminating namespaces to be deleted...
May  5 11:24:55.543: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-27-202 before test
May  5 11:24:55.562: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:24:55.562: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:24:55.562: INFO: calico-node-v6vzp from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:24:55.562: INFO: sonobuoy from sonobuoy started at 2020-05-05 11:16:48 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  5 11:24:55.562: INFO: pod-configmaps-46f39a43-fe68-49ca-ac6f-79761f9e904c from configmap-7176 started at 2020-05-05 11:24:51 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container configmap-volume-test ready: true, restart count 0
May  5 11:24:55.562: INFO: kube-proxy-m47jv from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:24:55.562: INFO: kubelet-99g5h from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.562: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:24:55.562: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-33-250 before test
May  5 11:24:55.583: INFO: coredns-6f64b7db7-z5b8s from kube-system started at 2020-05-05 11:00:47 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container coredns ready: true, restart count 0
May  5 11:24:55.583: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:24:55.583: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:24:55.583: INFO: calico-node-579x2 from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:24:55.583: INFO: kubelet-8cl8p from kube-system started at 2020-05-05 11:00:18 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:24:55.583: INFO: kube-proxy-8nsbj from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:24:55.583: INFO: sonobuoy-e2e-job-0f2dbdcc56724f7f from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:24:55.583: INFO: 	Container e2e ready: true, restart count 0
May  5 11:24:55.583: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: verifying the node has the label node ip-10-0-27-202
STEP: verifying the node has the label node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod pod-configmaps-46f39a43-fe68-49ca-ac6f-79761f9e904c requesting resource cpu=0m on Node ip-10-0-27-202
May  5 11:24:55.617: INFO: Pod calico-node-579x2 requesting resource cpu=150m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod calico-node-v6vzp requesting resource cpu=150m on Node ip-10-0-27-202
May  5 11:24:55.617: INFO: Pod coredns-6f64b7db7-z5b8s requesting resource cpu=100m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod kube-proxy-8nsbj requesting resource cpu=0m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod kube-proxy-m47jv requesting resource cpu=0m on Node ip-10-0-27-202
May  5 11:24:55.617: INFO: Pod kubelet-8cl8p requesting resource cpu=0m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod kubelet-99g5h requesting resource cpu=0m on Node ip-10-0-27-202
May  5 11:24:55.617: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-27-202
May  5 11:24:55.617: INFO: Pod sonobuoy-e2e-job-0f2dbdcc56724f7f requesting resource cpu=0m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd requesting resource cpu=0m on Node ip-10-0-33-250
May  5 11:24:55.617: INFO: Pod sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd requesting resource cpu=0m on Node ip-10-0-27-202
STEP: Starting Pods to consume most of the cluster CPU.
May  5 11:24:55.617: INFO: Creating a pod which consumes cpu=1295m on Node ip-10-0-27-202
May  5 11:24:55.627: INFO: Creating a pod which consumes cpu=1225m on Node ip-10-0-33-250
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb.160c1e210057f9f0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2918/filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb to ip-10-0-33-250]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb.160c1e213494825f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb.160c1e2137ca45e8], Reason = [Created], Message = [Created container filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb.160c1e213f36a762], Reason = [Started], Message = [Started container filler-pod-450cf3a7-8bd6-40d5-b969-68a8d24e49bb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7.160c1e20ffeece0f], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2918/filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7 to ip-10-0-27-202]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7.160c1e212de6deff], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7.160c1e213154ab99], Reason = [Created], Message = [Created container filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7.160c1e2138754e38], Reason = [Started], Message = [Started container filler-pod-74df73f7-f1f1-4e2a-99e6-970102541bc7]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.160c1e217846a973], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-27-202
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-33-250
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:24:58.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2918" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":280,"completed":30,"skipped":509,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:24:58.701: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-2bafa108-7692-47d4-b3b6-6949f267a63a
STEP: Creating a pod to test consume configMaps
May  5 11:24:58.861: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1" in namespace "projected-7807" to be "success or failure"
May  5 11:24:58.869: INFO: Pod "pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.31027ms
May  5 11:25:00.872: INFO: Pod "pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0111457s
STEP: Saw pod success
May  5 11:25:00.873: INFO: Pod "pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1" satisfied condition "success or failure"
May  5 11:25:00.875: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:25:00.891: INFO: Waiting for pod pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1 to disappear
May  5 11:25:00.894: INFO: Pod pod-projected-configmaps-39d17f6e-ac44-4f71-82db-9e1c154adce1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:00.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7807" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":31,"skipped":509,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:00.904: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:25:01.896: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:25:03.918: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274701, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274701, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274701, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274701, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:25:06.958: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:07.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6811" for this suite.
STEP: Destroying namespace "webhook-6811-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.223 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":280,"completed":32,"skipped":522,"failed":0}
SS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:07.126: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-8962
STEP: Creating secret with name secret-test-319be92b-2b45-4544-869f-201b43733756
STEP: Creating a pod to test consume secrets
May  5 11:25:07.428: INFO: Waiting up to 5m0s for pod "pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd" in namespace "secrets-1982" to be "success or failure"
May  5 11:25:07.433: INFO: Pod "pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.903917ms
May  5 11:25:09.448: INFO: Pod "pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018483057s
May  5 11:25:11.452: INFO: Pod "pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023335215s
STEP: Saw pod success
May  5 11:25:11.453: INFO: Pod "pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd" satisfied condition "success or failure"
May  5 11:25:11.456: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd container secret-volume-test: <nil>
STEP: delete the pod
May  5 11:25:11.483: INFO: Waiting for pod pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd to disappear
May  5 11:25:11.488: INFO: Pod pod-secrets-ffebde5e-a4bb-4c68-98c8-eb7f845f3dcd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:11.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1982" for this suite.
STEP: Destroying namespace "secret-namespace-8962" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":280,"completed":33,"skipped":524,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:11.505: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-c3c54f1c-62dc-4b5d-b8b5-513e21518330
STEP: Creating a pod to test consume secrets
May  5 11:25:11.672: INFO: Waiting up to 5m0s for pod "pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd" in namespace "secrets-1517" to be "success or failure"
May  5 11:25:11.678: INFO: Pod "pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.738903ms
May  5 11:25:13.681: INFO: Pod "pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008776291s
STEP: Saw pod success
May  5 11:25:13.681: INFO: Pod "pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd" satisfied condition "success or failure"
May  5 11:25:13.684: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd container secret-volume-test: <nil>
STEP: delete the pod
May  5 11:25:13.700: INFO: Waiting for pod pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd to disappear
May  5 11:25:13.703: INFO: Pod pod-secrets-3fa7ebd5-50ca-4aac-8a51-a84c014231dd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:13.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1517" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":34,"skipped":536,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:13.717: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:25:14.570: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:25:16.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274714, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274714, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274714, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274714, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:25:19.599: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:19.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4600" for this suite.
STEP: Destroying namespace "webhook-4600-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.037 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":280,"completed":35,"skipped":540,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:19.757: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8625
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:25:19.920: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:22.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8625" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":280,"completed":36,"skipped":545,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:22.728: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7791
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7791
STEP: creating replication controller externalsvc in namespace services-7791
I0505 11:25:23.118480      21 runners.go:189] Created replication controller with name: externalsvc, namespace: services-7791, replica count: 2
I0505 11:25:26.171039      21 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
May  5 11:25:26.185: INFO: Creating new exec pod
May  5 11:25:28.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-7791 execpod7kj4f -- /bin/sh -x -c nslookup nodeport-service'
May  5 11:25:28.403: INFO: stderr: "+ nslookup nodeport-service\n"
May  5 11:25:28.403: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nnodeport-service.services-7791.svc.cluster.local\tcanonical name = externalsvc.services-7791.svc.cluster.local.\nName:\texternalsvc.services-7791.svc.cluster.local\nAddress: 10.3.233.240\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7791, will wait for the garbage collector to delete the pods
May  5 11:25:28.462: INFO: Deleting ReplicationController externalsvc took: 6.03563ms
May  5 11:25:28.562: INFO: Terminating ReplicationController externalsvc pods took: 100.172076ms
May  5 11:25:41.194: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:41.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7791" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:18.509 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":280,"completed":37,"skipped":558,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:41.252: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2745
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:41.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2745" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":280,"completed":38,"skipped":607,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:41.450: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May  5 11:25:42.087: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
May  5 11:25:44.095: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274742, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274742, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274742, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274742, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:25:47.108: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:25:47.112: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:48.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-346" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:6.822 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":280,"completed":39,"skipped":656,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:48.275: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:50.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7701" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":280,"completed":40,"skipped":702,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:50.495: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test env composition
May  5 11:25:50.644: INFO: Waiting up to 5m0s for pod "var-expansion-d53f9673-f41f-4a59-973e-9237e730742a" in namespace "var-expansion-7721" to be "success or failure"
May  5 11:25:50.647: INFO: Pod "var-expansion-d53f9673-f41f-4a59-973e-9237e730742a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541231ms
May  5 11:25:52.650: INFO: Pod "var-expansion-d53f9673-f41f-4a59-973e-9237e730742a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005950092s
May  5 11:25:54.653: INFO: Pod "var-expansion-d53f9673-f41f-4a59-973e-9237e730742a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008769133s
STEP: Saw pod success
May  5 11:25:54.653: INFO: Pod "var-expansion-d53f9673-f41f-4a59-973e-9237e730742a" satisfied condition "success or failure"
May  5 11:25:54.655: INFO: Trying to get logs from node ip-10-0-27-202 pod var-expansion-d53f9673-f41f-4a59-973e-9237e730742a container dapi-container: <nil>
STEP: delete the pod
May  5 11:25:54.676: INFO: Waiting for pod var-expansion-d53f9673-f41f-4a59-973e-9237e730742a to disappear
May  5 11:25:54.678: INFO: Pod var-expansion-d53f9673-f41f-4a59-973e-9237e730742a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:25:54.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7721" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":280,"completed":41,"skipped":717,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:25:54.688: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-38
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:26:05.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-38" for this suite.

• [SLOW TEST:11.225 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":280,"completed":42,"skipped":731,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:26:05.915: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating all guestbook components
May  5 11:26:06.086: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

May  5 11:26:06.086: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:06.341: INFO: stderr: ""
May  5 11:26:06.341: INFO: stdout: "service/agnhost-slave created\n"
May  5 11:26:06.341: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

May  5 11:26:06.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:06.634: INFO: stderr: ""
May  5 11:26:06.634: INFO: stdout: "service/agnhost-master created\n"
May  5 11:26:06.634: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

May  5 11:26:06.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:06.863: INFO: stderr: ""
May  5 11:26:06.863: INFO: stdout: "service/frontend created\n"
May  5 11:26:06.863: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

May  5 11:26:06.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:07.170: INFO: stderr: ""
May  5 11:26:07.170: INFO: stdout: "deployment.apps/frontend created\n"
May  5 11:26:07.170: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  5 11:26:07.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:07.334: INFO: stderr: ""
May  5 11:26:07.334: INFO: stdout: "deployment.apps/agnhost-master created\n"
May  5 11:26:07.334: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

May  5 11:26:07.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-1379'
May  5 11:26:07.521: INFO: stderr: ""
May  5 11:26:07.521: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
May  5 11:26:07.522: INFO: Waiting for all frontend pods to be Running.
May  5 11:26:12.572: INFO: Waiting for frontend to serve content.
May  5 11:26:12.581: INFO: Trying to add a new entry to the guestbook.
May  5 11:26:12.590: INFO: Verifying that added entry can be retrieved.
May  5 11:26:12.596: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources
May  5 11:26:17.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:17.757: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:17.757: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
May  5 11:26:17.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:17.957: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:17.957: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
May  5 11:26:17.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:18.117: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:18.117: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  5 11:26:18.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:18.235: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:18.235: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
May  5 11:26:18.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:18.307: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:18.307: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
May  5 11:26:18.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-1379'
May  5 11:26:18.388: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 11:26:18.388: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:26:18.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1379" for this suite.

• [SLOW TEST:12.480 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:380
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":280,"completed":43,"skipped":749,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:26:18.395: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May  5 11:26:18.591: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:18.609: INFO: Number of nodes with available pods: 0
May  5 11:26:18.609: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:26:19.614: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:19.617: INFO: Number of nodes with available pods: 0
May  5 11:26:19.617: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:26:20.613: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:20.616: INFO: Number of nodes with available pods: 1
May  5 11:26:20.616: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:26:21.622: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:21.626: INFO: Number of nodes with available pods: 2
May  5 11:26:21.626: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
May  5 11:26:21.641: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:21.645: INFO: Number of nodes with available pods: 1
May  5 11:26:21.645: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:26:22.651: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:22.654: INFO: Number of nodes with available pods: 1
May  5 11:26:22.654: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:26:23.648: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 11:26:23.651: INFO: Number of nodes with available pods: 2
May  5 11:26:23.651: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5596, will wait for the garbage collector to delete the pods
May  5 11:26:23.714: INFO: Deleting DaemonSet.extensions daemon-set took: 5.192713ms
May  5 11:26:23.814: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.184082ms
May  5 11:26:35.418: INFO: Number of nodes with available pods: 0
May  5 11:26:35.418: INFO: Number of running nodes: 0, number of available pods: 0
May  5 11:26:35.435: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5596/daemonsets","resourceVersion":"8435"},"items":null}

May  5 11:26:35.441: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5596/pods","resourceVersion":"8435"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:26:35.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5596" for this suite.

• [SLOW TEST:17.091 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":280,"completed":44,"skipped":758,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:26:35.488: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2637
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-e4efe8c7-f280-4f2b-a5d7-5bb482f9b2b0
STEP: Creating configMap with name cm-test-opt-upd-886b7e36-16dc-4064-966a-2e525b1f2310
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-e4efe8c7-f280-4f2b-a5d7-5bb482f9b2b0
STEP: Updating configmap cm-test-opt-upd-886b7e36-16dc-4064-966a-2e525b1f2310
STEP: Creating configMap with name cm-test-opt-create-fdf24550-b5aa-4270-b2b4-be8ee0e8b1ac
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:27:46.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2637" for this suite.

• [SLOW TEST:70.609 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":45,"skipped":766,"failed":0}
SSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:27:46.098: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:27:46.243: INFO: (0) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.810881ms)
May  5 11:27:46.247: INFO: (1) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.355781ms)
May  5 11:27:46.250: INFO: (2) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.425512ms)
May  5 11:27:46.254: INFO: (3) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.41619ms)
May  5 11:27:46.262: INFO: (4) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.136437ms)
May  5 11:27:46.270: INFO: (5) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 7.615399ms)
May  5 11:27:46.278: INFO: (6) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.109055ms)
May  5 11:27:46.283: INFO: (7) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.597724ms)
May  5 11:27:46.287: INFO: (8) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.593112ms)
May  5 11:27:46.290: INFO: (9) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.289035ms)
May  5 11:27:46.294: INFO: (10) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.691941ms)
May  5 11:27:46.297: INFO: (11) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.377482ms)
May  5 11:27:46.301: INFO: (12) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.228248ms)
May  5 11:27:46.304: INFO: (13) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.311513ms)
May  5 11:27:46.308: INFO: (14) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.468512ms)
May  5 11:27:46.311: INFO: (15) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.232064ms)
May  5 11:27:46.314: INFO: (16) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.528064ms)
May  5 11:27:46.318: INFO: (17) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.096896ms)
May  5 11:27:46.322: INFO: (18) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.178257ms)
May  5 11:27:46.326: INFO: (19) /api/v1/nodes/ip-10-0-27-202/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.908469ms)
[AfterEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:27:46.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-305" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":280,"completed":46,"skipped":770,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:27:46.333: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
May  5 11:27:49.026: INFO: Successfully updated pod "labelsupdate0a370435-4ae1-426d-92a7-1ddc93eeaa6e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:27:51.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6749" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":47,"skipped":783,"failed":0}
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:27:51.057: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2760
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
May  5 11:27:51.201: INFO: Waiting up to 5m0s for pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a" in namespace "downward-api-2760" to be "success or failure"
May  5 11:27:51.205: INFO: Pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.714901ms
May  5 11:27:53.210: INFO: Pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009372797s
May  5 11:27:55.214: INFO: Pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012760618s
May  5 11:27:57.217: INFO: Pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015866188s
STEP: Saw pod success
May  5 11:27:57.217: INFO: Pod "downward-api-1986f8c7-4016-4721-914f-fa4414c5592a" satisfied condition "success or failure"
May  5 11:27:57.219: INFO: Trying to get logs from node ip-10-0-33-250 pod downward-api-1986f8c7-4016-4721-914f-fa4414c5592a container dapi-container: <nil>
STEP: delete the pod
May  5 11:27:57.233: INFO: Waiting for pod downward-api-1986f8c7-4016-4721-914f-fa4414c5592a to disappear
May  5 11:27:57.241: INFO: Pod downward-api-1986f8c7-4016-4721-914f-fa4414c5592a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:27:57.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2760" for this suite.

• [SLOW TEST:6.190 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":280,"completed":48,"skipped":791,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:27:57.247: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:27:57.935: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:27:59.944: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274877, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274877, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274877, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724274877, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:28:02.958: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:13.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3824" for this suite.
STEP: Destroying namespace "webhook-3824-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.911 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":280,"completed":49,"skipped":800,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:13.159: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1693
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1885
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:42.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3746" for this suite.
STEP: Destroying namespace "nsdeletetest-1693" for this suite.
May  5 11:28:42.598: INFO: Namespace nsdeletetest-1693 was already deleted
STEP: Destroying namespace "nsdeletetest-1885" for this suite.

• [SLOW TEST:29.443 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":280,"completed":50,"skipped":801,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:42.603: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1649
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-e03c3c83-3528-472e-a3c1-58d11a8ef104
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:44.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1649" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":51,"skipped":851,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:44.786: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:44.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4607" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":280,"completed":52,"skipped":872,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:45.027: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3328
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:28:45.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-3328'
May  5 11:28:45.712: INFO: stderr: ""
May  5 11:28:45.712: INFO: stdout: "replicationcontroller/agnhost-master created\n"
May  5 11:28:45.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-3328'
May  5 11:28:45.938: INFO: stderr: ""
May  5 11:28:45.938: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May  5 11:28:46.941: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:28:46.941: INFO: Found 0 / 1
May  5 11:28:47.941: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:28:47.941: INFO: Found 1 / 1
May  5 11:28:47.941: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  5 11:28:47.945: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 11:28:47.945: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  5 11:28:47.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 describe pod agnhost-master-8hp79 --namespace=kubectl-3328'
May  5 11:28:48.079: INFO: stderr: ""
May  5 11:28:48.079: INFO: stdout: "Name:         agnhost-master-8hp79\nNamespace:    kubectl-3328\nPriority:     0\nNode:         ip-10-0-33-250/10.0.33.250\nStart Time:   Tue, 05 May 2020 11:28:45 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 10.2.169.30/32\n              cni.projectcalico.org/podIPs: 10.2.169.30/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           10.2.169.30\nIPs:\n  IP:           10.2.169.30\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://540fe80ba094a9cbc2bdd987b2aba0265d74f6cdc7ff8a9f6a8984bb753f5357\n    Image:          gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 05 May 2020 11:28:46 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lr4wr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lr4wr:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lr4wr\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                     Message\n  ----    ------     ----       ----                     -------\n  Normal  Scheduled  <unknown>  default-scheduler        Successfully assigned kubectl-3328/agnhost-master-8hp79 to ip-10-0-33-250\n  Normal  Pulled     2s         kubelet, ip-10-0-33-250  Container image \"gcr.io/kubernetes-e2e-test-images/agnhost:2.8\" already present on machine\n  Normal  Created    2s         kubelet, ip-10-0-33-250  Created container agnhost-master\n  Normal  Started    2s         kubelet, ip-10-0-33-250  Started container agnhost-master\n"
May  5 11:28:48.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 describe rc agnhost-master --namespace=kubectl-3328'
May  5 11:28:48.262: INFO: stderr: ""
May  5 11:28:48.262: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-3328\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: agnhost-master-8hp79\n"
May  5 11:28:48.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 describe service agnhost-master --namespace=kubectl-3328'
May  5 11:28:48.386: INFO: stderr: ""
May  5 11:28:48.386: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-3328\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.3.164.201\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.2.169.30:6379\nSession Affinity:  None\nEvents:            <none>\n"
May  5 11:28:48.390: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 describe node ip-10-0-0-244'
May  5 11:28:48.657: INFO: stderr: ""
May  5 11:28:48.657: INFO: stdout: "Name:               ip-10-0-0-244\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-0-244\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/controller=true\n                    node.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.0.244/20\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.2.10.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 05 May 2020 11:00:17 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nLease:\n  HolderIdentity:  ip-10-0-0-244\n  AcquireTime:     <unset>\n  RenewTime:       Tue, 05 May 2020 11:28:41 +0000\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Tue, 05 May 2020 11:00:37 +0000   Tue, 05 May 2020 11:00:37 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Tue, 05 May 2020 11:27:22 +0000   Tue, 05 May 2020 11:00:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Tue, 05 May 2020 11:27:22 +0000   Tue, 05 May 2020 11:00:17 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Tue, 05 May 2020 11:27:22 +0000   Tue, 05 May 2020 11:00:17 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Tue, 05 May 2020 11:27:22 +0000   Tue, 05 May 2020 11:00:41 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.244\n  Hostname:    ip-10-0-0-244\nCapacity:\n  cpu:                2\n  ephemeral-storage:  38216108Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3978192Ki\n  pods:               110\nAllocatable:\n  cpu:                2\n  ephemeral-storage:  35219965075\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             3875792Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 ec27f3cb3f6f2bc4ae54a0e9dc1155e9\n  System UUID:                ec27f3cb-3f6f-2bc4-ae54-a0e9dc1155e9\n  Boot ID:                    28c1a93e-fec5-4937-b26e-126204595616\n  Kernel Version:             4.19.107-flatcar\n  OS Image:                   Flatcar Container Linux by Kinvolk 2345.3.1 (Rhyolite)\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://18.6.3\n  Kubelet Version:            v1.17.4\n  Kube-Proxy Version:         v1.17.4\nPodCIDR:                      10.2.1.0/24\nPodCIDRs:                     10.2.1.0/24\nNon-terminated Pods:          (12 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 calico-node-czh82                                          150m (7%)     0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 coredns-6f64b7db7-swrkl                                    100m (5%)     0 (0%)      70Mi (1%)        170Mi (4%)     28m\n  kube-system                 kube-apiserver-8cdf44f9-cstbk                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kube-controller-manager-8579767584-kbrmr                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kube-controller-manager-8579767584-kvg6f                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kube-proxy-lhmds                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kube-scheduler-77744f4fc6-4859r                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kube-scheduler-77744f4fc6-qlcgv                            0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 kubelet-h64gr                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 pod-checkpointer-vxzpm                                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         28m\n  kube-system                 pod-checkpointer-vxzpm-ip-10-0-0-244                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-nh2w9    0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  0 (0%)\n  memory             70Mi (1%)   170Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                       Message\n  ----    ------                   ----               ----                       -------\n  Normal  Starting                 28m                kubelet, ip-10-0-0-244     Starting kubelet.\n  Normal  NodeHasSufficientMemory  28m (x2 over 28m)  kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    28m (x2 over 28m)  kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     28m (x2 over 28m)  kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  28m                kubelet, ip-10-0-0-244     Updated Node Allocatable limit across pods\n  Normal  Starting                 28m                kube-proxy, ip-10-0-0-244  Starting kube-proxy.\n  Normal  Starting                 28m                kubelet, ip-10-0-0-244     Starting kubelet.\n  Normal  NodeHasSufficientMemory  28m                kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    28m                kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     28m                kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeHasSufficientPID\n  Normal  NodeAllocatableEnforced  28m                kubelet, ip-10-0-0-244     Updated Node Allocatable limit across pods\n  Normal  NodeReady                28m                kubelet, ip-10-0-0-244     Node ip-10-0-0-244 status is now: NodeReady\n"
May  5 11:28:48.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 describe namespace kubectl-3328'
May  5 11:28:48.796: INFO: stderr: ""
May  5 11:28:48.796: INFO: stdout: "Name:         kubectl-3328\nLabels:       e2e-framework=kubectl\n              e2e-run=8d6cecca-6da0-4a1e-95c3-e0070a484aaf\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:48.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3328" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":280,"completed":53,"skipped":872,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:48.805: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2865
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-bf33e4ae-ad55-4cff-b6bb-6a2fe07b5869
STEP: Creating a pod to test consume configMaps
May  5 11:28:48.942: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03" in namespace "projected-2865" to be "success or failure"
May  5 11:28:48.945: INFO: Pod "pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.336669ms
May  5 11:28:50.948: INFO: Pod "pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005262912s
STEP: Saw pod success
May  5 11:28:50.948: INFO: Pod "pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03" satisfied condition "success or failure"
May  5 11:28:50.950: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:28:50.966: INFO: Waiting for pod pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03 to disappear
May  5 11:28:50.968: INFO: Pod pod-projected-configmaps-8eedfabb-f83e-4e96-91c9-36a909bb9e03 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:50.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2865" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":54,"skipped":882,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:50.975: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1681
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 11:28:51.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-276'
May  5 11:28:51.214: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  5 11:28:51.214: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
May  5 11:28:51.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete jobs e2e-test-httpd-job --namespace=kubectl-276'
May  5 11:28:51.320: INFO: stderr: ""
May  5 11:28:51.320: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:28:51.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-276" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]","total":280,"completed":55,"skipped":896,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:28:51.330: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
May  5 11:29:01.516: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:29:01.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0505 11:29:01.516769      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2444" for this suite.

• [SLOW TEST:10.208 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":280,"completed":56,"skipped":917,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:29:01.538: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename lease-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in lease-test-1272
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:29:01.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-1272" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":280,"completed":57,"skipped":939,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:29:01.769: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6793
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
May  5 11:29:01.919: INFO: Found 0 stateful pods, waiting for 3
May  5 11:29:11.922: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:29:11.922: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:29:11.922: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:29:11.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-6793 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:29:12.273: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:29:12.273: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:29:12.273: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
May  5 11:29:22.307: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
May  5 11:29:32.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-6793 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:29:32.641: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:29:32.641: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:29:32.641: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:29:42.670: INFO: Waiting for StatefulSet statefulset-6793/ss2 to complete update
May  5 11:29:42.670: INFO: Waiting for Pod statefulset-6793/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May  5 11:29:42.670: INFO: Waiting for Pod statefulset-6793/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May  5 11:29:52.677: INFO: Waiting for StatefulSet statefulset-6793/ss2 to complete update
May  5 11:29:52.677: INFO: Waiting for Pod statefulset-6793/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May  5 11:29:52.677: INFO: Waiting for Pod statefulset-6793/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May  5 11:30:02.692: INFO: Waiting for StatefulSet statefulset-6793/ss2 to complete update
May  5 11:30:02.692: INFO: Waiting for Pod statefulset-6793/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
May  5 11:30:12.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-6793 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:30:12.952: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:30:12.952: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:30:12.952: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:30:23.001: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
May  5 11:30:33.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-6793 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:30:33.305: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:30:33.305: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:30:33.305: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:30:53.330: INFO: Waiting for StatefulSet statefulset-6793/ss2 to complete update
May  5 11:30:53.330: INFO: Waiting for Pod statefulset-6793/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
May  5 11:31:03.337: INFO: Waiting for StatefulSet statefulset-6793/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 11:31:13.336: INFO: Deleting all statefulset in ns statefulset-6793
May  5 11:31:13.339: INFO: Scaling statefulset ss2 to 0
May  5 11:31:33.351: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:31:33.355: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:31:33.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6793" for this suite.

• [SLOW TEST:151.620 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":280,"completed":58,"skipped":949,"failed":0}
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:31:33.389: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4665
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
May  5 11:31:33.529: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:31:36.894: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:31:49.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4665" for this suite.

• [SLOW TEST:16.425 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":280,"completed":59,"skipped":949,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:31:49.816: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8990
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:03.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8990" for this suite.

• [SLOW TEST:13.219 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":280,"completed":60,"skipped":979,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:03.036: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5764
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-3abe2241-ae5d-4042-a6af-526c9b4e46ff
STEP: Creating secret with name s-test-opt-upd-14f746b9-45b2-40f4-8a06-3a9971cc128b
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3abe2241-ae5d-4042-a6af-526c9b4e46ff
STEP: Updating secret s-test-opt-upd-14f746b9-45b2-40f4-8a06-3a9971cc128b
STEP: Creating secret with name s-test-opt-create-467498e6-3f67-4817-a9b8-06561b03be21
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:07.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5764" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":61,"skipped":1010,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:07.335: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
May  5 11:32:09.521: INFO: &Pod{ObjectMeta:{send-events-689937ff-6b94-4c35-92cf-b5a3a5b7fbc0  events-2099 /api/v1/namespaces/events-2099/pods/send-events-689937ff-6b94-4c35-92cf-b5a3a5b7fbc0 f4ba8838-86f5-46db-a05b-3211d8db8a8e 10326 0 2020-05-05 11:32:07 +0000 UTC <nil> <nil> map[name:foo time:498452117] map[cni.projectcalico.org/podIP:10.2.169.35/32 cni.projectcalico.org/podIPs:10.2.169.35/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lh2gp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lh2gp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lh2gp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:32:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:32:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:32:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:32:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.35,StartTime:2020-05-05 11:32:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:32:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://b3776741b328dbe7ab6f847b93237bc701c9076ad088d9c3ec34a0c8228024f8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
May  5 11:32:11.529: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
May  5 11:32:13.532: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:13.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2099" for this suite.

• [SLOW TEST:6.215 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":280,"completed":62,"skipped":1018,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:13.560: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  5 11:32:16.766: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:16.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-394" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":280,"completed":63,"skipped":1046,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:16.787: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:32:17.334: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:32:19.347: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275137, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275137, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275137, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275137, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:32:22.364: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
May  5 11:32:22.380: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:22.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1415" for this suite.
STEP: Destroying namespace "webhook-1415-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.691 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":280,"completed":64,"skipped":1051,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:22.483: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-41
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  5 11:32:22.663: INFO: Waiting up to 5m0s for pod "pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a" in namespace "emptydir-41" to be "success or failure"
May  5 11:32:22.666: INFO: Pod "pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.753464ms
May  5 11:32:24.671: INFO: Pod "pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008330645s
STEP: Saw pod success
May  5 11:32:24.671: INFO: Pod "pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a" satisfied condition "success or failure"
May  5 11:32:24.675: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a container test-container: <nil>
STEP: delete the pod
May  5 11:32:24.694: INFO: Waiting for pod pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a to disappear
May  5 11:32:24.696: INFO: Pod pod-7baf5f61-7daa-419a-868f-ed0fcfbf5f8a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:24.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-41" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":65,"skipped":1063,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:24.711: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting the proxy server
May  5 11:32:24.894: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-610752675 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:25.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3837" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":280,"completed":66,"skipped":1067,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:25.024: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:32:25.169: INFO: Waiting up to 5m0s for pod "downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15" in namespace "downward-api-5257" to be "success or failure"
May  5 11:32:25.173: INFO: Pod "downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15": Phase="Pending", Reason="", readiness=false. Elapsed: 3.476466ms
May  5 11:32:27.177: INFO: Pod "downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008170402s
STEP: Saw pod success
May  5 11:32:27.177: INFO: Pod "downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15" satisfied condition "success or failure"
May  5 11:32:27.180: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15 container client-container: <nil>
STEP: delete the pod
May  5 11:32:27.197: INFO: Waiting for pod downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15 to disappear
May  5 11:32:27.199: INFO: Pod downwardapi-volume-37674610-3782-49f3-9c83-fad65e92eb15 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:27.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5257" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":67,"skipped":1075,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:27.212: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4428
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  5 11:32:31.432: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:31.440: INFO: Pod pod-with-poststart-exec-hook still exists
May  5 11:32:33.440: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:33.443: INFO: Pod pod-with-poststart-exec-hook still exists
May  5 11:32:35.440: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:35.444: INFO: Pod pod-with-poststart-exec-hook still exists
May  5 11:32:37.441: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:37.445: INFO: Pod pod-with-poststart-exec-hook still exists
May  5 11:32:39.440: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:39.443: INFO: Pod pod-with-poststart-exec-hook still exists
May  5 11:32:41.440: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
May  5 11:32:41.444: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:41.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4428" for this suite.

• [SLOW TEST:14.238 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":280,"completed":68,"skipped":1095,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:41.451: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-7824cfe5-fc7c-4dac-b93d-f06d7216d6f1
STEP: Creating a pod to test consume secrets
May  5 11:32:41.589: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a" in namespace "projected-9197" to be "success or failure"
May  5 11:32:41.597: INFO: Pod "pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.246601ms
May  5 11:32:43.601: INFO: Pod "pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011736198s
STEP: Saw pod success
May  5 11:32:43.601: INFO: Pod "pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a" satisfied condition "success or failure"
May  5 11:32:43.603: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a container projected-secret-volume-test: <nil>
STEP: delete the pod
May  5 11:32:43.618: INFO: Waiting for pod pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a to disappear
May  5 11:32:43.620: INFO: Pod pod-projected-secrets-01e561d8-0734-4593-b5cd-246e94aeb08a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:43.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9197" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":69,"skipped":1131,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:43.627: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1632
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:32:43.771: INFO: (0) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.52819ms)
May  5 11:32:43.775: INFO: (1) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.281709ms)
May  5 11:32:43.778: INFO: (2) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.625073ms)
May  5 11:32:43.787: INFO: (3) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 8.392533ms)
May  5 11:32:43.791: INFO: (4) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.332596ms)
May  5 11:32:43.795: INFO: (5) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.790121ms)
May  5 11:32:43.810: INFO: (6) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 14.704852ms)
May  5 11:32:43.943: INFO: (7) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 133.411969ms)
May  5 11:32:43.948: INFO: (8) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.582674ms)
May  5 11:32:43.952: INFO: (9) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.150172ms)
May  5 11:32:43.956: INFO: (10) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.966291ms)
May  5 11:32:43.960: INFO: (11) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.537042ms)
May  5 11:32:43.964: INFO: (12) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.613864ms)
May  5 11:32:43.967: INFO: (13) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.159545ms)
May  5 11:32:43.971: INFO: (14) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.67978ms)
May  5 11:32:43.974: INFO: (15) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.105907ms)
May  5 11:32:43.977: INFO: (16) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.305071ms)
May  5 11:32:43.980: INFO: (17) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.408295ms)
May  5 11:32:43.984: INFO: (18) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.730077ms)
May  5 11:32:43.990: INFO: (19) /api/v1/nodes/ip-10-0-27-202:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 5.305637ms)
[AfterEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:43.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1632" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":280,"completed":70,"skipped":1154,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:44.008: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1626
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 11:32:44.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-4346'
May  5 11:32:44.256: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  5 11:32:44.256: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1631
May  5 11:32:46.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4346'
May  5 11:32:46.373: INFO: stderr: ""
May  5 11:32:46.373: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:32:46.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4346" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]","total":280,"completed":71,"skipped":1158,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:32:46.384: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3586
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:32:46.601: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
May  5 11:32:46.630: INFO: Number of nodes with available pods: 0
May  5 11:32:46.630: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
May  5 11:32:46.660: INFO: Number of nodes with available pods: 0
May  5 11:32:46.660: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:47.664: INFO: Number of nodes with available pods: 0
May  5 11:32:47.664: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:48.677: INFO: Number of nodes with available pods: 1
May  5 11:32:48.677: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
May  5 11:32:48.693: INFO: Number of nodes with available pods: 1
May  5 11:32:48.694: INFO: Number of running nodes: 0, number of available pods: 1
May  5 11:32:49.703: INFO: Number of nodes with available pods: 0
May  5 11:32:49.703: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
May  5 11:32:49.719: INFO: Number of nodes with available pods: 0
May  5 11:32:49.719: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:50.726: INFO: Number of nodes with available pods: 0
May  5 11:32:50.729: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:51.725: INFO: Number of nodes with available pods: 0
May  5 11:32:51.726: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:52.723: INFO: Number of nodes with available pods: 0
May  5 11:32:52.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:53.722: INFO: Number of nodes with available pods: 0
May  5 11:32:53.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:54.723: INFO: Number of nodes with available pods: 0
May  5 11:32:54.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:55.722: INFO: Number of nodes with available pods: 0
May  5 11:32:55.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:56.723: INFO: Number of nodes with available pods: 0
May  5 11:32:56.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:57.723: INFO: Number of nodes with available pods: 0
May  5 11:32:57.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:58.723: INFO: Number of nodes with available pods: 0
May  5 11:32:58.723: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:32:59.725: INFO: Number of nodes with available pods: 0
May  5 11:32:59.725: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:33:00.725: INFO: Number of nodes with available pods: 0
May  5 11:33:00.725: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:33:01.734: INFO: Number of nodes with available pods: 0
May  5 11:33:01.734: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:33:02.725: INFO: Number of nodes with available pods: 0
May  5 11:33:02.725: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 11:33:03.723: INFO: Number of nodes with available pods: 1
May  5 11:33:03.723: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3586, will wait for the garbage collector to delete the pods
May  5 11:33:03.789: INFO: Deleting DaemonSet.extensions daemon-set took: 5.935703ms
May  5 11:33:03.889: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.217725ms
May  5 11:33:11.192: INFO: Number of nodes with available pods: 0
May  5 11:33:11.192: INFO: Number of running nodes: 0, number of available pods: 0
May  5 11:33:11.195: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3586/daemonsets","resourceVersion":"10919"},"items":null}

May  5 11:33:11.198: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3586/pods","resourceVersion":"10919"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:33:11.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3586" for this suite.

• [SLOW TEST:24.839 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":280,"completed":72,"skipped":1207,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:33:11.224: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
May  5 11:33:11.377: INFO: Waiting up to 5m0s for pod "pod-8ea7d145-de58-49e7-9883-993ea3d44518" in namespace "emptydir-2337" to be "success or failure"
May  5 11:33:11.382: INFO: Pod "pod-8ea7d145-de58-49e7-9883-993ea3d44518": Phase="Pending", Reason="", readiness=false. Elapsed: 4.807801ms
May  5 11:33:13.392: INFO: Pod "pod-8ea7d145-de58-49e7-9883-993ea3d44518": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015375335s
May  5 11:33:15.395: INFO: Pod "pod-8ea7d145-de58-49e7-9883-993ea3d44518": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018541745s
STEP: Saw pod success
May  5 11:33:15.396: INFO: Pod "pod-8ea7d145-de58-49e7-9883-993ea3d44518" satisfied condition "success or failure"
May  5 11:33:15.398: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-8ea7d145-de58-49e7-9883-993ea3d44518 container test-container: <nil>
STEP: delete the pod
May  5 11:33:15.414: INFO: Waiting for pod pod-8ea7d145-de58-49e7-9883-993ea3d44518 to disappear
May  5 11:33:15.421: INFO: Pod pod-8ea7d145-de58-49e7-9883-993ea3d44518 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:33:15.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2337" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":73,"skipped":1227,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:33:15.440: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4287
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-b9ca0b00-80ef-4bf4-b1ae-62c7e422d7d9 in namespace container-probe-4287
May  5 11:33:17.585: INFO: Started pod busybox-b9ca0b00-80ef-4bf4-b1ae-62c7e422d7d9 in namespace container-probe-4287
STEP: checking the pod's current state and verifying that restartCount is present
May  5 11:33:17.588: INFO: Initial restart count of pod busybox-b9ca0b00-80ef-4bf4-b1ae-62c7e422d7d9 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:18.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4287" for this suite.

• [SLOW TEST:242.686 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":74,"skipped":1239,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:18.126: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
May  5 11:37:18.615: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:37:21.631: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:37:21.635: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:22.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3920" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":280,"completed":75,"skipped":1250,"failed":0}

------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:22.987: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's args
May  5 11:37:23.170: INFO: Waiting up to 5m0s for pod "var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0" in namespace "var-expansion-9326" to be "success or failure"
May  5 11:37:23.174: INFO: Pod "var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.708156ms
May  5 11:37:25.177: INFO: Pod "var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006848284s
STEP: Saw pod success
May  5 11:37:25.177: INFO: Pod "var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0" satisfied condition "success or failure"
May  5 11:37:25.179: INFO: Trying to get logs from node ip-10-0-27-202 pod var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0 container dapi-container: <nil>
STEP: delete the pod
May  5 11:37:25.206: INFO: Waiting for pod var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0 to disappear
May  5 11:37:25.218: INFO: Pod var-expansion-c40dad14-1bcc-4022-8b99-920cc2097cb0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:25.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9326" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":280,"completed":76,"skipped":1250,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:25.226: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9029
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:27.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9029" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":280,"completed":77,"skipped":1323,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:27.411: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:37:28.100: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:37:31.116: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
May  5 11:37:33.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 attach --namespace=webhook-2708 to-be-attached-pod -i -c=container1'
May  5 11:37:33.257: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:33.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2708" for this suite.
STEP: Destroying namespace "webhook-2708-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.917 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":280,"completed":78,"skipped":1368,"failed":0}
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:33.328: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1075
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:37:33.550: INFO: Creating ReplicaSet my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318
May  5 11:37:33.559: INFO: Pod name my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318: Found 0 pods out of 1
May  5 11:37:38.565: INFO: Pod name my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318: Found 1 pods out of 1
May  5 11:37:38.565: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318" is running
May  5 11:37:38.579: INFO: Pod "my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318-25zqg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:37:33 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:37:35 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:37:35 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:37:33 +0000 UTC Reason: Message:}])
May  5 11:37:38.579: INFO: Trying to dial the pod
May  5 11:37:43.590: INFO: Controller my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318: Got expected result from replica 1 [my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318-25zqg]: "my-hostname-basic-40b42b43-1284-4009-a577-289a502a6318-25zqg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:43.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1075" for this suite.

• [SLOW TEST:10.277 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":79,"skipped":1368,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:43.605: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
May  5 11:37:45.775: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-610752675 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May  5 11:37:50.893: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:37:50.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-648" for this suite.

• [SLOW TEST:7.298 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should be submitted and removed [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]","total":280,"completed":80,"skipped":1377,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:37:50.904: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May  5 11:37:55.093: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  5 11:37:55.096: INFO: Pod pod-with-prestop-http-hook still exists
May  5 11:37:57.096: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  5 11:37:57.100: INFO: Pod pod-with-prestop-http-hook still exists
May  5 11:37:59.097: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  5 11:37:59.100: INFO: Pod pod-with-prestop-http-hook still exists
May  5 11:38:01.096: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
May  5 11:38:01.100: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:38:01.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4139" for this suite.

• [SLOW TEST:10.212 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":280,"completed":81,"skipped":1384,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:38:01.116: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
May  5 11:38:01.250: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  5 11:38:01.260: INFO: Waiting for terminating namespaces to be deleted...
May  5 11:38:01.262: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-27-202 before test
May  5 11:38:01.268: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:38:01.268: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:38:01.268: INFO: pod-handle-http-request from container-lifecycle-hook-4139 started at 2020-05-05 11:37:51 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container pod-handle-http-request ready: true, restart count 0
May  5 11:38:01.268: INFO: calico-node-v6vzp from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:38:01.268: INFO: sonobuoy from sonobuoy started at 2020-05-05 11:16:48 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  5 11:38:01.268: INFO: kube-proxy-m47jv from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:38:01.268: INFO: kubelet-99g5h from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.268: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:38:01.268: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-33-250 before test
May  5 11:38:01.285: INFO: coredns-6f64b7db7-z5b8s from kube-system started at 2020-05-05 11:00:47 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container coredns ready: true, restart count 0
May  5 11:38:01.285: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:38:01.285: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:38:01.285: INFO: calico-node-579x2 from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:38:01.285: INFO: kubelet-8cl8p from kube-system started at 2020-05-05 11:00:18 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:38:01.285: INFO: kube-proxy-8nsbj from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:38:01.285: INFO: sonobuoy-e2e-job-0f2dbdcc56724f7f from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:38:01.285: INFO: 	Container e2e ready: true, restart count 0
May  5 11:38:01.285: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3c5fb442-65fa-4f41-aa50-ca8aaef615ef 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3c5fb442-65fa-4f41-aa50-ca8aaef615ef off the node ip-10-0-27-202
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3c5fb442-65fa-4f41-aa50-ca8aaef615ef
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:38:13.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8880" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:12.273 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":280,"completed":82,"skipped":1395,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:38:13.392: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-5820
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating stateful set ss in namespace statefulset-5820
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5820
May  5 11:38:13.615: INFO: Found 0 stateful pods, waiting for 1
May  5 11:38:23.619: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
May  5 11:38:23.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:38:23.871: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:38:23.871: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:38:23.871: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:38:23.874: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
May  5 11:38:33.878: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:38:33.878: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:38:33.896: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:33.896: INFO: ss-0  ip-10-0-33-250  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:24 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  }]
May  5 11:38:33.896: INFO: ss-1                  Pending         []
May  5 11:38:33.896: INFO: 
May  5 11:38:33.896: INFO: StatefulSet ss has not reached scale 3, at 2
May  5 11:38:34.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992251734s
May  5 11:38:35.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988823891s
May  5 11:38:36.907: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985306629s
May  5 11:38:37.911: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.981674014s
May  5 11:38:38.915: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976863199s
May  5 11:38:39.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973197293s
May  5 11:38:40.923: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.968457597s
May  5 11:38:41.927: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965334533s
May  5 11:38:42.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.495475ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5820
May  5 11:38:43.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:38:44.165: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
May  5 11:38:44.165: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:38:44.165: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:38:44.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:38:44.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  5 11:38:44.371: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:38:44.371: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:38:44.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
May  5 11:38:44.546: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
May  5 11:38:44.546: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
May  5 11:38:44.546: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

May  5 11:38:44.549: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:38:44.549: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
May  5 11:38:44.549: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
May  5 11:38:44.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:38:44.746: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:38:44.746: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:38:44.746: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:38:44.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:38:44.965: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:38:44.965: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:38:44.965: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:38:44.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=statefulset-5820 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
May  5 11:38:45.324: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
May  5 11:38:45.324: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
May  5 11:38:45.324: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

May  5 11:38:45.324: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:38:45.327: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
May  5 11:38:55.332: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:38:55.333: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:38:55.333: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
May  5 11:38:55.343: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:55.343: INFO: ss-0  ip-10-0-33-250  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  }]
May  5 11:38:55.343: INFO: ss-1  ip-10-0-27-202  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:55.343: INFO: ss-2  ip-10-0-27-202  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:55.343: INFO: 
May  5 11:38:55.343: INFO: StatefulSet ss has not reached scale 0, at 3
May  5 11:38:56.347: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:56.347: INFO: ss-0  ip-10-0-33-250  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  }]
May  5 11:38:56.347: INFO: ss-1  ip-10-0-27-202  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:56.347: INFO: ss-2  ip-10-0-27-202  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:56.347: INFO: 
May  5 11:38:56.347: INFO: StatefulSet ss has not reached scale 0, at 3
May  5 11:38:57.354: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:57.354: INFO: ss-0  ip-10-0-33-250  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:13 +0000 UTC  }]
May  5 11:38:57.354: INFO: ss-1  ip-10-0-27-202  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:57.354: INFO: ss-2  ip-10-0-27-202  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:57.354: INFO: 
May  5 11:38:57.354: INFO: StatefulSet ss has not reached scale 0, at 3
May  5 11:38:58.357: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:58.357: INFO: ss-1  ip-10-0-27-202  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:58.357: INFO: 
May  5 11:38:58.357: INFO: StatefulSet ss has not reached scale 0, at 1
May  5 11:38:59.362: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:38:59.362: INFO: ss-1  ip-10-0-27-202  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:38:59.362: INFO: 
May  5 11:38:59.362: INFO: StatefulSet ss has not reached scale 0, at 1
May  5 11:39:00.366: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
May  5 11:39:00.366: INFO: ss-1  ip-10-0-27-202  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-05-05 11:38:33 +0000 UTC  }]
May  5 11:39:00.366: INFO: 
May  5 11:39:00.366: INFO: StatefulSet ss has not reached scale 0, at 1
May  5 11:39:01.376: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.971951923s
May  5 11:39:02.386: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.959990565s
May  5 11:39:03.390: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.95132023s
May  5 11:39:04.394: INFO: Verifying statefulset ss doesn't scale past 0 for another 947.045311ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5820
May  5 11:39:05.403: INFO: Scaling statefulset ss to 0
May  5 11:39:05.413: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 11:39:05.415: INFO: Deleting all statefulset in ns statefulset-5820
May  5 11:39:05.417: INFO: Scaling statefulset ss to 0
May  5 11:39:05.424: INFO: Waiting for statefulset status.replicas updated to 0
May  5 11:39:05.426: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:05.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5820" for this suite.

• [SLOW TEST:52.051 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":280,"completed":83,"skipped":1401,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:05.443: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2199
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:39:05.582: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:06.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2199" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":280,"completed":84,"skipped":1401,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:06.113: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5269
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with configMap that has name projected-configmap-test-upd-28d240b3-7c5d-4c6f-bff0-b71f2bf20a03
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-28d240b3-7c5d-4c6f-bff0-b71f2bf20a03
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:10.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5269" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":85,"skipped":1415,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:10.347: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
May  5 11:39:13.516: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:14.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9084" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":280,"completed":86,"skipped":1426,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:14.539: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
May  5 11:39:14.675: INFO: Waiting up to 5m0s for pod "downward-api-c8149b97-1fb1-451a-aa29-d706acc85046" in namespace "downward-api-2922" to be "success or failure"
May  5 11:39:14.680: INFO: Pod "downward-api-c8149b97-1fb1-451a-aa29-d706acc85046": Phase="Pending", Reason="", readiness=false. Elapsed: 4.295111ms
May  5 11:39:16.683: INFO: Pod "downward-api-c8149b97-1fb1-451a-aa29-d706acc85046": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007758885s
STEP: Saw pod success
May  5 11:39:16.683: INFO: Pod "downward-api-c8149b97-1fb1-451a-aa29-d706acc85046" satisfied condition "success or failure"
May  5 11:39:16.686: INFO: Trying to get logs from node ip-10-0-27-202 pod downward-api-c8149b97-1fb1-451a-aa29-d706acc85046 container dapi-container: <nil>
STEP: delete the pod
May  5 11:39:16.702: INFO: Waiting for pod downward-api-c8149b97-1fb1-451a-aa29-d706acc85046 to disappear
May  5 11:39:16.704: INFO: Pod downward-api-c8149b97-1fb1-451a-aa29-d706acc85046 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:16.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2922" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":280,"completed":87,"skipped":1446,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:16.712: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:39:16.851: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4" in namespace "downward-api-1393" to be "success or failure"
May  5 11:39:16.856: INFO: Pod "downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.319467ms
May  5 11:39:18.861: INFO: Pod "downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009687276s
STEP: Saw pod success
May  5 11:39:18.861: INFO: Pod "downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4" satisfied condition "success or failure"
May  5 11:39:18.865: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4 container client-container: <nil>
STEP: delete the pod
May  5 11:39:18.887: INFO: Waiting for pod downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4 to disappear
May  5 11:39:18.890: INFO: Pod downwardapi-volume-be6236ae-372a-4bbd-bbbd-2a4aef1a31c4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:18.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1393" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":280,"completed":88,"skipped":1447,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:18.899: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating pod
May  5 11:39:21.063: INFO: Pod pod-hostip-388e556b-f82c-4ef2-82b9-bd51c23a3491 has hostIP: 10.0.27.202
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:21.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-794" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":280,"completed":89,"skipped":1453,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:21.070: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-1335
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  5 11:39:21.252: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  5 11:39:39.317: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.232.98:8080/dial?request=hostname&protocol=http&host=10.2.232.97&port=8080&tries=1'] Namespace:pod-network-test-1335 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:39:39.317: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:39:39.417: INFO: Waiting for responses: map[]
May  5 11:39:39.420: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.2.232.98:8080/dial?request=hostname&protocol=http&host=10.2.169.40&port=8080&tries=1'] Namespace:pod-network-test-1335 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:39:39.420: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:39:39.514: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:39.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1335" for this suite.

• [SLOW TEST:18.451 seconds]
[sig-network] Networking
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":90,"skipped":1458,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:39.525: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
May  5 11:39:43.737: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:43.750: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:45.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:45.753: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:47.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:47.753: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:49.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:49.753: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:51.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:51.754: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:53.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:53.753: INFO: Pod pod-with-prestop-exec-hook still exists
May  5 11:39:55.750: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
May  5 11:39:55.753: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:39:55.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3443" for this suite.

• [SLOW TEST:16.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":280,"completed":91,"skipped":1472,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:39:55.769: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-182
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  5 11:39:55.913: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  5 11:40:18.031: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.232.100 8081 | grep -v '^\s*$'] Namespace:pod-network-test-182 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:40:18.031: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:40:19.135: INFO: Found all expected endpoints: [netserver-0]
May  5 11:40:19.139: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.2.169.42 8081 | grep -v '^\s*$'] Namespace:pod-network-test-182 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:40:19.139: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:40:20.238: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:20.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-182" for this suite.

• [SLOW TEST:24.477 seconds]
[sig-network] Networking
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":92,"skipped":1491,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:20.248: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating replication controller my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce
May  5 11:40:20.395: INFO: Pod name my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce: Found 0 pods out of 1
May  5 11:40:25.398: INFO: Pod name my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce: Found 1 pods out of 1
May  5 11:40:25.399: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce" are running
May  5 11:40:25.401: INFO: Pod "my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce-bpxgp" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:40:20 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:40:22 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:40:22 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-05-05 11:40:20 +0000 UTC Reason: Message:}])
May  5 11:40:25.401: INFO: Trying to dial the pod
May  5 11:40:30.414: INFO: Controller my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce: Got expected result from replica 1 [my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce-bpxgp]: "my-hostname-basic-ba4bab07-0d2e-41bf-984a-61c6eb0e49ce-bpxgp", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:30.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7262" for this suite.

• [SLOW TEST:10.179 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":93,"skipped":1503,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:30.428: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9522.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9522.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9522.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9522.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9522.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 11:40:32.620: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.623: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.628: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.634: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.644: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.647: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.650: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.653: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9522.svc.cluster.local from pod dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691: the server could not find the requested resource (get pods dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691)
May  5 11:40:32.660: INFO: Lookups using dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9522.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9522.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9522.svc.cluster.local jessie_udp@dns-test-service-2.dns-9522.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9522.svc.cluster.local]

May  5 11:40:37.716: INFO: DNS probes using dns-9522/dns-test-4fa8baa2-5774-466d-9d87-357ca73d2691 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:37.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9522" for this suite.

• [SLOW TEST:7.317 seconds]
[sig-network] DNS
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":280,"completed":94,"skipped":1532,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:37.745: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:41.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3643" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":280,"completed":95,"skipped":1554,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:41.900: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8854
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on tmpfs
May  5 11:40:42.038: INFO: Waiting up to 5m0s for pod "pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb" in namespace "emptydir-8854" to be "success or failure"
May  5 11:40:42.040: INFO: Pod "pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.495846ms
May  5 11:40:44.043: INFO: Pod "pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005583579s
STEP: Saw pod success
May  5 11:40:44.043: INFO: Pod "pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb" satisfied condition "success or failure"
May  5 11:40:44.046: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb container test-container: <nil>
STEP: delete the pod
May  5 11:40:44.063: INFO: Waiting for pod pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb to disappear
May  5 11:40:44.066: INFO: Pod pod-51684ee8-5968-4eb5-931f-1b02c6f85fcb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:44.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8854" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":96,"skipped":1574,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:44.074: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:40:44.212: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e" in namespace "projected-6541" to be "success or failure"
May  5 11:40:44.214: INFO: Pod "downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.398539ms
May  5 11:40:46.219: INFO: Pod "downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006734683s
STEP: Saw pod success
May  5 11:40:46.219: INFO: Pod "downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e" satisfied condition "success or failure"
May  5 11:40:46.222: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e container client-container: <nil>
STEP: delete the pod
May  5 11:40:46.236: INFO: Waiting for pod downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e to disappear
May  5 11:40:46.238: INFO: Pod downwardapi-volume-4cf47390-fa03-4358-9e76-1aa333feba7e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:46.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6541" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":97,"skipped":1580,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:46.249: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-ce2ecb6e-6e81-4a18-ae1f-f62d9a808d12
STEP: Creating a pod to test consume secrets
May  5 11:40:46.389: INFO: Waiting up to 5m0s for pod "pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451" in namespace "secrets-8163" to be "success or failure"
May  5 11:40:46.393: INFO: Pod "pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451": Phase="Pending", Reason="", readiness=false. Elapsed: 4.403277ms
May  5 11:40:48.396: INFO: Pod "pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007658291s
STEP: Saw pod success
May  5 11:40:48.396: INFO: Pod "pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451" satisfied condition "success or failure"
May  5 11:40:48.399: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451 container secret-volume-test: <nil>
STEP: delete the pod
May  5 11:40:48.411: INFO: Waiting for pod pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451 to disappear
May  5 11:40:48.414: INFO: Pod pod-secrets-3e16be54-88e5-4dfb-8206-e7c6a8dc4451 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:48.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8163" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":98,"skipped":1600,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:48.421: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:40:48.894: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:40:51.910: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:40:51.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6545" for this suite.
STEP: Destroying namespace "webhook-6545-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":280,"completed":99,"skipped":1606,"failed":0}
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:40:51.959: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
May  5 11:40:56.618: INFO: Successfully updated pod "adopt-release-dtt8x"
STEP: Checking that the Job readopts the Pod
May  5 11:40:56.618: INFO: Waiting up to 15m0s for pod "adopt-release-dtt8x" in namespace "job-127" to be "adopted"
May  5 11:40:56.625: INFO: Pod "adopt-release-dtt8x": Phase="Running", Reason="", readiness=true. Elapsed: 6.947899ms
May  5 11:40:58.630: INFO: Pod "adopt-release-dtt8x": Phase="Running", Reason="", readiness=true. Elapsed: 2.011839264s
May  5 11:40:58.630: INFO: Pod "adopt-release-dtt8x" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
May  5 11:40:59.137: INFO: Successfully updated pod "adopt-release-dtt8x"
STEP: Checking that the Job releases the Pod
May  5 11:40:59.137: INFO: Waiting up to 15m0s for pod "adopt-release-dtt8x" in namespace "job-127" to be "released"
May  5 11:40:59.140: INFO: Pod "adopt-release-dtt8x": Phase="Running", Reason="", readiness=true. Elapsed: 3.035664ms
May  5 11:41:01.145: INFO: Pod "adopt-release-dtt8x": Phase="Running", Reason="", readiness=true. Elapsed: 2.007616642s
May  5 11:41:01.145: INFO: Pod "adopt-release-dtt8x" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:41:01.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-127" for this suite.

• [SLOW TEST:9.201 seconds]
[sig-apps] Job
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":280,"completed":100,"skipped":1611,"failed":0}
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:41:01.160: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap that has name configmap-test-emptyKey-d3273e3c-6e52-4196-bc8c-050c2a38f740
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:41:01.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7792" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":280,"completed":101,"skipped":1619,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:41:01.360: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1525
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 11:41:01.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3982'
May  5 11:41:01.598: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  5 11:41:01.598: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
May  5 11:41:01.615: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-t4nrs]
May  5 11:41:01.615: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-t4nrs" in namespace "kubectl-3982" to be "running and ready"
May  5 11:41:01.626: INFO: Pod "e2e-test-httpd-rc-t4nrs": Phase="Pending", Reason="", readiness=false. Elapsed: 10.731328ms
May  5 11:41:03.630: INFO: Pod "e2e-test-httpd-rc-t4nrs": Phase="Running", Reason="", readiness=true. Elapsed: 2.015255786s
May  5 11:41:03.630: INFO: Pod "e2e-test-httpd-rc-t4nrs" satisfied condition "running and ready"
May  5 11:41:03.630: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-t4nrs]
May  5 11:41:03.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs rc/e2e-test-httpd-rc --namespace=kubectl-3982'
May  5 11:41:03.790: INFO: stderr: ""
May  5 11:41:03.790: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.2.232.111. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.2.232.111. Set the 'ServerName' directive globally to suppress this message\n[Tue May 05 11:41:02.597885 2020] [mpm_event:notice] [pid 1:tid 140501753416552] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue May 05 11:41:02.597934 2020] [core:notice] [pid 1:tid 140501753416552] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1530
May  5 11:41:03.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete rc e2e-test-httpd-rc --namespace=kubectl-3982'
May  5 11:41:03.923: INFO: stderr: ""
May  5 11:41:03.923: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:41:03.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3982" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]","total":280,"completed":102,"skipped":1622,"failed":0}
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:41:03.960: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7779
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-7779/configmap-test-6298611b-6233-4b65-85a0-0c4e2de5dea3
STEP: Creating a pod to test consume configMaps
May  5 11:41:04.243: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c" in namespace "configmap-7779" to be "success or failure"
May  5 11:41:04.262: INFO: Pod "pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.723715ms
May  5 11:41:06.266: INFO: Pod "pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023311638s
STEP: Saw pod success
May  5 11:41:06.266: INFO: Pod "pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c" satisfied condition "success or failure"
May  5 11:41:06.269: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c container env-test: <nil>
STEP: delete the pod
May  5 11:41:06.295: INFO: Waiting for pod pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c to disappear
May  5 11:41:06.309: INFO: Pod pod-configmaps-fe0dfad9-8353-4e21-93dd-06db4e3f950c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:41:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7779" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":280,"completed":103,"skipped":1632,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:41:06.319: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-2051
STEP: creating a selector
STEP: Creating the service pods in kubernetes
May  5 11:41:06.461: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
May  5 11:41:26.573: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.232.112:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2051 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:41:26.573: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:41:26.682: INFO: Found all expected endpoints: [netserver-0]
May  5 11:41:26.685: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.2.169.45:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-2051 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:41:26.685: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:41:26.806: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:41:26.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2051" for this suite.

• [SLOW TEST:20.494 seconds]
[sig-network] Networking
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":104,"skipped":1637,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:41:26.813: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6901
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
May  5 11:41:26.943: INFO: PodSpec: initContainers in spec.initContainers
May  5 11:42:11.384: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-08fe645e-4851-4aa2-9add-b42c85079e0b", GenerateName:"", Namespace:"init-container-6901", SelfLink:"/api/v1/namespaces/init-container-6901/pods/pod-init-08fe645e-4851-4aa2-9add-b42c85079e0b", UID:"dcedcdfc-ea62-4776-94a9-7cc7e23a68b8", ResourceVersion:"14034", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63724275686, loc:(*time.Location)(0x791d1c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"943098254"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.2.232.114/32", "cni.projectcalico.org/podIPs":"10.2.232.114/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fhvlg", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006bf2140), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhvlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhvlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fhvlg", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0050bc2a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-27-202", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc006d000c0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0050bc330)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0050bc350)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0050bc358), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0050bc35c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275686, loc:(*time.Location)(0x791d1c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275686, loc:(*time.Location)(0x791d1c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275686, loc:(*time.Location)(0x791d1c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724275686, loc:(*time.Location)(0x791d1c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.27.202", PodIP:"10.2.232.114", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.2.232.114"}}, StartTime:(*v1.Time)(0xc0019701c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f3c150)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001f3c1c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://9a42fc45a5237ded6db077af6925e056e192b0204e0ae7dc7f69ce5cb5b9bb1f", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001970200), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0019701e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0050bc3df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:11.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6901" for this suite.

• [SLOW TEST:44.584 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":280,"completed":105,"skipped":1650,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:11.399: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:42:12.019: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:42:15.039: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:15.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6913" for this suite.
STEP: Destroying namespace "webhook-6913-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":280,"completed":106,"skipped":1659,"failed":0}
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:15.137: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
May  5 11:42:15.293: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:19.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8462" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":280,"completed":107,"skipped":1665,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:19.394: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:42:19.531: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
May  5 11:42:20.567: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:21.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5433" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":280,"completed":108,"skipped":1668,"failed":0}
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:21.584: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8218
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-secret-69hg
STEP: Creating a pod to test atomic-volume-subpath
May  5 11:42:21.746: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-69hg" in namespace "subpath-8218" to be "success or failure"
May  5 11:42:21.757: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Pending", Reason="", readiness=false. Elapsed: 11.13011ms
May  5 11:42:23.760: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 2.014714253s
May  5 11:42:25.764: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 4.017892137s
May  5 11:42:27.767: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 6.020995379s
May  5 11:42:29.770: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 8.024427041s
May  5 11:42:31.773: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 10.026918434s
May  5 11:42:33.777: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 12.031309056s
May  5 11:42:35.781: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 14.035398339s
May  5 11:42:37.784: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 16.038542613s
May  5 11:42:39.788: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 18.041860549s
May  5 11:42:41.791: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Running", Reason="", readiness=true. Elapsed: 20.045088153s
May  5 11:42:43.794: INFO: Pod "pod-subpath-test-secret-69hg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.048438734s
STEP: Saw pod success
May  5 11:42:43.794: INFO: Pod "pod-subpath-test-secret-69hg" satisfied condition "success or failure"
May  5 11:42:43.797: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-subpath-test-secret-69hg container test-container-subpath-secret-69hg: <nil>
STEP: delete the pod
May  5 11:42:43.913: INFO: Waiting for pod pod-subpath-test-secret-69hg to disappear
May  5 11:42:43.918: INFO: Pod pod-subpath-test-secret-69hg no longer exists
STEP: Deleting pod pod-subpath-test-secret-69hg
May  5 11:42:43.918: INFO: Deleting pod "pod-subpath-test-secret-69hg" in namespace "subpath-8218"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:43.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8218" for this suite.

• [SLOW TEST:22.345 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":280,"completed":109,"skipped":1673,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:43.929: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:42:44.078: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268" in namespace "projected-9083" to be "success or failure"
May  5 11:42:44.081: INFO: Pod "downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268": Phase="Pending", Reason="", readiness=false. Elapsed: 2.609083ms
May  5 11:42:46.093: INFO: Pod "downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014940867s
STEP: Saw pod success
May  5 11:42:46.093: INFO: Pod "downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268" satisfied condition "success or failure"
May  5 11:42:46.098: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268 container client-container: <nil>
STEP: delete the pod
May  5 11:42:46.113: INFO: Waiting for pod downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268 to disappear
May  5 11:42:46.116: INFO: Pod downwardapi-volume-4ff1d275-0286-41de-8b8e-796368693268 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:46.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9083" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":110,"skipped":1677,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:46.122: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:42:46.265: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91" in namespace "projected-8706" to be "success or failure"
May  5 11:42:46.270: INFO: Pod "downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.521005ms
May  5 11:42:48.273: INFO: Pod "downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008373998s
STEP: Saw pod success
May  5 11:42:48.274: INFO: Pod "downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91" satisfied condition "success or failure"
May  5 11:42:48.276: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91 container client-container: <nil>
STEP: delete the pod
May  5 11:42:48.292: INFO: Waiting for pod downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91 to disappear
May  5 11:42:48.294: INFO: Pod downwardapi-volume-a0e8adaf-e1f4-4ea4-8433-0d05b15e9c91 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:42:48.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8706" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":111,"skipped":1692,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:42:48.304: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-5zgl
STEP: Creating a pod to test atomic-volume-subpath
May  5 11:42:48.455: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5zgl" in namespace "subpath-2234" to be "success or failure"
May  5 11:42:48.461: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.900361ms
May  5 11:42:50.464: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 2.009711671s
May  5 11:42:52.468: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 4.01334151s
May  5 11:42:54.471: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 6.01643971s
May  5 11:42:56.478: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 8.023698937s
May  5 11:42:58.482: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 10.026891806s
May  5 11:43:00.485: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 12.03032099s
May  5 11:43:02.488: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 14.03366171s
May  5 11:43:04.492: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 16.037102205s
May  5 11:43:06.497: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 18.042706628s
May  5 11:43:08.501: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Running", Reason="", readiness=true. Elapsed: 20.046644188s
May  5 11:43:10.505: INFO: Pod "pod-subpath-test-configmap-5zgl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.050172231s
STEP: Saw pod success
May  5 11:43:10.505: INFO: Pod "pod-subpath-test-configmap-5zgl" satisfied condition "success or failure"
May  5 11:43:10.508: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-subpath-test-configmap-5zgl container test-container-subpath-configmap-5zgl: <nil>
STEP: delete the pod
May  5 11:43:10.525: INFO: Waiting for pod pod-subpath-test-configmap-5zgl to disappear
May  5 11:43:10.533: INFO: Pod pod-subpath-test-configmap-5zgl no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5zgl
May  5 11:43:10.533: INFO: Deleting pod "pod-subpath-test-configmap-5zgl" in namespace "subpath-2234"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:43:10.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2234" for this suite.

• [SLOW TEST:22.237 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":280,"completed":112,"skipped":1708,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:43:10.549: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7173
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
May  5 11:43:10.685: INFO: Waiting up to 5m0s for pod "pod-f6ee8804-1812-41dd-963c-da6390987e27" in namespace "emptydir-7173" to be "success or failure"
May  5 11:43:10.689: INFO: Pod "pod-f6ee8804-1812-41dd-963c-da6390987e27": Phase="Pending", Reason="", readiness=false. Elapsed: 4.519314ms
May  5 11:43:12.693: INFO: Pod "pod-f6ee8804-1812-41dd-963c-da6390987e27": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008244228s
STEP: Saw pod success
May  5 11:43:12.693: INFO: Pod "pod-f6ee8804-1812-41dd-963c-da6390987e27" satisfied condition "success or failure"
May  5 11:43:12.696: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-f6ee8804-1812-41dd-963c-da6390987e27 container test-container: <nil>
STEP: delete the pod
May  5 11:43:12.712: INFO: Waiting for pod pod-f6ee8804-1812-41dd-963c-da6390987e27 to disappear
May  5 11:43:12.714: INFO: Pod pod-f6ee8804-1812-41dd-963c-da6390987e27 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:43:12.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7173" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":113,"skipped":1733,"failed":0}
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:43:12.723: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
May  5 11:43:12.853: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  5 11:43:12.869: INFO: Waiting for terminating namespaces to be deleted...
May  5 11:43:12.872: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-27-202 before test
May  5 11:43:12.877: INFO: kube-proxy-m47jv from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.877: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:43:12.877: INFO: kubelet-99g5h from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.877: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:43:12.877: INFO: calico-node-v6vzp from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.877: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:43:12.878: INFO: sonobuoy from sonobuoy started at 2020-05-05 11:16:48 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.878: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  5 11:43:12.878: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:43:12.878: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:43:12.878: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:43:12.878: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-33-250 before test
May  5 11:43:12.893: INFO: calico-node-579x2 from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:43:12.893: INFO: kubelet-8cl8p from kube-system started at 2020-05-05 11:00:18 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:43:12.893: INFO: coredns-6f64b7db7-z5b8s from kube-system started at 2020-05-05 11:00:47 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container coredns ready: true, restart count 0
May  5 11:43:12.893: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:43:12.893: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:43:12.893: INFO: kube-proxy-8nsbj from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:43:12.893: INFO: sonobuoy-e2e-job-0f2dbdcc56724f7f from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:43:12.893: INFO: 	Container e2e ready: true, restart count 0
May  5 11:43:12.893: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d9dbbe92-2212-49db-8618-3508f77b9687 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-d9dbbe92-2212-49db-8618-3508f77b9687 off the node ip-10-0-27-202
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d9dbbe92-2212-49db-8618-3508f77b9687
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:16.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6910" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:304.265 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":280,"completed":114,"skipped":1743,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:16.988: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3451
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:48:17.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d" in namespace "downward-api-3451" to be "success or failure"
May  5 11:48:17.188: INFO: Pod "downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.816071ms
May  5 11:48:19.195: INFO: Pod "downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013724904s
STEP: Saw pod success
May  5 11:48:19.195: INFO: Pod "downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d" satisfied condition "success or failure"
May  5 11:48:19.198: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d container client-container: <nil>
STEP: delete the pod
May  5 11:48:19.233: INFO: Waiting for pod downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d to disappear
May  5 11:48:19.235: INFO: Pod downwardapi-volume-191d1b8d-94fa-4ea0-bbdd-8969f808f85d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:19.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3451" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":115,"skipped":1745,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:19.242: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  5 11:48:21.396: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:21.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4867" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":116,"skipped":1758,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:21.413: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
May  5 11:48:21.548: INFO: Waiting up to 5m0s for pod "pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2" in namespace "emptydir-390" to be "success or failure"
May  5 11:48:21.552: INFO: Pod "pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.439484ms
May  5 11:48:23.556: INFO: Pod "pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007983539s
STEP: Saw pod success
May  5 11:48:23.556: INFO: Pod "pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2" satisfied condition "success or failure"
May  5 11:48:23.559: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2 container test-container: <nil>
STEP: delete the pod
May  5 11:48:23.579: INFO: Waiting for pod pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2 to disappear
May  5 11:48:23.581: INFO: Pod pod-1c9bb4df-efc2-4ded-8467-8fbd9dd383e2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:23.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-390" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":117,"skipped":1767,"failed":0}
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:23.591: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1585
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 11:48:23.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6789'
May  5 11:48:23.876: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  5 11:48:23.876: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
May  5 11:48:23.884: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
May  5 11:48:23.889: INFO: scanned /root for discovery docs: <nil>
May  5 11:48:23.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6789'
May  5 11:48:39.691: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May  5 11:48:39.691: INFO: stdout: "Created e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0\nScaling up e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
May  5 11:48:39.691: INFO: stdout: "Created e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0\nScaling up e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
May  5 11:48:39.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-6789'
May  5 11:48:39.790: INFO: stderr: ""
May  5 11:48:39.790: INFO: stdout: "e2e-test-httpd-rc-bg7jj e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0-xrf2z "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
May  5 11:48:44.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-6789'
May  5 11:48:44.968: INFO: stderr: ""
May  5 11:48:44.968: INFO: stdout: "e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0-xrf2z "
May  5 11:48:44.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0-xrf2z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6789'
May  5 11:48:45.283: INFO: stderr: ""
May  5 11:48:45.283: INFO: stdout: "true"
May  5 11:48:45.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0-xrf2z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6789'
May  5 11:48:45.375: INFO: stderr: ""
May  5 11:48:45.375: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
May  5 11:48:45.375: INFO: e2e-test-httpd-rc-f4e4b940c8f65ca2df136964601baea0-xrf2z is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
May  5 11:48:45.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete rc e2e-test-httpd-rc --namespace=kubectl-6789'
May  5 11:48:45.475: INFO: stderr: ""
May  5 11:48:45.475: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:45.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6789" for this suite.

• [SLOW TEST:21.892 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1580
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]","total":280,"completed":118,"skipped":1776,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:45.483: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6582
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
May  5 11:48:45.665: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-resource-version 12e8aac1-720d-4d30-958f-92a22d96100b 15642 0 2020-05-05 11:48:45 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  5 11:48:45.665: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-resource-version 12e8aac1-720d-4d30-958f-92a22d96100b 15643 0 2020-05-05 11:48:45 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:45.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6582" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":280,"completed":119,"skipped":1798,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:45.674: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-3ac4f43a-2682-4598-b777-27fc07954684
STEP: Creating a pod to test consume configMaps
May  5 11:48:45.812: INFO: Waiting up to 5m0s for pod "pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d" in namespace "configmap-2446" to be "success or failure"
May  5 11:48:45.836: INFO: Pod "pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.784615ms
May  5 11:48:47.839: INFO: Pod "pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027750153s
STEP: Saw pod success
May  5 11:48:47.839: INFO: Pod "pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d" satisfied condition "success or failure"
May  5 11:48:47.842: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d container configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:48:47.856: INFO: Waiting for pod pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d to disappear
May  5 11:48:47.858: INFO: Pod pod-configmaps-ad264e6d-94f8-4620-a5e5-f5a4cdf6646d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:47.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2446" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":120,"skipped":1808,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:47.865: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
May  5 11:48:52.079: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  5 11:48:52.081: INFO: Pod pod-with-poststart-http-hook still exists
May  5 11:48:54.082: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  5 11:48:54.085: INFO: Pod pod-with-poststart-http-hook still exists
May  5 11:48:56.083: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
May  5 11:48:56.087: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:56.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5682" for this suite.

• [SLOW TEST:8.234 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":280,"completed":121,"skipped":1819,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:56.109: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4973
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
May  5 11:48:56.261: INFO: Waiting up to 5m0s for pod "pod-3671bb55-0617-4b09-8ca9-4af38dc34280" in namespace "emptydir-4973" to be "success or failure"
May  5 11:48:56.265: INFO: Pod "pod-3671bb55-0617-4b09-8ca9-4af38dc34280": Phase="Pending", Reason="", readiness=false. Elapsed: 3.907617ms
May  5 11:48:58.268: INFO: Pod "pod-3671bb55-0617-4b09-8ca9-4af38dc34280": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006814526s
STEP: Saw pod success
May  5 11:48:58.268: INFO: Pod "pod-3671bb55-0617-4b09-8ca9-4af38dc34280" satisfied condition "success or failure"
May  5 11:48:58.270: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-3671bb55-0617-4b09-8ca9-4af38dc34280 container test-container: <nil>
STEP: delete the pod
May  5 11:48:58.285: INFO: Waiting for pod pod-3671bb55-0617-4b09-8ca9-4af38dc34280 to disappear
May  5 11:48:58.287: INFO: Pod pod-3671bb55-0617-4b09-8ca9-4af38dc34280 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:48:58.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4973" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":122,"skipped":1871,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:48:58.296: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8812
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-607aab05-8810-46f4-aafa-3a5e620449fa
STEP: Creating a pod to test consume configMaps
May  5 11:48:58.442: INFO: Waiting up to 5m0s for pod "pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8" in namespace "configmap-8812" to be "success or failure"
May  5 11:48:58.446: INFO: Pod "pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.761759ms
May  5 11:49:00.449: INFO: Pod "pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006655448s
STEP: Saw pod success
May  5 11:49:00.449: INFO: Pod "pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8" satisfied condition "success or failure"
May  5 11:49:00.451: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8 container configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:49:00.467: INFO: Waiting for pod pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8 to disappear
May  5 11:49:00.469: INFO: Pod pod-configmaps-bddcf1f2-fba1-4a74-8247-f1afad3df2f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:00.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8812" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":123,"skipped":1881,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:00.477: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1917.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1917.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 45.27.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.27.45_udp@PTR;check="$$(dig +tcp +noall +answer +search 45.27.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.27.45_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1917.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1917.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1917.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1917.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1917.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 45.27.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.27.45_udp@PTR;check="$$(dig +tcp +noall +answer +search 45.27.3.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.3.27.45_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 11:49:02.650: INFO: Unable to read wheezy_udp@dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.655: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.659: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.662: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.698: INFO: Unable to read jessie_udp@dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.701: INFO: Unable to read jessie_tcp@dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.705: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.709: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local from pod dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5: the server could not find the requested resource (get pods dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5)
May  5 11:49:02.745: INFO: Lookups using dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5 failed for: [wheezy_udp@dns-test-service.dns-1917.svc.cluster.local wheezy_tcp@dns-test-service.dns-1917.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local jessie_udp@dns-test-service.dns-1917.svc.cluster.local jessie_tcp@dns-test-service.dns-1917.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1917.svc.cluster.local]

May  5 11:49:07.829: INFO: DNS probes using dns-1917/dns-test-58e055b8-76bb-4367-bfeb-ffdd7b3f19e5 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:07.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1917" for this suite.

• [SLOW TEST:7.428 seconds]
[sig-network] DNS
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":280,"completed":124,"skipped":1884,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:07.909: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
May  5 11:49:08.067: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  5 11:49:08.075: INFO: Waiting for terminating namespaces to be deleted...
May  5 11:49:08.077: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-27-202 before test
May  5 11:49:08.083: INFO: kube-proxy-m47jv from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.083: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:49:08.083: INFO: kubelet-99g5h from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.083: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:49:08.083: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:49:08.083: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:49:08.083: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:49:08.083: INFO: calico-node-v6vzp from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.083: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:49:08.083: INFO: sonobuoy from sonobuoy started at 2020-05-05 11:16:48 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.083: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  5 11:49:08.083: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-33-250 before test
May  5 11:49:08.099: INFO: coredns-6f64b7db7-z5b8s from kube-system started at 2020-05-05 11:00:47 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container coredns ready: true, restart count 0
May  5 11:49:08.099: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 11:49:08.099: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 11:49:08.099: INFO: calico-node-579x2 from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container calico-node ready: true, restart count 0
May  5 11:49:08.099: INFO: kubelet-8cl8p from kube-system started at 2020-05-05 11:00:18 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container kubelet ready: true, restart count 0
May  5 11:49:08.099: INFO: kube-proxy-8nsbj from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 11:49:08.099: INFO: sonobuoy-e2e-job-0f2dbdcc56724f7f from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 11:49:08.099: INFO: 	Container e2e ready: true, restart count 0
May  5 11:49:08.100: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.160c1f732f0a7dae], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.160c1f732f9354c2], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:09.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5637" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":280,"completed":125,"skipped":1911,"failed":0}
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:09.132: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4888
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
STEP: reading a file in the container
May  5 11:49:11.809: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4888 pod-service-account-67ddc8a4-bb7c-4ace-ac2a-4d5c65f85dd7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
May  5 11:49:11.989: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4888 pod-service-account-67ddc8a4-bb7c-4ace-ac2a-4d5c65f85dd7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
May  5 11:49:12.247: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-4888 pod-service-account-67ddc8a4-bb7c-4ace-ac2a-4d5c65f85dd7 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:12.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4888" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":280,"completed":126,"skipped":1919,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:12.445: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4013
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-0213ef1a-6ca9-42c7-b959-b2a0e8458755
STEP: Creating secret with name s-test-opt-upd-efdde9bb-a3ef-40cc-b65d-65c4024b7c81
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0213ef1a-6ca9-42c7-b959-b2a0e8458755
STEP: Updating secret s-test-opt-upd-efdde9bb-a3ef-40cc-b65d-65c4024b7c81
STEP: Creating secret with name s-test-opt-create-245085b1-66b9-47df-8b8c-7310b09c89a2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:16.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4013" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":127,"skipped":1930,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:16.732: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4785
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:49:16.867: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  5 11:49:20.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4785 create -f -'
May  5 11:49:20.870: INFO: stderr: ""
May  5 11:49:20.870: INFO: stdout: "e2e-test-crd-publish-openapi-9695-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  5 11:49:20.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4785 delete e2e-test-crd-publish-openapi-9695-crds test-cr'
May  5 11:49:20.969: INFO: stderr: ""
May  5 11:49:20.969: INFO: stdout: "e2e-test-crd-publish-openapi-9695-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
May  5 11:49:20.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4785 apply -f -'
May  5 11:49:21.141: INFO: stderr: ""
May  5 11:49:21.141: INFO: stdout: "e2e-test-crd-publish-openapi-9695-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
May  5 11:49:21.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4785 delete e2e-test-crd-publish-openapi-9695-crds test-cr'
May  5 11:49:21.213: INFO: stderr: ""
May  5 11:49:21.213: INFO: stdout: "e2e-test-crd-publish-openapi-9695-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May  5 11:49:21.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-9695-crds'
May  5 11:49:21.385: INFO: stderr: ""
May  5 11:49:21.385: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9695-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:24.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4785" for this suite.

• [SLOW TEST:8.011 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":280,"completed":128,"skipped":1941,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:24.742: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-609
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:49:24.878: INFO: Waiting up to 5m0s for pod "downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb" in namespace "projected-609" to be "success or failure"
May  5 11:49:24.881: INFO: Pod "downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.743109ms
May  5 11:49:26.884: INFO: Pod "downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005922478s
STEP: Saw pod success
May  5 11:49:26.884: INFO: Pod "downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb" satisfied condition "success or failure"
May  5 11:49:26.888: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb container client-container: <nil>
STEP: delete the pod
May  5 11:49:26.930: INFO: Waiting for pod downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb to disappear
May  5 11:49:26.935: INFO: Pod downwardapi-volume-baab3588-465e-4542-8188-56c1f003cbdb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:49:26.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-609" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":129,"skipped":1945,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:49:26.943: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-32233a30-b749-4633-806d-8c261b73f818 in namespace container-probe-5607
May  5 11:49:29.106: INFO: Started pod busybox-32233a30-b749-4633-806d-8c261b73f818 in namespace container-probe-5607
STEP: checking the pod's current state and verifying that restartCount is present
May  5 11:49:29.110: INFO: Initial restart count of pod busybox-32233a30-b749-4633-806d-8c261b73f818 is 0
May  5 11:50:15.228: INFO: Restart count of pod container-probe-5607/busybox-32233a30-b749-4633-806d-8c261b73f818 is now 1 (46.118078285s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:50:15.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5607" for this suite.

• [SLOW TEST:48.303 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":130,"skipped":1946,"failed":0}
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:50:15.248: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:50:41.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3960" for this suite.

• [SLOW TEST:26.426 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":280,"completed":131,"skipped":1951,"failed":0}
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:50:41.677: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
May  5 11:50:41.817: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16469 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  5 11:50:41.817: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16469 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
May  5 11:50:51.827: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16515 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May  5 11:50:51.827: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16515 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
May  5 11:51:01.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16539 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  5 11:51:01.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16539 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
May  5 11:51:11.845: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16563 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  5 11:51:11.846: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-a 8770918b-d951-4c1b-98bb-fce2ec668fc0 16563 0 2020-05-05 11:50:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
May  5 11:51:21.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-b c239d199-f64b-4bfb-a427-00853cc0768a 16587 0 2020-05-05 11:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  5 11:51:21.852: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-b c239d199-f64b-4bfb-a427-00853cc0768a 16587 0 2020-05-05 11:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
May  5 11:51:31.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-b c239d199-f64b-4bfb-a427-00853cc0768a 16612 0 2020-05-05 11:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  5 11:51:31.861: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-3483 /api/v1/namespaces/watch-3483/configmaps/e2e-watch-test-configmap-b c239d199-f64b-4bfb-a427-00853cc0768a 16612 0 2020-05-05 11:51:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:51:41.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3483" for this suite.

• [SLOW TEST:60.193 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":280,"completed":132,"skipped":1952,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:51:41.872: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-317
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
May  5 11:51:42.038: INFO: Waiting up to 5m0s for pod "downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793" in namespace "downward-api-317" to be "success or failure"
May  5 11:51:42.042: INFO: Pod "downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793": Phase="Pending", Reason="", readiness=false. Elapsed: 3.883863ms
May  5 11:51:44.045: INFO: Pod "downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007371171s
STEP: Saw pod success
May  5 11:51:44.045: INFO: Pod "downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793" satisfied condition "success or failure"
May  5 11:51:44.048: INFO: Trying to get logs from node ip-10-0-27-202 pod downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793 container dapi-container: <nil>
STEP: delete the pod
May  5 11:51:44.070: INFO: Waiting for pod downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793 to disappear
May  5 11:51:44.073: INFO: Pod downward-api-a8470edf-94c6-4dfa-9b8b-e1bec44ef793 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:51:44.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-317" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":280,"completed":133,"skipped":1969,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:51:44.081: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:51:44.222: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a" in namespace "projected-6424" to be "success or failure"
May  5 11:51:44.229: INFO: Pod "downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079475ms
May  5 11:51:46.232: INFO: Pod "downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009556025s
STEP: Saw pod success
May  5 11:51:46.232: INFO: Pod "downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a" satisfied condition "success or failure"
May  5 11:51:46.235: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a container client-container: <nil>
STEP: delete the pod
May  5 11:51:46.251: INFO: Waiting for pod downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a to disappear
May  5 11:51:46.255: INFO: Pod downwardapi-volume-55c01905-3d4e-4150-9e80-00f4b61d863a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:51:46.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6424" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":134,"skipped":2041,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:51:46.265: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1708
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1708
I0505 11:51:46.421781      21 runners.go:189] Created replication controller with name: externalname-service, namespace: services-1708, replica count: 2
I0505 11:51:49.472101      21 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  5 11:51:49.472: INFO: Creating new exec pod
May  5 11:51:52.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-1708 execpod7vhn4 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May  5 11:51:52.778: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  5 11:51:52.778: INFO: stdout: ""
May  5 11:51:52.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-1708 execpod7vhn4 -- /bin/sh -x -c nc -zv -t -w 2 10.3.125.215 80'
May  5 11:51:52.966: INFO: stderr: "+ nc -zv -t -w 2 10.3.125.215 80\nConnection to 10.3.125.215 80 port [tcp/http] succeeded!\n"
May  5 11:51:52.966: INFO: stdout: ""
May  5 11:51:52.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-1708 execpod7vhn4 -- /bin/sh -x -c nc -zv -t -w 2 10.0.27.202 31692'
May  5 11:51:53.171: INFO: stderr: "+ nc -zv -t -w 2 10.0.27.202 31692\nConnection to 10.0.27.202 31692 port [tcp/31692] succeeded!\n"
May  5 11:51:53.171: INFO: stdout: ""
May  5 11:51:53.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-1708 execpod7vhn4 -- /bin/sh -x -c nc -zv -t -w 2 10.0.33.250 31692'
May  5 11:51:53.360: INFO: stderr: "+ nc -zv -t -w 2 10.0.33.250 31692\nConnection to 10.0.33.250 31692 port [tcp/31692] succeeded!\n"
May  5 11:51:53.360: INFO: stdout: ""
May  5 11:51:53.360: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:51:53.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1708" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:7.154 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":280,"completed":135,"skipped":2042,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:51:53.421: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8483
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
May  5 11:51:53.593: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
May  5 11:52:00.625: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:00.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8483" for this suite.

• [SLOW TEST:7.214 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":280,"completed":136,"skipped":2044,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:00.635: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:52:00.786: INFO: Creating deployment "webserver-deployment"
May  5 11:52:00.790: INFO: Waiting for observed generation 1
May  5 11:52:02.802: INFO: Waiting for all required pods to come up
May  5 11:52:02.807: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
May  5 11:52:04.828: INFO: Waiting for deployment "webserver-deployment" to complete
May  5 11:52:04.833: INFO: Updating deployment "webserver-deployment" with a non-existent image
May  5 11:52:04.838: INFO: Updating deployment webserver-deployment
May  5 11:52:04.838: INFO: Waiting for observed generation 2
May  5 11:52:06.844: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
May  5 11:52:06.847: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
May  5 11:52:06.849: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  5 11:52:06.856: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
May  5 11:52:06.856: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
May  5 11:52:06.858: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
May  5 11:52:06.863: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
May  5 11:52:06.863: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
May  5 11:52:06.870: INFO: Updating deployment webserver-deployment
May  5 11:52:06.870: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
May  5 11:52:06.901: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
May  5 11:52:08.920: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
May  5 11:52:08.929: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8970 /apis/apps/v1/namespaces/deployment-8970/deployments/webserver-deployment 4dd6e3ab-fff0-41d9-9860-e7d8a06683a3 17218 3 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005847e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-05 11:52:06 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-05-05 11:52:07 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

May  5 11:52:08.933: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-8970 /apis/apps/v1/namespaces/deployment-8970/replicasets/webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 17217 3 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 4dd6e3ab-fff0-41d9-9860-e7d8a06683a3 0xc005893697 0xc005893698}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005893708 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 11:52:08.933: INFO: All old ReplicaSets of Deployment "webserver-deployment":
May  5 11:52:08.933: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-8970 /apis/apps/v1/namespaces/deployment-8970/replicasets/webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 17197 3 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 4dd6e3ab-fff0-41d9-9860-e7d8a06683a3 0xc0058935d7 0xc0058935d8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005893638 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
May  5 11:52:08.944: INFO: Pod "webserver-deployment-595b5b9587-2nf95" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2nf95 webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-2nf95 e1a5779c-45e2-4583-a616-07bb8efbe036 17036 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.169.51/32 cni.projectcalico.org/podIPs:10.2.169.51/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0277 0xc0058b0278}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.51,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4694383a23c26736683de0bf11e1ae2ca938a3a98f6ac7637c66ed929c697b30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.944: INFO: Pod "webserver-deployment-595b5b9587-67rmz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-67rmz webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-67rmz 93b5657c-29c3-4b10-ba49-1f09f5614632 17003 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.232.147/32 cni.projectcalico.org/podIPs:10.2.232.147/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0410 0xc0058b0411}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:10.2.232.147,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://18d7ff342f72f67db3ad6b5e72ca58f1a63d05a3dc0efec0eac416d795fc6774,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.232.147,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.948: INFO: Pod "webserver-deployment-595b5b9587-688p4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-688p4 webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-688p4 17485b75-7f56-44ca-8f1d-498d1d518875 17204 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0587 0xc0058b0588}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.949: INFO: Pod "webserver-deployment-595b5b9587-7gcfv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7gcfv webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-7gcfv d294cc43-46d9-4ec9-bf58-ee24c9a272da 17222 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b06e7 0xc0058b06e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.949: INFO: Pod "webserver-deployment-595b5b9587-fqczz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fqczz webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-fqczz f6807d2c-d2d1-4f5f-9424-52dbdf76ee0d 17014 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.232.148/32 cni.projectcalico.org/podIPs:10.2.232.148/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0867 0xc0058b0868}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:10.2.232.148,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3b0af71fb750e39d54cdbac9a3a702b900c112aa8b7590efda5553d8901deb55,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.232.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.949: INFO: Pod "webserver-deployment-595b5b9587-fvmnl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fvmnl webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-fvmnl 25f0f33c-15f2-4899-b17c-47da9629262c 17234 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b09e7 0xc0058b09e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.949: INFO: Pod "webserver-deployment-595b5b9587-jdltw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jdltw webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-jdltw 2408fbcc-063a-49ac-a670-f7a06ce9e1ea 17260 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0b47 0xc0058b0b48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.950: INFO: Pod "webserver-deployment-595b5b9587-kmdmv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kmdmv webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-kmdmv 71b4b832-8aab-482a-a1ab-283456ff73de 17180 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0ca7 0xc0058b0ca8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.950: INFO: Pod "webserver-deployment-595b5b9587-kr9jq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kr9jq webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-kr9jq fc5d573a-4c1c-45e3-8d4e-d98a395cbc97 17219 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0e07 0xc0058b0e08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.950: INFO: Pod "webserver-deployment-595b5b9587-mklr2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mklr2 webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-mklr2 1dbc4290-a3e3-4246-bac0-82ea72a62866 17033 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.169.53/32 cni.projectcalico.org/podIPs:10.2.169.53/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b0f87 0xc0058b0f88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.53,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6b7f40730fe221c79a0329a7f92c2c7cfaec671eb85ecd0330a8e66c9922acaa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.53,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.950: INFO: Pod "webserver-deployment-595b5b9587-pgczz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pgczz webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-pgczz 96aa9688-621f-4362-8c91-d707c6edbf15 17195 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1100 0xc0058b1101}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.951: INFO: Pod "webserver-deployment-595b5b9587-pxbpd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pxbpd webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-pxbpd 93049cce-fc5b-483c-a673-18b9494a0c10 17030 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.169.50/32 cni.projectcalico.org/podIPs:10.2.169.50/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1277 0xc0058b1278}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.50,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0bac2a6ab253c9b6ac2f49a131b4e82782d90a8b5ba7e40d24c2ac48339b6061,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.951: INFO: Pod "webserver-deployment-595b5b9587-rz5pn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rz5pn webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-rz5pn f70686f5-696a-4048-8b3b-1630d8ab1df5 17232 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b13f0 0xc0058b13f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.951: INFO: Pod "webserver-deployment-595b5b9587-rzcwr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rzcwr webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-rzcwr 33fd8235-c701-446d-a5a0-555b19080978 17010 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.232.149/32 cni.projectcalico.org/podIPs:10.2.232.149/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1567 0xc0058b1568}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:10.2.232.149,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d05fa61e61e7861e46b350ba0212b4803f815e2fcb298cc5dc9614064c1d6846,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.232.149,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.955: INFO: Pod "webserver-deployment-595b5b9587-sphbs" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sphbs webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-sphbs b86e895b-c6e6-4971-a73f-c4d2a528f7fd 17027 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.169.52/32 cni.projectcalico.org/podIPs:10.2.169.52/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1707 0xc0058b1708}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.52,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2ca6423ecfbffbef139703fbb45ae3b4109ed096628464e8a95f86aef8a241f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.956: INFO: Pod "webserver-deployment-595b5b9587-st8hj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-st8hj webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-st8hj 0dbf02b8-9f1c-4952-a87a-a0de6c7ea47e 17024 0 2020-05-05 11:52:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:10.2.169.54/32 cni.projectcalico.org/podIPs:10.2.169.54/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b18a0 0xc0058b18a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:10.2.169.54,StartTime:2020-05-05 11:52:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 11:52:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e38043170d1412168688b35a6c1260cbf87960a2f08051deb1c60875bc3bd8a2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.169.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.960: INFO: Pod "webserver-deployment-595b5b9587-tprml" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tprml webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-tprml e8caea3c-e5bb-4b62-9acc-da22859cb3f9 17221 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1a20 0xc0058b1a21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.960: INFO: Pod "webserver-deployment-595b5b9587-vqhb8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vqhb8 webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-vqhb8 87cb665b-51e2-472f-b6f2-845441922802 17249 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1b77 0xc0058b1b78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.961: INFO: Pod "webserver-deployment-595b5b9587-wfw7r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wfw7r webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-wfw7r 3c2138b6-4cbd-4291-9760-09d0f1e57cb3 17258 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1cd7 0xc0058b1cd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.961: INFO: Pod "webserver-deployment-595b5b9587-x6pm6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x6pm6 webserver-deployment-595b5b9587- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-595b5b9587-x6pm6 395db03d-a100-4a9c-a114-30acfaaf9bd4 17225 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d054d4e-62ca-4999-b51b-9e313defc861 0xc0058b1e57 0xc0058b1e58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.961: INFO: Pod "webserver-deployment-c7997dcc8-4f9l7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4f9l7 webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-4f9l7 b5bbf471-ae7b-4e70-aa23-8a121f8579a5 17115 0 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.169.55/32 cni.projectcalico.org/podIPs:10.2.169.55/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058b1fd7 0xc0058b1fd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.961: INFO: Pod "webserver-deployment-c7997dcc8-4lqv9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4lqv9 webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-4lqv9 d9886d4b-e295-4388-9019-106607c9089b 17259 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc150 0xc0058cc151}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.974: INFO: Pod "webserver-deployment-c7997dcc8-4tstd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4tstd webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-4tstd b9e7e8f5-995f-4bae-95a6-56d27289064c 17248 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc2c0 0xc0058cc2c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.974: INFO: Pod "webserver-deployment-c7997dcc8-775m4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-775m4 webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-775m4 84be6289-c0d9-4e9c-91c5-b48d36c24887 17224 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc430 0xc0058cc431}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.983: INFO: Pod "webserver-deployment-c7997dcc8-8hqzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8hqzh webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-8hqzh b49f4e5f-12c0-444d-afce-2d7197dbd53b 17223 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc5a0 0xc0058cc5a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.983: INFO: Pod "webserver-deployment-c7997dcc8-bwqpd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bwqpd webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-bwqpd 2c93b1f4-fbb2-4424-9e7d-61e54cf884cd 17134 0 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.232.153/32 cni.projectcalico.org/podIPs:10.2.232.153/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc730 0xc0058cc731}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.983: INFO: Pod "webserver-deployment-c7997dcc8-cddvl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cddvl webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-cddvl f070c878-8027-4207-9b68-3e25522af2bd 17214 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc8a0 0xc0058cc8a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.993: INFO: Pod "webserver-deployment-c7997dcc8-fntrv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fntrv webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-fntrv cb795148-9d1a-4334-9081-1955b03e4731 17242 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cc9c0 0xc0058cc9c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.996: INFO: Pod "webserver-deployment-c7997dcc8-fx9wk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fx9wk webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-fx9wk 21a6d2fb-0f27-4975-8577-57aeada8426d 17117 0 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.169.56/32 cni.projectcalico.org/podIPs:10.2.169.56/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058ccb50 0xc0058ccb51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.996: INFO: Pod "webserver-deployment-c7997dcc8-hq4qx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hq4qx webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-hq4qx 0734d522-160a-4994-be99-5eaae538f528 17133 0 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.232.152/32 cni.projectcalico.org/podIPs:10.2.232.152/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058ccce0 0xc0058ccce1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.997: INFO: Pod "webserver-deployment-c7997dcc8-jr2qz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jr2qz webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-jr2qz 944a8108-e0c1-418a-b1b3-fe6cc9626ecb 17244 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cce50 0xc0058cce51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.997: INFO: Pod "webserver-deployment-c7997dcc8-wdqtb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wdqtb webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-wdqtb c4d4d126-32ce-4ed8-8b44-2df16683576f 17182 0 2020-05-05 11:52:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058ccfd0 0xc0058ccfd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-33-250,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.33.250,PodIP:,StartTime:2020-05-05 11:52:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
May  5 11:52:08.997: INFO: Pod "webserver-deployment-c7997dcc8-zbd9k" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zbd9k webserver-deployment-c7997dcc8- deployment-8970 /api/v1/namespaces/deployment-8970/pods/webserver-deployment-c7997dcc8-zbd9k cd6d38af-ab49-4118-85b8-f58503c11af3 17123 0 2020-05-05 11:52:04 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:10.2.232.151/32 cni.projectcalico.org/podIPs:10.2.232.151/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 c966cdb7-d28a-4fd2-83a8-ffb935fdf1e3 0xc0058cd160 0xc0058cd161}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvnfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvnfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvnfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 11:52:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 11:52:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:08.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8970" for this suite.

• [SLOW TEST:8.372 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":280,"completed":137,"skipped":2055,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:09.009: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:172
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating server pod server in namespace prestop-3850
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3850
STEP: Deleting pre-stop pod
May  5 11:52:28.312: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:28.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3850" for this suite.

• [SLOW TEST:19.321 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":280,"completed":138,"skipped":2121,"failed":0}
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:28.331: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
May  5 11:52:32.514: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.514: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:32.603: INFO: Exec stderr: ""
May  5 11:52:32.603: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.603: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:32.700: INFO: Exec stderr: ""
May  5 11:52:32.700: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.700: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:32.792: INFO: Exec stderr: ""
May  5 11:52:32.792: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.793: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:32.902: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
May  5 11:52:32.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.902: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:32.994: INFO: Exec stderr: ""
May  5 11:52:32.994: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:32.994: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:33.102: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
May  5 11:52:33.102: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:33.102: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:33.215: INFO: Exec stderr: ""
May  5 11:52:33.215: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:33.215: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:33.357: INFO: Exec stderr: ""
May  5 11:52:33.357: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:33.357: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:33.537: INFO: Exec stderr: ""
May  5 11:52:33.537: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6884 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:52:33.537: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:52:33.653: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:33.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6884" for this suite.

• [SLOW TEST:5.330 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":139,"skipped":2126,"failed":0}
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:33.662: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-36ca9aae-cc5d-49a8-99fc-2e6b2c119554
STEP: Creating a pod to test consume secrets
May  5 11:52:33.817: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0" in namespace "projected-3829" to be "success or failure"
May  5 11:52:33.824: INFO: Pod "pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.7923ms
May  5 11:52:35.829: INFO: Pod "pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011695111s
STEP: Saw pod success
May  5 11:52:35.829: INFO: Pod "pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0" satisfied condition "success or failure"
May  5 11:52:35.836: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  5 11:52:35.876: INFO: Waiting for pod pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0 to disappear
May  5 11:52:35.886: INFO: Pod pod-projected-secrets-db52a665-20f4-45fc-9349-49eca3481da0 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:35.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3829" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":140,"skipped":2130,"failed":0}

------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:35.914: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:46
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:36.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9511" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":280,"completed":141,"skipped":2130,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:36.108: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:52:36.268: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-0b81ac5f-45f9-4126-855a-0b45c5c936c4" in namespace "security-context-test-9771" to be "success or failure"
May  5 11:52:36.271: INFO: Pod "busybox-readonly-false-0b81ac5f-45f9-4126-855a-0b45c5c936c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.791777ms
May  5 11:52:38.274: INFO: Pod "busybox-readonly-false-0b81ac5f-45f9-4126-855a-0b45c5c936c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006094534s
May  5 11:52:38.274: INFO: Pod "busybox-readonly-false-0b81ac5f-45f9-4126-855a-0b45c5c936c4" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:38.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9771" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":280,"completed":142,"skipped":2138,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:38.283: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating api versions
May  5 11:52:38.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 api-versions'
May  5 11:52:38.493: INFO: stderr: ""
May  5 11:52:38.493: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:38.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9831" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":280,"completed":143,"skipped":2215,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:38.502: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name projected-secret-test-c2d620c1-54a2-4977-bda1-151131ab2bc5
STEP: Creating a pod to test consume secrets
May  5 11:52:38.722: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28" in namespace "projected-4116" to be "success or failure"
May  5 11:52:38.726: INFO: Pod "pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28": Phase="Pending", Reason="", readiness=false. Elapsed: 4.000651ms
May  5 11:52:40.739: INFO: Pod "pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017750415s
STEP: Saw pod success
May  5 11:52:40.740: INFO: Pod "pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28" satisfied condition "success or failure"
May  5 11:52:40.743: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28 container secret-volume-test: <nil>
STEP: delete the pod
May  5 11:52:40.762: INFO: Waiting for pod pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28 to disappear
May  5 11:52:40.764: INFO: Pod pod-projected-secrets-a607e2a0-d566-4202-bdbe-f754c9673a28 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:40.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4116" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":144,"skipped":2226,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:40.773: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:46.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8773" for this suite.

• [SLOW TEST:6.234 seconds]
[sig-apps] Job
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":280,"completed":145,"skipped":2257,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:47.008: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  5 11:52:47.155: INFO: Waiting up to 5m0s for pod "pod-8faa94f1-0e59-459f-8c56-561c5238662e" in namespace "emptydir-1097" to be "success or failure"
May  5 11:52:47.158: INFO: Pod "pod-8faa94f1-0e59-459f-8c56-561c5238662e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.194385ms
May  5 11:52:49.161: INFO: Pod "pod-8faa94f1-0e59-459f-8c56-561c5238662e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006517166s
STEP: Saw pod success
May  5 11:52:49.162: INFO: Pod "pod-8faa94f1-0e59-459f-8c56-561c5238662e" satisfied condition "success or failure"
May  5 11:52:49.164: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-8faa94f1-0e59-459f-8c56-561c5238662e container test-container: <nil>
STEP: delete the pod
May  5 11:52:49.184: INFO: Waiting for pod pod-8faa94f1-0e59-459f-8c56-561c5238662e to disappear
May  5 11:52:49.188: INFO: Pod pod-8faa94f1-0e59-459f-8c56-561c5238662e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:49.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1097" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":146,"skipped":2259,"failed":0}
SSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:49.204: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-8640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test hostPath mode
May  5 11:52:49.339: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-8640" to be "success or failure"
May  5 11:52:49.341: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.812518ms
May  5 11:52:51.344: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005413014s
STEP: Saw pod success
May  5 11:52:51.344: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
May  5 11:52:51.347: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
May  5 11:52:51.369: INFO: Waiting for pod pod-host-path-test to disappear
May  5 11:52:51.371: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:51.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-8640" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":147,"skipped":2262,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:51.379: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override all
May  5 11:52:51.518: INFO: Waiting up to 5m0s for pod "client-containers-7bda327d-476f-4647-9c6f-428595aa153e" in namespace "containers-3917" to be "success or failure"
May  5 11:52:51.523: INFO: Pod "client-containers-7bda327d-476f-4647-9c6f-428595aa153e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.636256ms
May  5 11:52:53.527: INFO: Pod "client-containers-7bda327d-476f-4647-9c6f-428595aa153e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008972292s
STEP: Saw pod success
May  5 11:52:53.527: INFO: Pod "client-containers-7bda327d-476f-4647-9c6f-428595aa153e" satisfied condition "success or failure"
May  5 11:52:53.529: INFO: Trying to get logs from node ip-10-0-27-202 pod client-containers-7bda327d-476f-4647-9c6f-428595aa153e container test-container: <nil>
STEP: delete the pod
May  5 11:52:53.543: INFO: Waiting for pod client-containers-7bda327d-476f-4647-9c6f-428595aa153e to disappear
May  5 11:52:53.546: INFO: Pod client-containers-7bda327d-476f-4647-9c6f-428595aa153e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:52:53.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3917" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":280,"completed":148,"skipped":2270,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:52:53.554: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6530
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
May  5 11:53:33.755: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:53:33.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0505 11:53:33.755885      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6530" for this suite.

• [SLOW TEST:40.212 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":280,"completed":149,"skipped":2281,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:53:33.766: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:53:34.824: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 11:53:36.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276414, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276414, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276414, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276414, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:53:39.926: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:53:40.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4704" for this suite.
STEP: Destroying namespace "webhook-4704-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.373 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":280,"completed":150,"skipped":2281,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:53:40.140: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:53:56.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-867" for this suite.

• [SLOW TEST:16.254 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":280,"completed":151,"skipped":2285,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:53:56.405: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-ce32f411-1f7b-4ec7-bab9-a540a7e27763 in namespace container-probe-5565
May  5 11:53:58.595: INFO: Started pod liveness-ce32f411-1f7b-4ec7-bab9-a540a7e27763 in namespace container-probe-5565
STEP: checking the pod's current state and verifying that restartCount is present
May  5 11:53:58.598: INFO: Initial restart count of pod liveness-ce32f411-1f7b-4ec7-bab9-a540a7e27763 is 0
May  5 11:54:22.642: INFO: Restart count of pod container-probe-5565/liveness-ce32f411-1f7b-4ec7-bab9-a540a7e27763 is now 1 (24.044254868s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:22.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5565" for this suite.

• [SLOW TEST:26.253 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":152,"skipped":2316,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:22.659: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 11:54:23.433: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 11:54:26.449: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:54:26.456: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:27.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8984" for this suite.
STEP: Destroying namespace "webhook-8984-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":280,"completed":153,"skipped":2357,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:27.191: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override command
May  5 11:54:27.344: INFO: Waiting up to 5m0s for pod "client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d" in namespace "containers-8495" to be "success or failure"
May  5 11:54:27.350: INFO: Pod "client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.215506ms
May  5 11:54:29.353: INFO: Pod "client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008832625s
STEP: Saw pod success
May  5 11:54:29.353: INFO: Pod "client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d" satisfied condition "success or failure"
May  5 11:54:29.358: INFO: Trying to get logs from node ip-10-0-27-202 pod client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d container test-container: <nil>
STEP: delete the pod
May  5 11:54:29.384: INFO: Waiting for pod client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d to disappear
May  5 11:54:29.387: INFO: Pod client-containers-7e012215-5d5d-4e0a-894e-7099c51de59d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:29.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8495" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":280,"completed":154,"skipped":2374,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:29.397: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:54:29.533: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84" in namespace "downward-api-8676" to be "success or failure"
May  5 11:54:29.537: INFO: Pod "downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84": Phase="Pending", Reason="", readiness=false. Elapsed: 3.738923ms
May  5 11:54:31.540: INFO: Pod "downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006786621s
STEP: Saw pod success
May  5 11:54:31.540: INFO: Pod "downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84" satisfied condition "success or failure"
May  5 11:54:31.543: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84 container client-container: <nil>
STEP: delete the pod
May  5 11:54:31.558: INFO: Waiting for pod downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84 to disappear
May  5 11:54:31.561: INFO: Pod downwardapi-volume-d75a273b-c41e-4f6a-a01a-517dad311f84 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:31.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8676" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":155,"skipped":2381,"failed":0}
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:31.570: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-1091ebdf-5bff-4056-9dbb-e72e1a2fbd4a
STEP: Creating a pod to test consume configMaps
May  5 11:54:31.713: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51" in namespace "configmap-6818" to be "success or failure"
May  5 11:54:31.716: INFO: Pod "pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157707ms
May  5 11:54:33.719: INFO: Pod "pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006141669s
STEP: Saw pod success
May  5 11:54:33.719: INFO: Pod "pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51" satisfied condition "success or failure"
May  5 11:54:33.722: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51 container configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:54:33.735: INFO: Waiting for pod pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51 to disappear
May  5 11:54:33.737: INFO: Pod pod-configmaps-4ca651c6-dd2f-4881-b83c-d6d212cdfe51 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:33.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6818" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":156,"skipped":2387,"failed":0}
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:33.746: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8422
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
May  5 11:54:33.887: INFO: Created pod &Pod{ObjectMeta:{dns-8422  dns-8422 /api/v1/namespaces/dns-8422/pods/dns-8422 3f632aef-9a7a-4321-bd39-47dd6f89ba71 19193 0 2020-05-05 11:54:33 +0000 UTC <nil> <nil> map[] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w7zsp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w7zsp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w7zsp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
STEP: Verifying customized DNS suffix list is configured on pod...
May  5 11:54:35.894: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-8422 PodName:dns-8422 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:54:35.894: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Verifying customized DNS server is configured on pod...
May  5 11:54:36.000: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-8422 PodName:dns-8422 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 11:54:36.000: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 11:54:36.142: INFO: Deleting pod dns-8422...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:36.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8422" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":280,"completed":157,"skipped":2397,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:36.168: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:54:36.311: INFO: Waiting up to 5m0s for pod "downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf" in namespace "projected-3362" to be "success or failure"
May  5 11:54:36.317: INFO: Pod "downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf": Phase="Pending", Reason="", readiness=false. Elapsed: 5.334109ms
May  5 11:54:38.323: INFO: Pod "downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011095693s
STEP: Saw pod success
May  5 11:54:38.323: INFO: Pod "downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf" satisfied condition "success or failure"
May  5 11:54:38.325: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf container client-container: <nil>
STEP: delete the pod
May  5 11:54:38.338: INFO: Waiting for pod downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf to disappear
May  5 11:54:38.345: INFO: Pod downwardapi-volume-11d4f3f8-43a4-490b-950e-6e51abecb0cf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:38.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3362" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":158,"skipped":2445,"failed":0}
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:38.360: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
May  5 11:54:40.512: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:54:40.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3347" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":159,"skipped":2449,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:54:40.532: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-downwardapi-wpkf
STEP: Creating a pod to test atomic-volume-subpath
May  5 11:54:40.685: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wpkf" in namespace "subpath-8462" to be "success or failure"
May  5 11:54:40.696: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.381758ms
May  5 11:54:42.700: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 2.014742049s
May  5 11:54:44.746: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 4.061084348s
May  5 11:54:46.749: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 6.06433268s
May  5 11:54:48.753: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 8.067622347s
May  5 11:54:50.756: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 10.070959474s
May  5 11:54:52.759: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 12.074354501s
May  5 11:54:54.764: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 14.078725381s
May  5 11:54:56.767: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 16.081774613s
May  5 11:54:58.770: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 18.084949469s
May  5 11:55:00.775: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Running", Reason="", readiness=true. Elapsed: 20.089717439s
May  5 11:55:02.784: INFO: Pod "pod-subpath-test-downwardapi-wpkf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.099070748s
STEP: Saw pod success
May  5 11:55:02.784: INFO: Pod "pod-subpath-test-downwardapi-wpkf" satisfied condition "success or failure"
May  5 11:55:02.789: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-subpath-test-downwardapi-wpkf container test-container-subpath-downwardapi-wpkf: <nil>
STEP: delete the pod
May  5 11:55:02.807: INFO: Waiting for pod pod-subpath-test-downwardapi-wpkf to disappear
May  5 11:55:02.823: INFO: Pod pod-subpath-test-downwardapi-wpkf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wpkf
May  5 11:55:02.823: INFO: Deleting pod "pod-subpath-test-downwardapi-wpkf" in namespace "subpath-8462"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:02.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8462" for this suite.

• [SLOW TEST:22.304 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":280,"completed":160,"skipped":2460,"failed":0}
SSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:02.837: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-597
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 11:55:02.998: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-81ad85c5-f5ce-4a35-9722-bbf632b9f8f8" in namespace "security-context-test-597" to be "success or failure"
May  5 11:55:03.001: INFO: Pod "busybox-privileged-false-81ad85c5-f5ce-4a35-9722-bbf632b9f8f8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.157568ms
May  5 11:55:05.004: INFO: Pod "busybox-privileged-false-81ad85c5-f5ce-4a35-9722-bbf632b9f8f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006688165s
May  5 11:55:05.004: INFO: Pod "busybox-privileged-false-81ad85c5-f5ce-4a35-9722-bbf632b9f8f8" satisfied condition "success or failure"
May  5 11:55:05.012: INFO: Got logs for pod "busybox-privileged-false-81ad85c5-f5ce-4a35-9722-bbf632b9f8f8": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:05.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-597" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":161,"skipped":2463,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:05.023: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8244
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-669
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7552
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:11.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8244" for this suite.
STEP: Destroying namespace "nsdeletetest-669" for this suite.
May  5 11:55:11.589: INFO: Namespace nsdeletetest-669 was already deleted
STEP: Destroying namespace "nsdeletetest-7552" for this suite.

• [SLOW TEST:6.570 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":280,"completed":162,"skipped":2472,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:11.597: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6665
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-dnf6
STEP: Creating a pod to test atomic-volume-subpath
May  5 11:55:11.743: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-dnf6" in namespace "subpath-6665" to be "success or failure"
May  5 11:55:11.750: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.052647ms
May  5 11:55:13.753: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 2.008951478s
May  5 11:55:15.756: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 4.012221563s
May  5 11:55:17.759: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 6.015408392s
May  5 11:55:19.762: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 8.01870499s
May  5 11:55:21.766: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 10.02195621s
May  5 11:55:23.775: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 12.03155017s
May  5 11:55:25.778: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 14.034791899s
May  5 11:55:27.782: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 16.038397949s
May  5 11:55:29.785: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 18.041696173s
May  5 11:55:31.791: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Running", Reason="", readiness=true. Elapsed: 20.04724614s
May  5 11:55:33.794: INFO: Pod "pod-subpath-test-configmap-dnf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.050608981s
STEP: Saw pod success
May  5 11:55:33.794: INFO: Pod "pod-subpath-test-configmap-dnf6" satisfied condition "success or failure"
May  5 11:55:33.797: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-subpath-test-configmap-dnf6 container test-container-subpath-configmap-dnf6: <nil>
STEP: delete the pod
May  5 11:55:33.813: INFO: Waiting for pod pod-subpath-test-configmap-dnf6 to disappear
May  5 11:55:33.814: INFO: Pod pod-subpath-test-configmap-dnf6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-dnf6
May  5 11:55:33.815: INFO: Deleting pod "pod-subpath-test-configmap-dnf6" in namespace "subpath-6665"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:33.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6665" for this suite.

• [SLOW TEST:22.227 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":280,"completed":163,"skipped":2520,"failed":0}
S
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:33.825: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-4560
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4560
STEP: creating replication controller externalsvc in namespace services-4560
I0505 11:55:33.985638      21 runners.go:189] Created replication controller with name: externalsvc, namespace: services-4560, replica count: 2
I0505 11:55:37.038884      21 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
May  5 11:55:37.058: INFO: Creating new exec pod
May  5 11:55:39.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-4560 execpodlhj7k -- /bin/sh -x -c nslookup clusterip-service'
May  5 11:55:39.377: INFO: stderr: "+ nslookup clusterip-service\n"
May  5 11:55:39.377: INFO: stdout: "Server:\t\t10.3.0.10\nAddress:\t10.3.0.10#53\n\nclusterip-service.services-4560.svc.cluster.local\tcanonical name = externalsvc.services-4560.svc.cluster.local.\nName:\texternalsvc.services-4560.svc.cluster.local\nAddress: 10.3.72.18\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4560, will wait for the garbage collector to delete the pods
May  5 11:55:39.436: INFO: Deleting ReplicationController externalsvc took: 5.061457ms
May  5 11:55:39.836: INFO: Terminating ReplicationController externalsvc pods took: 400.160317ms
May  5 11:55:55.449: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:55.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4560" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:21.651 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":280,"completed":164,"skipped":2521,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:55.487: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 11:55:55.642: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b" in namespace "downward-api-2755" to be "success or failure"
May  5 11:55:55.647: INFO: Pod "downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.376619ms
May  5 11:55:57.651: INFO: Pod "downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008671876s
STEP: Saw pod success
May  5 11:55:57.651: INFO: Pod "downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b" satisfied condition "success or failure"
May  5 11:55:57.653: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b container client-container: <nil>
STEP: delete the pod
May  5 11:55:57.673: INFO: Waiting for pod downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b to disappear
May  5 11:55:57.675: INFO: Pod downwardapi-volume-24572325-8902-4b40-9c68-3ef368eabf3b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:55:57.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2755" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":165,"skipped":2544,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:55:57.684: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the initial replication controller
May  5 11:55:57.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-4484'
May  5 11:55:58.099: INFO: stderr: ""
May  5 11:55:58.099: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 11:55:58.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4484'
May  5 11:55:58.195: INFO: stderr: ""
May  5 11:55:58.195: INFO: stdout: "update-demo-nautilus-6mpb7 update-demo-nautilus-dwksm "
May  5 11:55:58.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-6mpb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:55:58.308: INFO: stderr: ""
May  5 11:55:58.308: INFO: stdout: ""
May  5 11:55:58.308: INFO: update-demo-nautilus-6mpb7 is created but not running
May  5 11:56:03.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4484'
May  5 11:56:03.431: INFO: stderr: ""
May  5 11:56:03.431: INFO: stdout: "update-demo-nautilus-6mpb7 update-demo-nautilus-dwksm "
May  5 11:56:03.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-6mpb7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:03.520: INFO: stderr: ""
May  5 11:56:03.520: INFO: stdout: "true"
May  5 11:56:03.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-6mpb7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:03.605: INFO: stderr: ""
May  5 11:56:03.605: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 11:56:03.605: INFO: validating pod update-demo-nautilus-6mpb7
May  5 11:56:03.610: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 11:56:03.611: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 11:56:03.611: INFO: update-demo-nautilus-6mpb7 is verified up and running
May  5 11:56:03.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-dwksm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:03.694: INFO: stderr: ""
May  5 11:56:03.694: INFO: stdout: "true"
May  5 11:56:03.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-dwksm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:03.774: INFO: stderr: ""
May  5 11:56:03.774: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 11:56:03.775: INFO: validating pod update-demo-nautilus-dwksm
May  5 11:56:03.781: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 11:56:03.781: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 11:56:03.781: INFO: update-demo-nautilus-dwksm is verified up and running
STEP: rolling-update to new replication controller
May  5 11:56:03.783: INFO: scanned /root for discovery docs: <nil>
May  5 11:56:03.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4484'
May  5 11:56:26.360: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
May  5 11:56:26.360: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 11:56:26.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4484'
May  5 11:56:26.490: INFO: stderr: ""
May  5 11:56:26.490: INFO: stdout: "update-demo-kitten-gr5dr update-demo-kitten-pmkfj "
May  5 11:56:26.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-kitten-gr5dr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:26.585: INFO: stderr: ""
May  5 11:56:26.585: INFO: stdout: "true"
May  5 11:56:26.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-kitten-gr5dr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:26.675: INFO: stderr: ""
May  5 11:56:26.675: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May  5 11:56:26.675: INFO: validating pod update-demo-kitten-gr5dr
May  5 11:56:26.680: INFO: got data: {
  "image": "kitten.jpg"
}

May  5 11:56:26.680: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May  5 11:56:26.680: INFO: update-demo-kitten-gr5dr is verified up and running
May  5 11:56:26.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-kitten-pmkfj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:26.797: INFO: stderr: ""
May  5 11:56:26.797: INFO: stdout: "true"
May  5 11:56:26.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-kitten-pmkfj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4484'
May  5 11:56:26.914: INFO: stderr: ""
May  5 11:56:26.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
May  5 11:56:26.914: INFO: validating pod update-demo-kitten-pmkfj
May  5 11:56:26.919: INFO: got data: {
  "image": "kitten.jpg"
}

May  5 11:56:26.919: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
May  5 11:56:26.919: INFO: update-demo-kitten-pmkfj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:56:26.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4484" for this suite.

• [SLOW TEST:29.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]","total":280,"completed":166,"skipped":2574,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:56:26.927: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5056
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  5 11:56:29.589: INFO: Successfully updated pod "pod-update-face3f5b-2de9-4105-8b5c-33f8da3f5b22"
STEP: verifying the updated pod is in kubernetes
May  5 11:56:29.602: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:56:29.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5056" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":280,"completed":167,"skipped":2600,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:56:29.615: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2748
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-b9f53bd6-e4b6-4a6c-b5dd-770450ad8ac8
STEP: Creating a pod to test consume configMaps
May  5 11:56:29.768: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730" in namespace "configmap-2748" to be "success or failure"
May  5 11:56:29.773: INFO: Pod "pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730": Phase="Pending", Reason="", readiness=false. Elapsed: 5.245287ms
May  5 11:56:31.777: INFO: Pod "pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008462262s
STEP: Saw pod success
May  5 11:56:31.777: INFO: Pod "pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730" satisfied condition "success or failure"
May  5 11:56:31.780: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730 container configmap-volume-test: <nil>
STEP: delete the pod
May  5 11:56:31.797: INFO: Waiting for pod pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730 to disappear
May  5 11:56:31.799: INFO: Pod pod-configmaps-4c51ea48-116e-42b3-8111-1592c0ef2730 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:56:31.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2748" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":168,"skipped":2607,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:56:31.806: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
May  5 11:56:31.944: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 11:56:35.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2269" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":280,"completed":169,"skipped":2616,"failed":0}
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 11:56:35.104: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5869
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod test-webserver-59062ce5-7092-4cf2-bf32-c4808ea76c21 in namespace container-probe-5869
May  5 11:56:37.479: INFO: Started pod test-webserver-59062ce5-7092-4cf2-bf32-c4808ea76c21 in namespace container-probe-5869
STEP: checking the pod's current state and verifying that restartCount is present
May  5 11:56:37.482: INFO: Initial restart count of pod test-webserver-59062ce5-7092-4cf2-bf32-c4808ea76c21 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:00:38.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5869" for this suite.

• [SLOW TEST:242.977 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":170,"skipped":2620,"failed":0}
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:00:38.084: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:00:38.221: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84" in namespace "projected-1658" to be "success or failure"
May  5 12:00:38.229: INFO: Pod "downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84": Phase="Pending", Reason="", readiness=false. Elapsed: 7.22076ms
May  5 12:00:40.232: INFO: Pod "downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010907007s
STEP: Saw pod success
May  5 12:00:40.232: INFO: Pod "downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84" satisfied condition "success or failure"
May  5 12:00:40.235: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84 container client-container: <nil>
STEP: delete the pod
May  5 12:00:40.259: INFO: Waiting for pod downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84 to disappear
May  5 12:00:40.265: INFO: Pod downwardapi-volume-7f3de79a-b915-4813-9929-b9c8d0f48c84 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:00:40.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1658" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":171,"skipped":2622,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:00:40.277: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-0cdeaabf-bf53-427a-b020-acdb6ce568be
STEP: Creating a pod to test consume secrets
May  5 12:00:40.434: INFO: Waiting up to 5m0s for pod "pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb" in namespace "secrets-3443" to be "success or failure"
May  5 12:00:40.438: INFO: Pod "pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.419521ms
May  5 12:00:42.441: INFO: Pod "pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007415775s
STEP: Saw pod success
May  5 12:00:42.441: INFO: Pod "pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb" satisfied condition "success or failure"
May  5 12:00:42.444: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb container secret-volume-test: <nil>
STEP: delete the pod
May  5 12:00:42.460: INFO: Waiting for pod pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb to disappear
May  5 12:00:42.463: INFO: Pod pod-secrets-5c47d1f6-ecb9-4120-9fa2-47ed0b2313fb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:00:42.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3443" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":172,"skipped":2632,"failed":0}
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:00:42.471: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8195
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override arguments
May  5 12:00:42.643: INFO: Waiting up to 5m0s for pod "client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7" in namespace "containers-8195" to be "success or failure"
May  5 12:00:42.649: INFO: Pod "client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.49701ms
May  5 12:00:44.652: INFO: Pod "client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008966096s
STEP: Saw pod success
May  5 12:00:44.653: INFO: Pod "client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7" satisfied condition "success or failure"
May  5 12:00:44.656: INFO: Trying to get logs from node ip-10-0-27-202 pod client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7 container test-container: <nil>
STEP: delete the pod
May  5 12:00:44.671: INFO: Waiting for pod client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7 to disappear
May  5 12:00:44.673: INFO: Pod client-containers-c1da45c9-4e36-4656-98eb-a5b7d6ef18a7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:00:44.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8195" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":280,"completed":173,"skipped":2637,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:00:44.688: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8302
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-9b14d164-17fb-49e5-9aa1-12ec713eebc8
STEP: Creating a pod to test consume secrets
May  5 12:00:44.879: INFO: Waiting up to 5m0s for pod "pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd" in namespace "secrets-8302" to be "success or failure"
May  5 12:00:44.889: INFO: Pod "pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.888527ms
May  5 12:00:46.892: INFO: Pod "pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012951347s
STEP: Saw pod success
May  5 12:00:46.893: INFO: Pod "pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd" satisfied condition "success or failure"
May  5 12:00:46.895: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd container secret-volume-test: <nil>
STEP: delete the pod
May  5 12:00:46.909: INFO: Waiting for pod pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd to disappear
May  5 12:00:46.911: INFO: Pod pod-secrets-8ecbf213-dfd8-43ae-a7d0-bfab4ce383bd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:00:46.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8302" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":174,"skipped":2681,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:00:46.928: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:03.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7342" for this suite.

• [SLOW TEST:16.211 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":280,"completed":175,"skipped":2724,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:03.139: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:05.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8215" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":176,"skipped":2733,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:05.323: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
May  5 12:01:05.478: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
May  5 12:01:05.489: INFO: Waiting for terminating namespaces to be deleted...
May  5 12:01:05.495: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-27-202 before test
May  5 12:01:05.503: INFO: kubelet-99g5h from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container kubelet ready: true, restart count 0
May  5 12:01:05.504: INFO: sonobuoy from sonobuoy started at 2020-05-05 11:16:48 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container kube-sonobuoy ready: true, restart count 0
May  5 12:01:05.504: INFO: kube-proxy-m47jv from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 12:01:05.504: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-pnqrd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 12:01:05.504: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 12:01:05.504: INFO: busybox-readonly-fsba506174-5b14-49bc-a303-f39dcc2ba375 from kubelet-test-8215 started at 2020-05-05 12:01:03 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container busybox-readonly-fsba506174-5b14-49bc-a303-f39dcc2ba375 ready: true, restart count 0
May  5 12:01:05.504: INFO: calico-node-v6vzp from kube-system started at 2020-05-05 11:00:22 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.504: INFO: 	Container calico-node ready: true, restart count 0
May  5 12:01:05.504: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-33-250 before test
May  5 12:01:05.519: INFO: calico-node-579x2 from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.519: INFO: 	Container calico-node ready: true, restart count 0
May  5 12:01:05.519: INFO: coredns-6f64b7db7-z5b8s from kube-system started at 2020-05-05 11:00:47 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.520: INFO: 	Container coredns ready: true, restart count 0
May  5 12:01:05.520: INFO: kubelet-8cl8p from kube-system started at 2020-05-05 11:00:18 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.520: INFO: 	Container kubelet ready: true, restart count 0
May  5 12:01:05.520: INFO: sonobuoy-systemd-logs-daemon-set-8f3a5efd741647c5-lt6zd from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 12:01:05.520: INFO: 	Container sonobuoy-worker ready: true, restart count 0
May  5 12:01:05.520: INFO: 	Container systemd-logs ready: true, restart count 0
May  5 12:01:05.520: INFO: kube-proxy-8nsbj from kube-system started at 2020-05-05 11:00:17 +0000 UTC (1 container statuses recorded)
May  5 12:01:05.520: INFO: 	Container kube-proxy ready: true, restart count 0
May  5 12:01:05.520: INFO: sonobuoy-e2e-job-0f2dbdcc56724f7f from sonobuoy started at 2020-05-05 11:16:54 +0000 UTC (2 container statuses recorded)
May  5 12:01:05.520: INFO: 	Container e2e ready: true, restart count 0
May  5 12:01:05.520: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-95ca80e2-7c50-4dd6-b67e-b7f78541f7c3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-95ca80e2-7c50-4dd6-b67e-b7f78541f7c3 off the node ip-10-0-27-202
STEP: verifying the node doesn't have the label kubernetes.io/e2e-95ca80e2-7c50-4dd6-b67e-b7f78541f7c3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:09.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9510" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":280,"completed":177,"skipped":2735,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:09.610: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9405
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating cluster-info
May  5 12:01:09.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 cluster-info'
May  5 12:01:10.104: INFO: stderr: ""
May  5 12:01:10.104: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.3.0.1:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:10.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9405" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":280,"completed":178,"skipped":2755,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:10.124: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run default
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1489
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 12:01:10.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4903'
May  5 12:01:10.370: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
May  5 12:01:10.370: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1495
May  5 12:01:12.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4903'
May  5 12:01:12.557: INFO: stderr: ""
May  5 12:01:12.557: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:12.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4903" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]","total":280,"completed":179,"skipped":2794,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:12.589: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2683
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name secret-emptykey-test-f3272b34-510e-4e77-b2b1-900fa35a91f3
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:12.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2683" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":280,"completed":180,"skipped":2803,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:12.870: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
May  5 12:01:13.074: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21177 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
May  5 12:01:13.074: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21178 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
May  5 12:01:13.074: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21179 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
May  5 12:01:23.095: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21258 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
May  5 12:01:23.095: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21259 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
May  5 12:01:23.096: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-320 /api/v1/namespaces/watch-320/configmaps/e2e-watch-test-label-changed 46d216c1-a2e5-4e7c-9b5f-c487b9995075 21260 0 2020-05-05 12:01:13 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:23.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-320" for this suite.

• [SLOW TEST:10.234 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":280,"completed":181,"skipped":2815,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:23.104: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3842
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
May  5 12:01:27.253: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-3842 PodName:pod-sharedvolume-9804327d-adea-4970-a25f-2722da4944f4 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
May  5 12:01:27.253: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 12:01:27.389: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:27.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3842" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":280,"completed":182,"skipped":2816,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:27.401: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-51825414-8121-438b-8b4f-93be32dd4640
STEP: Creating a pod to test consume configMaps
May  5 12:01:27.569: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269" in namespace "projected-2483" to be "success or failure"
May  5 12:01:27.576: INFO: Pod "pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269": Phase="Pending", Reason="", readiness=false. Elapsed: 6.818625ms
May  5 12:01:29.579: INFO: Pod "pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010145716s
STEP: Saw pod success
May  5 12:01:29.579: INFO: Pod "pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269" satisfied condition "success or failure"
May  5 12:01:29.582: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:01:29.600: INFO: Waiting for pod pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269 to disappear
May  5 12:01:29.604: INFO: Pod pod-projected-configmaps-773cf356-439b-433c-a3f6-e54d99baa269 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:29.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2483" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":280,"completed":183,"skipped":2821,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:29.611: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7170
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:01:29.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660" in namespace "downward-api-7170" to be "success or failure"
May  5 12:01:29.757: INFO: Pod "downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660": Phase="Pending", Reason="", readiness=false. Elapsed: 3.626935ms
May  5 12:01:31.761: INFO: Pod "downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007263651s
STEP: Saw pod success
May  5 12:01:31.761: INFO: Pod "downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660" satisfied condition "success or failure"
May  5 12:01:31.763: INFO: Trying to get logs from node ip-10-0-33-250 pod downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660 container client-container: <nil>
STEP: delete the pod
May  5 12:01:31.782: INFO: Waiting for pod downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660 to disappear
May  5 12:01:31.786: INFO: Pod downwardapi-volume-0edcd0e6-b38a-4637-9ca1-bb229f088660 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:31.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7170" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":184,"skipped":2833,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:31.795: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Starting the proxy
May  5 12:01:31.932: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-610752675 proxy --unix-socket=/tmp/kubectl-proxy-unix853712554/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:31.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2949" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":280,"completed":185,"skipped":2849,"failed":0}

------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:32.001: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
May  5 12:01:32.133: INFO: namespace kubectl-4732
May  5 12:01:32.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-4732'
May  5 12:01:32.300: INFO: stderr: ""
May  5 12:01:32.300: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
May  5 12:01:33.303: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 12:01:33.303: INFO: Found 0 / 1
May  5 12:01:34.303: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 12:01:34.303: INFO: Found 1 / 1
May  5 12:01:34.303: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
May  5 12:01:34.306: INFO: Selector matched 1 pods for map[app:agnhost]
May  5 12:01:34.306: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
May  5 12:01:34.306: INFO: wait on agnhost-master startup in kubectl-4732 
May  5 12:01:34.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 logs agnhost-master-nzskt agnhost-master --namespace=kubectl-4732'
May  5 12:01:34.393: INFO: stderr: ""
May  5 12:01:34.393: INFO: stdout: "Paused\n"
STEP: exposing RC
May  5 12:01:34.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4732'
May  5 12:01:34.483: INFO: stderr: ""
May  5 12:01:34.484: INFO: stdout: "service/rm2 exposed\n"
May  5 12:01:34.487: INFO: Service rm2 in namespace kubectl-4732 found.
STEP: exposing service
May  5 12:01:36.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4732'
May  5 12:01:36.598: INFO: stderr: ""
May  5 12:01:36.598: INFO: stdout: "service/rm3 exposed\n"
May  5 12:01:36.603: INFO: Service rm3 in namespace kubectl-4732 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:38.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4732" for this suite.

• [SLOW TEST:6.615 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1188
    should create services for rc  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":280,"completed":186,"skipped":2849,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:38.617: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-0608aa78-4694-4a5f-9e6d-55dd8fb64ba5
STEP: Creating a pod to test consume secrets
May  5 12:01:38.758: INFO: Waiting up to 5m0s for pod "pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424" in namespace "secrets-8178" to be "success or failure"
May  5 12:01:38.762: INFO: Pod "pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008392ms
May  5 12:01:40.765: INFO: Pod "pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007266909s
STEP: Saw pod success
May  5 12:01:40.765: INFO: Pod "pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424" satisfied condition "success or failure"
May  5 12:01:40.768: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424 container secret-env-test: <nil>
STEP: delete the pod
May  5 12:01:40.784: INFO: Waiting for pod pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424 to disappear
May  5 12:01:40.787: INFO: Pod pod-secrets-7f9ed610-9164-4bdd-b631-776fba956424 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:40.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8178" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":280,"completed":187,"skipped":2858,"failed":0}
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:40.794: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3921
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:52.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3921" for this suite.

• [SLOW TEST:11.246 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":280,"completed":188,"skipped":2859,"failed":0}
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:52.042: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:52.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5390" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":280,"completed":189,"skipped":2859,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:52.201: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:01:52.400: INFO: Pod name cleanup-pod: Found 0 pods out of 1
May  5 12:01:57.403: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  5 12:01:57.403: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
May  5 12:01:59.428: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/deployments/test-cleanup-deployment d582bf17-05f7-4367-a527-af5b89753ada 21659 1 2020-05-05 12:01:57 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fab708 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-05 12:01:57 +0000 UTC,LastTransitionTime:2020-05-05 12:01:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-55ffc6b7b6" has successfully progressed.,LastUpdateTime:2020-05-05 12:01:59 +0000 UTC,LastTransitionTime:2020-05-05 12:01:57 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  5 12:01:59.431: INFO: New ReplicaSet "test-cleanup-deployment-55ffc6b7b6" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6  deployment-9900 /apis/apps/v1/namespaces/deployment-9900/replicasets/test-cleanup-deployment-55ffc6b7b6 2711a7ba-6833-4acd-958a-ba8c81009dac 21650 1 2020-05-05 12:01:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment d582bf17-05f7-4367-a527-af5b89753ada 0xc002fabb07 0xc002fabb08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55ffc6b7b6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002fabb78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  5 12:01:59.434: INFO: Pod "test-cleanup-deployment-55ffc6b7b6-jtvkk" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6-jtvkk test-cleanup-deployment-55ffc6b7b6- deployment-9900 /api/v1/namespaces/deployment-9900/pods/test-cleanup-deployment-55ffc6b7b6-jtvkk 127c132d-7026-451c-a2b5-c2c95552c9f8 21649 0 2020-05-05 12:01:57 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[cni.projectcalico.org/podIP:10.2.232.213/32 cni.projectcalico.org/podIPs:10.2.232.213/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-55ffc6b7b6 2711a7ba-6833-4acd-958a-ba8c81009dac 0xc002c23f47 0xc002c23f48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-l72nm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-l72nm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-l72nm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:01:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:01:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:01:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:01:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:10.2.232.213,StartTime:2020-05-05 12:01:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 12:01:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://965c71e9a0b7c04b925a0af8cac04d3fe5ab29e82b765229ba572384c8eb131c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.232.213,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:01:59.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9900" for this suite.

• [SLOW TEST:7.245 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":280,"completed":190,"skipped":2868,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:01:59.447: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-948
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on node default medium
May  5 12:01:59.662: INFO: Waiting up to 5m0s for pod "pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986" in namespace "emptydir-948" to be "success or failure"
May  5 12:01:59.670: INFO: Pod "pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986": Phase="Pending", Reason="", readiness=false. Elapsed: 7.083865ms
May  5 12:02:01.702: INFO: Pod "pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039365402s
STEP: Saw pod success
May  5 12:02:01.702: INFO: Pod "pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986" satisfied condition "success or failure"
May  5 12:02:01.730: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986 container test-container: <nil>
STEP: delete the pod
May  5 12:02:01.842: INFO: Waiting for pod pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986 to disappear
May  5 12:02:01.871: INFO: Pod pod-5bbb6a79-729f-4865-8bdc-8ee8c6c66986 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:01.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-948" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":191,"skipped":2869,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:01.927: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6036
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6036.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6036.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6036.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6036.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6036.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6036.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:02:06.221: INFO: DNS probes using dns-6036/dns-test-d4e45922-edc0-4251-b958-3a8cae6530e9 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:06.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6036" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":280,"completed":192,"skipped":2895,"failed":0}
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:06.250: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:02:06.396: INFO: Creating deployment "test-recreate-deployment"
May  5 12:02:06.401: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
May  5 12:02:06.449: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
May  5 12:02:08.455: INFO: Waiting deployment "test-recreate-deployment" to complete
May  5 12:02:08.458: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276926, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276926, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276926, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276926, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:02:10.462: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
May  5 12:02:10.469: INFO: Updating deployment test-recreate-deployment
May  5 12:02:10.469: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
May  5 12:02:10.526: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9687 /apis/apps/v1/namespaces/deployment-9687/deployments/test-recreate-deployment 6ee86e2f-925f-4879-ae49-a0450fdbe096 21834 2 2020-05-05 12:02:06 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007c5578 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-05-05 12:02:10 +0000 UTC,LastTransitionTime:2020-05-05 12:02:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-05-05 12:02:10 +0000 UTC,LastTransitionTime:2020-05-05 12:02:06 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

May  5 12:02:10.531: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-9687 /apis/apps/v1/namespaces/deployment-9687/replicasets/test-recreate-deployment-5f94c574ff dd4d0f6e-493a-4ef0-827f-932928cf2fc0 21831 1 2020-05-05 12:02:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 6ee86e2f-925f-4879-ae49-a0450fdbe096 0xc001023897 0xc001023898}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0010238f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 12:02:10.531: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
May  5 12:02:10.531: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-799c574856  deployment-9687 /apis/apps/v1/namespaces/deployment-9687/replicasets/test-recreate-deployment-799c574856 d7be81ae-8f6c-4c05-ab58-a4d61f382c7c 21823 2 2020-05-05 12:02:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 6ee86e2f-925f-4879-ae49-a0450fdbe096 0xc001023af7 0xc001023af8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 799c574856,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001023b78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 12:02:10.534: INFO: Pod "test-recreate-deployment-5f94c574ff-pk742" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-pk742 test-recreate-deployment-5f94c574ff- deployment-9687 /api/v1/namespaces/deployment-9687/pods/test-recreate-deployment-5f94c574ff-pk742 39208ff9-dce1-4d41-987f-e7b2cb547c38 21835 0 2020-05-05 12:02:10 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff dd4d0f6e-493a-4ef0-827f-932928cf2fc0 0xc000820027 0xc000820028}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-nxkqx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-nxkqx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-nxkqx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:02:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:02:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:02:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:02:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:,StartTime:2020-05-05 12:02:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:10.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9687" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":193,"skipped":2897,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:10.542: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:02:11.774: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 12:02:13.783: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276931, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276931, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276931, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724276931, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:02:16.795: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:02:16.798: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9327-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:17.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4252" for this suite.
STEP: Destroying namespace "webhook-4252-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.432 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":280,"completed":194,"skipped":2902,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:17.979: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-e0a4cc87-bbe2-4597-a3cc-28cac2b77b2b
STEP: Creating a pod to test consume configMaps
May  5 12:02:18.172: INFO: Waiting up to 5m0s for pod "pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254" in namespace "configmap-1216" to be "success or failure"
May  5 12:02:18.190: INFO: Pod "pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254": Phase="Pending", Reason="", readiness=false. Elapsed: 16.766869ms
May  5 12:02:20.193: INFO: Pod "pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020655561s
STEP: Saw pod success
May  5 12:02:20.194: INFO: Pod "pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254" satisfied condition "success or failure"
May  5 12:02:20.196: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254 container configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:02:20.213: INFO: Waiting for pod pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254 to disappear
May  5 12:02:20.222: INFO: Pod pod-configmaps-22fdf194-4f68-4189-b841-46acbec51254 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:20.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1216" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":195,"skipped":2921,"failed":0}
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:20.233: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6173
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6173
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6173
I0505 12:02:20.408001      21 runners.go:189] Created replication controller with name: externalname-service, namespace: services-6173, replica count: 2
I0505 12:02:23.458632      21 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  5 12:02:23.458: INFO: Creating new exec pod
May  5 12:02:26.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-6173 execpodr842s -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
May  5 12:02:26.760: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
May  5 12:02:26.760: INFO: stdout: ""
May  5 12:02:26.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 exec --namespace=services-6173 execpodr842s -- /bin/sh -x -c nc -zv -t -w 2 10.3.127.8 80'
May  5 12:02:26.952: INFO: stderr: "+ nc -zv -t -w 2 10.3.127.8 80\nConnection to 10.3.127.8 80 port [tcp/http] succeeded!\n"
May  5 12:02:26.953: INFO: stdout: ""
May  5 12:02:26.953: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:26.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6173" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:6.739 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":280,"completed":196,"skipped":2928,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:26.974: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:02:31.146: INFO: DNS probes using dns-test-a270a97e-1205-49bd-95a5-40ff9835e4eb succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:02:35.189: INFO: DNS probes using dns-test-a4a8639a-0e9d-4aad-bac2-9d83707d6978 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3868.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3868.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:02:37.272: INFO: DNS probes using dns-test-6676463c-a440-4fed-9d88-0ed566ea4894 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:37.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3868" for this suite.

• [SLOW TEST:10.338 seconds]
[sig-network] DNS
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":280,"completed":197,"skipped":2955,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:37.314: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's command
May  5 12:02:37.491: INFO: Waiting up to 5m0s for pod "var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc" in namespace "var-expansion-4297" to be "success or failure"
May  5 12:02:37.519: INFO: Pod "var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc": Phase="Pending", Reason="", readiness=false. Elapsed: 28.147142ms
May  5 12:02:39.522: INFO: Pod "var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031750531s
STEP: Saw pod success
May  5 12:02:39.523: INFO: Pod "var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc" satisfied condition "success or failure"
May  5 12:02:39.525: INFO: Trying to get logs from node ip-10-0-27-202 pod var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc container dapi-container: <nil>
STEP: delete the pod
May  5 12:02:39.586: INFO: Waiting for pod var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc to disappear
May  5 12:02:39.589: INFO: Pod var-expansion-52726d23-9744-454e-b4c6-c1bfb17c9bbc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:39.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4297" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":280,"completed":198,"skipped":2966,"failed":0}

------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:39.599: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5887
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
May  5 12:02:39.750: INFO: Waiting up to 5m0s for pod "pod-8b521061-998c-4a38-be90-fc6145e84a30" in namespace "emptydir-5887" to be "success or failure"
May  5 12:02:39.752: INFO: Pod "pod-8b521061-998c-4a38-be90-fc6145e84a30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.851595ms
May  5 12:02:41.756: INFO: Pod "pod-8b521061-998c-4a38-be90-fc6145e84a30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00615823s
STEP: Saw pod success
May  5 12:02:41.756: INFO: Pod "pod-8b521061-998c-4a38-be90-fc6145e84a30" satisfied condition "success or failure"
May  5 12:02:41.759: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-8b521061-998c-4a38-be90-fc6145e84a30 container test-container: <nil>
STEP: delete the pod
May  5 12:02:41.775: INFO: Waiting for pod pod-8b521061-998c-4a38-be90-fc6145e84a30 to disappear
May  5 12:02:41.777: INFO: Pod pod-8b521061-998c-4a38-be90-fc6145e84a30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:41.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5887" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":199,"skipped":2966,"failed":0}
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:41.785: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
May  5 12:02:52.058: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:52.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0505 12:02:52.058821      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4938" for this suite.

• [SLOW TEST:10.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":280,"completed":200,"skipped":2968,"failed":0}
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:52.066: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8355.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8355.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8355.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8355.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8355.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8355.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:02:54.237: INFO: DNS probes using dns-8355/dns-test-3928b0fb-5e71-4c0d-a151-4b026b0df5c4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:02:54.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8355" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":280,"completed":201,"skipped":2968,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:02:54.256: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:344
May  5 12:02:54.387: INFO: Waiting up to 1m0s for all nodes to be ready
May  5 12:03:54.408: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:03:54.413: INFO: Starting informer...
STEP: Starting pods...
May  5 12:03:54.430: INFO: Pod1 is running on ip-10-0-27-202. Tainting Node
May  5 12:03:56.652: INFO: Pod2 is running on ip-10-0-27-202. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
May  5 12:04:11.119: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
May  5 12:04:23.539: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:23.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9903" for this suite.

• [SLOW TEST:89.303 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":280,"completed":202,"skipped":2976,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:23.560: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2495
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:04:23.698: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  5 12:04:25.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-2495 create -f -'
May  5 12:04:26.060: INFO: stderr: ""
May  5 12:04:26.060: INFO: stdout: "e2e-test-crd-publish-openapi-326-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  5 12:04:26.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-326-crds test-cr'
May  5 12:04:26.149: INFO: stderr: ""
May  5 12:04:26.149: INFO: stdout: "e2e-test-crd-publish-openapi-326-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
May  5 12:04:26.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-2495 apply -f -'
May  5 12:04:26.314: INFO: stderr: ""
May  5 12:04:26.314: INFO: stdout: "e2e-test-crd-publish-openapi-326-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
May  5 12:04:26.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-2495 delete e2e-test-crd-publish-openapi-326-crds test-cr'
May  5 12:04:26.392: INFO: stderr: ""
May  5 12:04:26.392: INFO: stdout: "e2e-test-crd-publish-openapi-326-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
May  5 12:04:26.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-326-crds'
May  5 12:04:26.568: INFO: stderr: ""
May  5 12:04:26.568: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-326-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:29.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2495" for this suite.

• [SLOW TEST:6.008 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":280,"completed":203,"skipped":2980,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:29.568: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
May  5 12:04:32.238: INFO: Successfully updated pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2"
May  5 12:04:32.238: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2" in namespace "pods-1084" to be "terminated due to deadline exceeded"
May  5 12:04:32.241: INFO: Pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2": Phase="Running", Reason="", readiness=true. Elapsed: 3.316089ms
May  5 12:04:34.245: INFO: Pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2": Phase="Running", Reason="", readiness=true. Elapsed: 2.006507366s
May  5 12:04:36.248: INFO: Pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.0103214s
May  5 12:04:36.249: INFO: Pod "pod-update-activedeadlineseconds-af33946b-db8f-44aa-afbe-8026e54e4af2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:36.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1084" for this suite.

• [SLOW TEST:6.695 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":280,"completed":204,"skipped":2989,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:36.265: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
May  5 12:04:36.398: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the sample API server.
May  5 12:04:36.897: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
May  5 12:04:38.964: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:04:40.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:04:42.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:04:44.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277076, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:04:49.398: INFO: Waited 2.41204187s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:49.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2240" for this suite.

• [SLOW TEST:13.749 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]","total":280,"completed":205,"skipped":3034,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:50.014: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4418
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:50.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4418" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":280,"completed":206,"skipped":3052,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:50.285: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8747
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:04:51.074: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:04:54.088: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:04:54.092: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5127-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:55.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8747" for this suite.
STEP: Destroying namespace "webhook-8747-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.212 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":280,"completed":207,"skipped":3065,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:55.497: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:04:55.742: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c2db410c-eb16-4b53-bb40-09339e64a9cf" in namespace "security-context-test-1061" to be "success or failure"
May  5 12:04:55.752: INFO: Pod "alpine-nnp-false-c2db410c-eb16-4b53-bb40-09339e64a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.263917ms
May  5 12:04:57.755: INFO: Pod "alpine-nnp-false-c2db410c-eb16-4b53-bb40-09339e64a9cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013104138s
May  5 12:04:59.758: INFO: Pod "alpine-nnp-false-c2db410c-eb16-4b53-bb40-09339e64a9cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016196332s
May  5 12:04:59.758: INFO: Pod "alpine-nnp-false-c2db410c-eb16-4b53-bb40-09339e64a9cf" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:04:59.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1061" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":208,"skipped":3072,"failed":0}
SS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:04:59.781: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7798
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7798, will wait for the garbage collector to delete the pods
May  5 12:05:03.992: INFO: Deleting Job.batch foo took: 5.239193ms
May  5 12:05:04.092: INFO: Terminating Job.batch foo pods took: 100.447322ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:05:37.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7798" for this suite.

• [SLOW TEST:37.921 seconds]
[sig-apps] Job
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":280,"completed":209,"skipped":3074,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:05:37.707: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7616
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
May  5 12:05:37.848: INFO: Waiting up to 5m0s for pod "downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568" in namespace "downward-api-7616" to be "success or failure"
May  5 12:05:37.851: INFO: Pod "downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568": Phase="Pending", Reason="", readiness=false. Elapsed: 2.948132ms
May  5 12:05:39.854: INFO: Pod "downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005725588s
STEP: Saw pod success
May  5 12:05:39.854: INFO: Pod "downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568" satisfied condition "success or failure"
May  5 12:05:39.856: INFO: Trying to get logs from node ip-10-0-27-202 pod downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568 container dapi-container: <nil>
STEP: delete the pod
May  5 12:05:39.878: INFO: Waiting for pod downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568 to disappear
May  5 12:05:39.882: INFO: Pod downward-api-3e75bf8b-6bf2-4c70-9a43-2205e2269568 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:05:39.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7616" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":280,"completed":210,"skipped":3123,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:05:39.891: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5582
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
May  5 12:05:40.025: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
May  5 12:05:43.485: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:05:55.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5582" for this suite.

• [SLOW TEST:15.853 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":280,"completed":211,"skipped":3126,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:05:55.743: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-e3a03072-6c39-48ce-ada0-f712abbcadd4
STEP: Creating a pod to test consume secrets
May  5 12:05:55.882: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522" in namespace "projected-9067" to be "success or failure"
May  5 12:05:55.890: INFO: Pod "pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522": Phase="Pending", Reason="", readiness=false. Elapsed: 8.127812ms
May  5 12:05:57.893: INFO: Pod "pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01075565s
STEP: Saw pod success
May  5 12:05:57.893: INFO: Pod "pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522" satisfied condition "success or failure"
May  5 12:05:57.895: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  5 12:05:57.913: INFO: Waiting for pod pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522 to disappear
May  5 12:05:57.916: INFO: Pod pod-projected-secrets-f3492c3a-8877-4a77-884c-c88892ac2522 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:05:57.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9067" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":212,"skipped":3136,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:05:57.926: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9335
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-bf3ddcd5-c782-45a5-b973-cef17278ef26
STEP: Creating a pod to test consume secrets
May  5 12:05:58.124: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34" in namespace "projected-9335" to be "success or failure"
May  5 12:05:58.128: INFO: Pod "pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34": Phase="Pending", Reason="", readiness=false. Elapsed: 3.773066ms
May  5 12:06:00.134: INFO: Pod "pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009658824s
STEP: Saw pod success
May  5 12:06:00.134: INFO: Pod "pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34" satisfied condition "success or failure"
May  5 12:06:00.138: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34 container projected-secret-volume-test: <nil>
STEP: delete the pod
May  5 12:06:00.173: INFO: Waiting for pod pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34 to disappear
May  5 12:06:00.176: INFO: Pod pod-projected-secrets-5f8a133a-7f9e-41d6-ba3d-3b393b752b34 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:06:00.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9335" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":213,"skipped":3167,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:06:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:06:11.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9234" for this suite.

• [SLOW TEST:11.365 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":280,"completed":214,"skipped":3183,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:06:11.553: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7199
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:06:12.147: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 12:06:14.156: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277172, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277172, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277172, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277172, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:06:17.166: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:06:17.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7199" for this suite.
STEP: Destroying namespace "webhook-7199-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.715 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":280,"completed":215,"skipped":3201,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:06:17.268: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2729
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
May  5 12:06:17.421: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:06:36.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2729" for this suite.

• [SLOW TEST:19.131 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":280,"completed":216,"skipped":3206,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:06:36.400: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
May  5 12:06:36.568: INFO: Pod name pod-release: Found 0 pods out of 1
May  5 12:06:41.572: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:06:41.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8527" for this suite.

• [SLOW TEST:5.230 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":280,"completed":217,"skipped":3220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:06:41.631: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1464
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating statefulset ss in namespace statefulset-1464
May  5 12:06:41.782: INFO: Found 0 stateful pods, waiting for 1
May  5 12:06:51.785: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 12:06:51.803: INFO: Deleting all statefulset in ns statefulset-1464
May  5 12:06:51.812: INFO: Scaling statefulset ss to 0
May  5 12:07:11.839: INFO: Waiting for statefulset status.replicas updated to 0
May  5 12:07:11.841: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:11.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1464" for this suite.

• [SLOW TEST:30.230 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":280,"completed":218,"skipped":3253,"failed":0}
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:11.862: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
May  5 12:07:12.528: INFO: created pod pod-service-account-defaultsa
May  5 12:07:12.528: INFO: pod pod-service-account-defaultsa service account token volume mount: true
May  5 12:07:12.534: INFO: created pod pod-service-account-mountsa
May  5 12:07:12.534: INFO: pod pod-service-account-mountsa service account token volume mount: true
May  5 12:07:12.542: INFO: created pod pod-service-account-nomountsa
May  5 12:07:12.542: INFO: pod pod-service-account-nomountsa service account token volume mount: false
May  5 12:07:12.552: INFO: created pod pod-service-account-defaultsa-mountspec
May  5 12:07:12.552: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
May  5 12:07:12.570: INFO: created pod pod-service-account-mountsa-mountspec
May  5 12:07:12.570: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
May  5 12:07:12.578: INFO: created pod pod-service-account-nomountsa-mountspec
May  5 12:07:12.578: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
May  5 12:07:12.603: INFO: created pod pod-service-account-defaultsa-nomountspec
May  5 12:07:12.603: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
May  5 12:07:12.607: INFO: created pod pod-service-account-mountsa-nomountspec
May  5 12:07:12.607: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
May  5 12:07:12.615: INFO: created pod pod-service-account-nomountsa-nomountspec
May  5 12:07:12.615: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:12.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8819" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":280,"completed":219,"skipped":3254,"failed":0}
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:12.636: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
May  5 12:07:12.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-4765'
May  5 12:07:13.596: INFO: stderr: ""
May  5 12:07:13.596: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 12:07:13.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4765'
May  5 12:07:13.850: INFO: stderr: ""
May  5 12:07:13.850: INFO: stdout: "update-demo-nautilus-dzcb8 update-demo-nautilus-qv6tq "
May  5 12:07:13.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-dzcb8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4765'
May  5 12:07:14.160: INFO: stderr: ""
May  5 12:07:14.160: INFO: stdout: ""
May  5 12:07:14.160: INFO: update-demo-nautilus-dzcb8 is created but not running
May  5 12:07:19.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4765'
May  5 12:07:19.404: INFO: stderr: ""
May  5 12:07:19.404: INFO: stdout: "update-demo-nautilus-dzcb8 update-demo-nautilus-qv6tq "
May  5 12:07:19.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-dzcb8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4765'
May  5 12:07:19.482: INFO: stderr: ""
May  5 12:07:19.482: INFO: stdout: "true"
May  5 12:07:19.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-dzcb8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4765'
May  5 12:07:19.561: INFO: stderr: ""
May  5 12:07:19.561: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:07:19.561: INFO: validating pod update-demo-nautilus-dzcb8
May  5 12:07:19.565: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:07:19.565: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:07:19.565: INFO: update-demo-nautilus-dzcb8 is verified up and running
May  5 12:07:19.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-qv6tq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4765'
May  5 12:07:19.636: INFO: stderr: ""
May  5 12:07:19.636: INFO: stdout: "true"
May  5 12:07:19.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-qv6tq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4765'
May  5 12:07:19.716: INFO: stderr: ""
May  5 12:07:19.716: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:07:19.716: INFO: validating pod update-demo-nautilus-qv6tq
May  5 12:07:19.721: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:07:19.721: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:07:19.721: INFO: update-demo-nautilus-qv6tq is verified up and running
STEP: using delete to clean up resources
May  5 12:07:19.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-4765'
May  5 12:07:19.790: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 12:07:19.790: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  5 12:07:19.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4765'
May  5 12:07:19.934: INFO: stderr: "No resources found in kubectl-4765 namespace.\n"
May  5 12:07:19.934: INFO: stdout: ""
May  5 12:07:19.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -l name=update-demo --namespace=kubectl-4765 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  5 12:07:20.066: INFO: stderr: ""
May  5 12:07:20.066: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:20.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4765" for this suite.

• [SLOW TEST:7.438 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":280,"completed":220,"skipped":3256,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:20.074: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:07:22.245: INFO: Waiting up to 5m0s for pod "client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea" in namespace "pods-2178" to be "success or failure"
May  5 12:07:22.249: INFO: Pod "client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea": Phase="Pending", Reason="", readiness=false. Elapsed: 3.015126ms
May  5 12:07:24.253: INFO: Pod "client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea": Phase="Running", Reason="", readiness=true. Elapsed: 2.007309835s
May  5 12:07:26.256: INFO: Pod "client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010445915s
STEP: Saw pod success
May  5 12:07:26.256: INFO: Pod "client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea" satisfied condition "success or failure"
May  5 12:07:26.259: INFO: Trying to get logs from node ip-10-0-27-202 pod client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea container env3cont: <nil>
STEP: delete the pod
May  5 12:07:26.276: INFO: Waiting for pod client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea to disappear
May  5 12:07:26.279: INFO: Pod client-envvars-d58a3368-0d4c-49e0-946a-d3c3bf7cefea no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:26.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2178" for this suite.

• [SLOW TEST:6.212 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":280,"completed":221,"skipped":3280,"failed":0}
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:26.288: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2396
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-3353909c-ee4a-43e3-a247-6e9c04261163
STEP: Creating a pod to test consume configMaps
May  5 12:07:26.446: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc" in namespace "projected-2396" to be "success or failure"
May  5 12:07:26.458: INFO: Pod "pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.11131ms
May  5 12:07:28.461: INFO: Pod "pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014271601s
May  5 12:07:30.464: INFO: Pod "pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017581984s
STEP: Saw pod success
May  5 12:07:30.464: INFO: Pod "pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc" satisfied condition "success or failure"
May  5 12:07:30.467: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:07:30.495: INFO: Waiting for pod pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc to disappear
May  5 12:07:30.499: INFO: Pod pod-projected-configmaps-d4f8d630-8942-4c90-9c52-9babf48c2efc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:30.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2396" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":222,"skipped":3280,"failed":0}
S
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:30.507: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:07:30.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de" in namespace "downward-api-3270" to be "success or failure"
May  5 12:07:30.680: INFO: Pod "downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de": Phase="Pending", Reason="", readiness=false. Elapsed: 9.439118ms
May  5 12:07:32.683: INFO: Pod "downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012757403s
STEP: Saw pod success
May  5 12:07:32.683: INFO: Pod "downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de" satisfied condition "success or failure"
May  5 12:07:32.687: INFO: Trying to get logs from node ip-10-0-33-250 pod downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de container client-container: <nil>
STEP: delete the pod
May  5 12:07:32.712: INFO: Waiting for pod downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de to disappear
May  5 12:07:32.714: INFO: Pod downwardapi-volume-8fd7068a-f26c-4b87-bb71-88b5697b27de no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:32.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3270" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":223,"skipped":3281,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:07:48.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4751" for this suite.

• [SLOW TEST:16.175 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":280,"completed":224,"skipped":3286,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:07:48.906: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-6613
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:07:49.048: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Creating first CR 
May  5 12:07:49.215: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:49Z generation:1 name:name1 resourceVersion:24631 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3d0b906a-9fdc-4bb0-9721-46df3ad2a62c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
May  5 12:07:59.219: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:59Z generation:1 name:name2 resourceVersion:24665 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:1484858f-352f-4ee0-b3a7-b263318cf416] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
May  5 12:08:09.224: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:49Z generation:2 name:name1 resourceVersion:24690 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3d0b906a-9fdc-4bb0-9721-46df3ad2a62c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
May  5 12:08:19.230: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:59Z generation:2 name:name2 resourceVersion:24715 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:1484858f-352f-4ee0-b3a7-b263318cf416] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
May  5 12:08:29.237: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:49Z generation:2 name:name1 resourceVersion:24740 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3d0b906a-9fdc-4bb0-9721-46df3ad2a62c] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
May  5 12:08:39.243: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-05-05T12:07:59Z generation:2 name:name2 resourceVersion:24765 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:1484858f-352f-4ee0-b3a7-b263318cf416] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:08:49.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-6613" for this suite.

• [SLOW TEST:60.884 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:41
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":280,"completed":225,"skipped":3290,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:08:49.790: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:09:09.993: INFO: Container started at 2020-05-05 12:08:50 +0000 UTC, pod became ready at 2020-05-05 12:09:09 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:09.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4343" for this suite.

• [SLOW TEST:20.211 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":280,"completed":226,"skipped":3307,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:10.001: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1276
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:09:10.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 version'
May  5 12:09:10.235: INFO: stderr: ""
May  5 12:09:10.235: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.4\", GitCommit:\"8d8aa39598534325ad77120c120a22b3a990b5ea\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T21:03:42Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.4\", GitCommit:\"8d8aa39598534325ad77120c120a22b3a990b5ea\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T20:55:23Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:10.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1276" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":280,"completed":227,"skipped":3325,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:10.243: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:09:10.702: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 12:09:12.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277350, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277350, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277350, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277350, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:09:15.725: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:09:15.728: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1393-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:16.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7717" for this suite.
STEP: Destroying namespace "webhook-7717-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.670 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":280,"completed":228,"skipped":3331,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:16.916: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5628
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:09:17.091: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
May  5 12:09:21.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 create -f -'
May  5 12:09:21.624: INFO: stderr: ""
May  5 12:09:21.624: INFO: stdout: "e2e-test-crd-publish-openapi-3974-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  5 12:09:21.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 delete e2e-test-crd-publish-openapi-3974-crds test-foo'
May  5 12:09:21.703: INFO: stderr: ""
May  5 12:09:21.703: INFO: stdout: "e2e-test-crd-publish-openapi-3974-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
May  5 12:09:21.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 apply -f -'
May  5 12:09:21.879: INFO: stderr: ""
May  5 12:09:21.879: INFO: stdout: "e2e-test-crd-publish-openapi-3974-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
May  5 12:09:21.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 delete e2e-test-crd-publish-openapi-3974-crds test-foo'
May  5 12:09:21.965: INFO: stderr: ""
May  5 12:09:21.965: INFO: stdout: "e2e-test-crd-publish-openapi-3974-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
May  5 12:09:21.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 create -f -'
May  5 12:09:22.121: INFO: rc: 1
May  5 12:09:22.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 apply -f -'
May  5 12:09:22.268: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
May  5 12:09:22.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 create -f -'
May  5 12:09:22.459: INFO: rc: 1
May  5 12:09:22.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-5628 apply -f -'
May  5 12:09:22.629: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
May  5 12:09:22.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-3974-crds'
May  5 12:09:22.828: INFO: stderr: ""
May  5 12:09:22.828: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3974-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
May  5 12:09:22.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-3974-crds.metadata'
May  5 12:09:23.117: INFO: stderr: ""
May  5 12:09:23.117: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3974-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
May  5 12:09:23.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-3974-crds.spec'
May  5 12:09:23.304: INFO: stderr: ""
May  5 12:09:23.304: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3974-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
May  5 12:09:23.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-3974-crds.spec.bars'
May  5 12:09:23.495: INFO: stderr: ""
May  5 12:09:23.495: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3974-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
May  5 12:09:23.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-3974-crds.spec.bars2'
May  5 12:09:23.671: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:27.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5628" for this suite.

• [SLOW TEST:10.219 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":280,"completed":229,"skipped":3352,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:27.137: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3334
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0505 12:09:33.310786      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
May  5 12:09:33.311: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:33.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3334" for this suite.

• [SLOW TEST:6.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":280,"completed":230,"skipped":3362,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:33.320: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:09:34.195: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 12:09:36.203: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277374, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277374, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277374, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277374, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:09:39.223: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:39.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2581" for this suite.
STEP: Destroying namespace "webhook-2581-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.006 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":280,"completed":231,"skipped":3399,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:39.334: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9956.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9956.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
May  5 12:09:41.562: INFO: DNS probes using dns-9956/dns-test-18fd20d7-a61b-4a75-94d5-7e8431c95e09 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:09:41.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9956" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":280,"completed":232,"skipped":3437,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:09:41.592: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec in namespace container-probe-9865
May  5 12:09:43.744: INFO: Started pod liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec in namespace container-probe-9865
STEP: checking the pod's current state and verifying that restartCount is present
May  5 12:09:43.747: INFO: Initial restart count of pod liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is 0
May  5 12:09:57.773: INFO: Restart count of pod container-probe-9865/liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is now 1 (14.025921921s elapsed)
May  5 12:10:17.830: INFO: Restart count of pod container-probe-9865/liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is now 2 (34.082964368s elapsed)
May  5 12:10:37.875: INFO: Restart count of pod container-probe-9865/liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is now 3 (54.128209923s elapsed)
May  5 12:10:57.911: INFO: Restart count of pod container-probe-9865/liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is now 4 (1m14.163889479s elapsed)
May  5 12:12:10.091: INFO: Restart count of pod container-probe-9865/liveness-fc453faa-5440-4d55-bf9c-ae6bfa0ff0ec is now 5 (2m26.344147946s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:12:10.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9865" for this suite.

• [SLOW TEST:148.526 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":280,"completed":233,"skipped":3445,"failed":0}
SSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:12:10.118: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-3766
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:163
May  5 12:12:10.286: INFO: Waiting up to 1m0s for all nodes to be ready
May  5 12:13:10.305: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:13:10.308: INFO: Starting informer...
STEP: Starting pod...
May  5 12:13:10.520: INFO: Pod is running on ip-10-0-27-202. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
May  5 12:13:10.532: INFO: Pod wasn't evicted. Proceeding
May  5 12:13:10.532: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
May  5 12:14:25.548: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:25.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3766" for this suite.

• [SLOW TEST:135.444 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":280,"completed":234,"skipped":3452,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:25.564: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1275
STEP: creating the pod
May  5 12:14:25.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-2912'
May  5 12:14:26.006: INFO: stderr: ""
May  5 12:14:26.006: INFO: stdout: "pod/pause created\n"
May  5 12:14:26.006: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
May  5 12:14:26.006: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2912" to be "running and ready"
May  5 12:14:26.010: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.653389ms
May  5 12:14:28.015: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009207872s
May  5 12:14:28.015: INFO: Pod "pause" satisfied condition "running and ready"
May  5 12:14:28.015: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: adding the label testing-label with value testing-label-value to a pod
May  5 12:14:28.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 label pods pause testing-label=testing-label-value --namespace=kubectl-2912'
May  5 12:14:28.111: INFO: stderr: ""
May  5 12:14:28.111: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
May  5 12:14:28.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pod pause -L testing-label --namespace=kubectl-2912'
May  5 12:14:28.244: INFO: stderr: ""
May  5 12:14:28.244: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
May  5 12:14:28.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 label pods pause testing-label- --namespace=kubectl-2912'
May  5 12:14:28.339: INFO: stderr: ""
May  5 12:14:28.339: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
May  5 12:14:28.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pod pause -L testing-label --namespace=kubectl-2912'
May  5 12:14:28.426: INFO: stderr: ""
May  5 12:14:28.426: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1282
STEP: using delete to clean up resources
May  5 12:14:28.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-2912'
May  5 12:14:28.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 12:14:28.529: INFO: stdout: "pod \"pause\" force deleted\n"
May  5 12:14:28.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get rc,svc -l name=pause --no-headers --namespace=kubectl-2912'
May  5 12:14:28.629: INFO: stderr: "No resources found in kubectl-2912 namespace.\n"
May  5 12:14:28.629: INFO: stdout: ""
May  5 12:14:28.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -l name=pause --namespace=kubectl-2912 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  5 12:14:28.714: INFO: stderr: ""
May  5 12:14:28.714: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:28.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2912" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":280,"completed":235,"skipped":3472,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:28.722: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:30.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2128" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":280,"completed":236,"skipped":3498,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:30.929: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7025
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-558793be-2c67-471f-b169-b6d0bdc23970
STEP: Creating configMap with name cm-test-opt-upd-4e45bdd4-740a-4469-ac11-62deab23e356
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-558793be-2c67-471f-b169-b6d0bdc23970
STEP: Updating configmap cm-test-opt-upd-4e45bdd4-740a-4469-ac11-62deab23e356
STEP: Creating configMap with name cm-test-opt-create-3b1f2263-326c-4275-ac52-4479e7161df5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:35.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7025" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":237,"skipped":3499,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:35.200: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:37.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1397" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":238,"skipped":3531,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:37.363: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3036
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-75c5607b-d0b8-4ba0-b09b-7e7c8a91e355
STEP: Creating a pod to test consume secrets
May  5 12:14:37.590: INFO: Waiting up to 5m0s for pod "pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d" in namespace "secrets-3036" to be "success or failure"
May  5 12:14:37.595: INFO: Pod "pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.74042ms
May  5 12:14:39.598: INFO: Pod "pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008058868s
STEP: Saw pod success
May  5 12:14:39.598: INFO: Pod "pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d" satisfied condition "success or failure"
May  5 12:14:39.600: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d container secret-volume-test: <nil>
STEP: delete the pod
May  5 12:14:39.615: INFO: Waiting for pod pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d to disappear
May  5 12:14:39.617: INFO: Pod pod-secrets-9d40efab-a917-44e6-831e-92e9e7ef526d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:39.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3036" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":239,"skipped":3539,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:39.636: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:14:39.767: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:41.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5023" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":280,"completed":240,"skipped":3572,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:41.890: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4095
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-c6595734-c8d5-471e-967f-2b64ddd48d17
STEP: Creating a pod to test consume configMaps
May  5 12:14:42.027: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1" in namespace "projected-4095" to be "success or failure"
May  5 12:14:42.034: INFO: Pod "pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.797094ms
May  5 12:14:44.037: INFO: Pod "pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009944738s
May  5 12:14:46.041: INFO: Pod "pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01322877s
STEP: Saw pod success
May  5 12:14:46.041: INFO: Pod "pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1" satisfied condition "success or failure"
May  5 12:14:46.043: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:14:46.059: INFO: Waiting for pod pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1 to disappear
May  5 12:14:46.063: INFO: Pod pod-projected-configmaps-3ee49b51-3cad-4609-b970-e59118ef48a1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:46.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4095" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":280,"completed":241,"skipped":3596,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:46.072: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9723
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  5 12:14:46.221: INFO: Waiting up to 5m0s for pod "pod-9967593c-2a3b-4e91-aed6-b7247371a1d1" in namespace "emptydir-9723" to be "success or failure"
May  5 12:14:46.225: INFO: Pod "pod-9967593c-2a3b-4e91-aed6-b7247371a1d1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.720063ms
May  5 12:14:48.230: INFO: Pod "pod-9967593c-2a3b-4e91-aed6-b7247371a1d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008334846s
May  5 12:14:50.249: INFO: Pod "pod-9967593c-2a3b-4e91-aed6-b7247371a1d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027696408s
STEP: Saw pod success
May  5 12:14:50.249: INFO: Pod "pod-9967593c-2a3b-4e91-aed6-b7247371a1d1" satisfied condition "success or failure"
May  5 12:14:50.253: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-9967593c-2a3b-4e91-aed6-b7247371a1d1 container test-container: <nil>
STEP: delete the pod
May  5 12:14:50.275: INFO: Waiting for pod pod-9967593c-2a3b-4e91-aed6-b7247371a1d1 to disappear
May  5 12:14:50.285: INFO: Pod pod-9967593c-2a3b-4e91-aed6-b7247371a1d1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:50.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9723" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":242,"skipped":3646,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:50.295: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:178
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:50.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4632" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":280,"completed":243,"skipped":3661,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:50.468: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-59028a8b-93ed-4cdb-8120-bdcbe095aaac
STEP: Creating a pod to test consume configMaps
May  5 12:14:50.614: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355" in namespace "projected-5710" to be "success or failure"
May  5 12:14:50.620: INFO: Pod "pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355": Phase="Pending", Reason="", readiness=false. Elapsed: 5.973684ms
May  5 12:14:52.627: INFO: Pod "pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013167582s
May  5 12:14:54.634: INFO: Pod "pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020142496s
STEP: Saw pod success
May  5 12:14:54.634: INFO: Pod "pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355" satisfied condition "success or failure"
May  5 12:14:54.637: INFO: Trying to get logs from node ip-10-0-33-250 pod pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355 container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:14:54.651: INFO: Waiting for pod pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355 to disappear
May  5 12:14:54.654: INFO: Pod pod-projected-configmaps-75c0bc77-d5dd-493a-bfb4-ba3481668355 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:54.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5710" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":244,"skipped":3737,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:54.661: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8270
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:14:54.794: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:14:55.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8270" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":280,"completed":245,"skipped":3747,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:14:55.383: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:14:55.651: INFO: Pod name rollover-pod: Found 0 pods out of 1
May  5 12:15:00.655: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
May  5 12:15:00.655: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
May  5 12:15:02.659: INFO: Creating deployment "test-rollover-deployment"
May  5 12:15:02.669: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
May  5 12:15:04.682: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
May  5 12:15:04.691: INFO: Ensure that both replica sets have 1 created replica
May  5 12:15:04.697: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
May  5 12:15:04.706: INFO: Updating deployment test-rollover-deployment
May  5 12:15:04.706: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
May  5 12:15:06.712: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
May  5 12:15:06.718: INFO: Make sure deployment "test-rollover-deployment" is complete
May  5 12:15:06.723: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:06.723: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277704, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:08.731: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:08.731: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277706, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:10.728: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:10.728: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277706, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:12.729: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:12.730: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277706, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:14.729: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:14.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277706, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:16.728: INFO: all replica sets need to contain the pod-template-hash label
May  5 12:15:16.729: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277706, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277702, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
May  5 12:15:18.729: INFO: 
May  5 12:15:18.729: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
May  5 12:15:18.742: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3308 /apis/apps/v1/namespaces/deployment-3308/deployments/test-rollover-deployment e7c50d41-e996-451e-917f-0bb25e154ecf 26851 2 2020-05-05 12:15:02 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00579b338 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-05-05 12:15:02 +0000 UTC,LastTransitionTime:2020-05-05 12:15:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-574d6dfbff" has successfully progressed.,LastUpdateTime:2020-05-05 12:15:16 +0000 UTC,LastTransitionTime:2020-05-05 12:15:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

May  5 12:15:18.745: INFO: New ReplicaSet "test-rollover-deployment-574d6dfbff" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-574d6dfbff  deployment-3308 /apis/apps/v1/namespaces/deployment-3308/replicasets/test-rollover-deployment-574d6dfbff 29f4ec5e-b605-43a4-b25f-7d7f23ae09d6 26841 2 2020-05-05 12:15:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment e7c50d41-e996-451e-917f-0bb25e154ecf 0xc005633d27 0xc005633d28}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 574d6dfbff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005633d98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
May  5 12:15:18.745: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
May  5 12:15:18.745: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3308 /apis/apps/v1/namespaces/deployment-3308/replicasets/test-rollover-controller e47338c5-6f8d-4f49-a64c-4723180b68ac 26850 2 2020-05-05 12:14:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment e7c50d41-e996-451e-917f-0bb25e154ecf 0xc005633c57 0xc005633c58}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005633cb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 12:15:18.745: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-3308 /apis/apps/v1/namespaces/deployment-3308/replicasets/test-rollover-deployment-f6c94f66c 2cac6449-595e-4ca6-b2f9-c0b6cab5557b 26776 2 2020-05-05 12:15:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment e7c50d41-e996-451e-917f-0bb25e154ecf 0xc005633e00 0xc005633e01}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005633e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
May  5 12:15:18.748: INFO: Pod "test-rollover-deployment-574d6dfbff-ql6v9" is available:
&Pod{ObjectMeta:{test-rollover-deployment-574d6dfbff-ql6v9 test-rollover-deployment-574d6dfbff- deployment-3308 /api/v1/namespaces/deployment-3308/pods/test-rollover-deployment-574d6dfbff-ql6v9 48f22f14-61c8-454e-a9bb-339363b1c796 26802 0 2020-05-05 12:15:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[cni.projectcalico.org/podIP:10.2.232.19/32 cni.projectcalico.org/podIPs:10.2.232.19/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-574d6dfbff 29f4ec5e-b605-43a4-b25f-7d7f23ae09d6 0xc00579b717 0xc00579b718}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cjtj5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cjtj5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cjtj5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-27-202,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:15:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:15:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:15:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-05-05 12:15:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.27.202,PodIP:10.2.232.19,StartTime:2020-05-05 12:15:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-05-05 12:15:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:daf5332100521b1256d0e3c56d697a238eaec3af48897ed9167cbadd426773b5,ContainerID:docker://f8d6d3b5e1cb47dbdc8e6f9573936f3bf1a8c2652a2144d8b793d4c295e4485a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.2.232.19,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:15:18.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3308" for this suite.

• [SLOW TEST:23.378 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":280,"completed":246,"skipped":3751,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:15:18.763: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3949
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:15:21.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3949" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":280,"completed":247,"skipped":3763,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:15:21.939: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4504
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:15:22.072: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
May  5 12:15:25.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4504 create -f -'
May  5 12:15:25.992: INFO: stderr: ""
May  5 12:15:25.992: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  5 12:15:25.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4504 delete e2e-test-crd-publish-openapi-5742-crds test-cr'
May  5 12:15:26.081: INFO: stderr: ""
May  5 12:15:26.081: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
May  5 12:15:26.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4504 apply -f -'
May  5 12:15:26.255: INFO: stderr: ""
May  5 12:15:26.255: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
May  5 12:15:26.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=crd-publish-openapi-4504 delete e2e-test-crd-publish-openapi-5742-crds test-cr'
May  5 12:15:26.333: INFO: stderr: ""
May  5 12:15:26.333: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
May  5 12:15:26.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 explain e2e-test-crd-publish-openapi-5742-crds'
May  5 12:15:26.502: INFO: stderr: ""
May  5 12:15:26.502: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5742-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:15:29.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4504" for this suite.

• [SLOW TEST:8.079 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":280,"completed":248,"skipped":3793,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:15:30.020: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3054
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
May  5 12:15:30.160: INFO: Waiting up to 5m0s for pod "pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2" in namespace "emptydir-3054" to be "success or failure"
May  5 12:15:30.163: INFO: Pod "pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2": Phase="Pending", Reason="", readiness=false. Elapsed: 3.386595ms
May  5 12:15:32.168: INFO: Pod "pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007803343s
STEP: Saw pod success
May  5 12:15:32.168: INFO: Pod "pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2" satisfied condition "success or failure"
May  5 12:15:32.173: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2 container test-container: <nil>
STEP: delete the pod
May  5 12:15:32.198: INFO: Waiting for pod pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2 to disappear
May  5 12:15:32.204: INFO: Pod pod-d7f38275-8dcb-43fe-8677-cd0869e48dc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:15:32.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3054" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":249,"skipped":3827,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:15:32.222: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4734
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-7e73a077-695b-4ecd-a25a-a969f91a6f8a
STEP: Creating a pod to test consume configMaps
May  5 12:15:32.386: INFO: Waiting up to 5m0s for pod "pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b" in namespace "configmap-4734" to be "success or failure"
May  5 12:15:32.390: INFO: Pod "pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.559763ms
May  5 12:15:34.394: INFO: Pod "pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007957194s
STEP: Saw pod success
May  5 12:15:34.394: INFO: Pod "pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b" satisfied condition "success or failure"
May  5 12:15:34.397: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b container configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:15:34.414: INFO: Waiting for pod pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b to disappear
May  5 12:15:34.417: INFO: Pod pod-configmaps-84029e1a-c91e-4f79-b6e3-9fa933fa289b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:15:34.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4734" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":250,"skipped":3849,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:15:34.425: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:15:34.568: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
May  5 12:15:34.577: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:34.580: INFO: Number of nodes with available pods: 0
May  5 12:15:34.580: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 12:15:35.584: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:35.587: INFO: Number of nodes with available pods: 0
May  5 12:15:35.587: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 12:15:36.584: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:36.587: INFO: Number of nodes with available pods: 2
May  5 12:15:36.587: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
May  5 12:15:36.613: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:36.613: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:36.618: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:37.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:37.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:37.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:38.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:38.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:38.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:39.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:39.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:39.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:39.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:40.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:40.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:40.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:40.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:41.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:41.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:41.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:41.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:42.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:42.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:42.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:42.624: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:43.623: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:43.623: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:43.623: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:43.628: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:44.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:44.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:44.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:44.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:45.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:45.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:45.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:45.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:46.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:46.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:46.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:46.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:47.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:47.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:47.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:47.626: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:48.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:48.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:48.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:48.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:49.622: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:49.622: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:49.622: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:49.625: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:50.624: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:50.624: INFO: Wrong image for pod: daemon-set-r6mjc. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:50.624: INFO: Pod daemon-set-r6mjc is not available
May  5 12:15:50.627: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:51.623: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:51.623: INFO: Pod daemon-set-xw8mr is not available
May  5 12:15:51.626: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:52.746: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:52.753: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:53.630: INFO: Wrong image for pod: daemon-set-h55w9. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
May  5 12:15:53.630: INFO: Pod daemon-set-h55w9 is not available
May  5 12:15:53.639: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:54.622: INFO: Pod daemon-set-g5vz4 is not available
May  5 12:15:54.627: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
May  5 12:15:54.636: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:54.640: INFO: Number of nodes with available pods: 1
May  5 12:15:54.640: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:15:55.643: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:55.646: INFO: Number of nodes with available pods: 1
May  5 12:15:55.646: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:15:56.647: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:15:56.650: INFO: Number of nodes with available pods: 2
May  5 12:15:56.650: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7614, will wait for the garbage collector to delete the pods
May  5 12:15:56.720: INFO: Deleting DaemonSet.extensions daemon-set took: 4.623748ms
May  5 12:15:57.121: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.879528ms
May  5 12:16:05.425: INFO: Number of nodes with available pods: 0
May  5 12:16:05.426: INFO: Number of running nodes: 0, number of available pods: 0
May  5 12:16:05.429: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7614/daemonsets","resourceVersion":"27261"},"items":null}

May  5 12:16:05.433: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7614/pods","resourceVersion":"27261"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:16:05.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7614" for this suite.

• [SLOW TEST:31.027 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":280,"completed":251,"skipped":3875,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:16:05.454: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
May  5 12:16:05.615: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:05.618: INFO: Number of nodes with available pods: 0
May  5 12:16:05.618: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 12:16:06.633: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:06.637: INFO: Number of nodes with available pods: 0
May  5 12:16:06.637: INFO: Node ip-10-0-27-202 is running more than one daemon pod
May  5 12:16:07.622: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:07.625: INFO: Number of nodes with available pods: 1
May  5 12:16:07.625: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:08.630: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:08.635: INFO: Number of nodes with available pods: 2
May  5 12:16:08.635: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
May  5 12:16:08.652: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:08.655: INFO: Number of nodes with available pods: 1
May  5 12:16:08.656: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:09.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:09.665: INFO: Number of nodes with available pods: 1
May  5 12:16:09.665: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:10.665: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:10.669: INFO: Number of nodes with available pods: 1
May  5 12:16:10.669: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:11.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:11.663: INFO: Number of nodes with available pods: 1
May  5 12:16:11.663: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:12.662: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:12.666: INFO: Number of nodes with available pods: 1
May  5 12:16:12.666: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:13.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:13.669: INFO: Number of nodes with available pods: 1
May  5 12:16:13.669: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:14.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:14.663: INFO: Number of nodes with available pods: 1
May  5 12:16:14.663: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:15.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:15.663: INFO: Number of nodes with available pods: 1
May  5 12:16:15.663: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:16.660: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:16.664: INFO: Number of nodes with available pods: 1
May  5 12:16:16.664: INFO: Node ip-10-0-33-250 is running more than one daemon pod
May  5 12:16:17.661: INFO: DaemonSet pods can't tolerate node ip-10-0-0-244 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
May  5 12:16:17.665: INFO: Number of nodes with available pods: 2
May  5 12:16:17.665: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4091, will wait for the garbage collector to delete the pods
May  5 12:16:17.725: INFO: Deleting DaemonSet.extensions daemon-set took: 4.902052ms
May  5 12:16:18.125: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.613229ms
May  5 12:16:25.429: INFO: Number of nodes with available pods: 0
May  5 12:16:25.429: INFO: Number of running nodes: 0, number of available pods: 0
May  5 12:16:25.431: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4091/daemonsets","resourceVersion":"27420"},"items":null}

May  5 12:16:25.434: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4091/pods","resourceVersion":"27420"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:16:25.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4091" for this suite.

• [SLOW TEST:19.996 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":280,"completed":252,"skipped":3880,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:16:25.454: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-813
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:16:25.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b" in namespace "projected-813" to be "success or failure"
May  5 12:16:25.680: INFO: Pod "downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.694637ms
May  5 12:16:27.685: INFO: Pod "downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009938623s
STEP: Saw pod success
May  5 12:16:27.685: INFO: Pod "downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b" satisfied condition "success or failure"
May  5 12:16:27.687: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b container client-container: <nil>
STEP: delete the pod
May  5 12:16:27.709: INFO: Waiting for pod downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b to disappear
May  5 12:16:27.711: INFO: Pod downwardapi-volume-73982fae-ad07-41a3-9bb8-08237385f53b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:16:27.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-813" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":253,"skipped":3888,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:16:27.736: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
May  5 12:16:27.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 create -f - --namespace=kubectl-7590'
May  5 12:16:28.149: INFO: stderr: ""
May  5 12:16:28.149: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 12:16:28.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:28.262: INFO: stderr: ""
May  5 12:16:28.262: INFO: stdout: "update-demo-nautilus-n75pq update-demo-nautilus-wz994 "
May  5 12:16:28.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-n75pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:28.354: INFO: stderr: ""
May  5 12:16:28.354: INFO: stdout: ""
May  5 12:16:28.354: INFO: update-demo-nautilus-n75pq is created but not running
May  5 12:16:33.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:33.483: INFO: stderr: ""
May  5 12:16:33.483: INFO: stdout: "update-demo-nautilus-n75pq update-demo-nautilus-wz994 "
May  5 12:16:33.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-n75pq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:33.582: INFO: stderr: ""
May  5 12:16:33.582: INFO: stdout: "true"
May  5 12:16:33.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-n75pq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:33.667: INFO: stderr: ""
May  5 12:16:33.667: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:16:33.667: INFO: validating pod update-demo-nautilus-n75pq
May  5 12:16:33.672: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:16:33.672: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:16:33.672: INFO: update-demo-nautilus-n75pq is verified up and running
May  5 12:16:33.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:33.764: INFO: stderr: ""
May  5 12:16:33.764: INFO: stdout: "true"
May  5 12:16:33.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:33.851: INFO: stderr: ""
May  5 12:16:33.851: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:16:33.851: INFO: validating pod update-demo-nautilus-wz994
May  5 12:16:33.855: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:16:33.855: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:16:33.855: INFO: update-demo-nautilus-wz994 is verified up and running
STEP: scaling down the replication controller
May  5 12:16:33.857: INFO: scanned /root for discovery docs: <nil>
May  5 12:16:33.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7590'
May  5 12:16:34.073: INFO: stderr: ""
May  5 12:16:34.073: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 12:16:34.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:34.154: INFO: stderr: ""
May  5 12:16:34.154: INFO: stdout: "update-demo-nautilus-n75pq update-demo-nautilus-wz994 "
STEP: Replicas for name=update-demo: expected=1 actual=2
May  5 12:16:39.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:39.317: INFO: stderr: ""
May  5 12:16:39.317: INFO: stdout: "update-demo-nautilus-wz994 "
May  5 12:16:39.317: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:39.433: INFO: stderr: ""
May  5 12:16:39.433: INFO: stdout: "true"
May  5 12:16:39.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:39.529: INFO: stderr: ""
May  5 12:16:39.529: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:16:39.529: INFO: validating pod update-demo-nautilus-wz994
May  5 12:16:39.533: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:16:39.533: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:16:39.533: INFO: update-demo-nautilus-wz994 is verified up and running
STEP: scaling up the replication controller
May  5 12:16:39.537: INFO: scanned /root for discovery docs: <nil>
May  5 12:16:39.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7590'
May  5 12:16:40.669: INFO: stderr: ""
May  5 12:16:40.669: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
May  5 12:16:40.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:40.745: INFO: stderr: ""
May  5 12:16:40.745: INFO: stdout: "update-demo-nautilus-ls8gn update-demo-nautilus-wz994 "
May  5 12:16:40.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-ls8gn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:40.818: INFO: stderr: ""
May  5 12:16:40.818: INFO: stdout: ""
May  5 12:16:40.818: INFO: update-demo-nautilus-ls8gn is created but not running
May  5 12:16:45.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7590'
May  5 12:16:46.024: INFO: stderr: ""
May  5 12:16:46.024: INFO: stdout: "update-demo-nautilus-ls8gn update-demo-nautilus-wz994 "
May  5 12:16:46.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-ls8gn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:46.234: INFO: stderr: ""
May  5 12:16:46.234: INFO: stdout: "true"
May  5 12:16:46.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-ls8gn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:46.308: INFO: stderr: ""
May  5 12:16:46.308: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:16:46.308: INFO: validating pod update-demo-nautilus-ls8gn
May  5 12:16:46.314: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:16:46.314: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:16:46.314: INFO: update-demo-nautilus-ls8gn is verified up and running
May  5 12:16:46.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:46.395: INFO: stderr: ""
May  5 12:16:46.395: INFO: stdout: "true"
May  5 12:16:46.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods update-demo-nautilus-wz994 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7590'
May  5 12:16:46.490: INFO: stderr: ""
May  5 12:16:46.490: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
May  5 12:16:46.490: INFO: validating pod update-demo-nautilus-wz994
May  5 12:16:46.499: INFO: got data: {
  "image": "nautilus.jpg"
}

May  5 12:16:46.499: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
May  5 12:16:46.499: INFO: update-demo-nautilus-wz994 is verified up and running
STEP: using delete to clean up resources
May  5 12:16:46.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete --grace-period=0 --force -f - --namespace=kubectl-7590'
May  5 12:16:46.577: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
May  5 12:16:46.577: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
May  5 12:16:46.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7590'
May  5 12:16:46.671: INFO: stderr: "No resources found in kubectl-7590 namespace.\n"
May  5 12:16:46.671: INFO: stdout: ""
May  5 12:16:46.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -l name=update-demo --namespace=kubectl-7590 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  5 12:16:46.749: INFO: stderr: ""
May  5 12:16:46.749: INFO: stdout: "update-demo-nautilus-ls8gn\nupdate-demo-nautilus-wz994\n"
May  5 12:16:47.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7590'
May  5 12:16:47.400: INFO: stderr: "No resources found in kubectl-7590 namespace.\n"
May  5 12:16:47.400: INFO: stdout: ""
May  5 12:16:47.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pods -l name=update-demo --namespace=kubectl-7590 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
May  5 12:16:47.520: INFO: stderr: ""
May  5 12:16:47.520: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:16:47.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7590" for this suite.

• [SLOW TEST:19.792 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":280,"completed":254,"skipped":3906,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:16:47.528: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-l6qz9 in namespace proxy-8025
I0505 12:16:47.680057      21 runners.go:189] Created replication controller with name: proxy-service-l6qz9, namespace: proxy-8025, replica count: 1
I0505 12:16:48.730643      21 runners.go:189] proxy-service-l6qz9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0505 12:16:49.730833      21 runners.go:189] proxy-service-l6qz9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0505 12:16:50.731037      21 runners.go:189] proxy-service-l6qz9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0505 12:16:51.731235      21 runners.go:189] proxy-service-l6qz9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  5 12:16:51.734: INFO: setup took 4.073558096s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
May  5 12:16:51.746: INFO: (0) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 9.473293ms)
May  5 12:16:51.746: INFO: (0) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 9.484718ms)
May  5 12:16:51.746: INFO: (0) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 11.598401ms)
May  5 12:16:51.747: INFO: (0) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 9.99583ms)
May  5 12:16:51.747: INFO: (0) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 10.67203ms)
May  5 12:16:51.749: INFO: (0) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.364712ms)
May  5 12:16:51.755: INFO: (0) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 18.274086ms)
May  5 12:16:51.756: INFO: (0) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 18.281641ms)
May  5 12:16:51.757: INFO: (0) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 19.378477ms)
May  5 12:16:51.760: INFO: (0) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 22.462198ms)
May  5 12:16:51.760: INFO: (0) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 22.853827ms)
May  5 12:16:51.763: INFO: (0) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 24.987462ms)
May  5 12:16:51.763: INFO: (0) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 25.576003ms)
May  5 12:16:51.766: INFO: (0) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 28.313344ms)
May  5 12:16:51.766: INFO: (0) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 28.325466ms)
May  5 12:16:51.770: INFO: (0) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 34.956878ms)
May  5 12:16:51.786: INFO: (1) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 15.848648ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 15.409971ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 16.964258ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 15.540883ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 15.494621ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 15.721436ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 16.253023ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 16.329825ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 15.968178ms)
May  5 12:16:51.787: INFO: (1) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 16.979348ms)
May  5 12:16:51.789: INFO: (1) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 17.683777ms)
May  5 12:16:51.790: INFO: (1) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 18.767661ms)
May  5 12:16:51.790: INFO: (1) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 18.930832ms)
May  5 12:16:51.790: INFO: (1) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 18.935038ms)
May  5 12:16:51.790: INFO: (1) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 19.644785ms)
May  5 12:16:51.790: INFO: (1) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 19.744299ms)
May  5 12:16:51.800: INFO: (2) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 9.640185ms)
May  5 12:16:51.800: INFO: (2) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 9.861376ms)
May  5 12:16:51.803: INFO: (2) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 12.577472ms)
May  5 12:16:51.803: INFO: (2) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 13.005312ms)
May  5 12:16:51.803: INFO: (2) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 13.147239ms)
May  5 12:16:51.803: INFO: (2) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 13.14357ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 12.991731ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 12.939948ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.914765ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 13.065062ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 13.030614ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.9432ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 13.219251ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 13.490708ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 13.577843ms)
May  5 12:16:51.804: INFO: (2) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 13.628515ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 11.372815ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.065402ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 12.242181ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 11.73402ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 12.394384ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 12.198082ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.220693ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.586754ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.255401ms)
May  5 12:16:51.817: INFO: (3) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 12.413935ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 12.891776ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 12.7259ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 12.970852ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 12.785881ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 12.578069ms)
May  5 12:16:51.818: INFO: (3) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 13.45852ms)
May  5 12:16:51.823: INFO: (4) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 4.624849ms)
May  5 12:16:51.825: INFO: (4) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 6.321859ms)
May  5 12:16:51.826: INFO: (4) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 7.04621ms)
May  5 12:16:51.826: INFO: (4) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 7.213324ms)
May  5 12:16:51.827: INFO: (4) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 7.594492ms)
May  5 12:16:51.827: INFO: (4) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 8.274056ms)
May  5 12:16:51.827: INFO: (4) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 8.111431ms)
May  5 12:16:51.827: INFO: (4) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 7.902184ms)
May  5 12:16:51.830: INFO: (4) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 11.079307ms)
May  5 12:16:51.830: INFO: (4) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 10.688526ms)
May  5 12:16:51.830: INFO: (4) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 11.588276ms)
May  5 12:16:51.831: INFO: (4) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 12.224747ms)
May  5 12:16:51.831: INFO: (4) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 12.433242ms)
May  5 12:16:51.832: INFO: (4) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 13.39378ms)
May  5 12:16:51.833: INFO: (4) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 13.656096ms)
May  5 12:16:51.833: INFO: (4) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 14.131319ms)
May  5 12:16:51.838: INFO: (5) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 5.166899ms)
May  5 12:16:51.838: INFO: (5) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 5.493413ms)
May  5 12:16:51.847: INFO: (5) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 13.656364ms)
May  5 12:16:51.847: INFO: (5) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 14.206429ms)
May  5 12:16:51.847: INFO: (5) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 14.123799ms)
May  5 12:16:51.847: INFO: (5) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 14.021135ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 14.550177ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 14.666051ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 14.592216ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 14.713351ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 14.633693ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 14.565289ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 14.714185ms)
May  5 12:16:51.848: INFO: (5) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 15.275184ms)
May  5 12:16:51.849: INFO: (5) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 15.327162ms)
May  5 12:16:51.849: INFO: (5) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 15.372048ms)
May  5 12:16:51.856: INFO: (6) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 7.130348ms)
May  5 12:16:51.861: INFO: (6) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 11.601329ms)
May  5 12:16:51.861: INFO: (6) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.15439ms)
May  5 12:16:51.861: INFO: (6) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 12.000228ms)
May  5 12:16:51.861: INFO: (6) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 12.27959ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 12.71739ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.223407ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 12.332959ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 12.51866ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.424727ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.64102ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 13.011223ms)
May  5 12:16:51.862: INFO: (6) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 13.129112ms)
May  5 12:16:51.863: INFO: (6) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 14.301876ms)
May  5 12:16:51.863: INFO: (6) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 14.505173ms)
May  5 12:16:51.864: INFO: (6) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 14.244937ms)
May  5 12:16:51.873: INFO: (7) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 8.928094ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 15.478207ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 15.676579ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 16.058759ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 15.882537ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 15.949194ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 15.634565ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 16.204293ms)
May  5 12:16:51.880: INFO: (7) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 15.702049ms)
May  5 12:16:51.881: INFO: (7) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 15.694458ms)
May  5 12:16:51.881: INFO: (7) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 15.688862ms)
May  5 12:16:51.881: INFO: (7) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 15.828723ms)
May  5 12:16:51.881: INFO: (7) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 16.31458ms)
May  5 12:16:51.881: INFO: (7) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 16.622773ms)
May  5 12:16:51.888: INFO: (7) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 23.460501ms)
May  5 12:16:51.888: INFO: (7) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 23.47198ms)
May  5 12:16:51.904: INFO: (8) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 16.044455ms)
May  5 12:16:51.905: INFO: (8) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 16.534544ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 17.189341ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 16.987214ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 17.371716ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 17.5132ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 18.018266ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 17.52813ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 17.696935ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 17.912541ms)
May  5 12:16:51.906: INFO: (8) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 17.898666ms)
May  5 12:16:51.907: INFO: (8) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 17.862881ms)
May  5 12:16:51.907: INFO: (8) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 17.935161ms)
May  5 12:16:51.907: INFO: (8) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 18.07544ms)
May  5 12:16:51.909: INFO: (8) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 20.197425ms)
May  5 12:16:51.909: INFO: (8) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 20.288105ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 6.490282ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 6.443028ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 6.557288ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 7.010283ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 6.6921ms)
May  5 12:16:51.916: INFO: (9) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 6.623021ms)
May  5 12:16:51.921: INFO: (9) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 10.819228ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 12.788572ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 13.343791ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 13.070795ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 13.457893ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 13.503594ms)
May  5 12:16:51.923: INFO: (9) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 13.393131ms)
May  5 12:16:51.924: INFO: (9) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 13.697256ms)
May  5 12:16:51.924: INFO: (9) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 13.631528ms)
May  5 12:16:51.924: INFO: (9) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 13.707437ms)
May  5 12:16:51.934: INFO: (10) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 9.786927ms)
May  5 12:16:51.934: INFO: (10) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 10.317155ms)
May  5 12:16:51.934: INFO: (10) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 10.512595ms)
May  5 12:16:51.934: INFO: (10) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 10.517751ms)
May  5 12:16:51.935: INFO: (10) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.655512ms)
May  5 12:16:51.935: INFO: (10) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.352068ms)
May  5 12:16:51.935: INFO: (10) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 11.234382ms)
May  5 12:16:51.935: INFO: (10) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 11.160124ms)
May  5 12:16:51.936: INFO: (10) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 11.382724ms)
May  5 12:16:51.937: INFO: (10) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 13.288709ms)
May  5 12:16:51.937: INFO: (10) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 13.632047ms)
May  5 12:16:51.938: INFO: (10) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 13.735528ms)
May  5 12:16:51.938: INFO: (10) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 13.773377ms)
May  5 12:16:51.938: INFO: (10) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 13.573971ms)
May  5 12:16:51.938: INFO: (10) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 13.68672ms)
May  5 12:16:51.939: INFO: (10) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 14.536595ms)
May  5 12:16:51.945: INFO: (11) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 5.766622ms)
May  5 12:16:51.947: INFO: (11) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 7.747099ms)
May  5 12:16:51.947: INFO: (11) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 7.732883ms)
May  5 12:16:51.948: INFO: (11) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 8.17198ms)
May  5 12:16:51.948: INFO: (11) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 7.925435ms)
May  5 12:16:51.948: INFO: (11) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 8.010558ms)
May  5 12:16:51.948: INFO: (11) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 9.441597ms)
May  5 12:16:51.948: INFO: (11) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 8.595532ms)
May  5 12:16:51.950: INFO: (11) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 10.194582ms)
May  5 12:16:51.950: INFO: (11) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 10.686972ms)
May  5 12:16:51.950: INFO: (11) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 10.80549ms)
May  5 12:16:51.951: INFO: (11) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 11.236264ms)
May  5 12:16:51.951: INFO: (11) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 11.304553ms)
May  5 12:16:51.951: INFO: (11) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 11.807512ms)
May  5 12:16:51.951: INFO: (11) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 11.897596ms)
May  5 12:16:51.951: INFO: (11) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 12.209381ms)
May  5 12:16:51.960: INFO: (12) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 7.646389ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 10.18903ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 10.258574ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.507169ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 10.391309ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.368017ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 10.517564ms)
May  5 12:16:51.962: INFO: (12) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 10.979556ms)
May  5 12:16:51.963: INFO: (12) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 10.663659ms)
May  5 12:16:51.963: INFO: (12) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 10.467166ms)
May  5 12:16:51.963: INFO: (12) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 10.526324ms)
May  5 12:16:51.965: INFO: (12) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 12.38045ms)
May  5 12:16:51.965: INFO: (12) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 12.361258ms)
May  5 12:16:51.965: INFO: (12) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 13.257546ms)
May  5 12:16:51.964: INFO: (12) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 12.705566ms)
May  5 12:16:51.965: INFO: (12) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 13.325503ms)
May  5 12:16:51.972: INFO: (13) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 7.047108ms)
May  5 12:16:51.972: INFO: (13) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 7.006283ms)
May  5 12:16:51.972: INFO: (13) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 7.197859ms)
May  5 12:16:51.972: INFO: (13) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 7.036757ms)
May  5 12:16:51.973: INFO: (13) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 7.156102ms)
May  5 12:16:51.973: INFO: (13) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 7.41679ms)
May  5 12:16:51.976: INFO: (13) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.48251ms)
May  5 12:16:51.977: INFO: (13) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 11.072126ms)
May  5 12:16:51.977: INFO: (13) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 11.295389ms)
May  5 12:16:51.977: INFO: (13) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 11.31719ms)
May  5 12:16:51.977: INFO: (13) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 11.884788ms)
May  5 12:16:51.978: INFO: (13) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 12.583499ms)
May  5 12:16:51.978: INFO: (13) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 12.347724ms)
May  5 12:16:51.979: INFO: (13) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 12.975068ms)
May  5 12:16:51.979: INFO: (13) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 13.176319ms)
May  5 12:16:51.979: INFO: (13) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 13.057746ms)
May  5 12:16:51.985: INFO: (14) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 6.015789ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 9.630087ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 9.39191ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 10.132251ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 9.892942ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 9.123792ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 10.051717ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 9.720918ms)
May  5 12:16:51.989: INFO: (14) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.026357ms)
May  5 12:16:51.990: INFO: (14) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.237193ms)
May  5 12:16:51.990: INFO: (14) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 9.748255ms)
May  5 12:16:51.992: INFO: (14) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 12.311804ms)
May  5 12:16:51.992: INFO: (14) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 11.567575ms)
May  5 12:16:51.992: INFO: (14) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 12.741934ms)
May  5 12:16:51.992: INFO: (14) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 12.080456ms)
May  5 12:16:51.992: INFO: (14) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 12.160566ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 16.620916ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 17.805913ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 17.182314ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 17.65994ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 17.960786ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 17.628379ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 17.596065ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 17.19125ms)
May  5 12:16:52.010: INFO: (15) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 17.020795ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 17.082321ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 17.965702ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 18.300153ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 18.262938ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 17.953045ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 18.433108ms)
May  5 12:16:52.011: INFO: (15) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 18.395461ms)
May  5 12:16:52.022: INFO: (16) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 7.104202ms)
May  5 12:16:52.022: INFO: (16) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 7.25691ms)
May  5 12:16:52.022: INFO: (16) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 7.216404ms)
May  5 12:16:52.022: INFO: (16) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 7.371561ms)
May  5 12:16:52.022: INFO: (16) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 7.667758ms)
May  5 12:16:52.027: INFO: (16) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 11.40406ms)
May  5 12:16:52.027: INFO: (16) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 11.718219ms)
May  5 12:16:52.027: INFO: (16) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 10.5627ms)
May  5 12:16:52.029: INFO: (16) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 11.647841ms)
May  5 12:16:52.030: INFO: (16) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 14.642807ms)
May  5 12:16:52.030: INFO: (16) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 15.14187ms)
May  5 12:16:52.031: INFO: (16) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 13.873336ms)
May  5 12:16:52.032: INFO: (16) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 16.156714ms)
May  5 12:16:52.032: INFO: (16) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 16.573663ms)
May  5 12:16:52.032: INFO: (16) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 15.106707ms)
May  5 12:16:52.032: INFO: (16) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 16.709037ms)
May  5 12:16:52.049: INFO: (17) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 12.419264ms)
May  5 12:16:52.049: INFO: (17) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 13.708521ms)
May  5 12:16:52.050: INFO: (17) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 11.185195ms)
May  5 12:16:52.051: INFO: (17) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 12.485454ms)
May  5 12:16:52.051: INFO: (17) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 15.565995ms)
May  5 12:16:52.051: INFO: (17) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 11.633835ms)
May  5 12:16:52.057: INFO: (17) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 20.841842ms)
May  5 12:16:52.057: INFO: (17) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 21.161268ms)
May  5 12:16:52.057: INFO: (17) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 18.472945ms)
May  5 12:16:52.057: INFO: (17) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 18.577752ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 18.671068ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 23.186896ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 22.590481ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 19.438192ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 19.326536ms)
May  5 12:16:52.058: INFO: (17) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 20.506293ms)
May  5 12:16:52.073: INFO: (18) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 13.020606ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 17.127428ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 16.343302ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 16.765919ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 16.533823ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 16.203691ms)
May  5 12:16:52.076: INFO: (18) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 17.897259ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 16.182779ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 16.137196ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 16.698665ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 16.846223ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 16.801252ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 16.621225ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 16.522965ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 16.465258ms)
May  5 12:16:52.077: INFO: (18) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 17.094607ms)
May  5 12:16:52.086: INFO: (19) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 5.328137ms)
May  5 12:16:52.086: INFO: (19) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:160/proxy/: foo (200; 5.128856ms)
May  5 12:16:52.086: INFO: (19) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 5.109141ms)
May  5 12:16:52.087: INFO: (19) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:443/proxy/tlsrewritem... (200; 5.976264ms)
May  5 12:16:52.087: INFO: (19) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v/proxy/rewriteme">test</a> (200; 5.923432ms)
May  5 12:16:52.094: INFO: (19) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">test<... (200; 13.136746ms)
May  5 12:16:52.095: INFO: (19) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:460/proxy/: tls baz (200; 7.896285ms)
May  5 12:16:52.095: INFO: (19) /api/v1/namespaces/proxy-8025/pods/proxy-service-l6qz9-wkb5v:162/proxy/: bar (200; 8.11449ms)
May  5 12:16:52.095: INFO: (19) /api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/: <a href="/api/v1/namespaces/proxy-8025/pods/http:proxy-service-l6qz9-wkb5v:1080/proxy/rewriteme">... (200; 8.547341ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname1/proxy/: foo (200; 18.034435ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname2/proxy/: tls qux (200; 18.410361ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/https:proxy-service-l6qz9:tlsportname1/proxy/: tls baz (200; 18.017157ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/proxy-service-l6qz9:portname2/proxy/: bar (200; 18.06578ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname2/proxy/: bar (200; 17.977455ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/services/http:proxy-service-l6qz9:portname1/proxy/: foo (200; 17.888722ms)
May  5 12:16:52.105: INFO: (19) /api/v1/namespaces/proxy-8025/pods/https:proxy-service-l6qz9-wkb5v:462/proxy/: tls qux (200; 18.304533ms)
STEP: deleting ReplicationController proxy-service-l6qz9 in namespace proxy-8025, will wait for the garbage collector to delete the pods
May  5 12:16:52.164: INFO: Deleting ReplicationController proxy-service-l6qz9 took: 5.523736ms
May  5 12:16:52.264: INFO: Terminating ReplicationController proxy-service-l6qz9 pods took: 100.165045ms
[AfterEach] version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:17:01.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8025" for this suite.

• [SLOW TEST:13.645 seconds]
[sig-network] Proxy
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":280,"completed":255,"skipped":3923,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:17:01.178: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
May  5 12:17:01.347: INFO: Waiting up to 5m0s for pod "pod-d724d458-744a-4e59-8283-e19356f279a5" in namespace "emptydir-8936" to be "success or failure"
May  5 12:17:01.352: INFO: Pod "pod-d724d458-744a-4e59-8283-e19356f279a5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.852153ms
May  5 12:17:03.360: INFO: Pod "pod-d724d458-744a-4e59-8283-e19356f279a5": Phase="Running", Reason="", readiness=true. Elapsed: 2.013106583s
May  5 12:17:05.364: INFO: Pod "pod-d724d458-744a-4e59-8283-e19356f279a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016745697s
STEP: Saw pod success
May  5 12:17:05.364: INFO: Pod "pod-d724d458-744a-4e59-8283-e19356f279a5" satisfied condition "success or failure"
May  5 12:17:05.367: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-d724d458-744a-4e59-8283-e19356f279a5 container test-container: <nil>
STEP: delete the pod
May  5 12:17:05.400: INFO: Waiting for pod pod-d724d458-744a-4e59-8283-e19356f279a5 to disappear
May  5 12:17:05.403: INFO: Pod pod-d724d458-744a-4e59-8283-e19356f279a5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:17:05.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8936" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":256,"skipped":3954,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:17:05.413: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5250
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:17:05.601: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:17:07.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5250" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":280,"completed":257,"skipped":3989,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:17:07.385: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-2305
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
May  5 12:17:07.581: INFO: Found 0 stateful pods, waiting for 3
May  5 12:17:17.586: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  5 12:17:17.587: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  5 12:17:17.587: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
May  5 12:17:17.613: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
May  5 12:17:27.645: INFO: Updating stateful set ss2
May  5 12:17:27.651: INFO: Waiting for Pod statefulset-2305/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
May  5 12:17:37.691: INFO: Found 1 stateful pods, waiting for 3
May  5 12:17:47.697: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
May  5 12:17:47.697: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
May  5 12:17:47.697: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
May  5 12:17:47.722: INFO: Updating stateful set ss2
May  5 12:17:47.773: INFO: Waiting for Pod statefulset-2305/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
May  5 12:17:57.798: INFO: Updating stateful set ss2
May  5 12:17:57.805: INFO: Waiting for StatefulSet statefulset-2305/ss2 to complete update
May  5 12:17:57.806: INFO: Waiting for Pod statefulset-2305/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
May  5 12:18:07.813: INFO: Deleting all statefulset in ns statefulset-2305
May  5 12:18:07.816: INFO: Scaling statefulset ss2 to 0
May  5 12:18:27.832: INFO: Waiting for statefulset status.replicas updated to 0
May  5 12:18:27.837: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:18:27.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2305" for this suite.

• [SLOW TEST:80.470 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":280,"completed":258,"skipped":4057,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:18:27.855: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
May  5 12:18:58.039: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:18:58.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0505 12:18:58.039083      21 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5925" for this suite.

• [SLOW TEST:30.190 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":280,"completed":259,"skipped":4065,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:18:58.046: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:18:58.184: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1895
I0505 12:18:58.204386      21 runners.go:189] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1895, replica count: 1
I0505 12:18:59.254912      21 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0505 12:19:00.255315      21 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
May  5 12:19:00.364: INFO: Created: latency-svc-q2chc
May  5 12:19:00.369: INFO: Got endpoints: latency-svc-q2chc [13.665799ms]
May  5 12:19:00.387: INFO: Created: latency-svc-6ghwd
May  5 12:19:00.388: INFO: Created: latency-svc-qwnhm
May  5 12:19:00.395: INFO: Created: latency-svc-2nrw4
May  5 12:19:00.395: INFO: Created: latency-svc-qjr9w
May  5 12:19:00.402: INFO: Got endpoints: latency-svc-qwnhm [29.594537ms]
May  5 12:19:00.403: INFO: Created: latency-svc-hm9q4
May  5 12:19:00.410: INFO: Got endpoints: latency-svc-2nrw4 [37.045154ms]
May  5 12:19:00.411: INFO: Got endpoints: latency-svc-6ghwd [37.878115ms]
May  5 12:19:00.411: INFO: Got endpoints: latency-svc-qjr9w [39.892267ms]
May  5 12:19:00.414: INFO: Got endpoints: latency-svc-hm9q4 [42.012997ms]
May  5 12:19:00.415: INFO: Created: latency-svc-fbwk7
May  5 12:19:00.422: INFO: Created: latency-svc-n8bdx
May  5 12:19:00.430: INFO: Created: latency-svc-2wwhc
May  5 12:19:00.430: INFO: Got endpoints: latency-svc-fbwk7 [56.077018ms]
May  5 12:19:00.432: INFO: Got endpoints: latency-svc-n8bdx [57.938995ms]
May  5 12:19:00.441: INFO: Created: latency-svc-z6n7p
May  5 12:19:00.442: INFO: Got endpoints: latency-svc-2wwhc [67.641203ms]
May  5 12:19:00.446: INFO: Got endpoints: latency-svc-z6n7p [72.609671ms]
May  5 12:19:00.447: INFO: Created: latency-svc-n2547
May  5 12:19:00.455: INFO: Created: latency-svc-mptph
May  5 12:19:00.468: INFO: Created: latency-svc-442wg
May  5 12:19:00.469: INFO: Got endpoints: latency-svc-n2547 [94.701037ms]
May  5 12:19:00.469: INFO: Got endpoints: latency-svc-mptph [95.878081ms]
May  5 12:19:00.476: INFO: Created: latency-svc-dxtqd
May  5 12:19:00.501: INFO: Got endpoints: latency-svc-442wg [126.457998ms]
May  5 12:19:00.503: INFO: Got endpoints: latency-svc-dxtqd [129.647502ms]
May  5 12:19:00.510: INFO: Created: latency-svc-2xtl8
May  5 12:19:00.525: INFO: Created: latency-svc-j79sb
May  5 12:19:00.531: INFO: Got endpoints: latency-svc-j79sb [157.414822ms]
May  5 12:19:00.543: INFO: Created: latency-svc-ncgcr
May  5 12:19:00.549: INFO: Got endpoints: latency-svc-2xtl8 [174.797385ms]
May  5 12:19:00.563: INFO: Created: latency-svc-wnngf
May  5 12:19:00.563: INFO: Got endpoints: latency-svc-ncgcr [160.154555ms]
May  5 12:19:00.565: INFO: Got endpoints: latency-svc-wnngf [154.936339ms]
May  5 12:19:00.574: INFO: Created: latency-svc-svcfc
May  5 12:19:00.577: INFO: Created: latency-svc-mhlp4
May  5 12:19:00.582: INFO: Created: latency-svc-6cf4k
May  5 12:19:00.587: INFO: Created: latency-svc-hvkb8
May  5 12:19:00.600: INFO: Got endpoints: latency-svc-mhlp4 [188.217199ms]
May  5 12:19:00.600: INFO: Got endpoints: latency-svc-svcfc [50.593723ms]
May  5 12:19:00.600: INFO: Got endpoints: latency-svc-6cf4k [186.552645ms]
May  5 12:19:00.603: INFO: Got endpoints: latency-svc-hvkb8 [191.382236ms]
May  5 12:19:00.605: INFO: Created: latency-svc-29vhj
May  5 12:19:00.627: INFO: Created: latency-svc-b4pvh
May  5 12:19:00.627: INFO: Created: latency-svc-hd2b2
May  5 12:19:00.628: INFO: Got endpoints: latency-svc-29vhj [197.869649ms]
May  5 12:19:00.637: INFO: Created: latency-svc-9dbwz
May  5 12:19:00.643: INFO: Created: latency-svc-mvblc
May  5 12:19:00.643: INFO: Got endpoints: latency-svc-b4pvh [201.726544ms]
May  5 12:19:00.645: INFO: Got endpoints: latency-svc-hd2b2 [213.349527ms]
May  5 12:19:00.647: INFO: Got endpoints: latency-svc-mvblc [201.327128ms]
May  5 12:19:00.652: INFO: Created: latency-svc-wtc8l
May  5 12:19:00.654: INFO: Got endpoints: latency-svc-9dbwz [184.611674ms]
May  5 12:19:00.656: INFO: Created: latency-svc-27t7l
May  5 12:19:00.665: INFO: Created: latency-svc-26bvj
May  5 12:19:00.668: INFO: Got endpoints: latency-svc-wtc8l [167.508511ms]
May  5 12:19:00.671: INFO: Created: latency-svc-b55rq
May  5 12:19:00.677: INFO: Got endpoints: latency-svc-27t7l [207.599019ms]
May  5 12:19:00.684: INFO: Created: latency-svc-cprhm
May  5 12:19:00.684: INFO: Got endpoints: latency-svc-26bvj [180.398734ms]
May  5 12:19:00.694: INFO: Got endpoints: latency-svc-b55rq [161.350732ms]
May  5 12:19:00.694: INFO: Got endpoints: latency-svc-cprhm [128.807471ms]
May  5 12:19:00.701: INFO: Created: latency-svc-zvgxs
May  5 12:19:00.703: INFO: Created: latency-svc-jjbwm
May  5 12:19:00.716: INFO: Created: latency-svc-2trwx
May  5 12:19:00.717: INFO: Got endpoints: latency-svc-jjbwm [117.619447ms]
May  5 12:19:00.718: INFO: Got endpoints: latency-svc-zvgxs [154.386416ms]
May  5 12:19:00.730: INFO: Got endpoints: latency-svc-2trwx [126.44168ms]
May  5 12:19:00.739: INFO: Created: latency-svc-cnmsm
May  5 12:19:00.740: INFO: Created: latency-svc-nk6sm
May  5 12:19:00.757: INFO: Created: latency-svc-xzj7g
May  5 12:19:00.771: INFO: Created: latency-svc-j467k
May  5 12:19:00.782: INFO: Got endpoints: latency-svc-cnmsm [181.964475ms]
May  5 12:19:00.788: INFO: Got endpoints: latency-svc-xzj7g [159.902039ms]
May  5 12:19:00.789: INFO: Got endpoints: latency-svc-nk6sm [188.854276ms]
May  5 12:19:00.793: INFO: Created: latency-svc-7x75g
May  5 12:19:00.801: INFO: Created: latency-svc-2xpp9
May  5 12:19:00.807: INFO: Created: latency-svc-sqk6z
May  5 12:19:00.810: INFO: Created: latency-svc-kpmrf
May  5 12:19:00.815: INFO: Created: latency-svc-c662h
May  5 12:19:00.824: INFO: Created: latency-svc-6b8cz
May  5 12:19:00.826: INFO: Got endpoints: latency-svc-j467k [181.306232ms]
May  5 12:19:00.831: INFO: Created: latency-svc-j7p7l
May  5 12:19:00.834: INFO: Created: latency-svc-g5xhl
May  5 12:19:00.845: INFO: Created: latency-svc-mdc79
May  5 12:19:00.846: INFO: Created: latency-svc-2cmrl
May  5 12:19:00.853: INFO: Created: latency-svc-xv87b
May  5 12:19:00.855: INFO: Created: latency-svc-9kcnj
May  5 12:19:00.872: INFO: Created: latency-svc-2htm4
May  5 12:19:00.877: INFO: Got endpoints: latency-svc-7x75g [230.141059ms]
May  5 12:19:00.892: INFO: Created: latency-svc-jvmvc
May  5 12:19:00.939: INFO: Created: latency-svc-g2sz8
May  5 12:19:00.939: INFO: Created: latency-svc-d9s7l
May  5 12:19:00.940: INFO: Got endpoints: latency-svc-2xpp9 [294.387656ms]
May  5 12:19:00.951: INFO: Created: latency-svc-xfkpj
May  5 12:19:00.969: INFO: Got endpoints: latency-svc-sqk6z [315.411693ms]
May  5 12:19:00.978: INFO: Created: latency-svc-4brsl
May  5 12:19:01.018: INFO: Got endpoints: latency-svc-kpmrf [349.789088ms]
May  5 12:19:01.030: INFO: Created: latency-svc-t9d8c
May  5 12:19:01.070: INFO: Got endpoints: latency-svc-c662h [392.660349ms]
May  5 12:19:01.079: INFO: Created: latency-svc-pk92q
May  5 12:19:01.120: INFO: Got endpoints: latency-svc-6b8cz [435.813811ms]
May  5 12:19:01.156: INFO: Created: latency-svc-sh2kc
May  5 12:19:01.190: INFO: Got endpoints: latency-svc-j7p7l [496.165305ms]
May  5 12:19:01.262: INFO: Got endpoints: latency-svc-g5xhl [567.415686ms]
May  5 12:19:01.315: INFO: Got endpoints: latency-svc-2cmrl [597.902929ms]
May  5 12:19:01.345: INFO: Created: latency-svc-9j47s
May  5 12:19:01.346: INFO: Created: latency-svc-7gzc5
May  5 12:19:01.401: INFO: Got endpoints: latency-svc-mdc79 [670.646826ms]
May  5 12:19:01.405: INFO: Created: latency-svc-ljgpk
May  5 12:19:01.413: INFO: Got endpoints: latency-svc-xv87b [695.038331ms]
May  5 12:19:01.421: INFO: Created: latency-svc-klf9h
May  5 12:19:01.431: INFO: Got endpoints: latency-svc-9kcnj [649.481162ms]
May  5 12:19:01.442: INFO: Created: latency-svc-65pc9
May  5 12:19:01.447: INFO: Created: latency-svc-tvmn8
May  5 12:19:01.471: INFO: Got endpoints: latency-svc-2htm4 [682.803079ms]
May  5 12:19:01.481: INFO: Created: latency-svc-4fjvx
May  5 12:19:01.519: INFO: Got endpoints: latency-svc-jvmvc [729.718899ms]
May  5 12:19:01.536: INFO: Created: latency-svc-fxzb2
May  5 12:19:01.569: INFO: Got endpoints: latency-svc-g2sz8 [742.665596ms]
May  5 12:19:01.579: INFO: Created: latency-svc-xg26h
May  5 12:19:01.617: INFO: Got endpoints: latency-svc-d9s7l [738.901944ms]
May  5 12:19:01.627: INFO: Created: latency-svc-bbhjl
May  5 12:19:01.671: INFO: Got endpoints: latency-svc-xfkpj [730.415448ms]
May  5 12:19:01.682: INFO: Created: latency-svc-zkddn
May  5 12:19:01.720: INFO: Got endpoints: latency-svc-4brsl [750.204382ms]
May  5 12:19:01.729: INFO: Created: latency-svc-wm6n4
May  5 12:19:01.768: INFO: Got endpoints: latency-svc-t9d8c [748.683864ms]
May  5 12:19:01.777: INFO: Created: latency-svc-lzs74
May  5 12:19:01.820: INFO: Got endpoints: latency-svc-pk92q [749.699652ms]
May  5 12:19:01.829: INFO: Created: latency-svc-rdbwz
May  5 12:19:01.868: INFO: Got endpoints: latency-svc-sh2kc [746.154989ms]
May  5 12:19:01.878: INFO: Created: latency-svc-2qxv2
May  5 12:19:01.918: INFO: Got endpoints: latency-svc-9j47s [728.416309ms]
May  5 12:19:01.929: INFO: Created: latency-svc-5fxbr
May  5 12:19:01.968: INFO: Got endpoints: latency-svc-7gzc5 [705.419053ms]
May  5 12:19:01.977: INFO: Created: latency-svc-wqntw
May  5 12:19:02.019: INFO: Got endpoints: latency-svc-ljgpk [703.01655ms]
May  5 12:19:02.028: INFO: Created: latency-svc-vkg64
May  5 12:19:02.074: INFO: Got endpoints: latency-svc-klf9h [672.854012ms]
May  5 12:19:02.083: INFO: Created: latency-svc-sbp4d
May  5 12:19:02.119: INFO: Got endpoints: latency-svc-65pc9 [703.668871ms]
May  5 12:19:02.129: INFO: Created: latency-svc-bk5sw
May  5 12:19:02.169: INFO: Got endpoints: latency-svc-tvmn8 [737.069874ms]
May  5 12:19:02.176: INFO: Created: latency-svc-6w6qh
May  5 12:19:02.219: INFO: Got endpoints: latency-svc-4fjvx [748.515005ms]
May  5 12:19:02.229: INFO: Created: latency-svc-5knv5
May  5 12:19:02.272: INFO: Got endpoints: latency-svc-fxzb2 [752.613629ms]
May  5 12:19:02.280: INFO: Created: latency-svc-2jlqn
May  5 12:19:02.319: INFO: Got endpoints: latency-svc-xg26h [749.089126ms]
May  5 12:19:02.329: INFO: Created: latency-svc-7m5s4
May  5 12:19:02.369: INFO: Got endpoints: latency-svc-bbhjl [751.680411ms]
May  5 12:19:02.379: INFO: Created: latency-svc-jf88m
May  5 12:19:02.419: INFO: Got endpoints: latency-svc-zkddn [747.709715ms]
May  5 12:19:02.431: INFO: Created: latency-svc-ksh8f
May  5 12:19:02.471: INFO: Got endpoints: latency-svc-wm6n4 [750.914162ms]
May  5 12:19:02.500: INFO: Created: latency-svc-h6d4z
May  5 12:19:02.518: INFO: Got endpoints: latency-svc-lzs74 [750.922586ms]
May  5 12:19:02.531: INFO: Created: latency-svc-5b7vn
May  5 12:19:02.568: INFO: Got endpoints: latency-svc-rdbwz [747.852932ms]
May  5 12:19:02.576: INFO: Created: latency-svc-wbjzf
May  5 12:19:02.619: INFO: Got endpoints: latency-svc-2qxv2 [749.902554ms]
May  5 12:19:02.628: INFO: Created: latency-svc-5b7l4
May  5 12:19:02.670: INFO: Got endpoints: latency-svc-5fxbr [751.545323ms]
May  5 12:19:02.681: INFO: Created: latency-svc-p5hq2
May  5 12:19:02.722: INFO: Got endpoints: latency-svc-wqntw [753.839822ms]
May  5 12:19:02.734: INFO: Created: latency-svc-xzxc7
May  5 12:19:02.768: INFO: Got endpoints: latency-svc-vkg64 [748.807104ms]
May  5 12:19:02.779: INFO: Created: latency-svc-f6nhn
May  5 12:19:02.822: INFO: Got endpoints: latency-svc-sbp4d [747.202538ms]
May  5 12:19:02.834: INFO: Created: latency-svc-w8w84
May  5 12:19:02.869: INFO: Got endpoints: latency-svc-bk5sw [750.452376ms]
May  5 12:19:02.879: INFO: Created: latency-svc-z6qfw
May  5 12:19:02.918: INFO: Got endpoints: latency-svc-6w6qh [749.103459ms]
May  5 12:19:02.929: INFO: Created: latency-svc-5tm67
May  5 12:19:02.971: INFO: Got endpoints: latency-svc-5knv5 [751.809271ms]
May  5 12:19:02.979: INFO: Created: latency-svc-p4mxp
May  5 12:19:03.019: INFO: Got endpoints: latency-svc-2jlqn [746.923792ms]
May  5 12:19:03.028: INFO: Created: latency-svc-27jqm
May  5 12:19:03.069: INFO: Got endpoints: latency-svc-7m5s4 [750.163516ms]
May  5 12:19:03.089: INFO: Created: latency-svc-pbffr
May  5 12:19:03.119: INFO: Got endpoints: latency-svc-jf88m [750.435835ms]
May  5 12:19:03.138: INFO: Created: latency-svc-6z4dh
May  5 12:19:03.177: INFO: Got endpoints: latency-svc-ksh8f [758.03224ms]
May  5 12:19:03.191: INFO: Created: latency-svc-572p5
May  5 12:19:03.229: INFO: Got endpoints: latency-svc-h6d4z [757.557015ms]
May  5 12:19:03.263: INFO: Created: latency-svc-hxbkl
May  5 12:19:03.274: INFO: Got endpoints: latency-svc-5b7vn [754.545893ms]
May  5 12:19:03.290: INFO: Created: latency-svc-fkxfd
May  5 12:19:03.320: INFO: Got endpoints: latency-svc-wbjzf [751.975849ms]
May  5 12:19:03.340: INFO: Created: latency-svc-8rgzt
May  5 12:19:03.379: INFO: Got endpoints: latency-svc-5b7l4 [760.10235ms]
May  5 12:19:03.397: INFO: Created: latency-svc-z78vj
May  5 12:19:03.422: INFO: Got endpoints: latency-svc-p5hq2 [751.91925ms]
May  5 12:19:03.433: INFO: Created: latency-svc-crtrq
May  5 12:19:03.479: INFO: Got endpoints: latency-svc-xzxc7 [756.584754ms]
May  5 12:19:03.491: INFO: Created: latency-svc-vcm2p
May  5 12:19:03.518: INFO: Got endpoints: latency-svc-f6nhn [749.848514ms]
May  5 12:19:03.530: INFO: Created: latency-svc-lbdk7
May  5 12:19:03.572: INFO: Got endpoints: latency-svc-w8w84 [750.004773ms]
May  5 12:19:03.582: INFO: Created: latency-svc-xh5lv
May  5 12:19:03.618: INFO: Got endpoints: latency-svc-z6qfw [748.873739ms]
May  5 12:19:03.628: INFO: Created: latency-svc-8qxgh
May  5 12:19:03.669: INFO: Got endpoints: latency-svc-5tm67 [750.543815ms]
May  5 12:19:03.738: INFO: Created: latency-svc-sqm9g
May  5 12:19:03.739: INFO: Got endpoints: latency-svc-p4mxp [767.16535ms]
May  5 12:19:03.757: INFO: Created: latency-svc-sflr9
May  5 12:19:03.772: INFO: Got endpoints: latency-svc-27jqm [752.317947ms]
May  5 12:19:03.782: INFO: Created: latency-svc-wz25x
May  5 12:19:03.819: INFO: Got endpoints: latency-svc-pbffr [749.501802ms]
May  5 12:19:03.831: INFO: Created: latency-svc-gp6qp
May  5 12:19:03.869: INFO: Got endpoints: latency-svc-6z4dh [748.158492ms]
May  5 12:19:03.886: INFO: Created: latency-svc-mb56h
May  5 12:19:03.918: INFO: Got endpoints: latency-svc-572p5 [741.235725ms]
May  5 12:19:03.930: INFO: Created: latency-svc-5n6pg
May  5 12:19:03.979: INFO: Got endpoints: latency-svc-hxbkl [749.863186ms]
May  5 12:19:04.012: INFO: Created: latency-svc-nb8tz
May  5 12:19:04.031: INFO: Got endpoints: latency-svc-fkxfd [756.75801ms]
May  5 12:19:04.054: INFO: Created: latency-svc-t98v7
May  5 12:19:04.074: INFO: Got endpoints: latency-svc-8rgzt [753.183223ms]
May  5 12:19:04.082: INFO: Created: latency-svc-c5mxd
May  5 12:19:04.122: INFO: Got endpoints: latency-svc-z78vj [742.825406ms]
May  5 12:19:04.139: INFO: Created: latency-svc-2bj7s
May  5 12:19:04.171: INFO: Got endpoints: latency-svc-crtrq [748.992765ms]
May  5 12:19:04.184: INFO: Created: latency-svc-7tnxt
May  5 12:19:04.224: INFO: Got endpoints: latency-svc-vcm2p [742.300945ms]
May  5 12:19:04.238: INFO: Created: latency-svc-gjmgh
May  5 12:19:04.272: INFO: Got endpoints: latency-svc-lbdk7 [753.132563ms]
May  5 12:19:04.286: INFO: Created: latency-svc-mxn5l
May  5 12:19:04.325: INFO: Got endpoints: latency-svc-xh5lv [752.922559ms]
May  5 12:19:04.333: INFO: Created: latency-svc-bzmwk
May  5 12:19:04.372: INFO: Got endpoints: latency-svc-8qxgh [752.855633ms]
May  5 12:19:04.391: INFO: Created: latency-svc-5htg5
May  5 12:19:04.418: INFO: Got endpoints: latency-svc-sqm9g [749.17483ms]
May  5 12:19:04.427: INFO: Created: latency-svc-4qgdz
May  5 12:19:04.468: INFO: Got endpoints: latency-svc-sflr9 [729.389435ms]
May  5 12:19:04.478: INFO: Created: latency-svc-n26mh
May  5 12:19:04.518: INFO: Got endpoints: latency-svc-wz25x [745.997141ms]
May  5 12:19:04.530: INFO: Created: latency-svc-zmc8x
May  5 12:19:04.569: INFO: Got endpoints: latency-svc-gp6qp [749.846075ms]
May  5 12:19:04.579: INFO: Created: latency-svc-fdckq
May  5 12:19:04.619: INFO: Got endpoints: latency-svc-mb56h [749.433012ms]
May  5 12:19:04.639: INFO: Created: latency-svc-hcgs6
May  5 12:19:04.669: INFO: Got endpoints: latency-svc-5n6pg [750.366575ms]
May  5 12:19:04.680: INFO: Created: latency-svc-sb4vj
May  5 12:19:04.720: INFO: Got endpoints: latency-svc-nb8tz [740.150438ms]
May  5 12:19:04.729: INFO: Created: latency-svc-ff5wd
May  5 12:19:04.773: INFO: Got endpoints: latency-svc-t98v7 [741.475141ms]
May  5 12:19:04.784: INFO: Created: latency-svc-nbplk
May  5 12:19:04.817: INFO: Got endpoints: latency-svc-c5mxd [743.377944ms]
May  5 12:19:04.827: INFO: Created: latency-svc-h7v5k
May  5 12:19:04.870: INFO: Got endpoints: latency-svc-2bj7s [747.330844ms]
May  5 12:19:04.879: INFO: Created: latency-svc-pdh2v
May  5 12:19:04.921: INFO: Got endpoints: latency-svc-7tnxt [749.749642ms]
May  5 12:19:04.929: INFO: Created: latency-svc-dqfr8
May  5 12:19:04.969: INFO: Got endpoints: latency-svc-gjmgh [745.281003ms]
May  5 12:19:04.979: INFO: Created: latency-svc-rtglv
May  5 12:19:05.019: INFO: Got endpoints: latency-svc-mxn5l [746.907191ms]
May  5 12:19:05.029: INFO: Created: latency-svc-wlp9h
May  5 12:19:05.069: INFO: Got endpoints: latency-svc-bzmwk [744.234151ms]
May  5 12:19:05.079: INFO: Created: latency-svc-d7q8p
May  5 12:19:05.124: INFO: Got endpoints: latency-svc-5htg5 [751.776448ms]
May  5 12:19:05.134: INFO: Created: latency-svc-d75g6
May  5 12:19:05.168: INFO: Got endpoints: latency-svc-4qgdz [749.449584ms]
May  5 12:19:05.178: INFO: Created: latency-svc-xdrtr
May  5 12:19:05.218: INFO: Got endpoints: latency-svc-n26mh [749.952077ms]
May  5 12:19:05.229: INFO: Created: latency-svc-kljwc
May  5 12:19:05.268: INFO: Got endpoints: latency-svc-zmc8x [749.010324ms]
May  5 12:19:05.277: INFO: Created: latency-svc-6kfrx
May  5 12:19:05.318: INFO: Got endpoints: latency-svc-fdckq [748.200102ms]
May  5 12:19:05.326: INFO: Created: latency-svc-d7wkw
May  5 12:19:05.376: INFO: Got endpoints: latency-svc-hcgs6 [756.985198ms]
May  5 12:19:05.390: INFO: Created: latency-svc-nkxmx
May  5 12:19:05.421: INFO: Got endpoints: latency-svc-sb4vj [752.076736ms]
May  5 12:19:05.431: INFO: Created: latency-svc-758dn
May  5 12:19:05.468: INFO: Got endpoints: latency-svc-ff5wd [747.664973ms]
May  5 12:19:05.478: INFO: Created: latency-svc-snpm6
May  5 12:19:05.520: INFO: Got endpoints: latency-svc-nbplk [746.766554ms]
May  5 12:19:05.529: INFO: Created: latency-svc-4mznc
May  5 12:19:05.571: INFO: Got endpoints: latency-svc-h7v5k [753.373177ms]
May  5 12:19:05.582: INFO: Created: latency-svc-lhc6s
May  5 12:19:05.619: INFO: Got endpoints: latency-svc-pdh2v [748.744702ms]
May  5 12:19:05.627: INFO: Created: latency-svc-wfcwc
May  5 12:19:05.668: INFO: Got endpoints: latency-svc-dqfr8 [746.799959ms]
May  5 12:19:05.677: INFO: Created: latency-svc-5k4rw
May  5 12:19:05.719: INFO: Got endpoints: latency-svc-rtglv [749.508184ms]
May  5 12:19:05.737: INFO: Created: latency-svc-dmfp7
May  5 12:19:05.769: INFO: Got endpoints: latency-svc-wlp9h [749.805273ms]
May  5 12:19:05.778: INFO: Created: latency-svc-kp29d
May  5 12:19:05.820: INFO: Got endpoints: latency-svc-d7q8p [751.018485ms]
May  5 12:19:05.829: INFO: Created: latency-svc-w9vh9
May  5 12:19:05.868: INFO: Got endpoints: latency-svc-d75g6 [743.786281ms]
May  5 12:19:05.879: INFO: Created: latency-svc-6bz7x
May  5 12:19:05.918: INFO: Got endpoints: latency-svc-xdrtr [748.824967ms]
May  5 12:19:05.939: INFO: Created: latency-svc-66fph
May  5 12:19:05.972: INFO: Got endpoints: latency-svc-kljwc [752.971022ms]
May  5 12:19:05.990: INFO: Created: latency-svc-cj6dd
May  5 12:19:06.024: INFO: Got endpoints: latency-svc-6kfrx [756.009164ms]
May  5 12:19:06.037: INFO: Created: latency-svc-vqwzm
May  5 12:19:06.071: INFO: Got endpoints: latency-svc-d7wkw [752.75281ms]
May  5 12:19:06.080: INFO: Created: latency-svc-ql8ns
May  5 12:19:06.119: INFO: Got endpoints: latency-svc-nkxmx [741.877043ms]
May  5 12:19:06.127: INFO: Created: latency-svc-pdpdx
May  5 12:19:06.169: INFO: Got endpoints: latency-svc-758dn [747.869589ms]
May  5 12:19:06.179: INFO: Created: latency-svc-xzpvt
May  5 12:19:06.218: INFO: Got endpoints: latency-svc-snpm6 [749.081092ms]
May  5 12:19:06.227: INFO: Created: latency-svc-kwxsd
May  5 12:19:06.268: INFO: Got endpoints: latency-svc-4mznc [748.464337ms]
May  5 12:19:06.277: INFO: Created: latency-svc-f2f59
May  5 12:19:06.318: INFO: Got endpoints: latency-svc-lhc6s [746.921005ms]
May  5 12:19:06.327: INFO: Created: latency-svc-c5rt2
May  5 12:19:06.372: INFO: Got endpoints: latency-svc-wfcwc [752.030343ms]
May  5 12:19:06.380: INFO: Created: latency-svc-fjkbc
May  5 12:19:06.424: INFO: Got endpoints: latency-svc-5k4rw [755.625316ms]
May  5 12:19:06.440: INFO: Created: latency-svc-f4bnw
May  5 12:19:06.474: INFO: Got endpoints: latency-svc-dmfp7 [754.888743ms]
May  5 12:19:06.520: INFO: Created: latency-svc-78rk9
May  5 12:19:06.523: INFO: Got endpoints: latency-svc-kp29d [753.771247ms]
May  5 12:19:06.538: INFO: Created: latency-svc-4tsd5
May  5 12:19:06.572: INFO: Got endpoints: latency-svc-w9vh9 [751.012175ms]
May  5 12:19:06.584: INFO: Created: latency-svc-z62sp
May  5 12:19:06.620: INFO: Got endpoints: latency-svc-6bz7x [752.025013ms]
May  5 12:19:06.628: INFO: Created: latency-svc-q92ss
May  5 12:19:06.669: INFO: Got endpoints: latency-svc-66fph [751.030671ms]
May  5 12:19:06.678: INFO: Created: latency-svc-shmnx
May  5 12:19:06.722: INFO: Got endpoints: latency-svc-cj6dd [750.569139ms]
May  5 12:19:06.732: INFO: Created: latency-svc-r2mzl
May  5 12:19:06.772: INFO: Got endpoints: latency-svc-vqwzm [747.706599ms]
May  5 12:19:06.780: INFO: Created: latency-svc-2jrvn
May  5 12:19:06.820: INFO: Got endpoints: latency-svc-ql8ns [748.233557ms]
May  5 12:19:06.827: INFO: Created: latency-svc-5cp2d
May  5 12:19:06.871: INFO: Got endpoints: latency-svc-pdpdx [752.070919ms]
May  5 12:19:06.881: INFO: Created: latency-svc-4zqv5
May  5 12:19:06.919: INFO: Got endpoints: latency-svc-xzpvt [748.674852ms]
May  5 12:19:06.929: INFO: Created: latency-svc-4744p
May  5 12:19:06.968: INFO: Got endpoints: latency-svc-kwxsd [749.746532ms]
May  5 12:19:06.979: INFO: Created: latency-svc-wd5g7
May  5 12:19:07.020: INFO: Got endpoints: latency-svc-f2f59 [752.077587ms]
May  5 12:19:07.034: INFO: Created: latency-svc-9tzws
May  5 12:19:07.069: INFO: Got endpoints: latency-svc-c5rt2 [750.665264ms]
May  5 12:19:07.079: INFO: Created: latency-svc-fqn6l
May  5 12:19:07.118: INFO: Got endpoints: latency-svc-fjkbc [746.162124ms]
May  5 12:19:07.127: INFO: Created: latency-svc-9pb67
May  5 12:19:07.171: INFO: Got endpoints: latency-svc-f4bnw [746.199676ms]
May  5 12:19:07.180: INFO: Created: latency-svc-d6g5w
May  5 12:19:07.219: INFO: Got endpoints: latency-svc-78rk9 [744.773867ms]
May  5 12:19:07.229: INFO: Created: latency-svc-8bxhj
May  5 12:19:07.269: INFO: Got endpoints: latency-svc-4tsd5 [745.703777ms]
May  5 12:19:07.277: INFO: Created: latency-svc-d8vfl
May  5 12:19:07.318: INFO: Got endpoints: latency-svc-z62sp [745.888706ms]
May  5 12:19:07.328: INFO: Created: latency-svc-x5sfl
May  5 12:19:07.375: INFO: Got endpoints: latency-svc-q92ss [753.840735ms]
May  5 12:19:07.401: INFO: Created: latency-svc-ppfzv
May  5 12:19:07.422: INFO: Got endpoints: latency-svc-shmnx [753.141122ms]
May  5 12:19:07.433: INFO: Created: latency-svc-zksrg
May  5 12:19:07.468: INFO: Got endpoints: latency-svc-r2mzl [745.87118ms]
May  5 12:19:07.480: INFO: Created: latency-svc-zv24m
May  5 12:19:07.519: INFO: Got endpoints: latency-svc-2jrvn [746.801957ms]
May  5 12:19:07.528: INFO: Created: latency-svc-8wsg6
May  5 12:19:07.571: INFO: Got endpoints: latency-svc-5cp2d [751.558899ms]
May  5 12:19:07.583: INFO: Created: latency-svc-s94gq
May  5 12:19:07.619: INFO: Got endpoints: latency-svc-4zqv5 [747.312854ms]
May  5 12:19:07.631: INFO: Created: latency-svc-z2blh
May  5 12:19:07.668: INFO: Got endpoints: latency-svc-4744p [749.683428ms]
May  5 12:19:07.678: INFO: Created: latency-svc-ppmnr
May  5 12:19:07.721: INFO: Got endpoints: latency-svc-wd5g7 [752.605783ms]
May  5 12:19:07.734: INFO: Created: latency-svc-mxg6k
May  5 12:19:07.768: INFO: Got endpoints: latency-svc-9tzws [745.217901ms]
May  5 12:19:07.776: INFO: Created: latency-svc-8cj9j
May  5 12:19:07.823: INFO: Got endpoints: latency-svc-fqn6l [753.974295ms]
May  5 12:19:07.836: INFO: Created: latency-svc-d4lr5
May  5 12:19:07.869: INFO: Got endpoints: latency-svc-9pb67 [751.154659ms]
May  5 12:19:07.878: INFO: Created: latency-svc-nfm8k
May  5 12:19:07.918: INFO: Got endpoints: latency-svc-d6g5w [747.430176ms]
May  5 12:19:07.927: INFO: Created: latency-svc-77vqd
May  5 12:19:07.969: INFO: Got endpoints: latency-svc-8bxhj [750.352366ms]
May  5 12:19:07.978: INFO: Created: latency-svc-lfxfj
May  5 12:19:08.026: INFO: Got endpoints: latency-svc-d8vfl [756.515423ms]
May  5 12:19:08.043: INFO: Created: latency-svc-l4m2w
May  5 12:19:08.068: INFO: Got endpoints: latency-svc-x5sfl [749.796572ms]
May  5 12:19:08.078: INFO: Created: latency-svc-zfhjk
May  5 12:19:08.118: INFO: Got endpoints: latency-svc-ppfzv [743.193118ms]
May  5 12:19:08.127: INFO: Created: latency-svc-n5ghm
May  5 12:19:08.170: INFO: Got endpoints: latency-svc-zksrg [747.797455ms]
May  5 12:19:08.187: INFO: Created: latency-svc-r2zf9
May  5 12:19:08.218: INFO: Got endpoints: latency-svc-zv24m [749.967649ms]
May  5 12:19:08.269: INFO: Got endpoints: latency-svc-8wsg6 [750.416637ms]
May  5 12:19:08.319: INFO: Got endpoints: latency-svc-s94gq [747.112485ms]
May  5 12:19:08.368: INFO: Got endpoints: latency-svc-z2blh [749.447934ms]
May  5 12:19:08.418: INFO: Got endpoints: latency-svc-ppmnr [749.661093ms]
May  5 12:19:08.470: INFO: Got endpoints: latency-svc-mxg6k [748.57262ms]
May  5 12:19:08.519: INFO: Got endpoints: latency-svc-8cj9j [751.496119ms]
May  5 12:19:08.570: INFO: Got endpoints: latency-svc-d4lr5 [747.216162ms]
May  5 12:19:08.619: INFO: Got endpoints: latency-svc-nfm8k [749.53821ms]
May  5 12:19:08.668: INFO: Got endpoints: latency-svc-77vqd [748.942127ms]
May  5 12:19:08.718: INFO: Got endpoints: latency-svc-lfxfj [748.624611ms]
May  5 12:19:08.769: INFO: Got endpoints: latency-svc-l4m2w [742.771408ms]
May  5 12:19:08.821: INFO: Got endpoints: latency-svc-zfhjk [752.432715ms]
May  5 12:19:08.871: INFO: Got endpoints: latency-svc-n5ghm [752.116925ms]
May  5 12:19:08.920: INFO: Got endpoints: latency-svc-r2zf9 [749.486836ms]
May  5 12:19:08.921: INFO: Latencies: [29.594537ms 37.045154ms 37.878115ms 39.892267ms 42.012997ms 50.593723ms 56.077018ms 57.938995ms 67.641203ms 72.609671ms 94.701037ms 95.878081ms 117.619447ms 126.44168ms 126.457998ms 128.807471ms 129.647502ms 154.386416ms 154.936339ms 157.414822ms 159.902039ms 160.154555ms 161.350732ms 167.508511ms 174.797385ms 180.398734ms 181.306232ms 181.964475ms 184.611674ms 186.552645ms 188.217199ms 188.854276ms 191.382236ms 197.869649ms 201.327128ms 201.726544ms 207.599019ms 213.349527ms 230.141059ms 294.387656ms 315.411693ms 349.789088ms 392.660349ms 435.813811ms 496.165305ms 567.415686ms 597.902929ms 649.481162ms 670.646826ms 672.854012ms 682.803079ms 695.038331ms 703.01655ms 703.668871ms 705.419053ms 728.416309ms 729.389435ms 729.718899ms 730.415448ms 737.069874ms 738.901944ms 740.150438ms 741.235725ms 741.475141ms 741.877043ms 742.300945ms 742.665596ms 742.771408ms 742.825406ms 743.193118ms 743.377944ms 743.786281ms 744.234151ms 744.773867ms 745.217901ms 745.281003ms 745.703777ms 745.87118ms 745.888706ms 745.997141ms 746.154989ms 746.162124ms 746.199676ms 746.766554ms 746.799959ms 746.801957ms 746.907191ms 746.921005ms 746.923792ms 747.112485ms 747.202538ms 747.216162ms 747.312854ms 747.330844ms 747.430176ms 747.664973ms 747.706599ms 747.709715ms 747.797455ms 747.852932ms 747.869589ms 748.158492ms 748.200102ms 748.233557ms 748.464337ms 748.515005ms 748.57262ms 748.624611ms 748.674852ms 748.683864ms 748.744702ms 748.807104ms 748.824967ms 748.873739ms 748.942127ms 748.992765ms 749.010324ms 749.081092ms 749.089126ms 749.103459ms 749.17483ms 749.433012ms 749.447934ms 749.449584ms 749.486836ms 749.501802ms 749.508184ms 749.53821ms 749.661093ms 749.683428ms 749.699652ms 749.746532ms 749.749642ms 749.796572ms 749.805273ms 749.846075ms 749.848514ms 749.863186ms 749.902554ms 749.952077ms 749.967649ms 750.004773ms 750.163516ms 750.204382ms 750.352366ms 750.366575ms 750.416637ms 750.435835ms 750.452376ms 750.543815ms 750.569139ms 750.665264ms 750.914162ms 750.922586ms 751.012175ms 751.018485ms 751.030671ms 751.154659ms 751.496119ms 751.545323ms 751.558899ms 751.680411ms 751.776448ms 751.809271ms 751.91925ms 751.975849ms 752.025013ms 752.030343ms 752.070919ms 752.076736ms 752.077587ms 752.116925ms 752.317947ms 752.432715ms 752.605783ms 752.613629ms 752.75281ms 752.855633ms 752.922559ms 752.971022ms 753.132563ms 753.141122ms 753.183223ms 753.373177ms 753.771247ms 753.839822ms 753.840735ms 753.974295ms 754.545893ms 754.888743ms 755.625316ms 756.009164ms 756.515423ms 756.584754ms 756.75801ms 756.985198ms 757.557015ms 758.03224ms 760.10235ms 767.16535ms]
May  5 12:19:08.921: INFO: 50 %ile: 747.869589ms
May  5 12:19:08.921: INFO: 90 %ile: 753.132563ms
May  5 12:19:08.921: INFO: 99 %ile: 760.10235ms
May  5 12:19:08.921: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:19:08.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1895" for this suite.

• [SLOW TEST:10.889 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":280,"completed":260,"skipped":4084,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:19:08.935: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
May  5 12:19:09.115: INFO: Waiting up to 5m0s for pod "pod-7a9435f0-16d7-4401-a340-05a7a14e9265" in namespace "emptydir-1133" to be "success or failure"
May  5 12:19:09.120: INFO: Pod "pod-7a9435f0-16d7-4401-a340-05a7a14e9265": Phase="Pending", Reason="", readiness=false. Elapsed: 5.365732ms
May  5 12:19:11.124: INFO: Pod "pod-7a9435f0-16d7-4401-a340-05a7a14e9265": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009218657s
STEP: Saw pod success
May  5 12:19:11.124: INFO: Pod "pod-7a9435f0-16d7-4401-a340-05a7a14e9265" satisfied condition "success or failure"
May  5 12:19:11.127: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-7a9435f0-16d7-4401-a340-05a7a14e9265 container test-container: <nil>
STEP: delete the pod
May  5 12:19:11.152: INFO: Waiting for pod pod-7a9435f0-16d7-4401-a340-05a7a14e9265 to disappear
May  5 12:19:11.155: INFO: Pod pod-7a9435f0-16d7-4401-a340-05a7a14e9265 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:19:11.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1133" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":261,"skipped":4096,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:19:11.167: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: executing a command with run --rm and attach with stdin
May  5 12:19:11.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 --namespace=kubectl-6303 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
May  5 12:19:13.425: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
May  5 12:19:13.425: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:19:15.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6303" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run --rm job should create a job from an image, then delete the job  [Conformance]","total":280,"completed":262,"skipped":4136,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:19:15.452: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
May  5 12:19:16.083: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
May  5 12:19:18.091: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277956, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277956, loc:(*time.Location)(0x791d1c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277956, loc:(*time.Location)(0x791d1c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63724277956, loc:(*time.Location)(0x791d1c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
May  5 12:19:21.102: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
May  5 12:19:22.102: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
May  5 12:19:23.102: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
May  5 12:19:24.102: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:19:36.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2727" for this suite.
STEP: Destroying namespace "webhook-2727-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:20.840 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":280,"completed":263,"skipped":4145,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:19:36.307: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:19:40.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8744" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":280,"completed":264,"skipped":4193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:19:40.796: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:20:40.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2211" for this suite.

• [SLOW TEST:60.214 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":280,"completed":265,"skipped":4254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:20:41.031: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
May  5 12:20:43.717: INFO: Successfully updated pod "annotationupdate375cded2-5804-4e59-a94a-480ab5ecfabe"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:20:47.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4695" for this suite.

• [SLOW TEST:6.739 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":266,"skipped":4290,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:20:47.770: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:04.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3877" for this suite.

• [SLOW TEST:17.175 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":280,"completed":267,"skipped":4306,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:04.945: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-f238a5be-1707-4d4d-9f8d-c4698a923018
STEP: Creating a pod to test consume configMaps
May  5 12:21:05.090: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e" in namespace "projected-5996" to be "success or failure"
May  5 12:21:05.094: INFO: Pod "pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.425568ms
May  5 12:21:07.099: INFO: Pod "pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008624507s
STEP: Saw pod success
May  5 12:21:07.099: INFO: Pod "pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e" satisfied condition "success or failure"
May  5 12:21:07.101: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e container projected-configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:21:07.117: INFO: Waiting for pod pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e to disappear
May  5 12:21:07.120: INFO: Pod pod-projected-configmaps-c3ca1957-340d-4831-bb8d-93843ea16d6e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:07.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5996" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":268,"skipped":4318,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:07.129: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:21:07.303: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"de05c481-0fb6-43d7-82a3-267d4a3fa8f6", Controller:(*bool)(0xc00510b5fe), BlockOwnerDeletion:(*bool)(0xc00510b5ff)}}
May  5 12:21:07.320: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a11b503b-146b-4e25-a3cd-fcb5581f59c2", Controller:(*bool)(0xc0052cb846), BlockOwnerDeletion:(*bool)(0xc0052cb847)}}
May  5 12:21:07.326: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fc04f190-cee5-4b52-9cd9-6584340e2cab", Controller:(*bool)(0xc00510b9da), BlockOwnerDeletion:(*bool)(0xc00510b9db)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:12.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4205" for this suite.

• [SLOW TEST:5.210 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":280,"completed":269,"skipped":4366,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:12.340: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-8864/configmap-test-348cc148-0b18-4302-a889-5c5d97daa2f9
STEP: Creating a pod to test consume configMaps
May  5 12:21:12.488: INFO: Waiting up to 5m0s for pod "pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8" in namespace "configmap-8864" to be "success or failure"
May  5 12:21:12.493: INFO: Pod "pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8": Phase="Pending", Reason="", readiness=false. Elapsed: 5.060228ms
May  5 12:21:14.495: INFO: Pod "pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007624794s
STEP: Saw pod success
May  5 12:21:14.495: INFO: Pod "pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8" satisfied condition "success or failure"
May  5 12:21:14.498: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8 container env-test: <nil>
STEP: delete the pod
May  5 12:21:14.514: INFO: Waiting for pod pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8 to disappear
May  5 12:21:14.517: INFO: Pod pod-configmaps-2dc060fa-e5cd-4a0e-bfa7-ca98d94630e8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:14.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8864" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":270,"skipped":4382,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:14.530: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
May  5 12:21:14.689: INFO: Waiting up to 5m0s for pod "pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1" in namespace "emptydir-9731" to be "success or failure"
May  5 12:21:14.698: INFO: Pod "pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.18715ms
May  5 12:21:16.701: INFO: Pod "pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012604552s
STEP: Saw pod success
May  5 12:21:16.702: INFO: Pod "pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1" satisfied condition "success or failure"
May  5 12:21:16.704: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1 container test-container: <nil>
STEP: delete the pod
May  5 12:21:16.717: INFO: Waiting for pod pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1 to disappear
May  5 12:21:16.720: INFO: Pod pod-9151b4dc-c5d5-4be8-a6d2-f218ca5e9cf1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:16.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9731" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":271,"skipped":4395,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:16.728: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1554
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-projected-all-test-volume-fbd58909-913d-401f-98ee-ca5768234e97
STEP: Creating secret with name secret-projected-all-test-volume-b530a218-bea7-4e06-8f42-a441d9ba8431
STEP: Creating a pod to test Check all projections for projected volume plugin
May  5 12:21:16.877: INFO: Waiting up to 5m0s for pod "projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae" in namespace "projected-1554" to be "success or failure"
May  5 12:21:16.880: INFO: Pod "projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.892121ms
May  5 12:21:18.894: INFO: Pod "projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017349903s
STEP: Saw pod success
May  5 12:21:18.894: INFO: Pod "projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae" satisfied condition "success or failure"
May  5 12:21:18.909: INFO: Trying to get logs from node ip-10-0-27-202 pod projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae container projected-all-volume-test: <nil>
STEP: delete the pod
May  5 12:21:18.928: INFO: Waiting for pod projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae to disappear
May  5 12:21:18.935: INFO: Pod projected-volume-d0072231-351a-4979-8b28-ffc1efebe9ae no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:18.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1554" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":280,"completed":272,"skipped":4406,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:18.949: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-279c09b7-de5e-4500-b0a2-932751b3719b
STEP: Creating a pod to test consume configMaps
May  5 12:21:19.146: INFO: Waiting up to 5m0s for pod "pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40" in namespace "configmap-7663" to be "success or failure"
May  5 12:21:19.156: INFO: Pod "pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40": Phase="Pending", Reason="", readiness=false. Elapsed: 9.121776ms
May  5 12:21:21.160: INFO: Pod "pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013027093s
STEP: Saw pod success
May  5 12:21:21.160: INFO: Pod "pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40" satisfied condition "success or failure"
May  5 12:21:21.162: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40 container configmap-volume-test: <nil>
STEP: delete the pod
May  5 12:21:21.181: INFO: Waiting for pod pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40 to disappear
May  5 12:21:21.183: INFO: Pod pod-configmaps-9f804f4e-7ccd-46ed-aa58-ffe38fae1b40 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:21.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7663" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":273,"skipped":4431,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:21.191: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
May  5 12:21:21.323: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:24.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2882" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":280,"completed":274,"skipped":4439,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:24.588: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:21:24.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e" in namespace "projected-516" to be "success or failure"
May  5 12:21:24.733: INFO: Pod "downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.295518ms
May  5 12:21:26.736: INFO: Pod "downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005372096s
May  5 12:21:28.740: INFO: Pod "downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009197139s
STEP: Saw pod success
May  5 12:21:28.740: INFO: Pod "downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e" satisfied condition "success or failure"
May  5 12:21:28.743: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e container client-container: <nil>
STEP: delete the pod
May  5 12:21:28.760: INFO: Waiting for pod downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e to disappear
May  5 12:21:28.763: INFO: Pod downwardapi-volume-45702c64-bd0e-4f79-9cb0-93284d1e7f2e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:28.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-516" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":280,"completed":275,"skipped":4462,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:28.773: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9738
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service endpoint-test2 in namespace services-9738
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9738 to expose endpoints map[]
May  5 12:21:28.923: INFO: successfully validated that service endpoint-test2 in namespace services-9738 exposes endpoints map[] (4.999624ms elapsed)
STEP: Creating pod pod1 in namespace services-9738
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9738 to expose endpoints map[pod1:[80]]
May  5 12:21:30.956: INFO: successfully validated that service endpoint-test2 in namespace services-9738 exposes endpoints map[pod1:[80]] (2.023884016s elapsed)
STEP: Creating pod pod2 in namespace services-9738
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9738 to expose endpoints map[pod1:[80] pod2:[80]]
May  5 12:21:34.011: INFO: successfully validated that service endpoint-test2 in namespace services-9738 exposes endpoints map[pod1:[80] pod2:[80]] (3.047459927s elapsed)
STEP: Deleting pod pod1 in namespace services-9738
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9738 to expose endpoints map[pod2:[80]]
May  5 12:21:34.027: INFO: successfully validated that service endpoint-test2 in namespace services-9738 exposes endpoints map[pod2:[80]] (10.118356ms elapsed)
STEP: Deleting pod pod2 in namespace services-9738
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9738 to expose endpoints map[]
May  5 12:21:34.058: INFO: successfully validated that service endpoint-test2 in namespace services-9738 exposes endpoints map[] (19.465069ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:34.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9738" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:5.311 seconds]
[sig-network] Services
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":280,"completed":276,"skipped":4522,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:34.084: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
May  5 12:21:34.226: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:36.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3420" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":280,"completed":277,"skipped":4530,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:36.263: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5373
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-8a175df0-6a70-493c-a857-805bc063f0c1
STEP: Creating a pod to test consume secrets
May  5 12:21:36.409: INFO: Waiting up to 5m0s for pod "pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa" in namespace "secrets-5373" to be "success or failure"
May  5 12:21:36.412: INFO: Pod "pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.611383ms
May  5 12:21:38.416: INFO: Pod "pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006566129s
STEP: Saw pod success
May  5 12:21:38.416: INFO: Pod "pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa" satisfied condition "success or failure"
May  5 12:21:38.418: INFO: Trying to get logs from node ip-10-0-27-202 pod pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa container secret-volume-test: <nil>
STEP: delete the pod
May  5 12:21:38.439: INFO: Waiting for pod pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa to disappear
May  5 12:21:38.443: INFO: Pod pod-secrets-a96e7a11-2fdf-4098-be5f-b3e392a7eefa no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:38.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5373" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":278,"skipped":4543,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:38.452: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1790
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
May  5 12:21:38.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3381'
May  5 12:21:38.718: INFO: stderr: ""
May  5 12:21:38.718: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
May  5 12:21:43.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 get pod e2e-test-httpd-pod --namespace=kubectl-3381 -o json'
May  5 12:21:43.892: INFO: stderr: ""
May  5 12:21:43.892: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.2.232.53/32\",\n            \"cni.projectcalico.org/podIPs\": \"10.2.232.53/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-05-05T12:21:38Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3381\",\n        \"resourceVersion\": \"30912\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3381/pods/e2e-test-httpd-pod\",\n        \"uid\": \"15783708-c07e-40b7-8ec8-76ec1ba119dd\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-tnpf4\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-27-202\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-tnpf4\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-tnpf4\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-05T12:21:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-05T12:21:40Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-05T12:21:40Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-05-05T12:21:38Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://a51f6f02e51cafe5ecb4de0ed1bf582419853da175e2d140d8017a37e8a3181d\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-05-05T12:21:39Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.27.202\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.2.232.53\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.2.232.53\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-05-05T12:21:38Z\"\n    }\n}\n"
STEP: replace the image in the pod
May  5 12:21:43.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 replace -f - --namespace=kubectl-3381'
May  5 12:21:44.221: INFO: stderr: ""
May  5 12:21:44.221: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1795
May  5 12:21:44.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-610752675 delete pods e2e-test-httpd-pod --namespace=kubectl-3381'
May  5 12:21:45.687: INFO: stderr: ""
May  5 12:21:45.687: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:45.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3381" for this suite.

• [SLOW TEST:7.243 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1786
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":280,"completed":279,"skipped":4549,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
May  5 12:21:45.696: INFO: >>> kubeConfig: /tmp/kubeconfig-610752675
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
May  5 12:21:45.841: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85" in namespace "downward-api-309" to be "success or failure"
May  5 12:21:45.844: INFO: Pod "downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85": Phase="Pending", Reason="", readiness=false. Elapsed: 3.204397ms
May  5 12:21:47.849: INFO: Pod "downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008083015s
STEP: Saw pod success
May  5 12:21:47.849: INFO: Pod "downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85" satisfied condition "success or failure"
May  5 12:21:47.854: INFO: Trying to get logs from node ip-10-0-27-202 pod downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85 container client-container: <nil>
STEP: delete the pod
May  5 12:21:47.872: INFO: Waiting for pod downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85 to disappear
May  5 12:21:47.875: INFO: Pod downwardapi-volume-26142f74-2a13-4dac-9342-c0288e200e85 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.4-beta.0.54+12bf0cb73007af/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
May  5 12:21:47.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-309" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":280,"skipped":4556,"failed":0}
SSSSSSMay  5 12:21:47.885: INFO: Running AfterSuite actions on all nodes
May  5 12:21:47.886: INFO: Running AfterSuite actions on node 1
May  5 12:21:47.886: INFO: Skipping dumping logs from cluster
{"msg":"Test Suite completed","total":280,"completed":280,"skipped":4562,"failed":0}

Ran 280 of 4842 Specs in 3874.156 seconds
SUCCESS! -- 280 Passed | 0 Failed | 0 Pending | 4562 Skipped
PASS

Ginkgo ran 1 suite in 1h4m35.505847018s
Test Suite Passed
