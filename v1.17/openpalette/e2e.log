I0327 08:59:04.739735      24 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-894470212
I0327 08:59:04.739761      24 test_context.go:419] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0327 08:59:04.739904      24 e2e.go:109] Starting e2e run "58c0ab2d-58bf-4b5a-b4b8-d309fc9a315e" on Ginkgo node 1
{"msg":"Test Suite starting","total":280,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1585299543 - Will randomize all specs
Will run 280 of 4843 specs

Mar 27 08:59:04.755: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 08:59:04.758: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar 27 08:59:04.770: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar 27 08:59:04.791: INFO: 3 / 3 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar 27 08:59:04.791: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Mar 27 08:59:04.791: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar 27 08:59:04.799: INFO: e2e test version: v1.17.2
Mar 27 08:59:04.800: INFO: kube-apiserver version: v1.17.2
Mar 27 08:59:04.800: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 08:59:04.805: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 08:59:04.808: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename var-expansion
Mar 27 08:59:05.088: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test env composition
Mar 27 08:59:05.092: INFO: Waiting up to 5m0s for pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35" in namespace "var-expansion-2239" to be "success or failure"
Mar 27 08:59:05.106: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 14.003828ms
Mar 27 08:59:07.108: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015954735s
Mar 27 08:59:09.110: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 4.017749048s
Mar 27 08:59:11.112: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020117712s
Mar 27 08:59:13.114: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 8.021978084s
Mar 27 08:59:15.116: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024013513s
Mar 27 08:59:17.119: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Pending", Reason="", readiness=false. Elapsed: 12.026787384s
Mar 27 08:59:19.121: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.028913353s
STEP: Saw pod success
Mar 27 08:59:19.121: INFO: Pod "var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35" satisfied condition "success or failure"
Mar 27 08:59:19.123: INFO: Trying to get logs from node 172.22.33.41 pod var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35 container dapi-container: <nil>
STEP: delete the pod
Mar 27 08:59:19.179: INFO: Waiting for pod var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35 to disappear
Mar 27 08:59:19.219: INFO: Pod var-expansion-229140f7-34be-4a0f-9013-40f888b1fb35 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 08:59:19.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2239" for this suite.

• [SLOW TEST:14.469 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":280,"completed":1,"skipped":57,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 08:59:19.277: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 08:59:19.694: INFO: Waiting up to 5m0s for pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62" in namespace "downward-api-866" to be "success or failure"
Mar 27 08:59:19.757: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 62.633304ms
Mar 27 08:59:21.809: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 2.114682902s
Mar 27 08:59:23.816: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 4.121752955s
Mar 27 08:59:25.818: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 6.123931272s
Mar 27 08:59:27.821: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 8.12623849s
Mar 27 08:59:29.823: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Pending", Reason="", readiness=false. Elapsed: 10.128660937s
Mar 27 08:59:31.825: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.131104218s
STEP: Saw pod success
Mar 27 08:59:31.826: INFO: Pod "downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62" satisfied condition "success or failure"
Mar 27 08:59:31.827: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62 container client-container: <nil>
STEP: delete the pod
Mar 27 08:59:32.037: INFO: Waiting for pod downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62 to disappear
Mar 27 08:59:32.063: INFO: Pod downwardapi-volume-99bde2cd-7e3d-48db-ab01-1d3c0ff06d62 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 08:59:32.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-866" for this suite.

• [SLOW TEST:12.840 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":2,"skipped":60,"failed":0}
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 08:59:32.117: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 08:59:44.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7336" for this suite.

• [SLOW TEST:12.670 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":3,"skipped":60,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 08:59:44.789: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar 27 08:59:46.157: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar 27 08:59:48.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 08:59:50.179: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 08:59:52.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 08:59:54.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 08:59:56.164: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896386, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 08:59:59.336: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 08:59:59.446: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:00:01.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-875" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:16.517 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":280,"completed":4,"skipped":79,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:00:01.306: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:00:01.490: INFO: Waiting up to 5m0s for pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255" in namespace "downward-api-2716" to be "success or failure"
Mar 27 09:00:01.613: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 122.471386ms
Mar 27 09:00:03.615: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 2.124692102s
Mar 27 09:00:05.617: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 4.12675305s
Mar 27 09:00:07.622: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 6.132351455s
Mar 27 09:00:09.624: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 8.13438596s
Mar 27 09:00:11.627: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 10.136618167s
Mar 27 09:00:13.691: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Pending", Reason="", readiness=false. Elapsed: 12.200521558s
Mar 27 09:00:15.822: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.331783605s
STEP: Saw pod success
Mar 27 09:00:15.822: INFO: Pod "downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255" satisfied condition "success or failure"
Mar 27 09:00:15.824: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255 container client-container: <nil>
STEP: delete the pod
Mar 27 09:00:16.164: INFO: Waiting for pod downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255 to disappear
Mar 27 09:00:16.208: INFO: Pod downwardapi-volume-717fc4b1-066b-4566-8ed8-e57ef2688255 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:00:16.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2716" for this suite.

• [SLOW TEST:14.906 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":5,"skipped":117,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:00:16.213: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:00:47.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2667" for this suite.

• [SLOW TEST:30.813 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":280,"completed":6,"skipped":124,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:00:47.027: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service nodeport-test with type=NodePort in namespace services-9967
STEP: creating replication controller nodeport-test in namespace services-9967
I0327 09:00:47.321436      24 runners.go:189] Created replication controller with name: nodeport-test, namespace: services-9967, replica count: 2
I0327 09:00:50.371781      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:00:53.371925      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:00:56.372217      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:00:59.372398      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 09:01:02.372: INFO: Creating new exec pod
I0327 09:01:02.372525      24 runners.go:189] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 09:01:15.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-9967 execpodfnt44 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Mar 27 09:01:18.334: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Mar 27 09:01:18.334: INFO: stdout: ""
Mar 27 09:01:18.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-9967 execpodfnt44 -- /bin/sh -x -c nc -zv -t -w 2 10.254.71.246 80'
Mar 27 09:01:18.476: INFO: stderr: "+ nc -zv -t -w 2 10.254.71.246 80\nConnection to 10.254.71.246 80 port [tcp/http] succeeded!\n"
Mar 27 09:01:18.476: INFO: stdout: ""
Mar 27 09:01:18.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-9967 execpodfnt44 -- /bin/sh -x -c nc -zv -t -w 2 172.22.33.40 31215'
Mar 27 09:01:18.618: INFO: stderr: "+ nc -zv -t -w 2 172.22.33.40 31215\nConnection to 172.22.33.40 31215 port [tcp/31215] succeeded!\n"
Mar 27 09:01:18.618: INFO: stdout: ""
Mar 27 09:01:18.618: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-9967 execpodfnt44 -- /bin/sh -x -c nc -zv -t -w 2 172.22.33.41 31215'
Mar 27 09:01:18.764: INFO: stderr: "+ nc -zv -t -w 2 172.22.33.41 31215\nConnection to 172.22.33.41 31215 port [tcp/31215] succeeded!\n"
Mar 27 09:01:18.764: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:01:18.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9967" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:31.740 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":280,"completed":7,"skipped":170,"failed":0}
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:01:18.768: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:01:18.926: INFO: Waiting up to 5m0s for pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6" in namespace "downward-api-5950" to be "success or failure"
Mar 27 09:01:18.948: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 21.921424ms
Mar 27 09:01:20.950: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023936932s
Mar 27 09:01:22.952: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025899565s
Mar 27 09:01:25.022: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.095806218s
Mar 27 09:01:27.244: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.318152812s
Mar 27 09:01:29.246: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.320239475s
Mar 27 09:01:31.248: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.322232931s
STEP: Saw pod success
Mar 27 09:01:31.248: INFO: Pod "downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6" satisfied condition "success or failure"
Mar 27 09:01:31.249: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6 container client-container: <nil>
STEP: delete the pod
Mar 27 09:01:31.537: INFO: Waiting for pod downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6 to disappear
Mar 27 09:01:31.578: INFO: Pod downwardapi-volume-afed503f-0c9e-4f95-8211-c5e1994e9dc6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:01:31.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5950" for this suite.

• [SLOW TEST:12.814 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":8,"skipped":175,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:01:31.582: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1861
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:01:32.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7560'
Mar 27 09:01:32.307: INFO: stderr: ""
Mar 27 09:01:32.307: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1866
Mar 27 09:01:32.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete pods e2e-test-httpd-pod --namespace=kubectl-7560'
Mar 27 09:01:32.706: INFO: stderr: ""
Mar 27 09:01:32.706: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:01:32.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7560" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":280,"completed":9,"skipped":200,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:01:32.981: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5968.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5968.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5968.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5968.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5968.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5968.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 09:02:07.523: INFO: Unable to read jessie_hosts@dns-querier-1 from pod dns-5968/dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd: the server could not find the requested resource (get pods dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd)
Mar 27 09:02:07.524: INFO: Unable to read jessie_udp@PodARecord from pod dns-5968/dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd: the server could not find the requested resource (get pods dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd)
Mar 27 09:02:07.526: INFO: Unable to read jessie_tcp@PodARecord from pod dns-5968/dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd: the server could not find the requested resource (get pods dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd)
Mar 27 09:02:07.526: INFO: Lookups using dns-5968/dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd failed for: [jessie_hosts@dns-querier-1 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 27 09:02:12.539: INFO: DNS probes using dns-5968/dns-test-f59717a0-1d0f-413e-9681-13bc17a2a3dd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:02:12.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5968" for this suite.

• [SLOW TEST:40.701 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":280,"completed":10,"skipped":203,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:02:13.683: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating secret secrets-8076/secret-test-b5b704ab-6dfb-4554-b827-ae4a9158003a
STEP: Creating a pod to test consume secrets
Mar 27 09:02:14.228: INFO: Waiting up to 5m0s for pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2" in namespace "secrets-8076" to be "success or failure"
Mar 27 09:02:14.254: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 26.464044ms
Mar 27 09:02:16.257: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028630184s
Mar 27 09:02:18.259: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030744977s
Mar 27 09:02:20.273: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.045511071s
Mar 27 09:02:22.276: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 8.047593374s
Mar 27 09:02:24.281: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Pending", Reason="", readiness=false. Elapsed: 10.0528225s
Mar 27 09:02:26.596: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.368367097s
STEP: Saw pod success
Mar 27 09:02:26.596: INFO: Pod "pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2" satisfied condition "success or failure"
Mar 27 09:02:26.598: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2 container env-test: <nil>
STEP: delete the pod
Mar 27 09:02:26.886: INFO: Waiting for pod pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2 to disappear
Mar 27 09:02:27.169: INFO: Pod pod-configmaps-a471462e-eec3-44ae-9198-51a28a5f23a2 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:02:27.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8076" for this suite.

• [SLOW TEST:13.491 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":11,"skipped":209,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:02:27.176: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-fcc0fb97-f0f1-4c41-ae62-4b5a020ff38a
STEP: Creating configMap with name cm-test-opt-upd-e2df81a9-4712-4668-b2da-42e96ceec652
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fcc0fb97-f0f1-4c41-ae62-4b5a020ff38a
STEP: Updating configmap cm-test-opt-upd-e2df81a9-4712-4668-b2da-42e96ceec652
STEP: Creating configMap with name cm-test-opt-create-a3d55b26-f40d-45bb-827d-6adea2168bf1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:02:44.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7446" for this suite.

• [SLOW TEST:17.150 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":12,"skipped":273,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:02:44.327: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:02:44.443: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4572
I0327 09:02:44.454628      24 runners.go:189] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4572, replica count: 1
I0327 09:02:45.505043      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:46.505332      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:47.505542      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:48.505819      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:49.506107      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:50.506395      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:51.506665      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:52.506886      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:53.507191      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:54.507475      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:55.507775      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:02:56.508077      24 runners.go:189] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 09:02:56.816: INFO: Created: latency-svc-lqdfw
Mar 27 09:02:56.863: INFO: Got endpoints: latency-svc-lqdfw [255.206269ms]
Mar 27 09:02:57.040: INFO: Created: latency-svc-ssbws
Mar 27 09:02:57.071: INFO: Created: latency-svc-t2wlv
Mar 27 09:02:57.071: INFO: Got endpoints: latency-svc-ssbws [207.536494ms]
Mar 27 09:02:57.260: INFO: Got endpoints: latency-svc-t2wlv [396.138645ms]
Mar 27 09:02:57.293: INFO: Created: latency-svc-66ww2
Mar 27 09:02:57.333: INFO: Got endpoints: latency-svc-66ww2 [469.401659ms]
Mar 27 09:02:57.630: INFO: Created: latency-svc-4jlnv
Mar 27 09:02:57.677: INFO: Got endpoints: latency-svc-4jlnv [813.003312ms]
Mar 27 09:02:57.879: INFO: Created: latency-svc-vgxld
Mar 27 09:02:57.893: INFO: Got endpoints: latency-svc-vgxld [1.028672666s]
Mar 27 09:02:57.966: INFO: Created: latency-svc-dq8xp
Mar 27 09:02:58.079: INFO: Got endpoints: latency-svc-dq8xp [1.214960102s]
Mar 27 09:02:58.085: INFO: Created: latency-svc-kqx6g
Mar 27 09:02:58.102: INFO: Got endpoints: latency-svc-kqx6g [1.23816624s]
Mar 27 09:02:58.247: INFO: Created: latency-svc-r7nq4
Mar 27 09:02:58.279: INFO: Created: latency-svc-6ghlx
Mar 27 09:02:58.280: INFO: Got endpoints: latency-svc-r7nq4 [1.415388561s]
Mar 27 09:02:58.308: INFO: Got endpoints: latency-svc-6ghlx [1.444240279s]
Mar 27 09:02:58.335: INFO: Created: latency-svc-kps2c
Mar 27 09:02:58.447: INFO: Got endpoints: latency-svc-kps2c [1.582949457s]
Mar 27 09:02:58.508: INFO: Created: latency-svc-cn6px
Mar 27 09:02:58.537: INFO: Got endpoints: latency-svc-cn6px [1.673114379s]
Mar 27 09:02:58.581: INFO: Created: latency-svc-jf78v
Mar 27 09:02:58.627: INFO: Got endpoints: latency-svc-jf78v [1.7631835s]
Mar 27 09:02:58.653: INFO: Created: latency-svc-b8tgv
Mar 27 09:02:58.674: INFO: Got endpoints: latency-svc-b8tgv [1.810055521s]
Mar 27 09:02:58.746: INFO: Created: latency-svc-cr6fn
Mar 27 09:02:58.770: INFO: Created: latency-svc-sbrgt
Mar 27 09:02:58.770: INFO: Got endpoints: latency-svc-cr6fn [1.906593187s]
Mar 27 09:02:58.785: INFO: Got endpoints: latency-svc-sbrgt [1.921693854s]
Mar 27 09:02:58.901: INFO: Created: latency-svc-j5kcn
Mar 27 09:02:58.917: INFO: Created: latency-svc-6wrq2
Mar 27 09:02:58.917: INFO: Got endpoints: latency-svc-j5kcn [1.845990012s]
Mar 27 09:02:58.926: INFO: Got endpoints: latency-svc-6wrq2 [1.665980754s]
Mar 27 09:02:59.045: INFO: Created: latency-svc-bmdvn
Mar 27 09:02:59.087: INFO: Created: latency-svc-65plx
Mar 27 09:02:59.087: INFO: Got endpoints: latency-svc-bmdvn [1.753889326s]
Mar 27 09:02:59.110: INFO: Got endpoints: latency-svc-65plx [1.433394899s]
Mar 27 09:02:59.136: INFO: Created: latency-svc-fd5sg
Mar 27 09:02:59.257: INFO: Got endpoints: latency-svc-fd5sg [1.363748815s]
Mar 27 09:02:59.334: INFO: Created: latency-svc-k4td8
Mar 27 09:02:59.343: INFO: Got endpoints: latency-svc-k4td8 [1.263695303s]
Mar 27 09:02:59.409: INFO: Created: latency-svc-rpscx
Mar 27 09:02:59.446: INFO: Created: latency-svc-vphvf
Mar 27 09:02:59.447: INFO: Got endpoints: latency-svc-rpscx [1.344164765s]
Mar 27 09:02:59.466: INFO: Got endpoints: latency-svc-vphvf [1.186113922s]
Mar 27 09:02:59.509: INFO: Created: latency-svc-8r2cs
Mar 27 09:02:59.648: INFO: Got endpoints: latency-svc-8r2cs [1.339133143s]
Mar 27 09:02:59.681: INFO: Created: latency-svc-tcc8n
Mar 27 09:02:59.739: INFO: Got endpoints: latency-svc-tcc8n [1.291896568s]
Mar 27 09:02:59.861: INFO: Created: latency-svc-7lj7v
Mar 27 09:02:59.912: INFO: Got endpoints: latency-svc-7lj7v [1.37439018s]
Mar 27 09:02:59.940: INFO: Created: latency-svc-7hc6r
Mar 27 09:03:00.062: INFO: Got endpoints: latency-svc-7hc6r [1.435013783s]
Mar 27 09:03:00.098: INFO: Created: latency-svc-62wfp
Mar 27 09:03:00.109: INFO: Got endpoints: latency-svc-62wfp [1.435251401s]
Mar 27 09:03:00.162: INFO: Created: latency-svc-wbqm7
Mar 27 09:03:00.333: INFO: Got endpoints: latency-svc-wbqm7 [1.563037812s]
Mar 27 09:03:00.356: INFO: Created: latency-svc-ffl68
Mar 27 09:03:00.395: INFO: Got endpoints: latency-svc-ffl68 [1.609726967s]
Mar 27 09:03:00.583: INFO: Created: latency-svc-kjw62
Mar 27 09:03:00.619: INFO: Got endpoints: latency-svc-kjw62 [1.701734699s]
Mar 27 09:03:00.717: INFO: Created: latency-svc-lm8hs
Mar 27 09:03:00.724: INFO: Got endpoints: latency-svc-lm8hs [1.797805661s]
Mar 27 09:03:00.858: INFO: Created: latency-svc-f7bqd
Mar 27 09:03:00.886: INFO: Got endpoints: latency-svc-f7bqd [1.79846293s]
Mar 27 09:03:00.914: INFO: Created: latency-svc-clmlf
Mar 27 09:03:00.951: INFO: Got endpoints: latency-svc-clmlf [1.841022104s]
Mar 27 09:03:01.054: INFO: Created: latency-svc-sj8s4
Mar 27 09:03:01.094: INFO: Got endpoints: latency-svc-sj8s4 [1.836969456s]
Mar 27 09:03:01.123: INFO: Created: latency-svc-glbjw
Mar 27 09:03:01.188: INFO: Got endpoints: latency-svc-glbjw [1.844844471s]
Mar 27 09:03:01.271: INFO: Created: latency-svc-7dvpp
Mar 27 09:03:01.465: INFO: Got endpoints: latency-svc-7dvpp [2.01837255s]
Mar 27 09:03:01.485: INFO: Created: latency-svc-qqkkf
Mar 27 09:03:01.555: INFO: Got endpoints: latency-svc-qqkkf [2.08931588s]
Mar 27 09:03:01.685: INFO: Created: latency-svc-mzhf9
Mar 27 09:03:01.719: INFO: Got endpoints: latency-svc-mzhf9 [2.070884317s]
Mar 27 09:03:01.772: INFO: Created: latency-svc-4pnmq
Mar 27 09:03:01.781: INFO: Got endpoints: latency-svc-4pnmq [2.041568448s]
Mar 27 09:03:01.827: INFO: Created: latency-svc-b7v8k
Mar 27 09:03:01.893: INFO: Created: latency-svc-c5phv
Mar 27 09:03:01.893: INFO: Got endpoints: latency-svc-b7v8k [1.981496859s]
Mar 27 09:03:02.049: INFO: Got endpoints: latency-svc-c5phv [1.986667266s]
Mar 27 09:03:02.098: INFO: Created: latency-svc-lkpk8
Mar 27 09:03:02.313: INFO: Got endpoints: latency-svc-lkpk8 [2.203609735s]
Mar 27 09:03:02.403: INFO: Created: latency-svc-82p7r
Mar 27 09:03:02.502: INFO: Got endpoints: latency-svc-82p7r [2.168635196s]
Mar 27 09:03:02.589: INFO: Created: latency-svc-kmdpx
Mar 27 09:03:02.590: INFO: Got endpoints: latency-svc-kmdpx [2.194224023s]
Mar 27 09:03:02.708: INFO: Created: latency-svc-wn8px
Mar 27 09:03:02.778: INFO: Created: latency-svc-87qws
Mar 27 09:03:02.778: INFO: Got endpoints: latency-svc-wn8px [2.159493717s]
Mar 27 09:03:02.935: INFO: Got endpoints: latency-svc-87qws [2.210836661s]
Mar 27 09:03:03.262: INFO: Created: latency-svc-dsr7k
Mar 27 09:03:03.353: INFO: Created: latency-svc-p9trw
Mar 27 09:03:03.354: INFO: Got endpoints: latency-svc-dsr7k [2.467745814s]
Mar 27 09:03:03.465: INFO: Got endpoints: latency-svc-p9trw [2.514005541s]
Mar 27 09:03:03.479: INFO: Created: latency-svc-fzql6
Mar 27 09:03:03.490: INFO: Got endpoints: latency-svc-fzql6 [2.395811433s]
Mar 27 09:03:03.527: INFO: Created: latency-svc-hwkf4
Mar 27 09:03:03.557: INFO: Got endpoints: latency-svc-hwkf4 [2.368798131s]
Mar 27 09:03:03.600: INFO: Created: latency-svc-g9svr
Mar 27 09:03:03.622: INFO: Got endpoints: latency-svc-g9svr [2.156955361s]
Mar 27 09:03:03.622: INFO: Created: latency-svc-dw45g
Mar 27 09:03:03.645: INFO: Got endpoints: latency-svc-dw45g [2.089618361s]
Mar 27 09:03:03.694: INFO: Created: latency-svc-smr2j
Mar 27 09:03:03.694: INFO: Got endpoints: latency-svc-smr2j [1.974913223s]
Mar 27 09:03:03.746: INFO: Created: latency-svc-2qvx2
Mar 27 09:03:03.797: INFO: Created: latency-svc-lpwl7
Mar 27 09:03:03.797: INFO: Got endpoints: latency-svc-2qvx2 [2.016605214s]
Mar 27 09:03:03.888: INFO: Got endpoints: latency-svc-lpwl7 [1.994990339s]
Mar 27 09:03:03.889: INFO: Created: latency-svc-bgkwr
Mar 27 09:03:03.894: INFO: Got endpoints: latency-svc-bgkwr [1.844722704s]
Mar 27 09:03:03.930: INFO: Created: latency-svc-rwvw4
Mar 27 09:03:03.940: INFO: Got endpoints: latency-svc-rwvw4 [1.626439358s]
Mar 27 09:03:03.981: INFO: Created: latency-svc-gqq8w
Mar 27 09:03:04.075: INFO: Created: latency-svc-q8qcs
Mar 27 09:03:04.075: INFO: Got endpoints: latency-svc-gqq8w [1.5723136s]
Mar 27 09:03:04.141: INFO: Got endpoints: latency-svc-q8qcs [1.551080942s]
Mar 27 09:03:04.260: INFO: Created: latency-svc-z9tww
Mar 27 09:03:04.305: INFO: Created: latency-svc-dth2f
Mar 27 09:03:04.306: INFO: Got endpoints: latency-svc-z9tww [1.527781716s]
Mar 27 09:03:04.311: INFO: Got endpoints: latency-svc-dth2f [1.376107984s]
Mar 27 09:03:04.346: INFO: Created: latency-svc-xzgkg
Mar 27 09:03:04.354: INFO: Got endpoints: latency-svc-xzgkg [1.000765721s]
Mar 27 09:03:04.432: INFO: Created: latency-svc-45gk2
Mar 27 09:03:04.454: INFO: Got endpoints: latency-svc-45gk2 [988.863722ms]
Mar 27 09:03:04.454: INFO: Created: latency-svc-4ft4k
Mar 27 09:03:04.463: INFO: Got endpoints: latency-svc-4ft4k [973.403747ms]
Mar 27 09:03:04.489: INFO: Created: latency-svc-zrr96
Mar 27 09:03:04.729: INFO: Got endpoints: latency-svc-zrr96 [1.17198411s]
Mar 27 09:03:04.729: INFO: Created: latency-svc-ckrrp
Mar 27 09:03:04.743: INFO: Got endpoints: latency-svc-ckrrp [1.120487036s]
Mar 27 09:03:04.768: INFO: Created: latency-svc-2ldv2
Mar 27 09:03:04.777: INFO: Got endpoints: latency-svc-2ldv2 [1.13207514s]
Mar 27 09:03:04.825: INFO: Created: latency-svc-rvfzt
Mar 27 09:03:04.919: INFO: Got endpoints: latency-svc-rvfzt [1.225366724s]
Mar 27 09:03:04.945: INFO: Created: latency-svc-m9c7p
Mar 27 09:03:04.951: INFO: Got endpoints: latency-svc-m9c7p [1.153594648s]
Mar 27 09:03:04.977: INFO: Created: latency-svc-f6m2n
Mar 27 09:03:04.985: INFO: Got endpoints: latency-svc-f6m2n [1.096900321s]
Mar 27 09:03:05.002: INFO: Created: latency-svc-q6vpt
Mar 27 09:03:05.012: INFO: Got endpoints: latency-svc-q6vpt [1.118460248s]
Mar 27 09:03:05.061: INFO: Created: latency-svc-vbrkc
Mar 27 09:03:05.088: INFO: Got endpoints: latency-svc-vbrkc [1.14866329s]
Mar 27 09:03:05.088: INFO: Created: latency-svc-mlvvc
Mar 27 09:03:05.136: INFO: Got endpoints: latency-svc-mlvvc [1.061597357s]
Mar 27 09:03:05.271: INFO: Created: latency-svc-pw2mk
Mar 27 09:03:05.340: INFO: Got endpoints: latency-svc-pw2mk [1.198859681s]
Mar 27 09:03:05.340: INFO: Created: latency-svc-9cspd
Mar 27 09:03:05.345: INFO: Got endpoints: latency-svc-9cspd [1.038740455s]
Mar 27 09:03:05.477: INFO: Created: latency-svc-l5kqp
Mar 27 09:03:05.511: INFO: Got endpoints: latency-svc-l5kqp [1.20016146s]
Mar 27 09:03:05.528: INFO: Created: latency-svc-xkndt
Mar 27 09:03:05.540: INFO: Got endpoints: latency-svc-xkndt [1.185142074s]
Mar 27 09:03:05.637: INFO: Created: latency-svc-vcbwd
Mar 27 09:03:05.654: INFO: Got endpoints: latency-svc-vcbwd [1.199262921s]
Mar 27 09:03:05.654: INFO: Created: latency-svc-vbjjj
Mar 27 09:03:05.702: INFO: Got endpoints: latency-svc-vbjjj [1.239184739s]
Mar 27 09:03:05.983: INFO: Created: latency-svc-7gg86
Mar 27 09:03:06.038: INFO: Got endpoints: latency-svc-7gg86 [1.309049516s]
Mar 27 09:03:06.275: INFO: Created: latency-svc-7z52t
Mar 27 09:03:06.363: INFO: Got endpoints: latency-svc-7z52t [1.620820277s]
Mar 27 09:03:06.364: INFO: Created: latency-svc-wnz9p
Mar 27 09:03:06.381: INFO: Got endpoints: latency-svc-wnz9p [1.604255602s]
Mar 27 09:03:06.430: INFO: Created: latency-svc-hjlrk
Mar 27 09:03:06.434: INFO: Got endpoints: latency-svc-hjlrk [1.51514164s]
Mar 27 09:03:06.554: INFO: Created: latency-svc-fhcnw
Mar 27 09:03:06.607: INFO: Created: latency-svc-8nzgx
Mar 27 09:03:06.607: INFO: Got endpoints: latency-svc-fhcnw [1.656283425s]
Mar 27 09:03:06.626: INFO: Got endpoints: latency-svc-8nzgx [1.640821508s]
Mar 27 09:03:06.740: INFO: Created: latency-svc-wp2fm
Mar 27 09:03:06.934: INFO: Got endpoints: latency-svc-wp2fm [1.921909105s]
Mar 27 09:03:06.934: INFO: Created: latency-svc-dwvm6
Mar 27 09:03:07.017: INFO: Got endpoints: latency-svc-dwvm6 [1.928730047s]
Mar 27 09:03:07.018: INFO: Created: latency-svc-fxpsv
Mar 27 09:03:07.029: INFO: Got endpoints: latency-svc-fxpsv [1.892752691s]
Mar 27 09:03:07.126: INFO: Created: latency-svc-tf6rt
Mar 27 09:03:07.151: INFO: Got endpoints: latency-svc-tf6rt [1.811510916s]
Mar 27 09:03:07.472: INFO: Created: latency-svc-j7h2f
Mar 27 09:03:07.557: INFO: Got endpoints: latency-svc-j7h2f [2.211374995s]
Mar 27 09:03:07.710: INFO: Created: latency-svc-9xbcx
Mar 27 09:03:07.804: INFO: Got endpoints: latency-svc-9xbcx [2.292946179s]
Mar 27 09:03:07.829: INFO: Created: latency-svc-6wvrt
Mar 27 09:03:07.855: INFO: Got endpoints: latency-svc-6wvrt [2.315192162s]
Mar 27 09:03:08.020: INFO: Created: latency-svc-sj46t
Mar 27 09:03:08.041: INFO: Got endpoints: latency-svc-sj46t [2.387242655s]
Mar 27 09:03:08.107: INFO: Created: latency-svc-zmxgb
Mar 27 09:03:08.266: INFO: Got endpoints: latency-svc-zmxgb [2.563450899s]
Mar 27 09:03:08.305: INFO: Created: latency-svc-g8bp4
Mar 27 09:03:08.357: INFO: Got endpoints: latency-svc-g8bp4 [2.31928244s]
Mar 27 09:03:08.834: INFO: Created: latency-svc-5qjcq
Mar 27 09:03:08.910: INFO: Created: latency-svc-5n2fz
Mar 27 09:03:08.910: INFO: Got endpoints: latency-svc-5qjcq [2.5466025s]
Mar 27 09:03:08.966: INFO: Got endpoints: latency-svc-5n2fz [2.584268635s]
Mar 27 09:03:09.197: INFO: Created: latency-svc-vl6kr
Mar 27 09:03:09.426: INFO: Created: latency-svc-x2562
Mar 27 09:03:09.426: INFO: Got endpoints: latency-svc-vl6kr [2.992142222s]
Mar 27 09:03:09.470: INFO: Created: latency-svc-cwzvj
Mar 27 09:03:09.470: INFO: Got endpoints: latency-svc-x2562 [2.862842666s]
Mar 27 09:03:09.494: INFO: Got endpoints: latency-svc-cwzvj [2.868017766s]
Mar 27 09:03:09.525: INFO: Created: latency-svc-xxd85
Mar 27 09:03:09.569: INFO: Got endpoints: latency-svc-xxd85 [2.634258064s]
Mar 27 09:03:09.569: INFO: Created: latency-svc-9j8m6
Mar 27 09:03:09.578: INFO: Got endpoints: latency-svc-9j8m6 [2.560537946s]
Mar 27 09:03:09.599: INFO: Created: latency-svc-pwpgd
Mar 27 09:03:09.668: INFO: Got endpoints: latency-svc-pwpgd [2.638443502s]
Mar 27 09:03:09.864: INFO: Created: latency-svc-b22tf
Mar 27 09:03:09.872: INFO: Got endpoints: latency-svc-b22tf [2.720698865s]
Mar 27 09:03:09.882: INFO: Created: latency-svc-v7cf5
Mar 27 09:03:09.889: INFO: Got endpoints: latency-svc-v7cf5 [2.332406541s]
Mar 27 09:03:09.905: INFO: Created: latency-svc-zcf62
Mar 27 09:03:09.922: INFO: Got endpoints: latency-svc-zcf62 [2.118290963s]
Mar 27 09:03:09.940: INFO: Created: latency-svc-cwjzb
Mar 27 09:03:09.947: INFO: Got endpoints: latency-svc-cwjzb [2.091672247s]
Mar 27 09:03:10.044: INFO: Created: latency-svc-bg68c
Mar 27 09:03:10.046: INFO: Got endpoints: latency-svc-bg68c [2.004876336s]
Mar 27 09:03:10.141: INFO: Created: latency-svc-jv5kl
Mar 27 09:03:10.236: INFO: Got endpoints: latency-svc-jv5kl [1.969692174s]
Mar 27 09:03:10.237: INFO: Created: latency-svc-4z6gj
Mar 27 09:03:10.251: INFO: Got endpoints: latency-svc-4z6gj [1.89360872s]
Mar 27 09:03:10.453: INFO: Created: latency-svc-rfgt4
Mar 27 09:03:10.463: INFO: Got endpoints: latency-svc-rfgt4 [1.55308217s]
Mar 27 09:03:10.483: INFO: Created: latency-svc-zrgkm
Mar 27 09:03:10.492: INFO: Got endpoints: latency-svc-zrgkm [1.526453815s]
Mar 27 09:03:10.511: INFO: Created: latency-svc-fktcn
Mar 27 09:03:10.521: INFO: Got endpoints: latency-svc-fktcn [1.093930525s]
Mar 27 09:03:10.540: INFO: Created: latency-svc-2569c
Mar 27 09:03:10.549: INFO: Got endpoints: latency-svc-2569c [1.078568176s]
Mar 27 09:03:10.621: INFO: Created: latency-svc-bl2l5
Mar 27 09:03:10.646: INFO: Got endpoints: latency-svc-bl2l5 [1.151988357s]
Mar 27 09:03:10.674: INFO: Created: latency-svc-fk49n
Mar 27 09:03:10.691: INFO: Got endpoints: latency-svc-fk49n [1.122449775s]
Mar 27 09:03:10.751: INFO: Created: latency-svc-82bjd
Mar 27 09:03:10.826: INFO: Created: latency-svc-52tk8
Mar 27 09:03:10.826: INFO: Got endpoints: latency-svc-82bjd [1.248081586s]
Mar 27 09:03:10.844: INFO: Got endpoints: latency-svc-52tk8 [1.17648949s]
Mar 27 09:03:10.887: INFO: Created: latency-svc-46m79
Mar 27 09:03:10.890: INFO: Got endpoints: latency-svc-46m79 [1.018029304s]
Mar 27 09:03:10.925: INFO: Created: latency-svc-tm6jr
Mar 27 09:03:10.934: INFO: Got endpoints: latency-svc-tm6jr [1.044872231s]
Mar 27 09:03:10.957: INFO: Created: latency-svc-tcpds
Mar 27 09:03:10.963: INFO: Got endpoints: latency-svc-tcpds [1.040490891s]
Mar 27 09:03:10.980: INFO: Created: latency-svc-zxvhv
Mar 27 09:03:11.100: INFO: Got endpoints: latency-svc-zxvhv [1.153709806s]
Mar 27 09:03:11.133: INFO: Created: latency-svc-zzvlg
Mar 27 09:03:11.188: INFO: Got endpoints: latency-svc-zzvlg [1.14167857s]
Mar 27 09:03:11.416: INFO: Created: latency-svc-h4xdz
Mar 27 09:03:11.443: INFO: Got endpoints: latency-svc-h4xdz [1.207675258s]
Mar 27 09:03:11.660: INFO: Created: latency-svc-gfphs
Mar 27 09:03:11.712: INFO: Got endpoints: latency-svc-gfphs [1.460606368s]
Mar 27 09:03:11.835: INFO: Created: latency-svc-ntcxn
Mar 27 09:03:11.867: INFO: Created: latency-svc-hx4fd
Mar 27 09:03:11.868: INFO: Got endpoints: latency-svc-ntcxn [1.404718167s]
Mar 27 09:03:11.878: INFO: Got endpoints: latency-svc-hx4fd [1.385713445s]
Mar 27 09:03:11.924: INFO: Created: latency-svc-nqhlt
Mar 27 09:03:12.076: INFO: Got endpoints: latency-svc-nqhlt [1.555706911s]
Mar 27 09:03:12.102: INFO: Created: latency-svc-946w7
Mar 27 09:03:12.154: INFO: Got endpoints: latency-svc-946w7 [1.605219495s]
Mar 27 09:03:12.334: INFO: Created: latency-svc-t75d7
Mar 27 09:03:12.373: INFO: Got endpoints: latency-svc-t75d7 [1.726287873s]
Mar 27 09:03:12.905: INFO: Created: latency-svc-fn8nv
Mar 27 09:03:13.074: INFO: Got endpoints: latency-svc-fn8nv [2.382988403s]
Mar 27 09:03:13.139: INFO: Created: latency-svc-p7mds
Mar 27 09:03:13.381: INFO: Got endpoints: latency-svc-p7mds [2.554794813s]
Mar 27 09:03:13.467: INFO: Created: latency-svc-qnpqp
Mar 27 09:03:13.625: INFO: Got endpoints: latency-svc-qnpqp [2.780243119s]
Mar 27 09:03:13.658: INFO: Created: latency-svc-z2pm6
Mar 27 09:03:13.696: INFO: Got endpoints: latency-svc-z2pm6 [2.805661035s]
Mar 27 09:03:14.009: INFO: Created: latency-svc-5fdpk
Mar 27 09:03:14.009: INFO: Got endpoints: latency-svc-5fdpk [3.07450053s]
Mar 27 09:03:14.192: INFO: Created: latency-svc-42czv
Mar 27 09:03:14.250: INFO: Got endpoints: latency-svc-42czv [3.286983108s]
Mar 27 09:03:14.484: INFO: Created: latency-svc-khb46
Mar 27 09:03:14.829: INFO: Created: latency-svc-gb8z7
Mar 27 09:03:14.829: INFO: Got endpoints: latency-svc-khb46 [3.728902481s]
Mar 27 09:03:14.855: INFO: Got endpoints: latency-svc-gb8z7 [3.66745287s]
Mar 27 09:03:14.896: INFO: Created: latency-svc-hgln5
Mar 27 09:03:14.910: INFO: Got endpoints: latency-svc-hgln5 [3.466461787s]
Mar 27 09:03:14.998: INFO: Created: latency-svc-8q5j5
Mar 27 09:03:15.013: INFO: Got endpoints: latency-svc-8q5j5 [3.301663586s]
Mar 27 09:03:15.014: INFO: Created: latency-svc-tcfmj
Mar 27 09:03:15.044: INFO: Got endpoints: latency-svc-tcfmj [3.175679447s]
Mar 27 09:03:15.065: INFO: Created: latency-svc-p89bv
Mar 27 09:03:15.078: INFO: Got endpoints: latency-svc-p89bv [3.200161108s]
Mar 27 09:03:15.128: INFO: Created: latency-svc-sghnm
Mar 27 09:03:15.144: INFO: Got endpoints: latency-svc-sghnm [3.067938802s]
Mar 27 09:03:15.145: INFO: Created: latency-svc-2sqv2
Mar 27 09:03:15.162: INFO: Got endpoints: latency-svc-2sqv2 [3.007607642s]
Mar 27 09:03:15.411: INFO: Created: latency-svc-7qh4n
Mar 27 09:03:15.485: INFO: Got endpoints: latency-svc-7qh4n [3.112413899s]
Mar 27 09:03:15.487: INFO: Created: latency-svc-klnst
Mar 27 09:03:15.634: INFO: Got endpoints: latency-svc-klnst [2.559788177s]
Mar 27 09:03:15.659: INFO: Created: latency-svc-kfmzt
Mar 27 09:03:16.241: INFO: Got endpoints: latency-svc-kfmzt [2.859924256s]
Mar 27 09:03:16.316: INFO: Created: latency-svc-4lvf4
Mar 27 09:03:16.593: INFO: Got endpoints: latency-svc-4lvf4 [2.968095308s]
Mar 27 09:03:16.608: INFO: Created: latency-svc-92zs8
Mar 27 09:03:16.648: INFO: Got endpoints: latency-svc-92zs8 [2.951747294s]
Mar 27 09:03:16.846: INFO: Created: latency-svc-b4r4k
Mar 27 09:03:16.872: INFO: Got endpoints: latency-svc-b4r4k [2.86334832s]
Mar 27 09:03:17.261: INFO: Created: latency-svc-wtglx
Mar 27 09:03:17.477: INFO: Created: latency-svc-xbhg4
Mar 27 09:03:17.477: INFO: Got endpoints: latency-svc-wtglx [3.227078501s]
Mar 27 09:03:17.559: INFO: Got endpoints: latency-svc-xbhg4 [2.729011768s]
Mar 27 09:03:17.735: INFO: Created: latency-svc-xjm8t
Mar 27 09:03:17.816: INFO: Got endpoints: latency-svc-xjm8t [2.960039321s]
Mar 27 09:03:17.865: INFO: Created: latency-svc-bnmgh
Mar 27 09:03:18.082: INFO: Got endpoints: latency-svc-bnmgh [3.171727113s]
Mar 27 09:03:18.156: INFO: Created: latency-svc-89vvs
Mar 27 09:03:18.352: INFO: Created: latency-svc-lv6hl
Mar 27 09:03:18.352: INFO: Got endpoints: latency-svc-89vvs [3.338585863s]
Mar 27 09:03:18.381: INFO: Got endpoints: latency-svc-lv6hl [3.336883476s]
Mar 27 09:03:18.448: INFO: Created: latency-svc-tdbkd
Mar 27 09:03:18.593: INFO: Got endpoints: latency-svc-tdbkd [3.514751639s]
Mar 27 09:03:18.670: INFO: Created: latency-svc-l4tkv
Mar 27 09:03:18.685: INFO: Got endpoints: latency-svc-l4tkv [3.541051856s]
Mar 27 09:03:18.816: INFO: Created: latency-svc-66wrn
Mar 27 09:03:18.867: INFO: Created: latency-svc-h9d7f
Mar 27 09:03:18.867: INFO: Got endpoints: latency-svc-66wrn [3.705479873s]
Mar 27 09:03:18.896: INFO: Got endpoints: latency-svc-h9d7f [3.411280131s]
Mar 27 09:03:19.078: INFO: Created: latency-svc-njsvd
Mar 27 09:03:19.078: INFO: Got endpoints: latency-svc-njsvd [3.44349698s]
Mar 27 09:03:19.193: INFO: Created: latency-svc-jj62k
Mar 27 09:03:19.272: INFO: Created: latency-svc-wlc66
Mar 27 09:03:19.273: INFO: Got endpoints: latency-svc-jj62k [3.031388805s]
Mar 27 09:03:19.386: INFO: Got endpoints: latency-svc-wlc66 [2.793323237s]
Mar 27 09:03:19.397: INFO: Created: latency-svc-tlg2v
Mar 27 09:03:19.415: INFO: Got endpoints: latency-svc-tlg2v [2.767230208s]
Mar 27 09:03:19.472: INFO: Created: latency-svc-4d4zr
Mar 27 09:03:19.483: INFO: Got endpoints: latency-svc-4d4zr [2.611057263s]
Mar 27 09:03:19.722: INFO: Created: latency-svc-pblc6
Mar 27 09:03:19.773: INFO: Got endpoints: latency-svc-pblc6 [2.295425272s]
Mar 27 09:03:19.773: INFO: Created: latency-svc-rqvcn
Mar 27 09:03:20.006: INFO: Got endpoints: latency-svc-rqvcn [2.447729559s]
Mar 27 09:03:20.007: INFO: Created: latency-svc-qqk57
Mar 27 09:03:20.087: INFO: Got endpoints: latency-svc-qqk57 [2.271225022s]
Mar 27 09:03:20.273: INFO: Created: latency-svc-pz24k
Mar 27 09:03:20.370: INFO: Got endpoints: latency-svc-pz24k [2.288012353s]
Mar 27 09:03:20.593: INFO: Created: latency-svc-bhz78
Mar 27 09:03:20.955: INFO: Got endpoints: latency-svc-bhz78 [2.6035179s]
Mar 27 09:03:21.236: INFO: Created: latency-svc-wrgjj
Mar 27 09:03:21.290: INFO: Created: latency-svc-sfpb7
Mar 27 09:03:21.290: INFO: Got endpoints: latency-svc-wrgjj [2.909443088s]
Mar 27 09:03:21.531: INFO: Got endpoints: latency-svc-sfpb7 [2.937923311s]
Mar 27 09:03:21.618: INFO: Created: latency-svc-789ph
Mar 27 09:03:21.745: INFO: Got endpoints: latency-svc-789ph [3.059844258s]
Mar 27 09:03:21.779: INFO: Created: latency-svc-wvdkk
Mar 27 09:03:21.820: INFO: Got endpoints: latency-svc-wvdkk [2.952924165s]
Mar 27 09:03:21.915: INFO: Created: latency-svc-mq4kb
Mar 27 09:03:21.929: INFO: Got endpoints: latency-svc-mq4kb [183.485119ms]
Mar 27 09:03:21.974: INFO: Created: latency-svc-cx22c
Mar 27 09:03:22.258: INFO: Got endpoints: latency-svc-cx22c [3.361241582s]
Mar 27 09:03:22.259: INFO: Created: latency-svc-dnfx6
Mar 27 09:03:22.332: INFO: Got endpoints: latency-svc-dnfx6 [3.254392826s]
Mar 27 09:03:22.550: INFO: Created: latency-svc-7qfwb
Mar 27 09:03:22.594: INFO: Got endpoints: latency-svc-7qfwb [3.321883235s]
Mar 27 09:03:22.594: INFO: Created: latency-svc-n2vwj
Mar 27 09:03:22.806: INFO: Got endpoints: latency-svc-n2vwj [3.419561006s]
Mar 27 09:03:22.835: INFO: Created: latency-svc-qch9v
Mar 27 09:03:22.858: INFO: Got endpoints: latency-svc-qch9v [3.443055823s]
Mar 27 09:03:23.040: INFO: Created: latency-svc-ljfds
Mar 27 09:03:23.100: INFO: Got endpoints: latency-svc-ljfds [3.616889246s]
Mar 27 09:03:23.101: INFO: Created: latency-svc-p8m7q
Mar 27 09:03:23.244: INFO: Got endpoints: latency-svc-p8m7q [3.470686075s]
Mar 27 09:03:23.257: INFO: Created: latency-svc-zfftv
Mar 27 09:03:23.293: INFO: Got endpoints: latency-svc-zfftv [3.285978912s]
Mar 27 09:03:23.766: INFO: Created: latency-svc-ksqfm
Mar 27 09:03:24.011: INFO: Got endpoints: latency-svc-ksqfm [3.923948957s]
Mar 27 09:03:24.011: INFO: Created: latency-svc-hczrg
Mar 27 09:03:24.103: INFO: Got endpoints: latency-svc-hczrg [3.732729577s]
Mar 27 09:03:24.201: INFO: Created: latency-svc-d2fjm
Mar 27 09:03:24.236: INFO: Got endpoints: latency-svc-d2fjm [3.280425349s]
Mar 27 09:03:24.352: INFO: Created: latency-svc-qz559
Mar 27 09:03:24.390: INFO: Got endpoints: latency-svc-qz559 [3.099363615s]
Mar 27 09:03:24.390: INFO: Created: latency-svc-blcpb
Mar 27 09:03:24.420: INFO: Got endpoints: latency-svc-blcpb [2.888934149s]
Mar 27 09:03:24.503: INFO: Created: latency-svc-pkj24
Mar 27 09:03:24.556: INFO: Created: latency-svc-pfrs5
Mar 27 09:03:24.556: INFO: Got endpoints: latency-svc-pkj24 [2.735336907s]
Mar 27 09:03:24.695: INFO: Got endpoints: latency-svc-pfrs5 [2.765887624s]
Mar 27 09:03:24.713: INFO: Created: latency-svc-tmsqd
Mar 27 09:03:24.731: INFO: Got endpoints: latency-svc-tmsqd [2.473239669s]
Mar 27 09:03:24.860: INFO: Created: latency-svc-gvt7n
Mar 27 09:03:24.886: INFO: Created: latency-svc-mkhqt
Mar 27 09:03:24.887: INFO: Got endpoints: latency-svc-gvt7n [2.554364016s]
Mar 27 09:03:24.889: INFO: Got endpoints: latency-svc-mkhqt [2.294470087s]
Mar 27 09:03:24.932: INFO: Created: latency-svc-qxntg
Mar 27 09:03:24.949: INFO: Got endpoints: latency-svc-qxntg [2.143323726s]
Mar 27 09:03:25.023: INFO: Created: latency-svc-9hrsh
Mar 27 09:03:25.050: INFO: Created: latency-svc-kxfgj
Mar 27 09:03:25.050: INFO: Got endpoints: latency-svc-9hrsh [2.191975243s]
Mar 27 09:03:25.057: INFO: Got endpoints: latency-svc-kxfgj [1.957052668s]
Mar 27 09:03:25.080: INFO: Created: latency-svc-6js28
Mar 27 09:03:25.086: INFO: Got endpoints: latency-svc-6js28 [1.842539512s]
Mar 27 09:03:25.112: INFO: Created: latency-svc-g5c78
Mar 27 09:03:25.182: INFO: Got endpoints: latency-svc-g5c78 [1.88888413s]
Mar 27 09:03:25.182: INFO: Created: latency-svc-kn6pp
Mar 27 09:03:25.221: INFO: Got endpoints: latency-svc-kn6pp [1.209385356s]
Mar 27 09:03:25.221: INFO: Latencies: [183.485119ms 207.536494ms 396.138645ms 469.401659ms 813.003312ms 973.403747ms 988.863722ms 1.000765721s 1.018029304s 1.028672666s 1.038740455s 1.040490891s 1.044872231s 1.061597357s 1.078568176s 1.093930525s 1.096900321s 1.118460248s 1.120487036s 1.122449775s 1.13207514s 1.14167857s 1.14866329s 1.151988357s 1.153594648s 1.153709806s 1.17198411s 1.17648949s 1.185142074s 1.186113922s 1.198859681s 1.199262921s 1.20016146s 1.207675258s 1.209385356s 1.214960102s 1.225366724s 1.23816624s 1.239184739s 1.248081586s 1.263695303s 1.291896568s 1.309049516s 1.339133143s 1.344164765s 1.363748815s 1.37439018s 1.376107984s 1.385713445s 1.404718167s 1.415388561s 1.433394899s 1.435013783s 1.435251401s 1.444240279s 1.460606368s 1.51514164s 1.526453815s 1.527781716s 1.551080942s 1.55308217s 1.555706911s 1.563037812s 1.5723136s 1.582949457s 1.604255602s 1.605219495s 1.609726967s 1.620820277s 1.626439358s 1.640821508s 1.656283425s 1.665980754s 1.673114379s 1.701734699s 1.726287873s 1.753889326s 1.7631835s 1.797805661s 1.79846293s 1.810055521s 1.811510916s 1.836969456s 1.841022104s 1.842539512s 1.844722704s 1.844844471s 1.845990012s 1.88888413s 1.892752691s 1.89360872s 1.906593187s 1.921693854s 1.921909105s 1.928730047s 1.957052668s 1.969692174s 1.974913223s 1.981496859s 1.986667266s 1.994990339s 2.004876336s 2.016605214s 2.01837255s 2.041568448s 2.070884317s 2.08931588s 2.089618361s 2.091672247s 2.118290963s 2.143323726s 2.156955361s 2.159493717s 2.168635196s 2.191975243s 2.194224023s 2.203609735s 2.210836661s 2.211374995s 2.271225022s 2.288012353s 2.292946179s 2.294470087s 2.295425272s 2.315192162s 2.31928244s 2.332406541s 2.368798131s 2.382988403s 2.387242655s 2.395811433s 2.447729559s 2.467745814s 2.473239669s 2.514005541s 2.5466025s 2.554364016s 2.554794813s 2.559788177s 2.560537946s 2.563450899s 2.584268635s 2.6035179s 2.611057263s 2.634258064s 2.638443502s 2.720698865s 2.729011768s 2.735336907s 2.765887624s 2.767230208s 2.780243119s 2.793323237s 2.805661035s 2.859924256s 2.862842666s 2.86334832s 2.868017766s 2.888934149s 2.909443088s 2.937923311s 2.951747294s 2.952924165s 2.960039321s 2.968095308s 2.992142222s 3.007607642s 3.031388805s 3.059844258s 3.067938802s 3.07450053s 3.099363615s 3.112413899s 3.171727113s 3.175679447s 3.200161108s 3.227078501s 3.254392826s 3.280425349s 3.285978912s 3.286983108s 3.301663586s 3.321883235s 3.336883476s 3.338585863s 3.361241582s 3.411280131s 3.419561006s 3.443055823s 3.44349698s 3.466461787s 3.470686075s 3.514751639s 3.541051856s 3.616889246s 3.66745287s 3.705479873s 3.728902481s 3.732729577s 3.923948957s]
Mar 27 09:03:25.221: INFO: 50 %ile: 1.994990339s
Mar 27 09:03:25.221: INFO: 90 %ile: 3.286983108s
Mar 27 09:03:25.221: INFO: 99 %ile: 3.732729577s
Mar 27 09:03:25.221: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:03:25.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4572" for this suite.

• [SLOW TEST:41.116 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":280,"completed":13,"skipped":291,"failed":0}
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:03:25.444: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 27 09:03:25.630: INFO: Waiting up to 5m0s for pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476" in namespace "downward-api-5261" to be "success or failure"
Mar 27 09:03:25.680: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 50.234201ms
Mar 27 09:03:27.682: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052411561s
Mar 27 09:03:29.684: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054522271s
Mar 27 09:03:31.747: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 6.116989582s
Mar 27 09:03:33.817: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187771987s
Mar 27 09:03:35.976: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 10.346861493s
Mar 27 09:03:38.075: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Pending", Reason="", readiness=false. Elapsed: 12.444917748s
Mar 27 09:03:40.198: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.568566562s
STEP: Saw pod success
Mar 27 09:03:40.198: INFO: Pod "downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476" satisfied condition "success or failure"
Mar 27 09:03:40.256: INFO: Trying to get logs from node 172.22.33.41 pod downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476 container dapi-container: <nil>
STEP: delete the pod
Mar 27 09:03:43.116: INFO: Waiting for pod downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476 to disappear
Mar 27 09:03:43.400: INFO: Pod downward-api-217755e4-bac1-470f-a8a1-db85a9ffa476 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:03:43.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5261" for this suite.

• [SLOW TEST:19.730 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":280,"completed":14,"skipped":300,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:03:45.175: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 27 09:03:48.956: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:04:05.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3658" for this suite.

• [SLOW TEST:20.671 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":280,"completed":15,"skipped":308,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:04:05.846: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-137
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 09:04:06.053: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 09:04:46.452: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.22.33.118:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-137 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:04:46.452: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:04:46.518: INFO: Found all expected endpoints: [netserver-0]
Mar 27 09:04:46.519: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.22.33.100:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-137 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:04:46.520: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:04:46.582: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:04:46.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-137" for this suite.

• [SLOW TEST:40.740 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":16,"skipped":315,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:04:46.586: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:04:59.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9521" for this suite.

• [SLOW TEST:13.000 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":280,"completed":17,"skipped":318,"failed":0}
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:04:59.587: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-00d3d235-f835-4341-8618-3208bd848f6f
STEP: Creating a pod to test consume secrets
Mar 27 09:04:59.704: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25" in namespace "projected-1424" to be "success or failure"
Mar 27 09:04:59.779: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 75.430363ms
Mar 27 09:05:01.781: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077509521s
Mar 27 09:05:03.784: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079587071s
Mar 27 09:05:05.786: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 6.081675893s
Mar 27 09:05:07.788: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083722071s
Mar 27 09:05:09.809: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Pending", Reason="", readiness=false. Elapsed: 10.104916063s
Mar 27 09:05:11.811: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.107156059s
STEP: Saw pod success
Mar 27 09:05:11.811: INFO: Pod "pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25" satisfied condition "success or failure"
Mar 27 09:05:11.813: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:05:12.040: INFO: Waiting for pod pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25 to disappear
Mar 27 09:05:12.325: INFO: Pod pod-projected-secrets-5db0dfa4-e60e-477e-8416-3cee639d6d25 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:05:12.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1424" for this suite.

• [SLOW TEST:12.743 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":18,"skipped":321,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:05:12.332: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 27 09:05:26.122: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:05:26.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4733" for this suite.

• [SLOW TEST:13.916 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:131
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":19,"skipped":350,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:05:26.249: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-8f8ae6c6-1a44-4cf8-9f46-88920492f419
STEP: Creating a pod to test consume configMaps
Mar 27 09:05:26.763: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e" in namespace "projected-301" to be "success or failure"
Mar 27 09:05:27.137: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 374.103774ms
Mar 27 09:05:29.139: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.37629395s
Mar 27 09:05:31.142: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.378542777s
Mar 27 09:05:33.144: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.380812997s
Mar 27 09:05:35.146: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.383120655s
Mar 27 09:05:37.149: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.385394932s
Mar 27 09:05:39.151: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.387572073s
STEP: Saw pod success
Mar 27 09:05:39.151: INFO: Pod "pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e" satisfied condition "success or failure"
Mar 27 09:05:39.152: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:05:39.191: INFO: Waiting for pod pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e to disappear
Mar 27 09:05:39.215: INFO: Pod pod-projected-configmaps-ff800aea-f37d-4c72-bb66-fbd23e2aa76e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:05:39.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-301" for this suite.

• [SLOW TEST:12.969 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":20,"skipped":373,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:05:39.219: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:05:40.288: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:05:42.292: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:05:44.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:05:46.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:05:48.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:05:50.294: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896740, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:05:53.370: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:05:54.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9578" for this suite.
STEP: Destroying namespace "webhook-9578-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.853 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":280,"completed":21,"skipped":391,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:05:55.073: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d0431e75-047c-418c-a527-ea7c66597408
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d0431e75-047c-418c-a527-ea7c66597408
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:07:34.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2629" for this suite.

• [SLOW TEST:99.140 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":22,"skipped":440,"failed":0}
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:07:34.213: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:07:46.872: INFO: Waiting up to 5m0s for pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af" in namespace "pods-8344" to be "success or failure"
Mar 27 09:07:47.156: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 283.644224ms
Mar 27 09:07:49.158: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.285768046s
Mar 27 09:07:51.160: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 4.287570351s
Mar 27 09:07:53.162: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 6.289664974s
Mar 27 09:07:55.164: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 8.29168703s
Mar 27 09:07:57.188: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 10.31540621s
Mar 27 09:07:59.190: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Pending", Reason="", readiness=false. Elapsed: 12.31738945s
Mar 27 09:08:01.192: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.31964078s
STEP: Saw pod success
Mar 27 09:08:01.192: INFO: Pod "client-envvars-c87bc3b8-8def-4241-8369-d933218f57af" satisfied condition "success or failure"
Mar 27 09:08:01.194: INFO: Trying to get logs from node 172.22.33.41 pod client-envvars-c87bc3b8-8def-4241-8369-d933218f57af container env3cont: <nil>
STEP: delete the pod
Mar 27 09:08:01.442: INFO: Waiting for pod client-envvars-c87bc3b8-8def-4241-8369-d933218f57af to disappear
Mar 27 09:08:01.503: INFO: Pod client-envvars-c87bc3b8-8def-4241-8369-d933218f57af no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:08:01.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8344" for this suite.

• [SLOW TEST:27.576 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":280,"completed":23,"skipped":440,"failed":0}
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:08:01.789: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:08:18.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7051" for this suite.

• [SLOW TEST:16.681 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":280,"completed":24,"skipped":444,"failed":0}
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:08:18.471: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:08:25.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1476" for this suite.

• [SLOW TEST:7.160 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":280,"completed":25,"skipped":447,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:08:25.634: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:08:26.261: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:08:28.265: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:08:30.276: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:08:32.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:08:34.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:08:36.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:08:38.268: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896906, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:08:41.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:08:41.307: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1022-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:08:42.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4915" for this suite.
STEP: Destroying namespace "webhook-4915-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.043 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":280,"completed":26,"skipped":506,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:08:42.678: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:08:55.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4767" for this suite.

• [SLOW TEST:13.262 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":280,"completed":27,"skipped":506,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:08:55.940: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:125
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:08:56.402: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar 27 09:08:58.988: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:00.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:02.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:04.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:06.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:08.990: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896936, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-78dcf5dd84\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:09:12.013: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:09:12.015: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:09:13.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7196" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:136

• [SLOW TEST:18.640 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":280,"completed":28,"skipped":515,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:09:14.580: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:09:15.070: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c" in namespace "downward-api-6111" to be "success or failure"
Mar 27 09:09:15.212: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 141.512768ms
Mar 27 09:09:17.214: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143422869s
Mar 27 09:09:19.216: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.145589827s
Mar 27 09:09:21.218: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147749716s
Mar 27 09:09:23.220: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.149922109s
Mar 27 09:09:25.222: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.152216887s
Mar 27 09:09:27.225: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.154451286s
Mar 27 09:09:29.227: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.156703353s
STEP: Saw pod success
Mar 27 09:09:29.227: INFO: Pod "downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c" satisfied condition "success or failure"
Mar 27 09:09:29.228: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c container client-container: <nil>
STEP: delete the pod
Mar 27 09:09:29.539: INFO: Waiting for pod downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c to disappear
Mar 27 09:09:29.632: INFO: Pod downwardapi-volume-fa53a868-2394-4da1-bb48-50a96ec1c65c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:09:29.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6111" for this suite.

• [SLOW TEST:15.056 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":29,"skipped":545,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:09:29.638: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:09:31.146: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:09:33.151: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896970, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:35.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896970, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:37.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896970, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:39.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896970, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:09:41.153: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896971, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720896970, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:09:44.288: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:09:44.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-751" for this suite.
STEP: Destroying namespace "webhook-751-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.214 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":280,"completed":30,"skipped":581,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:09:44.853: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:09:45.193: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 27 09:09:48.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-1594 create -f -'
Mar 27 09:09:51.857: INFO: stderr: ""
Mar 27 09:09:51.857: INFO: stdout: "e2e-test-crd-publish-openapi-72-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar 27 09:09:51.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-1594 delete e2e-test-crd-publish-openapi-72-crds test-cr'
Mar 27 09:09:52.029: INFO: stderr: ""
Mar 27 09:09:52.029: INFO: stdout: "e2e-test-crd-publish-openapi-72-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Mar 27 09:09:52.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-1594 apply -f -'
Mar 27 09:09:52.555: INFO: stderr: ""
Mar 27 09:09:52.555: INFO: stdout: "e2e-test-crd-publish-openapi-72-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar 27 09:09:52.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-1594 delete e2e-test-crd-publish-openapi-72-crds test-cr'
Mar 27 09:09:52.762: INFO: stderr: ""
Mar 27 09:09:52.762: INFO: stdout: "e2e-test-crd-publish-openapi-72-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar 27 09:09:52.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-72-crds'
Mar 27 09:09:53.344: INFO: stderr: ""
Mar 27 09:09:53.344: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-72-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:09:55.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1594" for this suite.

• [SLOW TEST:10.515 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":280,"completed":31,"skipped":606,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:09:55.368: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:09:55.477: INFO: Waiting up to 5m0s for pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a" in namespace "projected-2564" to be "success or failure"
Mar 27 09:09:55.507: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 30.174061ms
Mar 27 09:09:57.509: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032291045s
Mar 27 09:09:59.511: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034535417s
Mar 27 09:10:01.513: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036707383s
Mar 27 09:10:03.515: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038687197s
Mar 27 09:10:05.518: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.041333101s
Mar 27 09:10:07.520: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.043538923s
STEP: Saw pod success
Mar 27 09:10:07.520: INFO: Pod "downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a" satisfied condition "success or failure"
Mar 27 09:10:07.522: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a container client-container: <nil>
STEP: delete the pod
Mar 27 09:10:07.751: INFO: Waiting for pod downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a to disappear
Mar 27 09:10:07.795: INFO: Pod downwardapi-volume-245beca1-8522-44e6-bea2-32b5b9576a2a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:10:07.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2564" for this suite.

• [SLOW TEST:12.430 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":280,"completed":32,"skipped":617,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:10:07.799: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 27 09:10:08.528: INFO: Waiting up to 5m0s for pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98" in namespace "downward-api-2530" to be "success or failure"
Mar 27 09:10:08.627: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 98.411979ms
Mar 27 09:10:10.629: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.100518s
Mar 27 09:10:12.631: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.102651557s
Mar 27 09:10:14.633: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 6.104655846s
Mar 27 09:10:16.635: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 8.106556286s
Mar 27 09:10:18.760: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Pending", Reason="", readiness=false. Elapsed: 10.231806057s
Mar 27 09:10:20.762: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.233844232s
STEP: Saw pod success
Mar 27 09:10:20.762: INFO: Pod "downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98" satisfied condition "success or failure"
Mar 27 09:10:20.763: INFO: Trying to get logs from node 172.22.33.41 pod downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98 container dapi-container: <nil>
STEP: delete the pod
Mar 27 09:10:21.011: INFO: Waiting for pod downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98 to disappear
Mar 27 09:10:21.212: INFO: Pod downward-api-665b28c1-5b14-4697-a4fa-1995c615fc98 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:10:21.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2530" for this suite.

• [SLOW TEST:13.475 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":280,"completed":33,"skipped":632,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:10:21.275: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-3d5abd9d-ff85-458b-a913-f6961735f141
STEP: Creating secret with name s-test-opt-upd-eaac4157-c99a-4e8e-aa2a-43156ab4e000
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3d5abd9d-ff85-458b-a913-f6961735f141
STEP: Updating secret s-test-opt-upd-eaac4157-c99a-4e8e-aa2a-43156ab4e000
STEP: Creating secret with name s-test-opt-create-6d2c02ec-d764-4555-87e6-239956cb091b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:12:01.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3654" for this suite.

• [SLOW TEST:99.826 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":34,"skipped":642,"failed":0}
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:12:01.101: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 27 09:12:01.603: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 09:12:01.608: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 09:12:01.609: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.40 before test
Mar 27 09:12:01.620: INFO: zte-k8s-eviction-68f598776b-qxjnw from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:12:01.620: INFO: 	Container zte-k8s-eviction ready: true, restart count 0
Mar 27 09:12:01.620: INFO: sonobuoy-e2e-job-d8cb2578911a4e68 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:12:01.620: INFO: 	Container e2e ready: true, restart count 0
Mar 27 09:12:01.620: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:12:01.620: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:12:01.621: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:12:01.621: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:12:01.621: INFO: coredns-f589df4f5-d98zd from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:12:01.621: INFO: 	Container coredns ready: true, restart count 19
Mar 27 09:12:01.621: INFO: sonobuoy from sonobuoy started at 2020-03-27 08:57:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:12:01.621: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 09:12:01.621: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.41 before test
Mar 27 09:12:01.624: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s from sonobuoy started at 2020-03-27 08:58:18 +0000 UTC (2 container statuses recorded)
Mar 27 09:12:01.624: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:12:01.624: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:12:01.624: INFO: pod-projected-secrets-63a2d7fd-a09e-408c-a108-1ec975e2b053 from projected-3654 started at 2020-03-27 09:10:21 +0000 UTC (3 container statuses recorded)
Mar 27 09:12:01.624: INFO: 	Container creates-volume-test ready: true, restart count 0
Mar 27 09:12:01.624: INFO: 	Container dels-volume-test ready: true, restart count 0
Mar 27 09:12:01.624: INFO: 	Container upds-volume-test ready: true, restart count 0
Mar 27 09:12:01.624: INFO: iag-172.22.33.41 from kube-system started at 2020-03-26 02:05:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:12:01.624: INFO: 	Container iag ready: true, restart count 3
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ade6ac47-5b1c-48f6-9b5b-1fc15a171dc0 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-ade6ac47-5b1c-48f6-9b5b-1fc15a171dc0 off the node 172.22.33.41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ade6ac47-5b1c-48f6-9b5b-1fc15a171dc0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:17:28.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9874" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:327.236 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":280,"completed":35,"skipped":650,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:17:28.338: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name s-test-opt-del-0f42ddae-3e2f-4f5e-93fc-137d6d34b849
STEP: Creating secret with name s-test-opt-upd-b4bec2ad-49ae-4d52-bfd1-1a70850ebeb4
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-0f42ddae-3e2f-4f5e-93fc-137d6d34b849
STEP: Updating secret s-test-opt-upd-b4bec2ad-49ae-4d52-bfd1-1a70850ebeb4
STEP: Creating secret with name s-test-opt-create-9eb16dc2-b41c-44d4-8c7e-aded01498ff4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:18:56.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9995" for this suite.

• [SLOW TEST:87.723 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":36,"skipped":668,"failed":0}
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:18:56.063: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:18:56.929: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"c7c3a36e-ad86-467f-b33e-31772e2a3d88", Controller:(*bool)(0xc002b6c35a), BlockOwnerDeletion:(*bool)(0xc002b6c35b)}}
Mar 27 09:18:57.003: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"be163b3b-18ec-400d-bae8-cc945f9778db", Controller:(*bool)(0xc0034a151a), BlockOwnerDeletion:(*bool)(0xc0034a151b)}}
Mar 27 09:18:57.041: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"43a43f02-012c-457d-b2b0-830d7d41022d", Controller:(*bool)(0xc002b6c52a), BlockOwnerDeletion:(*bool)(0xc002b6c52b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:19:02.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6584" for this suite.

• [SLOW TEST:6.062 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":280,"completed":37,"skipped":668,"failed":0}
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:19:02.125: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 27 09:19:02.254: INFO: Waiting up to 5m0s for pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b" in namespace "emptydir-7327" to be "success or failure"
Mar 27 09:19:02.270: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 15.507001ms
Mar 27 09:19:04.272: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017689509s
Mar 27 09:19:06.274: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019780403s
Mar 27 09:19:08.276: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021925871s
Mar 27 09:19:10.279: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024032944s
Mar 27 09:19:12.281: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026819328s
Mar 27 09:19:14.284: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.02902949s
Mar 27 09:19:16.356: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 14.101080279s
Mar 27 09:19:18.358: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.103184534s
Mar 27 09:19:20.360: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.105525032s
Mar 27 09:19:22.362: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.107819386s
Mar 27 09:19:24.364: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.10997006s
Mar 27 09:19:26.367: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 24.112260551s
Mar 27 09:19:28.369: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.114503642s
Mar 27 09:19:30.371: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 28.116824551s
Mar 27 09:19:32.374: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Pending", Reason="", readiness=false. Elapsed: 30.119110653s
Mar 27 09:19:34.376: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.121205449s
STEP: Saw pod success
Mar 27 09:19:34.376: INFO: Pod "pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b" satisfied condition "success or failure"
Mar 27 09:19:34.377: INFO: Trying to get logs from node 172.22.33.41 pod pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b container test-container: <nil>
STEP: delete the pod
Mar 27 09:19:34.426: INFO: Waiting for pod pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b to disappear
Mar 27 09:19:34.559: INFO: Pod pod-5bd9a7a5-a239-4e83-bf32-74e3fa4fda3b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:19:34.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7327" for this suite.

• [SLOW TEST:32.437 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":38,"skipped":672,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:19:34.563: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-68f8c932-c39f-4d18-bd53-17350d05f3e6
STEP: Creating a pod to test consume secrets
Mar 27 09:19:34.731: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d" in namespace "projected-2133" to be "success or failure"
Mar 27 09:19:34.741: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.273844ms
Mar 27 09:19:36.743: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011901636s
Mar 27 09:19:38.745: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014076765s
Mar 27 09:19:40.747: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016246787s
Mar 27 09:19:42.749: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018358758s
Mar 27 09:19:44.760: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029003911s
Mar 27 09:19:46.762: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.031287392s
STEP: Saw pod success
Mar 27 09:19:46.763: INFO: Pod "pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d" satisfied condition "success or failure"
Mar 27 09:19:46.764: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:19:47.000: INFO: Waiting for pod pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d to disappear
Mar 27 09:19:47.061: INFO: Pod pod-projected-secrets-13628066-86cf-4a6d-baf7-224f1cc40f7d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:19:47.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2133" for this suite.

• [SLOW TEST:12.692 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":39,"skipped":682,"failed":0}
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:19:47.255: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar 27 09:19:47.439: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-928 /api/v1/namespaces/watch-928/configmaps/e2e-watch-test-resource-version 6b977eb9-394f-4aac-911d-7e8f3d4c4ce2 336897 0 2020-03-27 09:19:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 09:19:47.439: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-928 /api/v1/namespaces/watch-928/configmaps/e2e-watch-test-resource-version 6b977eb9-394f-4aac-911d-7e8f3d4c4ce2 336898 0 2020-03-27 09:19:47 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:19:47.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-928" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":280,"completed":40,"skipped":684,"failed":0}
S
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:19:47.565: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:19:48.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-4642" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":280,"completed":41,"skipped":685,"failed":0}
SSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:19:48.069: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:344
Mar 27 09:19:48.125: INFO: Waiting up to 1m0s for all nodes to be ready
Mar 27 09:20:48.134: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:20:48.135: INFO: Starting informer...
STEP: Starting pods...
Mar 27 09:20:48.379: INFO: Pod1 is running on 172.22.33.41. Tainting Node
Mar 27 09:21:03.295: INFO: Pod2 is running on 172.22.33.41. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Mar 27 09:21:11.372: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Mar 27 09:21:31.879: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:21:31.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-5171" for this suite.

• [SLOW TEST:103.883 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":280,"completed":42,"skipped":690,"failed":0}
S
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:21:31.952: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:21:32.755: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e" in namespace "security-context-test-540" to be "success or failure"
Mar 27 09:21:32.786: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 30.133599ms
Mar 27 09:21:34.788: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032349515s
Mar 27 09:21:36.790: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03451642s
Mar 27 09:21:38.792: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.036712453s
Mar 27 09:21:40.794: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038748617s
Mar 27 09:21:42.796: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.040739282s
Mar 27 09:21:44.798: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.04295848s
Mar 27 09:21:44.799: INFO: Pod "alpine-nnp-false-ba9dd332-ace6-4a00-965d-32037671a03e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:21:44.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-540" for this suite.

• [SLOW TEST:12.861 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:289
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":43,"skipped":691,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:21:44.813: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:21:45.745: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef" in namespace "projected-3728" to be "success or failure"
Mar 27 09:21:46.055: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 310.11945ms
Mar 27 09:21:48.076: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.331295185s
Mar 27 09:21:50.114: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.369461409s
Mar 27 09:21:52.117: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.37180169s
Mar 27 09:21:54.119: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.374063334s
Mar 27 09:21:56.121: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.376487033s
Mar 27 09:21:58.156: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Pending", Reason="", readiness=false. Elapsed: 12.410813457s
Mar 27 09:22:00.196: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.451511431s
STEP: Saw pod success
Mar 27 09:22:00.196: INFO: Pod "downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef" satisfied condition "success or failure"
Mar 27 09:22:00.342: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef container client-container: <nil>
STEP: delete the pod
Mar 27 09:22:00.381: INFO: Waiting for pod downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef to disappear
Mar 27 09:22:00.645: INFO: Pod downwardapi-volume-8fe11b7b-c174-4d6b-8a1d-00fc117250ef no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:22:00.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3728" for this suite.

• [SLOW TEST:15.836 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":280,"completed":44,"skipped":699,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:22:00.651: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating all guestbook components
Mar 27 09:22:01.940: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Mar 27 09:22:01.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:05.539: INFO: stderr: ""
Mar 27 09:22:05.539: INFO: stdout: "service/agnhost-slave created\n"
Mar 27 09:22:05.539: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Mar 27 09:22:05.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:05.887: INFO: stderr: ""
Mar 27 09:22:05.887: INFO: stdout: "service/agnhost-master created\n"
Mar 27 09:22:05.887: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar 27 09:22:05.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:06.336: INFO: stderr: ""
Mar 27 09:22:06.336: INFO: stdout: "service/frontend created\n"
Mar 27 09:22:06.337: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Mar 27 09:22:06.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:06.658: INFO: stderr: ""
Mar 27 09:22:06.658: INFO: stdout: "deployment.apps/frontend created\n"
Mar 27 09:22:06.658: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 27 09:22:06.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:06.926: INFO: stderr: ""
Mar 27 09:22:06.926: INFO: stdout: "deployment.apps/agnhost-master created\n"
Mar 27 09:22:06.927: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/kubernetes-e2e-test-images/agnhost:2.8
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar 27 09:22:06.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-7775'
Mar 27 09:22:07.214: INFO: stderr: ""
Mar 27 09:22:07.214: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Mar 27 09:22:07.214: INFO: Waiting for all frontend pods to be Running.
Mar 27 09:22:27.265: INFO: Waiting for frontend to serve content.
Mar 27 09:22:27.279: INFO: Trying to add a new entry to the guestbook.
Mar 27 09:22:27.301: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar 27 09:22:27.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:27.479: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:27.479: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 09:22:27.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:27.745: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:27.745: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 09:22:27.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:28.016: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:28.016: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 09:22:28.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:28.159: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:28.159: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 09:22:28.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:28.298: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:28.298: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Mar 27 09:22:28.298: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-7775'
Mar 27 09:22:28.516: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 09:22:28.516: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:22:28.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7775" for this suite.

• [SLOW TEST:27.982 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:386
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":280,"completed":45,"skipped":732,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:22:28.633: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 27 09:22:30.093: INFO: Waiting up to 5m0s for pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187" in namespace "emptydir-2593" to be "success or failure"
Mar 27 09:22:30.447: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 354.669411ms
Mar 27 09:22:32.752: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 2.65896825s
Mar 27 09:22:34.888: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 4.795666773s
Mar 27 09:22:36.890: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 6.797715403s
Mar 27 09:22:38.892: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 8.799868371s
Mar 27 09:22:40.894: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 10.801445617s
Mar 27 09:22:42.896: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 12.803431359s
Mar 27 09:22:44.898: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 14.805463534s
Mar 27 09:22:46.902: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 16.809641119s
Mar 27 09:22:48.904: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 18.811657023s
Mar 27 09:22:50.906: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 20.813685316s
Mar 27 09:22:52.914: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 22.8212256s
Mar 27 09:22:54.916: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 24.823200774s
Mar 27 09:22:56.918: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 26.825260769s
Mar 27 09:22:58.920: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 28.827211539s
Mar 27 09:23:00.922: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 30.829136474s
Mar 27 09:23:02.924: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Pending", Reason="", readiness=false. Elapsed: 32.83121429s
Mar 27 09:23:04.926: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.833222738s
STEP: Saw pod success
Mar 27 09:23:04.926: INFO: Pod "pod-ce6db22c-dcce-495a-906e-5898e2cee187" satisfied condition "success or failure"
Mar 27 09:23:04.927: INFO: Trying to get logs from node 172.22.33.41 pod pod-ce6db22c-dcce-495a-906e-5898e2cee187 container test-container: <nil>
STEP: delete the pod
Mar 27 09:23:05.072: INFO: Waiting for pod pod-ce6db22c-dcce-495a-906e-5898e2cee187 to disappear
Mar 27 09:23:05.291: INFO: Pod pod-ce6db22c-dcce-495a-906e-5898e2cee187 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:23:05.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2593" for this suite.

• [SLOW TEST:36.661 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":46,"skipped":744,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:23:05.294: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating replication controller my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687
Mar 27 09:23:05.695: INFO: Pod name my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687: Found 0 pods out of 1
Mar 27 09:23:10.697: INFO: Pod name my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687: Found 1 pods out of 1
Mar 27 09:23:10.697: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687" are running
Mar 27 09:23:16.757: INFO: Pod "my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687-nlvld" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 09:23:05 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 09:23:05 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 09:23:05 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 09:23:05 +0000 UTC Reason: Message:}])
Mar 27 09:23:16.757: INFO: Trying to dial the pod
Mar 27 09:23:21.764: INFO: Controller my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687: Got expected result from replica 1 [my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687-nlvld]: "my-hostname-basic-58e9f0cb-29d7-4baf-a591-e8fbd6a2b687-nlvld", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:23:21.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-818" for this suite.

• [SLOW TEST:16.473 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":47,"skipped":762,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:23:21.768: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:23:21.852: INFO: Creating deployment "test-recreate-deployment"
Mar 27 09:23:21.855: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar 27 09:23:21.885: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Mar 27 09:23:23.888: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar 27 09:23:23.889: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897802, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:23:25.891: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897802, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:23:27.902: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897802, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:23:29.892: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897802, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:23:31.959: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897802, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720897801, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-799c574856\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:23:33.891: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar 27 09:23:33.894: INFO: Updating deployment test-recreate-deployment
Mar 27 09:23:33.894: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 27 09:23:35.271: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7748 /apis/apps/v1/namespaces/deployment-7748/deployments/test-recreate-deployment 46216043-41d0-47dc-b41d-f9b779761493 337585 2 2020-03-27 09:23:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00356ead8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-27 09:23:34 +0000 UTC,LastTransitionTime:2020-03-27 09:23:34 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-03-27 09:23:35 +0000 UTC,LastTransitionTime:2020-03-27 09:23:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Mar 27 09:23:35.273: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-7748 /apis/apps/v1/namespaces/deployment-7748/replicasets/test-recreate-deployment-5f94c574ff 4c56c5b1-2297-4f0d-a118-38f2cfd68a62 337582 1 2020-03-27 09:23:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 46216043-41d0-47dc-b41d-f9b779761493 0xc00356eea7 0xc00356eea8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00356ef08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 09:23:35.273: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar 27 09:23:35.273: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-799c574856  deployment-7748 /apis/apps/v1/namespaces/deployment-7748/replicasets/test-recreate-deployment-799c574856 6daa0e72-1683-4626-a504-72945ca6dce1 337572 2 2020-03-27 09:23:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 46216043-41d0-47dc-b41d-f9b779761493 0xc00356ef77 0xc00356ef78}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 799c574856,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:799c574856] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00356efe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 09:23:35.275: INFO: Pod "test-recreate-deployment-5f94c574ff-clmdh" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-clmdh test-recreate-deployment-5f94c574ff- deployment-7748 /api/v1/namespaces/deployment-7748/pods/test-recreate-deployment-5f94c574ff-clmdh af0637e2-ebd7-437c-80f7-8efc1c1eb230 337584 0 2020-03-27 09:23:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 4c56c5b1-2297-4f0d-a118-38f2cfd68a62 0xc00356f467 0xc00356f468}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cwkbz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cwkbz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cwkbz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:23:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:23:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:23:34 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:23:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 09:23:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:23:35.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7748" for this suite.

• [SLOW TEST:13.510 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":48,"skipped":775,"failed":0}
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:23:35.278: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Mar 27 09:24:10.465: INFO: Successfully updated pod "adopt-release-9dz7d"
STEP: Checking that the Job readopts the Pod
Mar 27 09:24:10.465: INFO: Waiting up to 15m0s for pod "adopt-release-9dz7d" in namespace "job-5856" to be "adopted"
Mar 27 09:24:10.496: INFO: Pod "adopt-release-9dz7d": Phase="Running", Reason="", readiness=true. Elapsed: 30.949074ms
Mar 27 09:24:12.606: INFO: Pod "adopt-release-9dz7d": Phase="Running", Reason="", readiness=true. Elapsed: 2.141067972s
Mar 27 09:24:12.606: INFO: Pod "adopt-release-9dz7d" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Mar 27 09:24:13.111: INFO: Successfully updated pod "adopt-release-9dz7d"
STEP: Checking that the Job releases the Pod
Mar 27 09:24:13.111: INFO: Waiting up to 15m0s for pod "adopt-release-9dz7d" in namespace "job-5856" to be "released"
Mar 27 09:24:13.277: INFO: Pod "adopt-release-9dz7d": Phase="Running", Reason="", readiness=true. Elapsed: 165.709725ms
Mar 27 09:24:13.277: INFO: Pod "adopt-release-9dz7d" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:24:13.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5856" for this suite.

• [SLOW TEST:38.044 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":280,"completed":49,"skipped":775,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:24:13.324: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating pod
Mar 27 09:24:25.721: INFO: Pod pod-hostip-0c38ba37-ceb3-458f-b7e0-1f3a08e12eaf has hostIP: 172.22.33.41
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:24:25.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3939" for this suite.

• [SLOW TEST:12.400 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":280,"completed":50,"skipped":798,"failed":0}
SSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:24:25.725: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:24:25.843: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85" in namespace "security-context-test-8779" to be "success or failure"
Mar 27 09:24:25.858: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 14.436495ms
Mar 27 09:24:27.860: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016593504s
Mar 27 09:24:29.862: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01870883s
Mar 27 09:24:31.864: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 6.020725174s
Mar 27 09:24:33.866: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 8.022788156s
Mar 27 09:24:35.868: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Pending", Reason="", readiness=false. Elapsed: 10.024810628s
Mar 27 09:24:37.870: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.026858373s
Mar 27 09:24:37.870: INFO: Pod "busybox-readonly-false-cebb6d8b-0a4b-498f-a8ef-97a49b9dde85" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:24:37.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8779" for this suite.

• [SLOW TEST:12.149 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:164
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":280,"completed":51,"skipped":803,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:24:37.878: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0327 09:24:48.530123      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 09:24:48.530: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:24:48.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5419" for this suite.

• [SLOW TEST:10.656 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":280,"completed":52,"skipped":897,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:24:48.537: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:24:48.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1533" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":280,"completed":53,"skipped":974,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:24:49.398: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:24:50.327: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604" in namespace "projected-3365" to be "success or failure"
Mar 27 09:24:50.329: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 1.479774ms
Mar 27 09:24:52.382: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054516295s
Mar 27 09:24:54.384: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 4.056716045s
Mar 27 09:24:56.386: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058423732s
Mar 27 09:24:58.388: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 8.060609652s
Mar 27 09:25:00.390: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 10.06266787s
Mar 27 09:25:02.392: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Pending", Reason="", readiness=false. Elapsed: 12.064838413s
Mar 27 09:25:04.395: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.067048872s
STEP: Saw pod success
Mar 27 09:25:04.395: INFO: Pod "downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604" satisfied condition "success or failure"
Mar 27 09:25:04.396: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604 container client-container: <nil>
STEP: delete the pod
Mar 27 09:25:04.524: INFO: Waiting for pod downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604 to disappear
Mar 27 09:25:04.540: INFO: Pod downwardapi-volume-3e862568-8e91-451b-8c47-24c59a464604 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:25:04.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3365" for this suite.

• [SLOW TEST:15.146 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":54,"skipped":991,"failed":0}
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:25:04.544: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 27 09:25:28.806: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 09:25:28.893: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 09:25:30.893: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 09:25:30.908: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 09:25:32.893: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 09:25:32.917: INFO: Pod pod-with-poststart-exec-hook still exists
Mar 27 09:25:34.893: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar 27 09:25:34.895: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:25:34.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7200" for this suite.

• [SLOW TEST:30.355 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":280,"completed":55,"skipped":991,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:25:34.900: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:25:35.050: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37" in namespace "security-context-test-5571" to be "success or failure"
Mar 27 09:25:35.231: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 180.318203ms
Mar 27 09:25:37.232: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.181933128s
Mar 27 09:25:39.235: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 4.184038919s
Mar 27 09:25:41.237: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 6.186074122s
Mar 27 09:25:43.239: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 8.188170867s
Mar 27 09:25:45.241: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Pending", Reason="", readiness=false. Elapsed: 10.190306229s
Mar 27 09:25:47.243: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.192135869s
Mar 27 09:25:47.243: INFO: Pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37" satisfied condition "success or failure"
Mar 27 09:25:47.247: INFO: Got logs for pod "busybox-privileged-false-280c4c0b-b221-4bcf-a995-5840e3c3ba37": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:25:47.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5571" for this suite.

• [SLOW TEST:12.350 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  When creating a pod with privileged
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:225
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":56,"skipped":1007,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:25:47.251: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6450.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6450.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 09:26:21.759: INFO: DNS probes using dns-6450/dns-test-32349485-f460-4a1a-8932-aa4297b22df5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:26:21.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6450" for this suite.

• [SLOW TEST:34.643 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":280,"completed":57,"skipped":1012,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:26:21.895: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: executing a command with run --rm and attach with stdin
Mar 27 09:26:22.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=kubectl-7373 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar 27 09:26:33.129: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar 27 09:26:33.129: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:26:35.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7373" for this suite.

• [SLOW TEST:13.247 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1944
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run --rm job should create a job from an image, then delete the job  [Conformance]","total":280,"completed":58,"skipped":1016,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:26:35.142: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:26:35.493: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:26:42.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6259" for this suite.

• [SLOW TEST:7.842 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:47
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":280,"completed":59,"skipped":1022,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:26:42.986: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar 27 09:26:43.836: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8398 /api/v1/namespaces/watch-8398/configmaps/e2e-watch-test-watch-closed 6ea552f4-cb75-4700-8a36-a5a268447351 338213 0 2020-03-27 09:26:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 09:26:43.836: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8398 /api/v1/namespaces/watch-8398/configmaps/e2e-watch-test-watch-closed 6ea552f4-cb75-4700-8a36-a5a268447351 338215 0 2020-03-27 09:26:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar 27 09:26:43.900: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8398 /api/v1/namespaces/watch-8398/configmaps/e2e-watch-test-watch-closed 6ea552f4-cb75-4700-8a36-a5a268447351 338216 0 2020-03-27 09:26:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 09:26:43.900: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8398 /api/v1/namespaces/watch-8398/configmaps/e2e-watch-test-watch-closed 6ea552f4-cb75-4700-8a36-a5a268447351 338217 0 2020-03-27 09:26:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:26:43.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8398" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":280,"completed":60,"skipped":1039,"failed":0}
SSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:26:43.993: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 27 09:26:44.246: INFO: Waiting up to 5m0s for pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60" in namespace "downward-api-8778" to be "success or failure"
Mar 27 09:26:44.251: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.403853ms
Mar 27 09:26:46.253: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006840799s
Mar 27 09:26:48.260: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013654132s
Mar 27 09:26:50.341: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 6.094413774s
Mar 27 09:26:52.344: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 8.096928106s
Mar 27 09:26:54.346: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Pending", Reason="", readiness=false. Elapsed: 10.099056829s
Mar 27 09:26:56.348: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.101098522s
STEP: Saw pod success
Mar 27 09:26:56.348: INFO: Pod "downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60" satisfied condition "success or failure"
Mar 27 09:26:56.349: INFO: Trying to get logs from node 172.22.33.41 pod downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60 container dapi-container: <nil>
STEP: delete the pod
Mar 27 09:26:56.587: INFO: Waiting for pod downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60 to disappear
Mar 27 09:26:56.769: INFO: Pod downward-api-ddf193a9-71dd-4d31-8490-1d1d6b926c60 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:26:56.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8778" for this suite.

• [SLOW TEST:12.780 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":280,"completed":61,"skipped":1044,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:26:56.775: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:27:12.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4302" for this suite.

• [SLOW TEST:15.520 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":280,"completed":62,"skipped":1069,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:27:12.295: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-e3796c75-2860-4b8d-9685-a6f68bb3de76
STEP: Creating a pod to test consume configMaps
Mar 27 09:27:12.365: INFO: Waiting up to 5m0s for pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed" in namespace "configmap-6065" to be "success or failure"
Mar 27 09:27:12.387: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 21.670514ms
Mar 27 09:27:14.389: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023913114s
Mar 27 09:27:16.391: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025879807s
Mar 27 09:27:18.394: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 6.029608284s
Mar 27 09:27:20.407: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042245145s
Mar 27 09:27:22.409: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.04451858s
Mar 27 09:27:24.432: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.067244415s
STEP: Saw pod success
Mar 27 09:27:24.432: INFO: Pod "pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed" satisfied condition "success or failure"
Mar 27 09:27:24.434: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:27:24.627: INFO: Waiting for pod pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed to disappear
Mar 27 09:27:24.645: INFO: Pod pod-configmaps-97f3e8c3-0832-4502-bb95-668d13e9baed no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:27:24.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6065" for this suite.

• [SLOW TEST:12.354 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":63,"skipped":1150,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:27:24.650: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar 27 09:27:24.721: INFO: Waiting up to 5m0s for pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9" in namespace "emptydir-516" to be "success or failure"
Mar 27 09:27:24.873: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 151.202482ms
Mar 27 09:27:26.875: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.153195149s
Mar 27 09:27:28.877: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155252742s
Mar 27 09:27:30.879: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157279576s
Mar 27 09:27:32.881: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.159545357s
Mar 27 09:27:34.883: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.161738581s
Mar 27 09:27:36.885: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.1636878s
Mar 27 09:27:38.887: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.165867328s
Mar 27 09:27:40.889: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.167890232s
Mar 27 09:27:42.892: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.170000072s
Mar 27 09:27:44.894: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.172311137s
Mar 27 09:27:46.896: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.174397708s
Mar 27 09:27:48.898: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.176528007s
Mar 27 09:27:50.905: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.183033615s
Mar 27 09:27:52.907: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 28.185138266s
Mar 27 09:27:54.999: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Pending", Reason="", readiness=false. Elapsed: 30.277267537s
Mar 27 09:27:57.001: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.279065377s
STEP: Saw pod success
Mar 27 09:27:57.001: INFO: Pod "pod-952d6d67-e8ce-452c-802f-5b2638d701f9" satisfied condition "success or failure"
Mar 27 09:27:57.002: INFO: Trying to get logs from node 172.22.33.41 pod pod-952d6d67-e8ce-452c-802f-5b2638d701f9 container test-container: <nil>
STEP: delete the pod
Mar 27 09:27:57.240: INFO: Waiting for pod pod-952d6d67-e8ce-452c-802f-5b2638d701f9 to disappear
Mar 27 09:27:57.309: INFO: Pod pod-952d6d67-e8ce-452c-802f-5b2638d701f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:27:57.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-516" for this suite.

• [SLOW TEST:32.663 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":64,"skipped":1177,"failed":0}
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:27:57.313: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-2754/configmap-test-a38c97e9-0df0-4f9a-8528-01430bec0edd
STEP: Creating a pod to test consume configMaps
Mar 27 09:27:58.512: INFO: Waiting up to 5m0s for pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427" in namespace "configmap-2754" to be "success or failure"
Mar 27 09:27:58.708: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 196.224776ms
Mar 27 09:28:01.008: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.495672802s
Mar 27 09:28:03.010: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497685712s
Mar 27 09:28:05.012: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 6.499750457s
Mar 27 09:28:07.014: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 8.501890595s
Mar 27 09:28:09.016: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 10.504032213s
Mar 27 09:28:11.018: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Pending", Reason="", readiness=false. Elapsed: 12.506021709s
Mar 27 09:28:13.020: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.508244851s
STEP: Saw pod success
Mar 27 09:28:13.020: INFO: Pod "pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427" satisfied condition "success or failure"
Mar 27 09:28:13.022: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427 container env-test: <nil>
STEP: delete the pod
Mar 27 09:28:13.068: INFO: Waiting for pod pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427 to disappear
Mar 27 09:28:13.269: INFO: Pod pod-configmaps-cddb2ce8-79a0-412d-95ef-a147584c8427 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:28:13.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2754" for this suite.

• [SLOW TEST:15.960 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":280,"completed":65,"skipped":1179,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:28:13.274: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:28:13.535: INFO: Waiting up to 5m0s for pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be" in namespace "downward-api-370" to be "success or failure"
Mar 27 09:28:13.686: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 151.523967ms
Mar 27 09:28:15.688: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.153510168s
Mar 27 09:28:17.690: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.155495595s
Mar 27 09:28:19.692: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 6.157448293s
Mar 27 09:28:21.694: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 8.159572623s
Mar 27 09:28:23.696: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Pending", Reason="", readiness=false. Elapsed: 10.161450415s
Mar 27 09:28:25.752: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.217570444s
STEP: Saw pod success
Mar 27 09:28:25.753: INFO: Pod "downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be" satisfied condition "success or failure"
Mar 27 09:28:25.754: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be container client-container: <nil>
STEP: delete the pod
Mar 27 09:28:25.789: INFO: Waiting for pod downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be to disappear
Mar 27 09:28:25.834: INFO: Pod downwardapi-volume-454e2f13-217e-43fe-93d9-f1315d5533be no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:28:25.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-370" for this suite.

• [SLOW TEST:12.564 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":66,"skipped":1194,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:28:25.839: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:28:26.304: INFO: Waiting up to 5m0s for pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f" in namespace "projected-7306" to be "success or failure"
Mar 27 09:28:26.343: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 38.700735ms
Mar 27 09:28:28.345: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040791969s
Mar 27 09:28:30.459: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154709308s
Mar 27 09:28:32.461: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.156811334s
Mar 27 09:28:34.596: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.291447124s
Mar 27 09:28:36.598: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.293706342s
Mar 27 09:28:38.600: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.295918429s
STEP: Saw pod success
Mar 27 09:28:38.600: INFO: Pod "downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f" satisfied condition "success or failure"
Mar 27 09:28:38.602: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f container client-container: <nil>
STEP: delete the pod
Mar 27 09:28:38.821: INFO: Waiting for pod downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f to disappear
Mar 27 09:28:38.909: INFO: Pod downwardapi-volume-669a074b-1003-408a-8708-4973f48a923f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:28:38.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7306" for this suite.

• [SLOW TEST:13.074 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":67,"skipped":1201,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:28:38.912: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar 27 09:28:39.538: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 27 09:28:56.573: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:28:56.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7336" for this suite.

• [SLOW TEST:17.665 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":280,"completed":68,"skipped":1213,"failed":0}
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:28:56.578: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run default
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1596
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:28:56.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9622'
Mar 27 09:28:56.949: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 09:28:56.949: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1602
Mar 27 09:28:58.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9622'
Mar 27 09:28:59.157: INFO: stderr: ""
Mar 27 09:28:59.157: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:28:59.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9622" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run default should create an rc or deployment from an image  [Conformance]","total":280,"completed":69,"skipped":1213,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:28:59.162: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 27 09:28:59.584: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 09:28:59.676: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 09:28:59.810: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.40 before test
Mar 27 09:28:59.822: INFO: sonobuoy from sonobuoy started at 2020-03-27 08:57:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:28:59.822: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 09:28:59.822: INFO: coredns-f589df4f5-d98zd from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:28:59.822: INFO: 	Container coredns ready: true, restart count 19
Mar 27 09:28:59.822: INFO: zte-k8s-eviction-68f598776b-qxjnw from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:28:59.822: INFO: 	Container zte-k8s-eviction ready: true, restart count 0
Mar 27 09:28:59.822: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:28:59.822: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:28:59.822: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:28:59.822: INFO: sonobuoy-e2e-job-d8cb2578911a4e68 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:28:59.822: INFO: 	Container e2e ready: true, restart count 0
Mar 27 09:28:59.822: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:28:59.822: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.41 before test
Mar 27 09:28:59.825: INFO: iag-172.22.33.41 from kube-system started at 2020-03-26 02:05:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:28:59.825: INFO: 	Container iag ready: true, restart count 3
Mar 27 09:28:59.825: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s from sonobuoy started at 2020-03-27 08:58:18 +0000 UTC (2 container statuses recorded)
Mar 27 09:28:59.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:28:59.825: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:28:59.825: INFO: e2e-test-httpd-deployment-594dddd44f-5ftkh from kubectl-9622 started at 2020-03-27 09:28:56 +0000 UTC (1 container statuses recorded)
Mar 27 09:28:59.825: INFO: 	Container e2e-test-httpd-deployment ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c9b2330f-90db-4951-924d-85ebf28799e7 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c9b2330f-90db-4951-924d-85ebf28799e7 off the node 172.22.33.41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c9b2330f-90db-4951-924d-85ebf28799e7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:29:26.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6939" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:27.070 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":280,"completed":70,"skipped":1225,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:29:26.233: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1897
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:29:26.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7674'
Mar 27 09:29:26.395: INFO: stderr: ""
Mar 27 09:29:26.395: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Mar 27 09:29:41.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pod e2e-test-httpd-pod --namespace=kubectl-7674 -o json'
Mar 27 09:29:41.521: INFO: stderr: ""
Mar 27 09:29:41.521: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"network.knitter.io/configuration-result\": \"{\\\"version\\\":\\\"v1\\\",\\\"ports\\\":[{\\\"function\\\":\\\"std\\\",\\\"network_name\\\":\\\"net_api\\\",\\\"ip_address\\\":\\\"172.22.33.17\\\",\\\"ipv6_address\\\":\\\"\\\",\\\"layer_type\\\":\\\"layer3\\\"}]}\"\n        },\n        \"creationTimestamp\": \"2020-03-27T09:29:26Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7674\",\n        \"resourceVersion\": \"338725\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7674/pods/e2e-test-httpd-pod\",\n        \"uid\": \"1ba2c9e8-be32-4ede-bac8-243564687df1\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-hkf6l\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"172.22.33.41\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-hkf6l\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-hkf6l\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-27T09:29:26Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-27T09:29:38Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-27T09:29:38Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-27T09:29:26Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://690f44e948adb631396a327e6af3ef1c363378cc147e0f42ce3a68f308229d61\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-27T09:29:37Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.22.33.41\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.22.33.17\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.22.33.17\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-27T09:29:26Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar 27 09:29:41.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 replace -f - --namespace=kubectl-7674'
Mar 27 09:29:41.902: INFO: stderr: ""
Mar 27 09:29:41.902: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1902
Mar 27 09:29:41.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete pods e2e-test-httpd-pod --namespace=kubectl-7674'
Mar 27 09:29:43.870: INFO: stderr: ""
Mar 27 09:29:43.870: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:29:43.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7674" for this suite.

• [SLOW TEST:17.669 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1893
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":280,"completed":71,"skipped":1236,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:29:43.902: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1788
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:29:44.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7861'
Mar 27 09:29:44.184: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 09:29:44.184: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1793
Mar 27 09:29:44.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete jobs e2e-test-httpd-job --namespace=kubectl-7861'
Mar 27 09:29:44.429: INFO: stderr: ""
Mar 27 09:29:44.429: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:29:44.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7861" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run job should create a job from an image when restart is OnFailure  [Conformance]","total":280,"completed":72,"skipped":1270,"failed":0}

------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:29:44.433: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's args
Mar 27 09:29:44.967: INFO: Waiting up to 5m0s for pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14" in namespace "var-expansion-6861" to be "success or failure"
Mar 27 09:29:45.109: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 142.00622ms
Mar 27 09:29:47.111: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.143920833s
Mar 27 09:29:49.146: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 4.178452243s
Mar 27 09:29:51.148: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 6.180535381s
Mar 27 09:29:53.150: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 8.182637326s
Mar 27 09:29:55.152: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 10.184633652s
Mar 27 09:29:57.154: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Pending", Reason="", readiness=false. Elapsed: 12.186731496s
Mar 27 09:29:59.156: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.18878302s
STEP: Saw pod success
Mar 27 09:29:59.156: INFO: Pod "var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14" satisfied condition "success or failure"
Mar 27 09:29:59.158: INFO: Trying to get logs from node 172.22.33.41 pod var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14 container dapi-container: <nil>
STEP: delete the pod
Mar 27 09:29:59.201: INFO: Waiting for pod var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14 to disappear
Mar 27 09:29:59.427: INFO: Pod var-expansion-d974c61b-7ad5-436b-921e-5b76ed63ae14 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:29:59.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6861" for this suite.

• [SLOW TEST:14.998 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":280,"completed":73,"skipped":1270,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:29:59.431: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:30:01.250: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:30:03.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:30:05.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:30:07.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:30:09.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:30:11.262: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898201, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:30:14.399: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:30:14.401: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:30:15.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1411" for this suite.
STEP: Destroying namespace "webhook-1411-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.497 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":280,"completed":74,"skipped":1285,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:30:15.928: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar 27 09:30:56.387: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0327 09:30:56.387626      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:30:56.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4038" for this suite.

• [SLOW TEST:40.462 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":280,"completed":75,"skipped":1292,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:30:56.391: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-c7e46ead-723f-4898-a9fe-105936c47655 in namespace container-probe-7775
Mar 27 09:31:08.988: INFO: Started pod liveness-c7e46ead-723f-4898-a9fe-105936c47655 in namespace container-probe-7775
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 09:31:08.990: INFO: Initial restart count of pod liveness-c7e46ead-723f-4898-a9fe-105936c47655 is 0
Mar 27 09:31:25.008: INFO: Restart count of pod container-probe-7775/liveness-c7e46ead-723f-4898-a9fe-105936c47655 is now 1 (16.01816775s elapsed)
Mar 27 09:31:45.157: INFO: Restart count of pod container-probe-7775/liveness-c7e46ead-723f-4898-a9fe-105936c47655 is now 2 (36.167379512s elapsed)
Mar 27 09:32:05.198: INFO: Restart count of pod container-probe-7775/liveness-c7e46ead-723f-4898-a9fe-105936c47655 is now 3 (56.208223181s elapsed)
Mar 27 09:32:25.337: INFO: Restart count of pod container-probe-7775/liveness-c7e46ead-723f-4898-a9fe-105936c47655 is now 4 (1m16.347317987s elapsed)
Mar 27 09:33:27.520: INFO: Restart count of pod container-probe-7775/liveness-c7e46ead-723f-4898-a9fe-105936c47655 is now 5 (2m18.530817227s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:33:27.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7775" for this suite.

• [SLOW TEST:151.286 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":280,"completed":76,"skipped":1303,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:33:27.678: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:33:27.840: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Creating first CR 
Mar 27 09:33:28.828: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:28Z generation:1 name:name1 resourceVersion:339318 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3340ef5c-e116-415e-ad03-3c91d4832d0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Mar 27 09:33:38.833: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:38Z generation:1 name:name2 resourceVersion:339343 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:bbe61546-7507-4a07-bec0-5fe949ad1ead] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Mar 27 09:33:48.837: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:28Z generation:2 name:name1 resourceVersion:339355 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3340ef5c-e116-415e-ad03-3c91d4832d0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Mar 27 09:33:58.841: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:38Z generation:2 name:name2 resourceVersion:339367 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:bbe61546-7507-4a07-bec0-5fe949ad1ead] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Mar 27 09:34:08.845: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:28Z generation:2 name:name1 resourceVersion:339379 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3340ef5c-e116-415e-ad03-3c91d4832d0e] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Mar 27 09:34:18.851: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-27T09:33:38Z generation:2 name:name2 resourceVersion:339391 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:bbe61546-7507-4a07-bec0-5fe949ad1ead] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:34:29.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7267" for this suite.

• [SLOW TEST:61.685 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:41
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":280,"completed":77,"skipped":1304,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:34:29.364: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod test-webserver-350d91a5-fd6e-4ae7-b954-3098e78659b5 in namespace container-probe-2861
Mar 27 09:34:42.141: INFO: Started pod test-webserver-350d91a5-fd6e-4ae7-b954-3098e78659b5 in namespace container-probe-2861
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 09:34:42.143: INFO: Initial restart count of pod test-webserver-350d91a5-fd6e-4ae7-b954-3098e78659b5 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:38:43.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2861" for this suite.

• [SLOW TEST:253.927 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":78,"skipped":1327,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:38:43.291: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 27 09:38:56.093: INFO: Successfully updated pod "labelsupdatecf8c041f-dc6e-4eb0-a434-73ffb348c850"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:38:58.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2533" for this suite.

• [SLOW TEST:14.875 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":79,"skipped":1332,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:38:58.167: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar 27 09:39:22.647: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 09:39:22.788: INFO: Pod pod-with-poststart-http-hook still exists
Mar 27 09:39:24.788: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 09:39:24.790: INFO: Pod pod-with-poststart-http-hook still exists
Mar 27 09:39:26.788: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar 27 09:39:26.790: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:39:26.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7544" for this suite.

• [SLOW TEST:28.628 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":280,"completed":80,"skipped":1343,"failed":0}
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:39:26.795: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:39:54.987: INFO: Container started at 2020-03-27 09:39:36 +0000 UTC, pod became ready at 2020-03-27 09:39:54 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:39:54.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4597" for this suite.

• [SLOW TEST:28.196 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":280,"completed":81,"skipped":1355,"failed":0}
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:39:54.992: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7384
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 09:39:55.069: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 09:40:35.578: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.22.33.181 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7384 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:40:35.578: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:40:36.634: INFO: Found all expected endpoints: [netserver-0]
Mar 27 09:40:36.636: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.22.33.182 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7384 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:40:36.636: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:40:37.695: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:40:37.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7384" for this suite.

• [SLOW TEST:42.707 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":82,"skipped":1362,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:40:37.699: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-0459d3b1-86a6-4600-9480-3f7d8df10900
STEP: Creating a pod to test consume configMaps
Mar 27 09:40:37.847: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57" in namespace "projected-571" to be "success or failure"
Mar 27 09:40:38.056: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 209.391482ms
Mar 27 09:40:40.263: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.416232259s
Mar 27 09:40:42.266: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.418590459s
Mar 27 09:40:44.298: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 6.451082101s
Mar 27 09:40:46.300: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 8.453254848s
Mar 27 09:40:48.384: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 10.53729194s
Mar 27 09:40:50.387: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Pending", Reason="", readiness=false. Elapsed: 12.539439133s
Mar 27 09:40:52.389: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.541723757s
STEP: Saw pod success
Mar 27 09:40:52.389: INFO: Pod "pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57" satisfied condition "success or failure"
Mar 27 09:40:52.390: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:40:52.625: INFO: Waiting for pod pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57 to disappear
Mar 27 09:40:52.689: INFO: Pod pod-projected-configmaps-acbb0ac2-edc8-4099-94d4-92cfd5390c57 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:40:52.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-571" for this suite.

• [SLOW TEST:14.993 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":83,"skipped":1376,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:40:52.693: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Mar 27 09:40:52.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-2005'
Mar 27 09:40:56.227: INFO: stderr: ""
Mar 27 09:40:56.227: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 27 09:40:57.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:40:57.230: INFO: Found 0 / 1
Mar 27 09:40:58.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:40:58.230: INFO: Found 0 / 1
Mar 27 09:40:59.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:40:59.230: INFO: Found 0 / 1
Mar 27 09:41:00.299: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:00.299: INFO: Found 0 / 1
Mar 27 09:41:01.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:01.230: INFO: Found 0 / 1
Mar 27 09:41:02.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:02.230: INFO: Found 0 / 1
Mar 27 09:41:03.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:03.230: INFO: Found 0 / 1
Mar 27 09:41:04.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:04.230: INFO: Found 0 / 1
Mar 27 09:41:05.251: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:05.251: INFO: Found 0 / 1
Mar 27 09:41:06.229: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:06.229: INFO: Found 0 / 1
Mar 27 09:41:07.230: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:07.230: INFO: Found 1 / 1
Mar 27 09:41:07.230: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar 27 09:41:07.231: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:07.231: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 09:41:07.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 patch pod agnhost-master-br26m --namespace=kubectl-2005 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar 27 09:41:07.315: INFO: stderr: ""
Mar 27 09:41:07.315: INFO: stdout: "pod/agnhost-master-br26m patched\n"
STEP: checking annotations
Mar 27 09:41:07.316: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 09:41:07.316: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:41:07.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2005" for this suite.

• [SLOW TEST:14.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1539
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":280,"completed":84,"skipped":1397,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:41:07.320: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:41:07.402: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d" in namespace "projected-781" to be "success or failure"
Mar 27 09:41:07.411: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.84155ms
Mar 27 09:41:09.618: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215906168s
Mar 27 09:41:11.620: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.217914487s
Mar 27 09:41:13.622: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.219956487s
Mar 27 09:41:15.624: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.221625537s
Mar 27 09:41:17.626: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.223681314s
Mar 27 09:41:19.704: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.301888573s
Mar 27 09:41:21.706: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.303935883s
STEP: Saw pod success
Mar 27 09:41:21.706: INFO: Pod "downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d" satisfied condition "success or failure"
Mar 27 09:41:21.708: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d container client-container: <nil>
STEP: delete the pod
Mar 27 09:41:21.756: INFO: Waiting for pod downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d to disappear
Mar 27 09:41:21.987: INFO: Pod downwardapi-volume-63c5addb-ca54-4809-bae2-599912fb682d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:41:21.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-781" for this suite.

• [SLOW TEST:14.670 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":85,"skipped":1429,"failed":0}
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:41:21.991: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:41:23.237: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:41:25.247: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:41:27.251: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:41:29.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:41:31.249: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:41:33.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720898883, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:41:36.284: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:41:37.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3179" for this suite.
STEP: Destroying namespace "webhook-3179-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.409 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":280,"completed":86,"skipped":1429,"failed":0}
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:41:37.401: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-30c56d89-7fb8-4caa-a12a-a6e44ea62eae
STEP: Creating a pod to test consume secrets
Mar 27 09:41:37.595: INFO: Waiting up to 5m0s for pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c" in namespace "secrets-7328" to be "success or failure"
Mar 27 09:41:37.712: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 116.224429ms
Mar 27 09:41:39.789: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.193850203s
Mar 27 09:41:41.791: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.195977109s
Mar 27 09:41:43.793: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197932596s
Mar 27 09:41:45.795: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.200045562s
Mar 27 09:41:47.798: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.202105555s
Mar 27 09:41:49.800: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.204364475s
Mar 27 09:41:51.802: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.20652497s
STEP: Saw pod success
Mar 27 09:41:51.802: INFO: Pod "pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c" satisfied condition "success or failure"
Mar 27 09:41:51.803: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:41:51.863: INFO: Waiting for pod pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c to disappear
Mar 27 09:41:52.143: INFO: Pod pod-secrets-eb87199f-2f21-4a40-883e-a122f610b16c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:41:52.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7328" for this suite.

• [SLOW TEST:14.746 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":87,"skipped":1432,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:41:52.148: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 27 09:42:05.642: INFO: Successfully updated pod "labelsupdate0bcce29c-b80d-4f18-8d83-f02ee289b0fb"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:42:07.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9879" for this suite.

• [SLOW TEST:15.515 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":280,"completed":88,"skipped":1450,"failed":0}
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:42:07.663: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 27 09:42:31.915: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 09:42:31.981: INFO: Pod pod-with-prestop-http-hook still exists
Mar 27 09:42:33.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 09:42:33.984: INFO: Pod pod-with-prestop-http-hook still exists
Mar 27 09:42:35.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 09:42:35.984: INFO: Pod pod-with-prestop-http-hook still exists
Mar 27 09:42:37.982: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar 27 09:42:37.984: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:42:37.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2976" for this suite.

• [SLOW TEST:30.331 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":280,"completed":89,"skipped":1458,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:42:37.996: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap that has name configmap-test-emptyKey-a5db5b79-50a9-4a6b-9d91-1a0f29306f07
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:42:38.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7723" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":280,"completed":90,"skipped":1499,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:42:38.114: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:42:38.257: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5" in namespace "downward-api-4235" to be "success or failure"
Mar 27 09:42:38.273: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.14735ms
Mar 27 09:42:40.276: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018498737s
Mar 27 09:42:42.278: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020519282s
Mar 27 09:42:44.280: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022540098s
Mar 27 09:42:46.291: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033988188s
Mar 27 09:42:48.293: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036377603s
Mar 27 09:42:50.486: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.228709499s
STEP: Saw pod success
Mar 27 09:42:50.486: INFO: Pod "downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5" satisfied condition "success or failure"
Mar 27 09:42:50.487: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5 container client-container: <nil>
STEP: delete the pod
Mar 27 09:42:50.719: INFO: Waiting for pod downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5 to disappear
Mar 27 09:42:50.804: INFO: Pod downwardapi-volume-c557921c-4919-4b18-aae5-230f7ad6a9c5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:42:50.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4235" for this suite.

• [SLOW TEST:12.694 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":280,"completed":91,"skipped":1516,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:42:50.809: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-6ca0beb9-8f22-4c5c-8f9f-02327a56f8a9
STEP: Creating a pod to test consume secrets
Mar 27 09:42:52.175: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7" in namespace "projected-7085" to be "success or failure"
Mar 27 09:42:52.492: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 316.077677ms
Mar 27 09:42:54.494: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.318140616s
Mar 27 09:42:56.540: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.364870746s
Mar 27 09:42:58.542: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.36694313s
Mar 27 09:43:00.545: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.369264518s
Mar 27 09:43:02.746: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.570565062s
Mar 27 09:43:04.748: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.572701682s
STEP: Saw pod success
Mar 27 09:43:04.748: INFO: Pod "pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7" satisfied condition "success or failure"
Mar 27 09:43:04.750: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:43:04.775: INFO: Waiting for pod pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7 to disappear
Mar 27 09:43:04.818: INFO: Pod pod-projected-secrets-dff1bc90-c219-4d31-b911-0c2e50f223f7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:43:04.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7085" for this suite.

• [SLOW TEST:14.013 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":92,"skipped":1532,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:43:04.822: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-map-b7523b32-757a-4238-8f61-8e9eb79eb54e
STEP: Creating a pod to test consume secrets
Mar 27 09:43:05.201: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714" in namespace "projected-1570" to be "success or failure"
Mar 27 09:43:05.234: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 33.059105ms
Mar 27 09:43:07.236: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034773472s
Mar 27 09:43:09.238: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03701204s
Mar 27 09:43:11.241: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 6.03915692s
Mar 27 09:43:13.253: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 8.051364142s
Mar 27 09:43:15.255: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Pending", Reason="", readiness=false. Elapsed: 10.053408679s
Mar 27 09:43:17.257: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.055829201s
STEP: Saw pod success
Mar 27 09:43:17.257: INFO: Pod "pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714" satisfied condition "success or failure"
Mar 27 09:43:17.259: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:43:17.439: INFO: Waiting for pod pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714 to disappear
Mar 27 09:43:17.458: INFO: Pod pod-projected-secrets-03e8245b-2587-430e-be46-26e9cfca7714 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:43:17.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1570" for this suite.

• [SLOW TEST:12.639 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":93,"skipped":1543,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:43:17.465: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-6c07e657-1b2c-4a05-ba0a-cbfe48efeb09
STEP: Creating a pod to test consume secrets
Mar 27 09:43:17.657: INFO: Waiting up to 5m0s for pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8" in namespace "secrets-6324" to be "success or failure"
Mar 27 09:43:17.790: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 133.342328ms
Mar 27 09:43:19.793: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.135685573s
Mar 27 09:43:21.794: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.13744593s
Mar 27 09:43:23.797: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.139561606s
Mar 27 09:43:25.799: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.141685632s
Mar 27 09:43:27.801: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.143815429s
Mar 27 09:43:29.803: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.146116847s
STEP: Saw pod success
Mar 27 09:43:29.803: INFO: Pod "pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8" satisfied condition "success or failure"
Mar 27 09:43:29.805: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:43:29.932: INFO: Waiting for pod pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8 to disappear
Mar 27 09:43:30.260: INFO: Pod pod-secrets-f02c0d0a-7c3d-4783-b152-87f7d6b3fbc8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:43:30.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6324" for this suite.

• [SLOW TEST:13.038 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":94,"skipped":1618,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:43:30.504: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 27 09:43:30.711: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:43:44.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5797" for this suite.

• [SLOW TEST:13.987 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":280,"completed":95,"skipped":1631,"failed":0}
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:43:44.491: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 27 09:43:44.943: INFO: Waiting up to 5m0s for pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd" in namespace "emptydir-7762" to be "success or failure"
Mar 27 09:43:45.010: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 67.428309ms
Mar 27 09:43:47.012: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.06941028s
Mar 27 09:43:49.014: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071680324s
Mar 27 09:43:51.017: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.073942329s
Mar 27 09:43:53.027: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.084233873s
Mar 27 09:43:55.029: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.086742383s
Mar 27 09:43:57.032: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.088993592s
Mar 27 09:43:59.034: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.09107896s
Mar 27 09:44:01.036: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.093276991s
Mar 27 09:44:03.038: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.095529428s
Mar 27 09:44:05.040: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.097524781s
Mar 27 09:44:07.042: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 22.099730127s
Mar 27 09:44:09.045: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 24.101873228s
Mar 27 09:44:11.053: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 26.110483648s
Mar 27 09:44:13.056: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 28.112790196s
Mar 27 09:44:15.058: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Pending", Reason="", readiness=false. Elapsed: 30.114914342s
Mar 27 09:44:17.060: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.117068847s
STEP: Saw pod success
Mar 27 09:44:17.060: INFO: Pod "pod-e5839e3c-5336-4dff-a771-d5e064ef65dd" satisfied condition "success or failure"
Mar 27 09:44:17.061: INFO: Trying to get logs from node 172.22.33.41 pod pod-e5839e3c-5336-4dff-a771-d5e064ef65dd container test-container: <nil>
STEP: delete the pod
Mar 27 09:44:17.241: INFO: Waiting for pod pod-e5839e3c-5336-4dff-a771-d5e064ef65dd to disappear
Mar 27 09:44:17.292: INFO: Pod pod-e5839e3c-5336-4dff-a771-d5e064ef65dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:44:17.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7762" for this suite.

• [SLOW TEST:32.804 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":96,"skipped":1634,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:44:17.297: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:44:17.613: INFO: Pod name rollover-pod: Found 0 pods out of 1
Mar 27 09:44:22.630: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 09:44:28.646: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar 27 09:44:30.648: INFO: Creating deployment "test-rollover-deployment"
Mar 27 09:44:30.889: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar 27 09:44:32.892: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar 27 09:44:32.895: INFO: Ensure that both replica sets have 1 created replica
Mar 27 09:44:32.898: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar 27 09:44:32.905: INFO: Updating deployment test-rollover-deployment
Mar 27 09:44:32.905: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar 27 09:44:35.179: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar 27 09:44:35.182: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar 27 09:44:35.185: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:35.185: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899073, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:37.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:37.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899073, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:39.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:39.190: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899073, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:41.188: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:41.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899073, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:43.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:43.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899073, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:45.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:45.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899084, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:47.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:47.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899084, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:49.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:49.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899084, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:51.234: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:51.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899084, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:53.189: INFO: all replica sets need to contain the pod-template-hash label
Mar 27 09:44:53.189: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899071, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899084, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899070, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-574d6dfbff\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:44:55.189: INFO: 
Mar 27 09:44:55.189: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 27 09:44:55.192: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2881 /apis/apps/v1/namespaces/deployment-2881/deployments/test-rollover-deployment d1bea0fd-e2a5-49c3-b958-651ce9e538bf 340836 2 2020-03-27 09:44:30 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00191a4b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-27 09:44:31 +0000 UTC,LastTransitionTime:2020-03-27 09:44:31 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-574d6dfbff" has successfully progressed.,LastUpdateTime:2020-03-27 09:44:54 +0000 UTC,LastTransitionTime:2020-03-27 09:44:30 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar 27 09:44:55.194: INFO: New ReplicaSet "test-rollover-deployment-574d6dfbff" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-574d6dfbff  deployment-2881 /apis/apps/v1/namespaces/deployment-2881/replicasets/test-rollover-deployment-574d6dfbff 8d1fd227-1ca9-4318-bef5-510ac03963cb 340825 2 2020-03-27 09:44:32 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d1bea0fd-e2a5-49c3-b958-651ce9e538bf 0xc00191aa67 0xc00191aa68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 574d6dfbff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00191aad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 27 09:44:55.194: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar 27 09:44:55.194: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2881 /apis/apps/v1/namespaces/deployment-2881/replicasets/test-rollover-controller a06c5b26-de45-4474-9333-492e87527310 340834 2 2020-03-27 09:44:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d1bea0fd-e2a5-49c3-b958-651ce9e538bf 0xc00191a997 0xc00191a998}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00191a9f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 09:44:55.194: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-2881 /apis/apps/v1/namespaces/deployment-2881/replicasets/test-rollover-deployment-f6c94f66c ad75b0cc-8a12-47cc-bf0c-65eb2105f2f8 340790 2 2020-03-27 09:44:30 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d1bea0fd-e2a5-49c3-b958-651ce9e538bf 0xc00191ab40 0xc00191ab41}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00191abc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 09:44:55.196: INFO: Pod "test-rollover-deployment-574d6dfbff-sdh62" is available:
&Pod{ObjectMeta:{test-rollover-deployment-574d6dfbff-sdh62 test-rollover-deployment-574d6dfbff- deployment-2881 /api/v1/namespaces/deployment-2881/pods/test-rollover-deployment-574d6dfbff-sdh62 5c86d2ac-4b73-45fa-b2a1-f698a9fac023 340811 0 2020-03-27 09:44:33 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:574d6dfbff] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.200","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet test-rollover-deployment-574d6dfbff 8d1fd227-1ca9-4318-bef5-510ac03963cb 0xc00191b2d7 0xc00191b2d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-22fpc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-22fpc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-22fpc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:44:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:44:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:44:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 09:44:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.200,StartTime:2020-03-27 09:44:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 09:44:43 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:agnhost:2.12,ImageID:docker://sha256:21140f8e943083beda4f999e416557c8aa43ba360b0d288e6562f322f42abaf7,ContainerID:docker://6a5074799d92f47b8c9bca4178c7b24d803a84edf1e8f53c6e2ae9c92f669e28,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.200,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:44:55.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2881" for this suite.

• [SLOW TEST:37.957 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":280,"completed":97,"skipped":1653,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:44:55.255: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-53f3dcef-a0b4-4f15-9984-f44ce2004188
STEP: Creating a pod to test consume configMaps
Mar 27 09:44:55.576: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458" in namespace "configmap-4120" to be "success or failure"
Mar 27 09:44:55.614: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 37.633147ms
Mar 27 09:44:57.616: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039787848s
Mar 27 09:44:59.619: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042068168s
Mar 27 09:45:01.635: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 6.058528257s
Mar 27 09:45:03.637: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 8.060678512s
Mar 27 09:45:05.640: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Pending", Reason="", readiness=false. Elapsed: 10.063175212s
Mar 27 09:45:07.642: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.065361556s
STEP: Saw pod success
Mar 27 09:45:07.642: INFO: Pod "pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458" satisfied condition "success or failure"
Mar 27 09:45:07.643: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:45:07.839: INFO: Waiting for pod pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458 to disappear
Mar 27 09:45:07.884: INFO: Pod pod-configmaps-6f47af0d-046e-44f1-8a05-fbc5e2478458 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:45:07.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4120" for this suite.

• [SLOW TEST:12.633 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":98,"skipped":1663,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:45:07.889: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3958.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3958.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3958.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3958.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 27.20.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.20.27_udp@PTR;check="$$(dig +tcp +noall +answer +search 27.20.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.20.27_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3958.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3958.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3958.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3958.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3958.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3958.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 27.20.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.20.27_udp@PTR;check="$$(dig +tcp +noall +answer +search 27.20.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.20.27_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 09:45:42.681: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.682: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.683: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.685: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.695: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.696: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.698: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.699: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:42.707: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:45:47.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.711: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.714: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.723: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.724: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.726: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.727: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:47.735: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:45:52.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.712: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.715: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.724: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.726: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.729: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:52.738: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:45:57.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.712: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.714: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.725: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.726: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.727: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.728: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:45:57.736: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:46:02.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.712: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.715: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.724: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.725: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.726: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.727: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:02.735: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:46:07.710: INFO: Unable to read wheezy_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.712: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.713: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.715: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.725: INFO: Unable to read jessie_udp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.726: INFO: Unable to read jessie_tcp@dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.727: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.729: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local from pod dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a: the server could not find the requested resource (get pods dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a)
Mar 27 09:46:07.737: INFO: Lookups using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a failed for: [wheezy_udp@dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@dns-test-service.dns-3958.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_udp@dns-test-service.dns-3958.svc.cluster.local jessie_tcp@dns-test-service.dns-3958.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3958.svc.cluster.local]

Mar 27 09:46:12.745: INFO: DNS probes using dns-3958/dns-test-f11e68ee-2c17-4d10-acba-187a5439d26a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:46:13.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3958" for this suite.

• [SLOW TEST:66.000 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":280,"completed":99,"skipped":1671,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:46:13.890: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:46
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:46:14.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8317" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":280,"completed":100,"skipped":1699,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:46:14.080: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 27 09:46:14.323: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:46:26.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4427" for this suite.

• [SLOW TEST:12.681 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":280,"completed":101,"skipped":1720,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:46:26.762: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:46:27.960: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:46:29.965: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899187, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:46:31.972: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899187, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:46:33.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899187, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:46:35.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899187, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:46:38.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899188, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899187, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:46:41.108: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Mar 27 09:46:41.129: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:46:41.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1913" for this suite.
STEP: Destroying namespace "webhook-1913-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.030 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":280,"completed":102,"skipped":1721,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:46:41.792: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-35fae1dd-de51-446d-996b-61597b2e1d0b
STEP: Creating a pod to test consume configMaps
Mar 27 09:46:42.224: INFO: Waiting up to 5m0s for pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979" in namespace "configmap-2022" to be "success or failure"
Mar 27 09:46:42.360: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 135.265851ms
Mar 27 09:46:44.362: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137491199s
Mar 27 09:46:46.369: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 4.144900341s
Mar 27 09:46:48.372: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147167955s
Mar 27 09:46:50.374: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 8.149325093s
Mar 27 09:46:52.376: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Pending", Reason="", readiness=false. Elapsed: 10.151529162s
Mar 27 09:46:54.378: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.153766473s
STEP: Saw pod success
Mar 27 09:46:54.378: INFO: Pod "pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979" satisfied condition "success or failure"
Mar 27 09:46:54.379: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:46:54.476: INFO: Waiting for pod pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979 to disappear
Mar 27 09:46:54.490: INFO: Pod pod-configmaps-b45d88b3-c916-477a-a5a4-0fd7cdeeb979 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:46:54.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2022" for this suite.

• [SLOW TEST:12.701 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":280,"completed":103,"skipped":1731,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:46:54.494: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar 27 09:47:27.031: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7980 PodName:pod-sharedvolume-76bb1e08-be2e-4a05-b0b4-944051838c66 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:47:27.031: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:47:27.090: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:47:27.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7980" for this suite.

• [SLOW TEST:32.601 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":280,"completed":104,"skipped":1781,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:47:27.094: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 09:47:27.299: INFO: Number of nodes with available pods: 0
Mar 27 09:47:27.299: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:28.305: INFO: Number of nodes with available pods: 0
Mar 27 09:47:28.305: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:29.303: INFO: Number of nodes with available pods: 0
Mar 27 09:47:29.304: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:30.306: INFO: Number of nodes with available pods: 0
Mar 27 09:47:30.306: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:31.303: INFO: Number of nodes with available pods: 0
Mar 27 09:47:31.303: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:32.303: INFO: Number of nodes with available pods: 0
Mar 27 09:47:32.303: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:33.304: INFO: Number of nodes with available pods: 0
Mar 27 09:47:33.304: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:34.304: INFO: Number of nodes with available pods: 0
Mar 27 09:47:34.304: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:35.349: INFO: Number of nodes with available pods: 0
Mar 27 09:47:35.350: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:36.304: INFO: Number of nodes with available pods: 0
Mar 27 09:47:36.304: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:37.320: INFO: Number of nodes with available pods: 0
Mar 27 09:47:37.320: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 09:47:38.304: INFO: Number of nodes with available pods: 1
Mar 27 09:47:38.304: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:39.304: INFO: Number of nodes with available pods: 2
Mar 27 09:47:39.304: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar 27 09:47:39.448: INFO: Number of nodes with available pods: 1
Mar 27 09:47:39.449: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:40.452: INFO: Number of nodes with available pods: 1
Mar 27 09:47:40.452: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:41.468: INFO: Number of nodes with available pods: 1
Mar 27 09:47:41.468: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:42.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:42.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:43.553: INFO: Number of nodes with available pods: 1
Mar 27 09:47:43.553: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:44.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:44.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:45.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:45.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:46.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:46.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:47.452: INFO: Number of nodes with available pods: 1
Mar 27 09:47:47.452: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:48.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:48.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:49.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:49.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:50.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:50.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:51.453: INFO: Number of nodes with available pods: 1
Mar 27 09:47:51.453: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:52.452: INFO: Number of nodes with available pods: 1
Mar 27 09:47:52.452: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:53.617: INFO: Number of nodes with available pods: 1
Mar 27 09:47:53.617: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 09:47:54.454: INFO: Number of nodes with available pods: 2
Mar 27 09:47:54.454: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-347, will wait for the garbage collector to delete the pods
Mar 27 09:47:54.509: INFO: Deleting DaemonSet.extensions daemon-set took: 2.952336ms
Mar 27 09:47:55.010: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.179392ms
Mar 27 09:47:58.825: INFO: Number of nodes with available pods: 0
Mar 27 09:47:58.825: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 09:47:58.827: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-347/daemonsets","resourceVersion":"341382"},"items":null}

Mar 27 09:47:58.829: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-347/pods","resourceVersion":"341382"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:47:58.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-347" for this suite.

• [SLOW TEST:31.742 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":280,"completed":105,"skipped":1784,"failed":0}
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:47:58.837: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:47:59.245: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:48:00.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5018" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":280,"completed":106,"skipped":1788,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:48:00.216: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1692
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:48:00.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1234'
Mar 27 09:48:00.363: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 09:48:00.363: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Mar 27 09:48:00.377: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar 27 09:48:00.433: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar 27 09:48:01.311: INFO: scanned /root for discovery docs: <nil>
Mar 27 09:48:01.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1234'
Mar 27 09:48:27.360: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 27 09:48:27.360: INFO: stdout: "Created e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05\nScaling up e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Mar 27 09:48:27.360: INFO: stdout: "Created e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05\nScaling up e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Mar 27 09:48:27.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-1234'
Mar 27 09:48:27.582: INFO: stderr: ""
Mar 27 09:48:27.582: INFO: stdout: "e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05-wtxpc "
Mar 27 09:48:27.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05-wtxpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1234'
Mar 27 09:48:27.658: INFO: stderr: ""
Mar 27 09:48:27.658: INFO: stdout: "true"
Mar 27 09:48:27.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05-wtxpc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1234'
Mar 27 09:48:27.741: INFO: stderr: ""
Mar 27 09:48:27.741: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Mar 27 09:48:27.741: INFO: e2e-test-httpd-rc-0a1dc683bc66f27949bf0fe89cf3ee05-wtxpc is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1698
Mar 27 09:48:27.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete rc e2e-test-httpd-rc --namespace=kubectl-1234'
Mar 27 09:48:27.831: INFO: stderr: ""
Mar 27 09:48:27.831: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:48:27.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1234" for this suite.

• [SLOW TEST:27.947 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1687
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl rolling-update should support rolling-update to same image  [Conformance]","total":280,"completed":107,"skipped":1792,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:48:28.163: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:48:42.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5480" for this suite.

• [SLOW TEST:14.470 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a read only busybox container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":108,"skipped":1811,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:48:42.633: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Mar 27 09:48:42.693: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:48:44.764: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:48:56.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9447" for this suite.

• [SLOW TEST:13.847 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":280,"completed":109,"skipped":1820,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:48:56.480: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:48:57.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3271" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":280,"completed":110,"skipped":1826,"failed":0}
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:48:57.224: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
Mar 27 09:48:57.472: INFO: PodSpec: initContainers in spec.initContainers
Mar 27 09:49:51.797: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7cd35996-2bab-4c76-bf9d-43c980cbcf94", GenerateName:"", Namespace:"init-container-4515", SelfLink:"/api/v1/namespaces/init-container-4515/pods/pod-init-7cd35996-2bab-4c76-bf9d-43c980cbcf94", UID:"b3925d01-f62a-4df6-afb1-8df38dbaccdd", ResourceVersion:"341738", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63720899337, loc:(*time.Location)(0x7db4bc0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"472293953"}, Annotations:map[string]string{"network.knitter.io/configuration-result":"{\"version\":\"v1\",\"ports\":[{\"function\":\"std\",\"network_name\":\"net_api\",\"ip_address\":\"172.22.33.213\",\"ipv6_address\":\"\",\"layer_type\":\"layer3\"}]}"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-56f2l", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc004a8a700), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-56f2l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-56f2l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-56f2l", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0034a05f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"172.22.33.41", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001cf2300), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034a06a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0034a06e0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0034a06e8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0034a06ec), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899337, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899337, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899337, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899337, loc:(*time.Location)(0x7db4bc0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.22.33.41", PodIP:"172.22.33.213", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.22.33.213"}}, StartTime:(*v1.Time)(0xc0038ef320), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0030c45b0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0030c4620)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://b753f8e5e249310f5118fcf74b3c8630e445a39011f2cba70cb2340258af5841", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0038ef420), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0038ef3a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0034a077f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:49:51.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4515" for this suite.

• [SLOW TEST:54.900 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":280,"completed":111,"skipped":1827,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:49:52.126: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 27 09:49:52.583: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 09:49:52.610: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 09:49:52.611: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.40 before test
Mar 27 09:49:52.622: INFO: coredns-f589df4f5-d98zd from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:49:52.622: INFO: 	Container coredns ready: true, restart count 19
Mar 27 09:49:52.622: INFO: sonobuoy from sonobuoy started at 2020-03-27 08:57:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:49:52.622: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 09:49:52.622: INFO: zte-k8s-eviction-68f598776b-qxjnw from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 09:49:52.622: INFO: 	Container zte-k8s-eviction ready: true, restart count 0
Mar 27 09:49:52.622: INFO: sonobuoy-e2e-job-d8cb2578911a4e68 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:49:52.622: INFO: 	Container e2e ready: true, restart count 0
Mar 27 09:49:52.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:49:52.622: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 09:49:52.622: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:49:52.622: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:49:52.622: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.41 before test
Mar 27 09:49:52.625: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s from sonobuoy started at 2020-03-27 08:58:18 +0000 UTC (2 container statuses recorded)
Mar 27 09:49:52.625: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 09:49:52.625: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 09:49:52.625: INFO: pod-init-7cd35996-2bab-4c76-bf9d-43c980cbcf94 from init-container-4515 started at 2020-03-27 09:48:57 +0000 UTC (1 container statuses recorded)
Mar 27 09:49:52.625: INFO: 	Container run1 ready: false, restart count 0
Mar 27 09:49:52.625: INFO: iag-172.22.33.41 from kube-system started at 2020-03-26 02:05:47 +0000 UTC (1 container statuses recorded)
Mar 27 09:49:52.625: INFO: 	Container iag ready: true, restart count 3
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c6b965cd-a991-4b09-9620-53becd357429 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-c6b965cd-a991-4b09-9620-53becd357429 off the node 172.22.33.41
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c6b965cd-a991-4b09-9620-53becd357429
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:50:43.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3703" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:51.251 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":280,"completed":112,"skipped":1853,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:50:43.378: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1733
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 09:50:43.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-8566'
Mar 27 09:50:43.634: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 09:50:43.634: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1738
Mar 27 09:50:45.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete deployment e2e-test-httpd-deployment --namespace=kubectl-8566'
Mar 27 09:50:45.792: INFO: stderr: ""
Mar 27 09:50:45.792: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:50:45.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8566" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl run deployment should create a deployment from an image  [Conformance]","total":280,"completed":113,"skipped":1881,"failed":0}
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:50:45.796: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:50:45.968: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb" in namespace "projected-984" to be "success or failure"
Mar 27 09:50:46.131: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 162.777873ms
Mar 27 09:50:48.148: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.179313781s
Mar 27 09:50:50.403: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.434159621s
Mar 27 09:50:52.430: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.461957786s
Mar 27 09:50:54.556: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.58730072s
Mar 27 09:50:56.558: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.589327856s
Mar 27 09:50:58.561: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.592445144s
Mar 27 09:51:00.563: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.594547022s
STEP: Saw pod success
Mar 27 09:51:00.563: INFO: Pod "downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb" satisfied condition "success or failure"
Mar 27 09:51:00.565: INFO: Trying to get logs from node 172.22.33.40 pod downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb container client-container: <nil>
STEP: delete the pod
Mar 27 09:51:00.850: INFO: Waiting for pod downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb to disappear
Mar 27 09:51:00.898: INFO: Pod downwardapi-volume-b732363e-36e8-4d4e-bc8e-5221a969d3eb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:51:00.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-984" for this suite.

• [SLOW TEST:15.209 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":114,"skipped":1888,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:51:01.005: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:51:02.376: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:51:04.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:06.383: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:08.383: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:10.383: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:12.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:14.481: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899462, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:51:17.766: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:51:18.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-407" for this suite.
STEP: Destroying namespace "webhook-407-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:17.173 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":280,"completed":115,"skipped":1904,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:51:18.179: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0327 09:51:30.294531      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 09:51:30.294: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:51:30.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4207" for this suite.

• [SLOW TEST:12.129 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":280,"completed":116,"skipped":1909,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:51:30.309: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:51:31.860: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:51:33.865: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899492, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:35.915: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899492, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:37.876: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899492, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:39.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899492, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:51:41.867: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899492, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899491, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:51:45.019: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:51:57.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2201" for this suite.
STEP: Destroying namespace "webhook-2201-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:27.468 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":280,"completed":117,"skipped":1990,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:51:57.778: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Starting the proxy
Mar 27 09:51:57.955: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-894470212 proxy --unix-socket=/tmp/kubectl-proxy-unix531916027/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:51:58.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1514" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":280,"completed":118,"skipped":2011,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:51:58.150: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override arguments
Mar 27 09:51:58.848: INFO: Waiting up to 5m0s for pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe" in namespace "containers-4380" to be "success or failure"
Mar 27 09:51:59.101: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 252.902126ms
Mar 27 09:52:01.147: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298729744s
Mar 27 09:52:03.149: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.300727477s
Mar 27 09:52:05.151: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.302691723s
Mar 27 09:52:07.153: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.304846237s
Mar 27 09:52:09.181: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.332280676s
Mar 27 09:52:11.249: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.400229548s
STEP: Saw pod success
Mar 27 09:52:11.249: INFO: Pod "client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe" satisfied condition "success or failure"
Mar 27 09:52:11.297: INFO: Trying to get logs from node 172.22.33.41 pod client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe container test-container: <nil>
STEP: delete the pod
Mar 27 09:52:11.324: INFO: Waiting for pod client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe to disappear
Mar 27 09:52:11.343: INFO: Pod client-containers-b98cb6f2-bf9e-4179-8c1a-937856360cbe no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:52:11.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4380" for this suite.

• [SLOW TEST:13.197 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":280,"completed":119,"skipped":2032,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:52:11.348: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 27 09:52:11.441: INFO: Waiting up to 5m0s for pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084" in namespace "emptydir-2610" to be "success or failure"
Mar 27 09:52:11.449: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 7.2229ms
Mar 27 09:52:13.451: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009333483s
Mar 27 09:52:15.453: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011429554s
Mar 27 09:52:17.455: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013337292s
Mar 27 09:52:19.457: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015446995s
Mar 27 09:52:21.459: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017573565s
Mar 27 09:52:23.461: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019684614s
Mar 27 09:52:25.464: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 14.022477007s
Mar 27 09:52:27.466: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024367357s
Mar 27 09:52:29.546: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 18.104569868s
Mar 27 09:52:31.647: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 20.205671505s
Mar 27 09:52:33.649: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 22.207778564s
Mar 27 09:52:35.651: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209894886s
Mar 27 09:52:37.653: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 26.212015197s
Mar 27 09:52:39.667: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 28.225298822s
Mar 27 09:52:41.669: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Pending", Reason="", readiness=false. Elapsed: 30.227574145s
Mar 27 09:52:43.671: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.229816706s
STEP: Saw pod success
Mar 27 09:52:43.671: INFO: Pod "pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084" satisfied condition "success or failure"
Mar 27 09:52:43.673: INFO: Trying to get logs from node 172.22.33.41 pod pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084 container test-container: <nil>
STEP: delete the pod
Mar 27 09:52:43.758: INFO: Waiting for pod pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084 to disappear
Mar 27 09:52:43.777: INFO: Pod pod-d042c0b3-2bdf-4b7d-ad1b-9f0971598084 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:52:43.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2610" for this suite.

• [SLOW TEST:32.434 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":120,"skipped":2044,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:52:43.783: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar 27 09:52:43.967: INFO: Waiting up to 5m0s for pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543" in namespace "emptydir-2634" to be "success or failure"
Mar 27 09:52:43.992: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 25.6352ms
Mar 27 09:52:46.004: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037767656s
Mar 27 09:52:48.006: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039692693s
Mar 27 09:52:50.008: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 6.041717182s
Mar 27 09:52:52.010: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 8.043698028s
Mar 27 09:52:54.012: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 10.045765593s
Mar 27 09:52:56.014: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 12.047769134s
Mar 27 09:52:58.019: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052292495s
Mar 27 09:53:00.200: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 16.232903785s
Mar 27 09:53:02.201: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 18.234633623s
Mar 27 09:53:04.203: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 20.236595395s
Mar 27 09:53:06.205: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 22.238683186s
Mar 27 09:53:08.208: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 24.240890886s
Mar 27 09:53:10.230: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 26.262897648s
Mar 27 09:53:12.232: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 28.264992184s
Mar 27 09:53:14.234: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Pending", Reason="", readiness=false. Elapsed: 30.267060466s
Mar 27 09:53:16.236: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.269040766s
STEP: Saw pod success
Mar 27 09:53:16.236: INFO: Pod "pod-1e8d9fd9-f1b2-41c3-8371-472635446543" satisfied condition "success or failure"
Mar 27 09:53:16.237: INFO: Trying to get logs from node 172.22.33.41 pod pod-1e8d9fd9-f1b2-41c3-8371-472635446543 container test-container: <nil>
STEP: delete the pod
Mar 27 09:53:16.261: INFO: Waiting for pod pod-1e8d9fd9-f1b2-41c3-8371-472635446543 to disappear
Mar 27 09:53:16.466: INFO: Pod pod-1e8d9fd9-f1b2-41c3-8371-472635446543 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:53:16.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2634" for this suite.

• [SLOW TEST:32.687 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":121,"skipped":2067,"failed":0}
SSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:53:16.470: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting the proxy server
Mar 27 09:53:16.724: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-894470212 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:53:16.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3926" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":280,"completed":122,"skipped":2072,"failed":0}
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:53:16.804: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1090
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1090
I0327 09:53:16.992336      24 runners.go:189] Created replication controller with name: externalname-service, namespace: services-1090, replica count: 2
I0327 09:53:20.042647      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:53:23.042805      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:53:26.042963      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:53:29.043121      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 09:53:32.043: INFO: Creating new exec pod
I0327 09:53:32.043251      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 09:53:45.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-1090 execpodj7pdz -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar 27 09:53:47.981: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar 27 09:53:47.981: INFO: stdout: ""
Mar 27 09:53:47.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-1090 execpodj7pdz -- /bin/sh -x -c nc -zv -t -w 2 10.254.213.252 80'
Mar 27 09:53:48.120: INFO: stderr: "+ nc -zv -t -w 2 10.254.213.252 80\nConnection to 10.254.213.252 80 port [tcp/http] succeeded!\n"
Mar 27 09:53:48.120: INFO: stdout: ""
Mar 27 09:53:48.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-1090 execpodj7pdz -- /bin/sh -x -c nc -zv -t -w 2 172.22.33.40 31734'
Mar 27 09:53:48.257: INFO: stderr: "+ nc -zv -t -w 2 172.22.33.40 31734\nConnection to 172.22.33.40 31734 port [tcp/31734] succeeded!\n"
Mar 27 09:53:48.257: INFO: stdout: ""
Mar 27 09:53:48.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-1090 execpodj7pdz -- /bin/sh -x -c nc -zv -t -w 2 172.22.33.41 31734'
Mar 27 09:53:48.449: INFO: stderr: "+ nc -zv -t -w 2 172.22.33.41 31734\nConnection to 172.22.33.41 31734 port [tcp/31734] succeeded!\n"
Mar 27 09:53:48.449: INFO: stdout: ""
Mar 27 09:53:48.449: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:53:48.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1090" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:31.922 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":280,"completed":123,"skipped":2078,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:53:48.726: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9464
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9464
STEP: creating replication controller externalsvc in namespace services-9464
I0327 09:53:48.954256      24 runners.go:189] Created replication controller with name: externalsvc, namespace: services-9464, replica count: 2
I0327 09:53:52.004603      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:53:55.004764      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:53:58.004927      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:54:01.005078      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 09:54:04.005243      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Mar 27 09:54:04.141: INFO: Creating new exec pod
Mar 27 09:54:18.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-9464 execpodtvkxj -- /bin/sh -x -c nslookup nodeport-service'
Mar 27 09:54:18.448: INFO: stderr: "+ nslookup nodeport-service\n"
Mar 27 09:54:18.448: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nnodeport-service.services-9464.svc.cluster.local\tcanonical name = externalsvc.services-9464.svc.cluster.local.\nName:\texternalsvc.services-9464.svc.cluster.local\nAddress: 10.254.221.158\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9464, will wait for the garbage collector to delete the pods
Mar 27 09:54:18.503: INFO: Deleting ReplicationController externalsvc took: 2.70615ms
Mar 27 09:54:18.903: INFO: Terminating ReplicationController externalsvc pods took: 400.174554ms
Mar 27 09:54:24.631: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:54:24.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9464" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:36.369 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":280,"completed":124,"skipped":2086,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:54:25.095: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 27 09:54:38.080: INFO: Successfully updated pod "annotationupdate1b12fdf6-3279-4ee9-b6af-094fe7ecbdf7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:54:40.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5464" for this suite.

• [SLOW TEST:15.002 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":125,"skipped":2095,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:54:40.098: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 09:54:40.619: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 09:54:42.624: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:54:44.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:54:46.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:54:48.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 09:54:50.627: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720899680, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 09:54:53.872: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 09:54:53.875: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9377-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:54:55.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3134" for this suite.
STEP: Destroying namespace "webhook-3134-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.282 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":280,"completed":126,"skipped":2113,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:54:55.380: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name projected-secret-test-fd382500-f9c8-43e4-a1f3-50821c7fea8c
STEP: Creating a pod to test consume secrets
Mar 27 09:54:55.542: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535" in namespace "projected-1212" to be "success or failure"
Mar 27 09:54:55.573: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 30.230524ms
Mar 27 09:54:57.575: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032684423s
Mar 27 09:54:59.578: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035851608s
Mar 27 09:55:01.585: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 6.042673649s
Mar 27 09:55:03.587: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 8.044924792s
Mar 27 09:55:05.589: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Pending", Reason="", readiness=false. Elapsed: 10.047025049s
Mar 27 09:55:07.592: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.049228483s
STEP: Saw pod success
Mar 27 09:55:07.592: INFO: Pod "pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535" satisfied condition "success or failure"
Mar 27 09:55:07.593: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar 27 09:55:07.701: INFO: Waiting for pod pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535 to disappear
Mar 27 09:55:07.741: INFO: Pod pod-projected-secrets-64dadadb-eb5a-4163-ad75-84b3b9d68535 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:55:07.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1212" for this suite.

• [SLOW TEST:12.365 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":127,"skipped":2136,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:55:07.748: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar 27 09:55:24.491: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.491: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.546: INFO: Exec stderr: ""
Mar 27 09:55:24.546: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.546: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.602: INFO: Exec stderr: ""
Mar 27 09:55:24.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.603: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.658: INFO: Exec stderr: ""
Mar 27 09:55:24.658: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.658: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.714: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar 27 09:55:24.714: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.714: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.770: INFO: Exec stderr: ""
Mar 27 09:55:24.770: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.770: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.825: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar 27 09:55:24.826: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.826: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.881: INFO: Exec stderr: ""
Mar 27 09:55:24.881: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.881: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.939: INFO: Exec stderr: ""
Mar 27 09:55:24.939: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.939: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:24.997: INFO: Exec stderr: ""
Mar 27 09:55:24.997: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1080 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 09:55:24.997: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 09:55:25.065: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:55:25.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1080" for this suite.

• [SLOW TEST:17.321 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":128,"skipped":2204,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:55:25.069: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-91204c78-d091-4b2f-b435-3c9426ed0000
STEP: Creating a pod to test consume configMaps
Mar 27 09:55:25.339: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3" in namespace "configmap-7537" to be "success or failure"
Mar 27 09:55:25.359: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 19.131516ms
Mar 27 09:55:27.361: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021266391s
Mar 27 09:55:29.363: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.023598844s
Mar 27 09:55:31.365: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.025702767s
Mar 27 09:55:33.367: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.027889308s
Mar 27 09:55:35.591: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.251363293s
Mar 27 09:55:37.593: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.253577548s
STEP: Saw pod success
Mar 27 09:55:37.593: INFO: Pod "pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3" satisfied condition "success or failure"
Mar 27 09:55:37.595: INFO: Trying to get logs from node 172.22.33.40 pod pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:55:37.789: INFO: Waiting for pod pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3 to disappear
Mar 27 09:55:37.833: INFO: Pod pod-configmaps-aa65347f-5846-43e4-b69e-7b4775e29ed3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:55:37.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7537" for this suite.

• [SLOW TEST:12.767 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":129,"skipped":2205,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:55:37.838: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:172
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating server pod server in namespace prestop-164
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-164
STEP: Deleting pre-stop pod
Mar 27 09:56:05.559: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:56:05.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-164" for this suite.

• [SLOW TEST:27.966 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":280,"completed":130,"skipped":2234,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:56:05.805: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:56:12.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8466" for this suite.

• [SLOW TEST:6.336 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":280,"completed":131,"skipped":2244,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:56:12.141: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 09:56:12.262: INFO: Waiting up to 5m0s for pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa" in namespace "projected-2347" to be "success or failure"
Mar 27 09:56:12.271: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 9.443519ms
Mar 27 09:56:14.274: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012178567s
Mar 27 09:56:16.276: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014446512s
Mar 27 09:56:18.279: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016866642s
Mar 27 09:56:20.286: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024245266s
Mar 27 09:56:22.289: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026625203s
Mar 27 09:56:24.291: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.028792073s
STEP: Saw pod success
Mar 27 09:56:24.291: INFO: Pod "downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa" satisfied condition "success or failure"
Mar 27 09:56:24.292: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa container client-container: <nil>
STEP: delete the pod
Mar 27 09:56:24.652: INFO: Waiting for pod downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa to disappear
Mar 27 09:56:24.739: INFO: Pod downwardapi-volume-805636ab-58b9-4cf0-892d-72320f4607fa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:56:24.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2347" for this suite.

• [SLOW TEST:12.602 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":280,"completed":132,"skipped":2254,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:56:24.745: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:178
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:56:25.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1676" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":280,"completed":133,"skipped":2293,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:56:25.643: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9709 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9709;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9709 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9709;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9709.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9709.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9709.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9709.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9709.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9709.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9709.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9709.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9709.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.89.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.89.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.89.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.89.202_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9709 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9709;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9709 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9709;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9709.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9709.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9709.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9709.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9709.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9709.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9709.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9709.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9709.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9709.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 202.89.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.89.202_udp@PTR;check="$$(dig +tcp +noall +answer +search 202.89.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.89.202_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 09:56:59.985: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.987: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.988: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.989: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.991: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.992: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.993: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.995: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.996: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.997: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:56:59.999: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.000: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.001: INFO: Unable to read 10.254.89.202_udp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.003: INFO: Unable to read 10.254.89.202_tcp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.004: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.005: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.007: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.008: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.009: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.011: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.012: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.013: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.015: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.016: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.017: INFO: Unable to read jessie_udp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.019: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.020: INFO: Unable to read 10.254.89.202_udp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.021: INFO: Unable to read 10.254.89.202_tcp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:00.021: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc wheezy_udp@_http._tcp.dns-test-service.dns-9709.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9709.svc wheezy_udp@_http._tcp.test-service-2.dns-9709.svc wheezy_tcp@_http._tcp.test-service-2.dns-9709.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.254.89.202_udp@PTR 10.254.89.202_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc jessie_udp@_http._tcp.dns-test-service.dns-9709.svc jessie_tcp@_http._tcp.dns-test-service.dns-9709.svc jessie_udp@_http._tcp.test-service-2.dns-9709.svc jessie_tcp@_http._tcp.test-service-2.dns-9709.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.254.89.202_udp@PTR 10.254.89.202_tcp@PTR]

Mar 27 09:57:05.024: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.025: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.028: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.030: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.031: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.032: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.033: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.034: INFO: Unable to read wheezy_udp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.036: INFO: Unable to read wheezy_tcp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.037: INFO: Unable to read wheezy_udp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.038: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.039: INFO: Unable to read 10.254.89.202_udp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.041: INFO: Unable to read 10.254.89.202_tcp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.042: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.043: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.044: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.045: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.046: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.047: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.049: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.050: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.051: INFO: Unable to read jessie_udp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.052: INFO: Unable to read jessie_tcp@_http._tcp.test-service-2.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.056: INFO: Unable to read jessie_udp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.057: INFO: Unable to read jessie_tcp@PodARecord from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.059: INFO: Unable to read 10.254.89.202_udp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.060: INFO: Unable to read 10.254.89.202_tcp@PTR from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:05.060: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc wheezy_udp@_http._tcp.dns-test-service.dns-9709.svc wheezy_tcp@_http._tcp.dns-test-service.dns-9709.svc wheezy_udp@_http._tcp.test-service-2.dns-9709.svc wheezy_tcp@_http._tcp.test-service-2.dns-9709.svc wheezy_udp@PodARecord wheezy_tcp@PodARecord 10.254.89.202_udp@PTR 10.254.89.202_tcp@PTR jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc jessie_udp@_http._tcp.dns-test-service.dns-9709.svc jessie_tcp@_http._tcp.dns-test-service.dns-9709.svc jessie_udp@_http._tcp.test-service-2.dns-9709.svc jessie_tcp@_http._tcp.test-service-2.dns-9709.svc jessie_udp@PodARecord jessie_tcp@PodARecord 10.254.89.202_udp@PTR 10.254.89.202_tcp@PTR]

Mar 27 09:57:10.024: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.025: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.028: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.029: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.031: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.043: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.044: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.046: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.047: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.048: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.049: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:10.059: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc]

Mar 27 09:57:15.024: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.025: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.028: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.030: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.031: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.044: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.045: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.046: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.048: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.049: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.050: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:15.061: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc]

Mar 27 09:57:20.024: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.025: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.029: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.030: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.032: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.044: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.045: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.046: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.048: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.049: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.050: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:20.060: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc]

Mar 27 09:57:25.024: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.025: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.027: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.028: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.029: INFO: Unable to read wheezy_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.031: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.042: INFO: Unable to read jessie_udp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.043: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.044: INFO: Unable to read jessie_udp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.045: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709 from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.046: INFO: Unable to read jessie_udp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.048: INFO: Unable to read jessie_tcp@dns-test-service.dns-9709.svc from pod dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87: the server could not find the requested resource (get pods dns-test-18828638-4c95-4292-b459-2ba7e6513c87)
Mar 27 09:57:25.057: INFO: Lookups using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-9709 wheezy_tcp@dns-test-service.dns-9709 wheezy_udp@dns-test-service.dns-9709.svc wheezy_tcp@dns-test-service.dns-9709.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-9709 jessie_tcp@dns-test-service.dns-9709 jessie_udp@dns-test-service.dns-9709.svc jessie_tcp@dns-test-service.dns-9709.svc]

Mar 27 09:57:30.057: INFO: DNS probes using dns-9709/dns-test-18828638-4c95-4292-b459-2ba7e6513c87 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:57:31.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9709" for this suite.

• [SLOW TEST:65.672 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":280,"completed":134,"skipped":2311,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:57:31.316: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-e3c0c61d-0be5-499f-8b31-5e466aff51a2
STEP: Creating a pod to test consume configMaps
Mar 27 09:57:31.829: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884" in namespace "projected-7473" to be "success or failure"
Mar 27 09:57:32.008: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 178.648487ms
Mar 27 09:57:34.010: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 2.180747286s
Mar 27 09:57:36.012: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 4.182901422s
Mar 27 09:57:38.015: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 6.184966772s
Mar 27 09:57:40.017: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 8.187232003s
Mar 27 09:57:42.019: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Pending", Reason="", readiness=false. Elapsed: 10.189456s
Mar 27 09:57:44.021: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.191745424s
STEP: Saw pod success
Mar 27 09:57:44.021: INFO: Pod "pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884" satisfied condition "success or failure"
Mar 27 09:57:44.023: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 09:57:44.076: INFO: Waiting for pod pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884 to disappear
Mar 27 09:57:44.092: INFO: Pod pod-projected-configmaps-462c21f9-decd-4767-9e18-979d87f39884 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:57:44.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7473" for this suite.

• [SLOW TEST:12.780 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":135,"skipped":2316,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:57:44.098: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar 27 09:57:44.616: INFO: Waiting up to 5m0s for pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb" in namespace "emptydir-7009" to be "success or failure"
Mar 27 09:57:44.648: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 31.50718ms
Mar 27 09:57:46.650: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033588824s
Mar 27 09:57:48.652: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035753375s
Mar 27 09:57:50.654: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038009378s
Mar 27 09:57:52.656: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040076671s
Mar 27 09:57:54.659: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.042282696s
Mar 27 09:57:56.662: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.046050039s
Mar 27 09:57:58.664: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.048130291s
Mar 27 09:58:00.667: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.050444981s
Mar 27 09:58:02.679: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.06284773s
Mar 27 09:58:04.681: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.065087714s
Mar 27 09:58:06.683: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.067149548s
Mar 27 09:58:08.693: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.076916624s
Mar 27 09:58:10.695: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 26.079153846s
Mar 27 09:58:12.777: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 28.160266313s
Mar 27 09:58:14.779: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Pending", Reason="", readiness=false. Elapsed: 30.16246231s
Mar 27 09:58:16.781: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.164473247s
STEP: Saw pod success
Mar 27 09:58:16.781: INFO: Pod "pod-749fdb61-9520-4f05-bd96-9fada5b130fb" satisfied condition "success or failure"
Mar 27 09:58:16.782: INFO: Trying to get logs from node 172.22.33.41 pod pod-749fdb61-9520-4f05-bd96-9fada5b130fb container test-container: <nil>
STEP: delete the pod
Mar 27 09:58:16.798: INFO: Waiting for pod pod-749fdb61-9520-4f05-bd96-9fada5b130fb to disappear
Mar 27 09:58:16.822: INFO: Pod pod-749fdb61-9520-4f05-bd96-9fada5b130fb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:58:16.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7009" for this suite.

• [SLOW TEST:32.727 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":136,"skipped":2353,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:58:16.827: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-downwardapi-fhtf
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 09:58:17.395: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-fhtf" in namespace "subpath-1063" to be "success or failure"
Mar 27 09:58:17.397: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.682272ms
Mar 27 09:58:19.399: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003970165s
Mar 27 09:58:21.401: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006077551s
Mar 27 09:58:23.404: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008130212s
Mar 27 09:58:25.559: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.163279865s
Mar 27 09:58:27.561: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.165431767s
Mar 27 09:58:29.563: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.167760144s
Mar 27 09:58:31.565: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.169947127s
Mar 27 09:58:33.568: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.1721256s
Mar 27 09:58:35.795: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.399462378s
Mar 27 09:58:37.797: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.40153514s
Mar 27 09:58:39.799: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.403640349s
Mar 27 09:58:41.801: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 24.405796859s
Mar 27 09:58:43.803: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 26.4078503s
Mar 27 09:58:45.805: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 28.410016783s
Mar 27 09:58:47.808: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Pending", Reason="", readiness=false. Elapsed: 30.412130612s
Mar 27 09:58:49.810: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 32.41436098s
Mar 27 09:58:51.812: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 34.416596323s
Mar 27 09:58:53.814: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 36.418735836s
Mar 27 09:58:55.816: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 38.420869837s
Mar 27 09:58:57.818: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 40.422984828s
Mar 27 09:58:59.821: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 42.425138845s
Mar 27 09:59:01.831: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 44.435798599s
Mar 27 09:59:03.833: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 46.437867318s
Mar 27 09:59:05.835: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 48.439910795s
Mar 27 09:59:07.837: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Running", Reason="", readiness=true. Elapsed: 50.442057716s
Mar 27 09:59:09.840: INFO: Pod "pod-subpath-test-downwardapi-fhtf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 52.444946906s
STEP: Saw pod success
Mar 27 09:59:09.840: INFO: Pod "pod-subpath-test-downwardapi-fhtf" satisfied condition "success or failure"
Mar 27 09:59:09.842: INFO: Trying to get logs from node 172.22.33.41 pod pod-subpath-test-downwardapi-fhtf container test-container-subpath-downwardapi-fhtf: <nil>
STEP: delete the pod
Mar 27 09:59:09.885: INFO: Waiting for pod pod-subpath-test-downwardapi-fhtf to disappear
Mar 27 09:59:09.924: INFO: Pod pod-subpath-test-downwardapi-fhtf no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-fhtf
Mar 27 09:59:09.924: INFO: Deleting pod "pod-subpath-test-downwardapi-fhtf" in namespace "subpath-1063"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:59:09.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1063" for this suite.

• [SLOW TEST:53.103 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":280,"completed":137,"skipped":2366,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:59:09.930: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 09:59:10.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9995" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":280,"completed":138,"skipped":2375,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 09:59:10.299: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the initial replication controller
Mar 27 09:59:10.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-4064'
Mar 27 09:59:10.844: INFO: stderr: ""
Mar 27 09:59:10.844: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 09:59:10.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4064'
Mar 27 09:59:11.043: INFO: stderr: ""
Mar 27 09:59:11.043: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Mar 27 09:59:16.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4064'
Mar 27 09:59:16.207: INFO: stderr: ""
Mar 27 09:59:16.207: INFO: stdout: "update-demo-nautilus-dj5p5 update-demo-nautilus-wdjn6 "
Mar 27 09:59:16.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-dj5p5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:16.287: INFO: stderr: ""
Mar 27 09:59:16.287: INFO: stdout: ""
Mar 27 09:59:16.287: INFO: update-demo-nautilus-dj5p5 is created but not running
Mar 27 09:59:21.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4064'
Mar 27 09:59:21.544: INFO: stderr: ""
Mar 27 09:59:21.544: INFO: stdout: "update-demo-nautilus-dj5p5 update-demo-nautilus-wdjn6 "
Mar 27 09:59:21.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-dj5p5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:21.619: INFO: stderr: ""
Mar 27 09:59:21.620: INFO: stdout: ""
Mar 27 09:59:21.620: INFO: update-demo-nautilus-dj5p5 is created but not running
Mar 27 09:59:26.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4064'
Mar 27 09:59:26.703: INFO: stderr: ""
Mar 27 09:59:26.703: INFO: stdout: "update-demo-nautilus-dj5p5 update-demo-nautilus-wdjn6 "
Mar 27 09:59:26.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-dj5p5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:26.783: INFO: stderr: ""
Mar 27 09:59:26.783: INFO: stdout: "true"
Mar 27 09:59:26.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-dj5p5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:26.873: INFO: stderr: ""
Mar 27 09:59:26.873: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 09:59:26.873: INFO: validating pod update-demo-nautilus-dj5p5
Mar 27 09:59:26.879: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 09:59:26.879: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 09:59:26.879: INFO: update-demo-nautilus-dj5p5 is verified up and running
Mar 27 09:59:26.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-wdjn6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:26.953: INFO: stderr: ""
Mar 27 09:59:26.953: INFO: stdout: "true"
Mar 27 09:59:26.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-wdjn6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 09:59:27.032: INFO: stderr: ""
Mar 27 09:59:27.032: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 09:59:27.032: INFO: validating pod update-demo-nautilus-wdjn6
Mar 27 09:59:27.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 09:59:27.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 09:59:27.036: INFO: update-demo-nautilus-wdjn6 is verified up and running
STEP: rolling-update to new replication controller
Mar 27 09:59:27.038: INFO: scanned /root for discovery docs: <nil>
Mar 27 09:59:27.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4064'
Mar 27 10:00:06.415: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar 27 10:00:06.415: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 10:00:06.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4064'
Mar 27 10:00:06.764: INFO: stderr: ""
Mar 27 10:00:06.764: INFO: stdout: "update-demo-kitten-lv6qz update-demo-kitten-x92gj "
Mar 27 10:00:06.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-kitten-lv6qz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 10:00:07.228: INFO: stderr: ""
Mar 27 10:00:07.228: INFO: stdout: "true"
Mar 27 10:00:07.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-kitten-lv6qz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 10:00:07.489: INFO: stderr: ""
Mar 27 10:00:07.489: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 27 10:00:07.489: INFO: validating pod update-demo-kitten-lv6qz
Mar 27 10:00:07.496: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 27 10:00:07.496: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 27 10:00:07.496: INFO: update-demo-kitten-lv6qz is verified up and running
Mar 27 10:00:07.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-kitten-x92gj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 10:00:07.572: INFO: stderr: ""
Mar 27 10:00:07.572: INFO: stdout: "true"
Mar 27 10:00:07.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-kitten-x92gj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4064'
Mar 27 10:00:07.652: INFO: stderr: ""
Mar 27 10:00:07.652: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Mar 27 10:00:07.652: INFO: validating pod update-demo-kitten-x92gj
Mar 27 10:00:07.658: INFO: got data: {
  "image": "kitten.jpg"
}

Mar 27 10:00:07.658: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar 27 10:00:07.658: INFO: update-demo-kitten-x92gj is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:00:07.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4064" for this suite.

• [SLOW TEST:57.363 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should do a rolling update of a replication controller  [Conformance]","total":280,"completed":139,"skipped":2388,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:00:07.662: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-75666510-e8cb-4013-8495-a23d7e791155
STEP: Creating a pod to test consume configMaps
Mar 27 10:00:08.018: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9" in namespace "projected-9149" to be "success or failure"
Mar 27 10:00:08.033: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.100356ms
Mar 27 10:00:10.085: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067504323s
Mar 27 10:00:12.087: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069521525s
Mar 27 10:00:14.170: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.152140325s
Mar 27 10:00:16.185: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.167582763s
Mar 27 10:00:18.187: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.169634332s
Mar 27 10:00:20.330: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312047418s
Mar 27 10:00:22.332: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.314044846s
Mar 27 10:00:24.334: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.31607666s
STEP: Saw pod success
Mar 27 10:00:24.334: INFO: Pod "pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9" satisfied condition "success or failure"
Mar 27 10:00:24.335: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:00:24.542: INFO: Waiting for pod pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9 to disappear
Mar 27 10:00:24.578: INFO: Pod pod-projected-configmaps-6f2e57fc-dd80-4208-a56a-8880e09783d9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:00:24.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9149" for this suite.

• [SLOW TEST:16.920 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":140,"skipped":2403,"failed":0}
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:00:24.582: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 27 10:00:39.000: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:00:39.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3501" for this suite.

• [SLOW TEST:14.665 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:131
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":141,"skipped":2404,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:00:39.247: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name cm-test-opt-del-1432ede8-7ee8-4529-9f5b-6b3927648ae3
STEP: Creating configMap with name cm-test-opt-upd-9534013f-0b97-4669-bee4-865063a1b8e8
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1432ede8-7ee8-4529-9f5b-6b3927648ae3
STEP: Updating configmap cm-test-opt-upd-9534013f-0b97-4669-bee4-865063a1b8e8
STEP: Creating configMap with name cm-test-opt-create-89cfc839-eb1b-4a5a-8a1e-eadde4e39323
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:02:27.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4378" for this suite.

• [SLOW TEST:108.425 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":142,"skipped":2422,"failed":0}
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:02:27.674: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service multi-endpoint-test in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[]
Mar 27 10:02:27.992: INFO: Get endpoints failed (15.143192ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar 27 10:02:28.994: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[] (1.017304119s elapsed)
STEP: Creating pod pod1 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod1:[100]]
Mar 27 10:02:33.219: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.221602606s elapsed, will retry)
Mar 27 10:02:38.559: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (9.562331728s elapsed, will retry)
Mar 27 10:02:40.740: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod1:[100]] (11.742567927s elapsed)
STEP: Creating pod pod2 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod1:[100] pod2:[101]]
Mar 27 10:02:45.176: INFO: Unexpected endpoints: found map[0c7517ba-134a-42b4-89ee-da1ce7cae793:[100]], expected map[pod1:[100] pod2:[101]] (4.434350519s elapsed, will retry)
Mar 27 10:02:50.266: INFO: Unexpected endpoints: found map[0c7517ba-134a-42b4-89ee-da1ce7cae793:[100]], expected map[pod1:[100] pod2:[101]] (9.524473709s elapsed, will retry)
Mar 27 10:02:51.278: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod1:[100] pod2:[101]] (10.535945157s elapsed)
STEP: Deleting pod pod1 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[pod2:[101]]
Mar 27 10:02:52.377: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[pod2:[101]] (1.097008004s elapsed)
STEP: Deleting pod pod2 in namespace services-1094
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1094 to expose endpoints map[]
Mar 27 10:02:53.721: INFO: successfully validated that service multi-endpoint-test in namespace services-1094 exposes endpoints map[] (1.341475318s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:02:53.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1094" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:26.223 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":280,"completed":143,"skipped":2422,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:02:53.898: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 27 10:03:06.551: INFO: Successfully updated pod "pod-update-581f2f55-8226-4d16-a6ed-85cb1dcbc6dc"
STEP: verifying the updated pod is in kubernetes
Mar 27 10:03:06.692: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:03:06.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7204" for this suite.

• [SLOW TEST:12.798 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":280,"completed":144,"skipped":2451,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:03:06.696: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:03:32.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7268" for this suite.
STEP: Destroying namespace "nsdeletetest-9069" for this suite.
Mar 27 10:03:32.294: INFO: Namespace nsdeletetest-9069 was already deleted
STEP: Destroying namespace "nsdeletetest-5391" for this suite.

• [SLOW TEST:25.601 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":280,"completed":145,"skipped":2455,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:03:32.299: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:46
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar 27 10:03:48.507: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-894470212 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar 27 10:03:53.584: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:03:53.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-903" for this suite.

• [SLOW TEST:21.291 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should be submitted and removed [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period should be submitted and removed [Conformance]","total":280,"completed":146,"skipped":2488,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:03:53.590: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:03:53.770: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 27 10:03:55.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5455 create -f -'
Mar 27 10:03:59.278: INFO: stderr: ""
Mar 27 10:03:59.278: INFO: stdout: "e2e-test-crd-publish-openapi-7797-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar 27 10:03:59.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5455 delete e2e-test-crd-publish-openapi-7797-crds test-cr'
Mar 27 10:03:59.436: INFO: stderr: ""
Mar 27 10:03:59.436: INFO: stdout: "e2e-test-crd-publish-openapi-7797-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Mar 27 10:03:59.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5455 apply -f -'
Mar 27 10:03:59.746: INFO: stderr: ""
Mar 27 10:03:59.746: INFO: stdout: "e2e-test-crd-publish-openapi-7797-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar 27 10:03:59.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5455 delete e2e-test-crd-publish-openapi-7797-crds test-cr'
Mar 27 10:03:59.880: INFO: stderr: ""
Mar 27 10:03:59.880: INFO: stdout: "e2e-test-crd-publish-openapi-7797-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar 27 10:03:59.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-7797-crds'
Mar 27 10:04:00.205: INFO: stderr: ""
Mar 27 10:04:00.205: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7797-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:04:02.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5455" for this suite.

• [SLOW TEST:8.649 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":280,"completed":147,"skipped":2504,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:04:02.241: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:04:18.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-363" for this suite.

• [SLOW TEST:16.265 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":280,"completed":148,"skipped":2520,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:04:18.506: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:04:18.579: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar 27 10:04:22.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5530 create -f -'
Mar 27 10:04:25.050: INFO: stderr: ""
Mar 27 10:04:25.050: INFO: stdout: "e2e-test-crd-publish-openapi-1861-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar 27 10:04:25.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5530 delete e2e-test-crd-publish-openapi-1861-crds test-cr'
Mar 27 10:04:25.167: INFO: stderr: ""
Mar 27 10:04:25.167: INFO: stdout: "e2e-test-crd-publish-openapi-1861-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Mar 27 10:04:25.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5530 apply -f -'
Mar 27 10:04:25.470: INFO: stderr: ""
Mar 27 10:04:25.470: INFO: stdout: "e2e-test-crd-publish-openapi-1861-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar 27 10:04:25.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-5530 delete e2e-test-crd-publish-openapi-1861-crds test-cr'
Mar 27 10:04:26.029: INFO: stderr: ""
Mar 27 10:04:26.029: INFO: stdout: "e2e-test-crd-publish-openapi-1861-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Mar 27 10:04:26.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-1861-crds'
Mar 27 10:04:26.354: INFO: stderr: ""
Mar 27 10:04:26.354: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1861-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:04:29.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5530" for this suite.

• [SLOW TEST:11.380 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":280,"completed":149,"skipped":2521,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:04:29.887: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar 27 10:04:53.056: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 10:04:53.084: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 10:04:55.084: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 10:04:55.105: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 10:04:57.084: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 10:04:57.086: INFO: Pod pod-with-prestop-exec-hook still exists
Mar 27 10:04:59.084: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar 27 10:04:59.086: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:04:59.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8872" for this suite.

• [SLOW TEST:29.209 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when create a pod with lifecycle hook
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":280,"completed":150,"skipped":2537,"failed":0}
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:04:59.097: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-11a932ef-a53b-4205-b9d3-da0425cfcd2c
STEP: Creating a pod to test consume secrets
Mar 27 10:04:59.337: INFO: Waiting up to 5m0s for pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c" in namespace "secrets-3627" to be "success or failure"
Mar 27 10:04:59.382: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 45.42926ms
Mar 27 10:05:01.385: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047685987s
Mar 27 10:05:03.387: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049884517s
Mar 27 10:05:05.389: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.051913398s
Mar 27 10:05:07.391: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.054202078s
Mar 27 10:05:09.393: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.056363405s
Mar 27 10:05:11.396: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.058545581s
STEP: Saw pod success
Mar 27 10:05:11.396: INFO: Pod "pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c" satisfied condition "success or failure"
Mar 27 10:05:11.397: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:05:11.518: INFO: Waiting for pod pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c to disappear
Mar 27 10:05:11.553: INFO: Pod pod-secrets-6a0ad44f-85e8-46ff-8932-a53f7d800e3c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:05:11.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3627" for this suite.

• [SLOW TEST:12.460 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":280,"completed":151,"skipped":2541,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:05:11.557: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-5zbjl in namespace proxy-9661
I0327 10:05:12.264249      24 runners.go:189] Created replication controller with name: proxy-service-5zbjl, namespace: proxy-9661, replica count: 1
I0327 10:05:13.314632      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:14.314926      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:15.315239      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:16.315555      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:17.315848      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:18.316083      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:19.316262      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:20.316487      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:21.316773      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:22.317065      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:23.317363      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:24.317683      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:05:25.317987      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 10:05:26.318285      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 10:05:27.318584      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 10:05:28.318860      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0327 10:05:29.319150      24 runners.go:189] proxy-service-5zbjl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 10:05:29.321: INFO: setup took 17.140286543s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar 27 10:05:29.324: INFO: (0) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.702565ms)
Mar 27 10:05:29.324: INFO: (0) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.835519ms)
Mar 27 10:05:29.327: INFO: (0) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 6.228667ms)
Mar 27 10:05:29.331: INFO: (0) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 10.013724ms)
Mar 27 10:05:29.332: INFO: (0) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 10.601674ms)
Mar 27 10:05:29.332: INFO: (0) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 10.645261ms)
Mar 27 10:05:29.332: INFO: (0) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 10.560599ms)
Mar 27 10:05:29.333: INFO: (0) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 12.426767ms)
Mar 27 10:05:29.334: INFO: (0) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 13.451081ms)
Mar 27 10:05:29.335: INFO: (0) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 13.693328ms)
Mar 27 10:05:29.335: INFO: (0) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 13.889301ms)
Mar 27 10:05:29.336: INFO: (0) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 15.477875ms)
Mar 27 10:05:29.338: INFO: (0) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 17.241124ms)
Mar 27 10:05:29.338: INFO: (0) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 17.304432ms)
Mar 27 10:05:29.340: INFO: (0) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 18.89071ms)
Mar 27 10:05:29.340: INFO: (0) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 18.790534ms)
Mar 27 10:05:29.342: INFO: (1) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.903228ms)
Mar 27 10:05:29.342: INFO: (1) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.072501ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.824069ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.798229ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.338553ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.487154ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 3.053787ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 2.941156ms)
Mar 27 10:05:29.343: INFO: (1) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.11274ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.175597ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.963957ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.589396ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.153207ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.530012ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.412097ms)
Mar 27 10:05:29.344: INFO: (1) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.508593ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 1.610809ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 1.805079ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 1.551917ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 1.74865ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 1.63735ms)
Mar 27 10:05:29.346: INFO: (2) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.104409ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.191377ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.437992ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 2.286471ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.61292ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.114695ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 2.876212ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.839963ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 2.884991ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.061301ms)
Mar 27 10:05:29.347: INFO: (2) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.154098ms)
Mar 27 10:05:29.350: INFO: (3) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.086312ms)
Mar 27 10:05:29.350: INFO: (3) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.274228ms)
Mar 27 10:05:29.350: INFO: (3) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.391167ms)
Mar 27 10:05:29.350: INFO: (3) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 2.902733ms)
Mar 27 10:05:29.350: INFO: (3) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 2.644478ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 2.99522ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.4048ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.405213ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 3.221899ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.188938ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.120798ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.370716ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.608536ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.303865ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.786063ms)
Mar 27 10:05:29.351: INFO: (3) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.202223ms)
Mar 27 10:05:29.354: INFO: (4) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 2.428574ms)
Mar 27 10:05:29.354: INFO: (4) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.685638ms)
Mar 27 10:05:29.354: INFO: (4) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 2.685761ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.839992ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.92667ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.119887ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.118591ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.28088ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 3.313224ms)
Mar 27 10:05:29.355: INFO: (4) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.407554ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.88957ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.650976ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.878075ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.961418ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 4.138706ms)
Mar 27 10:05:29.356: INFO: (4) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 4.820994ms)
Mar 27 10:05:29.358: INFO: (5) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 1.438842ms)
Mar 27 10:05:29.358: INFO: (5) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 1.873988ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.422023ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.377046ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.544746ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 1.959828ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.419206ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 2.574584ms)
Mar 27 10:05:29.359: INFO: (5) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.150936ms)
Mar 27 10:05:29.360: INFO: (5) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.555918ms)
Mar 27 10:05:29.360: INFO: (5) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.363437ms)
Mar 27 10:05:29.360: INFO: (5) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.421256ms)
Mar 27 10:05:29.360: INFO: (5) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.570664ms)
Mar 27 10:05:29.361: INFO: (5) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 4.498756ms)
Mar 27 10:05:29.362: INFO: (5) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 4.614511ms)
Mar 27 10:05:29.362: INFO: (5) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 4.769646ms)
Mar 27 10:05:29.364: INFO: (6) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 1.780919ms)
Mar 27 10:05:29.364: INFO: (6) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.884613ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 4.02886ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.841103ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.86903ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.847828ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 4.434165ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 3.905175ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 4.241288ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 4.343542ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 4.139286ms)
Mar 27 10:05:29.366: INFO: (6) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 4.25208ms)
Mar 27 10:05:29.367: INFO: (6) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 4.48542ms)
Mar 27 10:05:29.367: INFO: (6) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 4.377738ms)
Mar 27 10:05:29.367: INFO: (6) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 4.414098ms)
Mar 27 10:05:29.367: INFO: (6) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 4.602539ms)
Mar 27 10:05:29.369: INFO: (7) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.82652ms)
Mar 27 10:05:29.369: INFO: (7) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 1.823946ms)
Mar 27 10:05:29.369: INFO: (7) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 1.956741ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.572566ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 3.041838ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.041623ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.145858ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.229197ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.119632ms)
Mar 27 10:05:29.370: INFO: (7) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.461389ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.462809ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.594362ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.455871ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.667317ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.633598ms)
Mar 27 10:05:29.371: INFO: (7) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.98433ms)
Mar 27 10:05:29.373: INFO: (8) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.371012ms)
Mar 27 10:05:29.373: INFO: (8) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.144031ms)
Mar 27 10:05:29.373: INFO: (8) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.274754ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.473973ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 2.708879ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.629567ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 2.900932ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.679416ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.668415ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 2.670719ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.905933ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.026692ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.084984ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.200904ms)
Mar 27 10:05:29.374: INFO: (8) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.07941ms)
Mar 27 10:05:29.375: INFO: (8) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.459828ms)
Mar 27 10:05:29.378: INFO: (9) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 3.091143ms)
Mar 27 10:05:29.378: INFO: (9) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.209748ms)
Mar 27 10:05:29.378: INFO: (9) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.364062ms)
Mar 27 10:05:29.379: INFO: (9) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.560187ms)
Mar 27 10:05:29.379: INFO: (9) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 3.684784ms)
Mar 27 10:05:29.379: INFO: (9) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.752836ms)
Mar 27 10:05:29.379: INFO: (9) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.751786ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 4.770017ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 4.8801ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 4.831798ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 5.23043ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 5.301907ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 5.292544ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 5.278223ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 5.418296ms)
Mar 27 10:05:29.380: INFO: (9) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 5.556497ms)
Mar 27 10:05:29.383: INFO: (10) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 2.113196ms)
Mar 27 10:05:29.383: INFO: (10) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 2.321644ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 4.300161ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 4.516276ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 4.446985ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 4.550756ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 4.572914ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 4.570926ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 4.57002ms)
Mar 27 10:05:29.385: INFO: (10) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 4.744809ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 4.626484ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 5.383422ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 5.190828ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 5.278311ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 5.693248ms)
Mar 27 10:05:29.386: INFO: (10) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 5.392043ms)
Mar 27 10:05:29.388: INFO: (11) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.891162ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.515207ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.031396ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 3.089857ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.994137ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.012058ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.03556ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.163058ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.556538ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.808249ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.437511ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.37359ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.660552ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 3.55138ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.503954ms)
Mar 27 10:05:29.390: INFO: (11) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.944653ms)
Mar 27 10:05:29.392: INFO: (12) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.393998ms)
Mar 27 10:05:29.392: INFO: (12) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.842844ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.752693ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.021655ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 2.039181ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.057981ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.145866ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 2.38769ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.543576ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 2.673148ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.665253ms)
Mar 27 10:05:29.393: INFO: (12) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.641774ms)
Mar 27 10:05:29.394: INFO: (12) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 2.979122ms)
Mar 27 10:05:29.394: INFO: (12) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.116243ms)
Mar 27 10:05:29.394: INFO: (12) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.265474ms)
Mar 27 10:05:29.395: INFO: (12) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.938623ms)
Mar 27 10:05:29.397: INFO: (13) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.403673ms)
Mar 27 10:05:29.397: INFO: (13) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.538058ms)
Mar 27 10:05:29.397: INFO: (13) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.583763ms)
Mar 27 10:05:29.397: INFO: (13) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.548757ms)
Mar 27 10:05:29.397: INFO: (13) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.738715ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.667218ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.840793ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.844616ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.161211ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.433445ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.502604ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.504033ms)
Mar 27 10:05:29.398: INFO: (13) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.60445ms)
Mar 27 10:05:29.399: INFO: (13) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 4.023329ms)
Mar 27 10:05:29.399: INFO: (13) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 4.139964ms)
Mar 27 10:05:29.399: INFO: (13) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 4.269466ms)
Mar 27 10:05:29.401: INFO: (14) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 1.666867ms)
Mar 27 10:05:29.404: INFO: (14) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 4.929663ms)
Mar 27 10:05:29.404: INFO: (14) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 4.929816ms)
Mar 27 10:05:29.405: INFO: (14) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 5.462993ms)
Mar 27 10:05:29.405: INFO: (14) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 5.323873ms)
Mar 27 10:05:29.405: INFO: (14) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 5.293476ms)
Mar 27 10:05:29.405: INFO: (14) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 5.265977ms)
Mar 27 10:05:29.405: INFO: (14) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 5.83148ms)
Mar 27 10:05:29.406: INFO: (14) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 6.337584ms)
Mar 27 10:05:29.406: INFO: (14) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 6.402639ms)
Mar 27 10:05:29.406: INFO: (14) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 7.083185ms)
Mar 27 10:05:29.407: INFO: (14) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 7.076852ms)
Mar 27 10:05:29.407: INFO: (14) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 7.606983ms)
Mar 27 10:05:29.407: INFO: (14) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 7.645476ms)
Mar 27 10:05:29.407: INFO: (14) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 7.955284ms)
Mar 27 10:05:29.408: INFO: (14) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 8.219012ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.922152ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.995389ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 2.376154ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 2.347241ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.174295ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 2.41674ms)
Mar 27 10:05:29.410: INFO: (15) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 2.693139ms)
Mar 27 10:05:29.411: INFO: (15) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.662182ms)
Mar 27 10:05:29.411: INFO: (15) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.747416ms)
Mar 27 10:05:29.412: INFO: (15) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.606684ms)
Mar 27 10:05:29.412: INFO: (15) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.576659ms)
Mar 27 10:05:29.412: INFO: (15) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.629693ms)
Mar 27 10:05:29.412: INFO: (15) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 4.147036ms)
Mar 27 10:05:29.412: INFO: (15) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 4.1955ms)
Mar 27 10:05:29.413: INFO: (15) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 4.528005ms)
Mar 27 10:05:29.413: INFO: (15) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 4.504ms)
Mar 27 10:05:29.414: INFO: (16) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.357027ms)
Mar 27 10:05:29.414: INFO: (16) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 1.677345ms)
Mar 27 10:05:29.415: INFO: (16) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 1.70528ms)
Mar 27 10:05:29.415: INFO: (16) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 1.984254ms)
Mar 27 10:05:29.415: INFO: (16) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.098161ms)
Mar 27 10:05:29.415: INFO: (16) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 2.507631ms)
Mar 27 10:05:29.415: INFO: (16) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 2.06862ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 2.483031ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.413859ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 2.536252ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 2.988235ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 2.653441ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 2.744427ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 2.865817ms)
Mar 27 10:05:29.416: INFO: (16) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.188347ms)
Mar 27 10:05:29.417: INFO: (16) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.797124ms)
Mar 27 10:05:29.419: INFO: (17) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.686529ms)
Mar 27 10:05:29.419: INFO: (17) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 1.555693ms)
Mar 27 10:05:29.419: INFO: (17) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 1.63224ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.251027ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.360405ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 3.000025ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 3.310186ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.590661ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.09947ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 3.192811ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.661715ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 3.74292ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.545324ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.612478ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.261825ms)
Mar 27 10:05:29.420: INFO: (17) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.205184ms)
Mar 27 10:05:29.423: INFO: (18) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 1.705794ms)
Mar 27 10:05:29.423: INFO: (18) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 1.77887ms)
Mar 27 10:05:29.423: INFO: (18) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 1.956911ms)
Mar 27 10:05:29.423: INFO: (18) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 1.927204ms)
Mar 27 10:05:29.423: INFO: (18) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 2.023702ms)
Mar 27 10:05:29.424: INFO: (18) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 2.248113ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.591463ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 3.373559ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 3.265901ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 3.876269ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 3.649624ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 3.614475ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 3.580332ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 3.468153ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 3.708072ms)
Mar 27 10:05:29.425: INFO: (18) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 3.518849ms)
Mar 27 10:05:29.429: INFO: (19) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:460/proxy/: tls baz (200; 3.502122ms)
Mar 27 10:05:29.429: INFO: (19) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 4.196473ms)
Mar 27 10:05:29.429: INFO: (19) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 4.243535ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname2/proxy/: bar (200; 4.516653ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:462/proxy/: tls qux (200; 4.400603ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:162/proxy/: bar (200; 4.614249ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/services/http:proxy-service-5zbjl:portname1/proxy/: foo (200; 4.751012ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/https:proxy-service-5zbjl-t9t6x:443/proxy/tlsrewritem... (200; 4.764692ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname1/proxy/: foo (200; 5.037105ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/services/proxy-service-5zbjl:portname2/proxy/: bar (200; 5.182626ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">test<... (200; 5.116751ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname2/proxy/: tls qux (200; 5.190838ms)
Mar 27 10:05:29.430: INFO: (19) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x:160/proxy/: foo (200; 5.242456ms)
Mar 27 10:05:29.431: INFO: (19) /api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/http:proxy-service-5zbjl-t9t6x:1080/proxy/rewriteme">... (200; 5.279932ms)
Mar 27 10:05:29.431: INFO: (19) /api/v1/namespaces/proxy-9661/services/https:proxy-service-5zbjl:tlsportname1/proxy/: tls baz (200; 5.401364ms)
Mar 27 10:05:29.431: INFO: (19) /api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/: <a href="/api/v1/namespaces/proxy-9661/pods/proxy-service-5zbjl-t9t6x/proxy/rewriteme">test</a> (200; 5.3929ms)
STEP: deleting ReplicationController proxy-service-5zbjl in namespace proxy-9661, will wait for the garbage collector to delete the pods
Mar 27 10:05:29.485: INFO: Deleting ReplicationController proxy-service-5zbjl took: 2.900673ms
Mar 27 10:05:29.785: INFO: Terminating ReplicationController proxy-service-5zbjl pods took: 300.238063ms
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:05:32.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9661" for this suite.

• [SLOW TEST:21.309 seconds]
[sig-network] Proxy
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":280,"completed":152,"skipped":2553,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:05:32.868: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:07:28.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-413" for this suite.

• [SLOW TEST:115.199 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":280,"completed":153,"skipped":2573,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:07:28.068: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:07:28.540: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 10:07:28.826: INFO: Number of nodes with available pods: 0
Mar 27 10:07:28.826: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:29.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:29.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:30.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:30.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:31.872: INFO: Number of nodes with available pods: 0
Mar 27 10:07:31.872: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:32.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:32.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:34.114: INFO: Number of nodes with available pods: 0
Mar 27 10:07:34.114: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:34.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:34.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:35.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:35.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:36.945: INFO: Number of nodes with available pods: 0
Mar 27 10:07:36.945: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:37.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:37.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:38.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:38.831: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:39.830: INFO: Number of nodes with available pods: 0
Mar 27 10:07:39.830: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:07:40.830: INFO: Number of nodes with available pods: 1
Mar 27 10:07:40.830: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:07:41.900: INFO: Number of nodes with available pods: 1
Mar 27 10:07:41.900: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:07:42.830: INFO: Number of nodes with available pods: 2
Mar 27 10:07:42.830: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar 27 10:07:42.861: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:42.861: INFO: Wrong image for pod: daemon-set-jtpbz. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:43.973: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:43.974: INFO: Wrong image for pod: daemon-set-jtpbz. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:43.974: INFO: Pod daemon-set-jtpbz is not available
Mar 27 10:07:45.021: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:45.021: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:45.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:45.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:46.988: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:46.988: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:47.973: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:47.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:48.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:48.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:49.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:49.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:50.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:50.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:51.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:51.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:52.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:52.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:53.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:53.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:54.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:54.974: INFO: Pod daemon-set-lbpc6 is not available
Mar 27 10:07:55.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:57.181: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:57.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:58.974: INFO: Wrong image for pod: daemon-set-26qtt. Expected: gcr.io/kubernetes-e2e-test-images/agnhost:2.8, got: docker.io/library/httpd:2.4.38-alpine.
Mar 27 10:07:58.974: INFO: Pod daemon-set-26qtt is not available
Mar 27 10:07:59.974: INFO: Pod daemon-set-jq9zh is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Mar 27 10:07:59.978: INFO: Number of nodes with available pods: 1
Mar 27 10:07:59.978: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:00.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:00.982: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:01.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:01.983: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:02.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:02.983: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:03.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:03.983: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:04.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:04.982: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:05.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:05.983: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:06.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:06.982: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:07.982: INFO: Number of nodes with available pods: 1
Mar 27 10:08:07.982: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:09.135: INFO: Number of nodes with available pods: 1
Mar 27 10:08:09.135: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:10.032: INFO: Number of nodes with available pods: 1
Mar 27 10:08:10.032: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:08:10.982: INFO: Number of nodes with available pods: 2
Mar 27 10:08:10.982: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1217, will wait for the garbage collector to delete the pods
Mar 27 10:08:11.042: INFO: Deleting DaemonSet.extensions daemon-set took: 2.817702ms
Mar 27 10:08:11.543: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.206407ms
Mar 27 10:08:16.268: INFO: Number of nodes with available pods: 0
Mar 27 10:08:16.268: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 10:08:16.270: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1217/daemonsets","resourceVersion":"344974"},"items":null}

Mar 27 10:08:16.271: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1217/pods","resourceVersion":"344974"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:08:16.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1217" for this suite.

• [SLOW TEST:48.209 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":280,"completed":154,"skipped":2593,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:08:16.278: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-5rdx
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 10:08:16.663: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5rdx" in namespace "subpath-8903" to be "success or failure"
Mar 27 10:08:16.677: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.120254ms
Mar 27 10:08:18.679: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016266548s
Mar 27 10:08:20.682: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019065206s
Mar 27 10:08:22.684: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021239169s
Mar 27 10:08:24.686: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.023374795s
Mar 27 10:08:26.688: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 10.025491529s
Mar 27 10:08:28.690: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 12.027623529s
Mar 27 10:08:30.703: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.040094905s
Mar 27 10:08:32.705: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.042253897s
Mar 27 10:08:34.707: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 18.044175764s
Mar 27 10:08:36.709: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 20.046317188s
Mar 27 10:08:38.711: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 22.048656743s
Mar 27 10:08:40.714: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 24.050885475s
Mar 27 10:08:42.716: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 26.053148907s
Mar 27 10:08:44.718: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 28.05546776s
Mar 27 10:08:46.721: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Pending", Reason="", readiness=false. Elapsed: 30.058476616s
Mar 27 10:08:48.724: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 32.061586579s
Mar 27 10:08:50.726: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 34.063714398s
Mar 27 10:08:52.797: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 36.13448581s
Mar 27 10:08:54.799: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 38.136531466s
Mar 27 10:08:56.801: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 40.138611266s
Mar 27 10:08:58.803: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 42.140802456s
Mar 27 10:09:00.806: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 44.142905945s
Mar 27 10:09:02.808: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 46.14515088s
Mar 27 10:09:04.810: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 48.147202687s
Mar 27 10:09:06.812: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Running", Reason="", readiness=true. Elapsed: 50.149334233s
Mar 27 10:09:08.844: INFO: Pod "pod-subpath-test-configmap-5rdx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 52.180859859s
STEP: Saw pod success
Mar 27 10:09:08.844: INFO: Pod "pod-subpath-test-configmap-5rdx" satisfied condition "success or failure"
Mar 27 10:09:08.845: INFO: Trying to get logs from node 172.22.33.41 pod pod-subpath-test-configmap-5rdx container test-container-subpath-configmap-5rdx: <nil>
STEP: delete the pod
Mar 27 10:09:08.910: INFO: Waiting for pod pod-subpath-test-configmap-5rdx to disappear
Mar 27 10:09:09.000: INFO: Pod pod-subpath-test-configmap-5rdx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5rdx
Mar 27 10:09:09.000: INFO: Deleting pod "pod-subpath-test-configmap-5rdx" in namespace "subpath-8903"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:09:09.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8903" for this suite.

• [SLOW TEST:52.727 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":280,"completed":155,"skipped":2652,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:09:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:09:09.217: INFO: Creating deployment "webserver-deployment"
Mar 27 10:09:09.272: INFO: Waiting for observed generation 1
Mar 27 10:09:11.537: INFO: Waiting for all required pods to come up
Mar 27 10:09:11.539: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar 27 10:09:33.825: INFO: Waiting for deployment "webserver-deployment" to complete
Mar 27 10:09:33.834: INFO: Updating deployment "webserver-deployment" with a non-existent image
Mar 27 10:09:33.837: INFO: Updating deployment webserver-deployment
Mar 27 10:09:33.837: INFO: Waiting for observed generation 2
Mar 27 10:09:36.040: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar 27 10:09:36.229: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar 27 10:09:36.230: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar 27 10:09:36.234: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar 27 10:09:36.234: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar 27 10:09:36.234: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar 27 10:09:36.236: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Mar 27 10:09:36.236: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Mar 27 10:09:36.239: INFO: Updating deployment webserver-deployment
Mar 27 10:09:36.239: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Mar 27 10:09:36.428: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar 27 10:09:36.430: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 27 10:09:37.571: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8716 /apis/apps/v1/namespaces/deployment-8716/deployments/webserver-deployment 34276bb8-3e38-4c9f-8c2e-edc9437a1348 345330 3 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00373fca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-03-27 10:09:35 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-27 10:09:36 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Mar 27 10:09:37.800: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-8716 /apis/apps/v1/namespaces/deployment-8716/replicasets/webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 345365 3 2020-03-27 10:09:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 34276bb8-3e38-4c9f-8c2e-edc9437a1348 0xc005948197 0xc005948198}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005948208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 10:09:37.800: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Mar 27 10:09:37.800: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-8716 /apis/apps/v1/namespaces/deployment-8716/replicasets/webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 345363 3 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 34276bb8-3e38-4c9f-8c2e-edc9437a1348 0xc0059480d7 0xc0059480d8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005948138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Mar 27 10:09:38.374: INFO: Pod "webserver-deployment-595b5b9587-2gbz2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2gbz2 webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-2gbz2 0fd44e1a-e920-4a7f-8520-9b0ed52565f6 345219 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.57","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cc767 0xc0057cc768}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.57,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://211c111316cd193eb225d293ae4db7318b5de17b284d1105f1326b2432eefc28,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.374: INFO: Pod "webserver-deployment-595b5b9587-66nkh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-66nkh webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-66nkh b5aac09e-5279-42db-8ab0-a0ba77e05759 345227 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.59","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cc8e7 0xc0057cc8e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.59,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://92cd9c0d016fa63e7ded889f0ebce06eb686802a5a284d21fbd7345029d46d24,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-6msst" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6msst webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-6msst 7c5a8da4-a4cd-4f17-8e21-a1d79d0ee1f0 345226 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.58","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cca97 0xc0057cca98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:172.22.33.58,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://42b90c4350c1db7eb43786fa9605ce3276adbb543c97f930b94c931c9a844878,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-6pldh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6pldh webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-6pldh 0bf24eca-20b5-4550-9179-4e7d8235e72d 345340 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057ccc27 0xc0057ccc28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-6r2g5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6r2g5 webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-6r2g5 28718635-6e83-4b64-b09a-b610432b74e6 345339 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057ccd40 0xc0057ccd41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-7jc8x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7jc8x webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-7jc8x a81b2b46-181b-4909-844b-8b947fdd851f 345179 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.55","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cce50 0xc0057cce51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.55,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b02059e2695ce7455331a104fedc322d68f1eeaf1a44a7603534794390d6385a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-96kxl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-96kxl webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-96kxl 38efa976-863e-434d-b59d-0788c8f21092 345362 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057ccfc7 0xc0057ccfc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.375: INFO: Pod "webserver-deployment-595b5b9587-9p5rk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9p5rk webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-9p5rk 01661200-2ece-4915-981f-a617719bd711 345341 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd0e0 0xc0057cd0e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-d6hlq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-d6hlq webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-d6hlq caa28158-9c84-43e3-af6c-331d6f13bfda 345192 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.56","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd1f0 0xc0057cd1f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:172.22.33.56,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f3501d3ec3fcff659d2a9d2398f68875ea61065c9593b9466fd5cc3b1292b66e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-dpm4r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dpm4r webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-dpm4r 834f8ba1-c755-41c9-9258-dd3534742e54 345357 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd367 0xc0057cd368}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-f869t" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-f869t webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-f869t c36e328e-5c9d-4583-854b-42cbe76af729 345235 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.64","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd480 0xc0057cd481}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:172.22.33.64,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://325ed07455733667d32543559ebac0739098ecc99b772c48265d8be069e7331f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-khk8c" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-khk8c webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-khk8c f9c472ae-2760-4bae-921b-d336b46add3c 345359 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd5f7 0xc0057cd5f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-mqmn7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mqmn7 webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-mqmn7 30d55ef3-2577-435d-84d5-f20c401d7880 345355 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd710 0xc0057cd711}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 10:09:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.376: INFO: Pod "webserver-deployment-595b5b9587-n9zz7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-n9zz7 webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-n9zz7 284a8ae4-4afb-4328-a7c5-fb7b8073b03e 345207 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.60","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd867 0xc0057cd868}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:172.22.33.60,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://84bb6b68d4cea822bd752c770f5fee5949ed505a87d6f0209de2304771a36512,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-nn2zc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nn2zc webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-nn2zc bd151f2f-74e3-4e54-8cc4-aa218f5c8f39 345360 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cd9e7 0xc0057cd9e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-r24dp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r24dp webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-r24dp b978cc4a-dfe9-4cf8-89d1-bdd33f760cad 345231 0 2020-03-27 10:09:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.62","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cdb00 0xc0057cdb01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:172.22.33.62,StartTime:2020-03-27 10:09:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:09:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f199884120ea3176e70af8208046d22d392c1dc62610fe71c5c7bdc80d9bf348,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-tv5gh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tv5gh webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-tv5gh 7fe7ed8a-b399-4e27-acb1-3256ee0d9568 345338 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cdc77 0xc0057cdc78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-wnqkr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wnqkr webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-wnqkr 2d13470d-3517-4d2f-87a5-c561d005d5ab 345370 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cdd90 0xc0057cdd91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 10:09:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-z2848" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z2848 webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-z2848 b28fa38f-a17a-4d51-b4ff-dd01dd874c27 345328 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc0057cdee7 0xc0057cdee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-595b5b9587-zzmqx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zzmqx webserver-deployment-595b5b9587- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-595b5b9587-zzmqx 135f3ae8-2d5c-4d18-a3dd-136ccaf78856 345361 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 258be6a8-c720-4c13-9e75-bf02265940d7 0xc005976000 0xc005976001}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.377: INFO: Pod "webserver-deployment-c7997dcc8-2f66j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2f66j webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-2f66j 4bdb1e9a-3584-4ab7-9ef6-9e1aab08fd42 345344 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976110 0xc005976111}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-6tzrx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6tzrx webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-6tzrx 939c43e3-8ee4-4bfa-aa0d-9cd3d2018150 345353 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976230 0xc005976231}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:,StartTime:2020-03-27 10:09:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-7l8h5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7l8h5 webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-7l8h5 3d840a07-b401-42cb-91c0-923e7b9e9eed 345303 0 2020-03-27 10:09:34 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc0059763a7 0xc0059763a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:,StartTime:2020-03-27 10:09:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-9fcs9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9fcs9 webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-9fcs9 00eaba47-c308-41ee-9f43-105d8b72600d 345371 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976527 0xc005976528}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:,StartTime:2020-03-27 10:09:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-cr4lc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cr4lc webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-cr4lc 44af4484-08de-4846-acdf-30534f529a1c 345351 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc0059766a7 0xc0059766a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-f48jq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f48jq webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-f48jq 833946b2-3208-41c1-800f-2f90a1b4f0d9 345273 0 2020-03-27 10:09:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc0059767d0 0xc0059767d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 10:09:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.378: INFO: Pod "webserver-deployment-c7997dcc8-kmn29" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kmn29 webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-kmn29 288e45c6-177e-47cd-9e53-5426084462f6 345277 0 2020-03-27 10:09:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976947 0xc005976948}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.40,PodIP:,StartTime:2020-03-27 10:09:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-l2qbn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-l2qbn webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-l2qbn 8f9c1857-c3cd-47c6-ade9-eae8e83e52ac 345345 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976ac7 0xc005976ac8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.40,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-lcdf2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lcdf2 webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-lcdf2 896cf946-2530-4ee7-9371-d4b9dd965a0d 345304 0 2020-03-27 10:09:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976bf0 0xc005976bf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 10:09:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-lklsh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lklsh webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-lklsh 01d330e4-7de4-47a8-8d5a-d9303857af9c 345280 0 2020-03-27 10:09:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976d67 0xc005976d68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:,StartTime:2020-03-27 10:09:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-mksd2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mksd2 webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-mksd2 81c39b2a-fd81-4db6-bc88-8602c1d67ae1 345342 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005976ee7 0xc005976ee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-tjd5w" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tjd5w webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-tjd5w 6e77aa30-71be-43fb-903f-3d2723404dcc 345356 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005977010 0xc005977011}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 10:09:38.379: INFO: Pod "webserver-deployment-c7997dcc8-xkx2q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xkx2q webserver-deployment-c7997dcc8- deployment-8716 /api/v1/namespaces/deployment-8716/pods/webserver-deployment-c7997dcc8-xkx2q 3f69549c-8f8c-4aba-9faa-184727ad8f86 345329 0 2020-03-27 10:09:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 34abbe3f-c4d1-4a81-a3f6-acb2eddf5359 0xc005977130 0xc005977131}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9kmjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9kmjt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9kmjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:09:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:09:38.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8716" for this suite.

• [SLOW TEST:31.037 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":280,"completed":156,"skipped":2670,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:09:40.044: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:10:00.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8671" for this suite.

• [SLOW TEST:20.581 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":280,"completed":157,"skipped":2683,"failed":0}
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:10:00.626: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar 27 10:10:01.467: INFO: Pod name pod-release: Found 0 pods out of 1
Mar 27 10:10:06.506: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:10:06.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9640" for this suite.

• [SLOW TEST:6.897 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":280,"completed":158,"skipped":2693,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:10:07.524: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-map-2c6406bc-daf1-44a2-aeef-c646541195d6
STEP: Creating a pod to test consume configMaps
Mar 27 10:10:08.711: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd" in namespace "projected-9675" to be "success or failure"
Mar 27 10:10:08.806: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 95.324382ms
Mar 27 10:10:10.809: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.097490701s
Mar 27 10:10:12.835: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124102635s
Mar 27 10:10:15.044: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.333004173s
Mar 27 10:10:17.046: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.33508852s
Mar 27 10:10:19.048: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.337177138s
Mar 27 10:10:21.050: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.339247991s
Mar 27 10:10:23.053: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.341514158s
Mar 27 10:10:25.072: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.361051131s
Mar 27 10:10:27.075: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.363648061s
Mar 27 10:10:29.077: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.36582024s
Mar 27 10:10:31.093: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 22.381791338s
Mar 27 10:10:33.101: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Pending", Reason="", readiness=false. Elapsed: 24.390246398s
Mar 27 10:10:35.414: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.70264603s
STEP: Saw pod success
Mar 27 10:10:35.414: INFO: Pod "pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd" satisfied condition "success or failure"
Mar 27 10:10:35.415: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:10:37.206: INFO: Waiting for pod pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd to disappear
Mar 27 10:10:38.322: INFO: Pod pod-projected-configmaps-023b9e38-db2f-4444-ba33-5d2f846c15cd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:10:38.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9675" for this suite.

• [SLOW TEST:30.803 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":280,"completed":159,"skipped":2697,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:10:38.328: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-f9dc7a44-72d9-4a67-b178-fd69e59c7e1e
STEP: Creating a pod to test consume secrets
Mar 27 10:10:41.613: INFO: Waiting up to 5m0s for pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa" in namespace "secrets-6924" to be "success or failure"
Mar 27 10:10:42.032: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 419.039922ms
Mar 27 10:10:44.559: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.945243397s
Mar 27 10:10:46.561: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.947386337s
Mar 27 10:10:48.563: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.949591308s
Mar 27 10:10:50.565: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 8.951823864s
Mar 27 10:10:52.569: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 10.955587503s
Mar 27 10:10:54.571: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 12.957862424s
Mar 27 10:10:56.573: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Pending", Reason="", readiness=false. Elapsed: 14.959945254s
Mar 27 10:10:58.576: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.962198139s
STEP: Saw pod success
Mar 27 10:10:58.576: INFO: Pod "pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa" satisfied condition "success or failure"
Mar 27 10:10:58.577: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:10:58.648: INFO: Waiting for pod pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa to disappear
Mar 27 10:10:58.728: INFO: Pod pod-secrets-7b6b7c1c-6e9b-4b3c-b2ac-ae405c5a1eaa no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:10:58.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6924" for this suite.

• [SLOW TEST:20.404 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":160,"skipped":2715,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:10:58.733: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:10:59.174: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:10:59.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9418" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":280,"completed":161,"skipped":2715,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:10:59.910: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 27 10:11:13.296: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:11:13.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4447" for this suite.

• [SLOW TEST:13.669 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:131
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":280,"completed":162,"skipped":2717,"failed":0}
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:11:13.579: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-7224
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating stateful set ss in namespace statefulset-7224
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7224
Mar 27 10:11:14.324: INFO: Found 0 stateful pods, waiting for 1
Mar 27 10:11:24.532: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 10:11:34.327: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar 27 10:11:34.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:11:34.691: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:11:34.691: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:11:34.691: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 10:11:34.693: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 27 10:11:44.697: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 10:11:44.698: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:11:44.743: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:11:44.743: INFO: ss-0  172.22.33.41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:35 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:11:44.743: INFO: 
Mar 27 10:11:44.743: INFO: StatefulSet ss has not reached scale 3, at 1
Mar 27 10:11:45.782: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.958574787s
Mar 27 10:11:46.785: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.919339122s
Mar 27 10:11:47.787: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.916943006s
Mar 27 10:11:48.790: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.914515441s
Mar 27 10:11:49.880: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.91221955s
Mar 27 10:11:50.882: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.82170051s
Mar 27 10:11:51.885: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.819412976s
Mar 27 10:11:52.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.817082601s
Mar 27 10:11:53.889: INFO: Verifying statefulset ss doesn't scale past 3 for another 814.769634ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7224
Mar 27 10:11:54.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:11:55.030: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 10:11:55.030: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 10:11:55.030: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 10:11:55.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:11:55.129: INFO: rc: 1
Mar 27 10:11:55.129: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Mar 27 10:12:05.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:05.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 27 10:12:05.274: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 10:12:05.274: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 10:12:05.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:05.431: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar 27 10:12:05.431: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 10:12:05.432: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 10:12:05.436: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:12:05.436: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:12:05.436: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar 27 10:12:05.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:12:05.580: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:12:05.580: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:12:05.580: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 10:12:05.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:12:05.875: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:12:05.875: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:12:05.875: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 10:12:05.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:12:06.030: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:12:06.030: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:12:06.030: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 10:12:06.030: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:12:06.031: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar 27 10:12:16.039: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 10:12:16.039: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 10:12:16.039: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 10:12:16.053: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:16.053: INFO: ss-0  172.22.33.41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:16.053: INFO: ss-1  172.22.33.40  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:16.054: INFO: ss-2  172.22.33.41  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:16.054: INFO: 
Mar 27 10:12:16.054: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 10:12:17.056: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:17.056: INFO: ss-0  172.22.33.41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:17.056: INFO: ss-1  172.22.33.40  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:17.056: INFO: ss-2  172.22.33.41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:17.056: INFO: 
Mar 27 10:12:17.056: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 10:12:18.059: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:18.059: INFO: ss-0  172.22.33.41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:18.059: INFO: ss-1  172.22.33.40  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:18.059: INFO: ss-2  172.22.33.41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:18.059: INFO: 
Mar 27 10:12:18.059: INFO: StatefulSet ss has not reached scale 0, at 3
Mar 27 10:12:19.061: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:19.061: INFO: ss-0  172.22.33.41  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:19.061: INFO: ss-2  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:06 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:44 +0000 UTC  }]
Mar 27 10:12:19.061: INFO: 
Mar 27 10:12:19.061: INFO: StatefulSet ss has not reached scale 0, at 2
Mar 27 10:12:20.063: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:20.063: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:20.063: INFO: 
Mar 27 10:12:20.063: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 10:12:21.066: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:21.066: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:21.066: INFO: 
Mar 27 10:12:21.066: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 10:12:22.068: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:22.068: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:22.068: INFO: 
Mar 27 10:12:22.068: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 10:12:23.070: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:23.070: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:23.070: INFO: 
Mar 27 10:12:23.070: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 10:12:24.200: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:24.200: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:24.200: INFO: 
Mar 27 10:12:24.200: INFO: StatefulSet ss has not reached scale 0, at 1
Mar 27 10:12:25.202: INFO: POD   NODE          PHASE    GRACE  CONDITIONS
Mar 27 10:12:25.202: INFO: ss-0  172.22.33.41  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:12:05 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-27 10:11:14 +0000 UTC  }]
Mar 27 10:12:25.203: INFO: 
Mar 27 10:12:25.203: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7224
Mar 27 10:12:26.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:26.320: INFO: rc: 1
Mar 27 10:12:26.320: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Mar 27 10:12:36.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:36.402: INFO: rc: 1
Mar 27 10:12:36.402: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:12:46.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:46.481: INFO: rc: 1
Mar 27 10:12:46.482: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:12:56.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:12:56.559: INFO: rc: 1
Mar 27 10:12:56.559: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:06.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:06.636: INFO: rc: 1
Mar 27 10:13:06.636: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:16.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:16.715: INFO: rc: 1
Mar 27 10:13:16.715: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:26.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:26.798: INFO: rc: 1
Mar 27 10:13:26.799: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:36.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:36.880: INFO: rc: 1
Mar 27 10:13:36.880: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:46.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:46.966: INFO: rc: 1
Mar 27 10:13:46.966: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:13:56.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:13:57.040: INFO: rc: 1
Mar 27 10:13:57.040: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:14:07.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:14:07.120: INFO: rc: 1
Mar 27 10:14:07.120: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:14:17.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:14:17.207: INFO: rc: 1
Mar 27 10:14:17.207: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:14:27.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:14:30.651: INFO: rc: 1
Mar 27 10:14:30.652: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:14:40.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:14:40.731: INFO: rc: 1
Mar 27 10:14:40.731: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:14:50.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:14:50.808: INFO: rc: 1
Mar 27 10:14:50.808: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:00.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:00.899: INFO: rc: 1
Mar 27 10:15:00.899: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:10.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:10.975: INFO: rc: 1
Mar 27 10:15:10.975: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:20.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:21.052: INFO: rc: 1
Mar 27 10:15:21.052: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:31.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:31.133: INFO: rc: 1
Mar 27 10:15:31.133: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:41.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:41.207: INFO: rc: 1
Mar 27 10:15:41.207: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:15:51.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:15:51.295: INFO: rc: 1
Mar 27 10:15:51.296: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:01.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:01.377: INFO: rc: 1
Mar 27 10:16:01.377: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:11.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:11.462: INFO: rc: 1
Mar 27 10:16:11.462: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:21.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:21.543: INFO: rc: 1
Mar 27 10:16:21.543: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:31.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:31.618: INFO: rc: 1
Mar 27 10:16:31.618: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:41.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:41.695: INFO: rc: 1
Mar 27 10:16:41.695: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:16:51.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:16:51.771: INFO: rc: 1
Mar 27 10:16:51.771: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:17:01.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:17:01.851: INFO: rc: 1
Mar 27 10:17:01.851: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:17:11.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:17:11.930: INFO: rc: 1
Mar 27 10:17:11.930: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:17:21.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:17:22.007: INFO: rc: 1
Mar 27 10:17:22.007: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Mar 27 10:17:32.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-7224 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:17:32.088: INFO: rc: 1
Mar 27 10:17:32.088: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Mar 27 10:17:32.088: INFO: Scaling statefulset ss to 0
Mar 27 10:17:32.092: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 10:17:32.093: INFO: Deleting all statefulset in ns statefulset-7224
Mar 27 10:17:32.094: INFO: Scaling statefulset ss to 0
Mar 27 10:17:32.098: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:17:32.099: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:17:32.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7224" for this suite.

• [SLOW TEST:378.530 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":280,"completed":163,"skipped":2720,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:17:32.109: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 10:17:32.495: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be" in namespace "downward-api-8665" to be "success or failure"
Mar 27 10:17:32.582: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 87.147464ms
Mar 27 10:17:34.586: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090926507s
Mar 27 10:17:36.588: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093118529s
Mar 27 10:17:38.636: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 6.140816086s
Mar 27 10:17:40.710: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 8.214686668s
Mar 27 10:17:42.712: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Pending", Reason="", readiness=false. Elapsed: 10.216824229s
Mar 27 10:17:44.714: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.218749203s
STEP: Saw pod success
Mar 27 10:17:44.714: INFO: Pod "downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be" satisfied condition "success or failure"
Mar 27 10:17:44.715: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be container client-container: <nil>
STEP: delete the pod
Mar 27 10:17:44.744: INFO: Waiting for pod downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be to disappear
Mar 27 10:17:44.800: INFO: Pod downwardapi-volume-8e75a0db-fbd2-47b6-b235-3598d1e823be no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:17:44.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8665" for this suite.

• [SLOW TEST:12.695 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":280,"completed":164,"skipped":2746,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:17:44.804: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-f7908b3c-d728-4a58-a26b-d7ed1dcb1eca
STEP: Creating a pod to test consume configMaps
Mar 27 10:17:45.128: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b" in namespace "configmap-3385" to be "success or failure"
Mar 27 10:17:45.162: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.402444ms
Mar 27 10:17:47.164: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03641482s
Mar 27 10:17:49.166: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03840853s
Mar 27 10:17:51.168: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040493876s
Mar 27 10:17:53.170: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042515685s
Mar 27 10:17:55.172: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.044682437s
Mar 27 10:17:57.175: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.046886032s
STEP: Saw pod success
Mar 27 10:17:57.175: INFO: Pod "pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b" satisfied condition "success or failure"
Mar 27 10:17:57.176: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:17:57.221: INFO: Waiting for pod pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b to disappear
Mar 27 10:17:57.346: INFO: Pod pod-configmaps-b2b83126-ec93-4eea-9cd0-cd2110f8d83b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:17:57.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3385" for this suite.

• [SLOW TEST:12.546 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":165,"skipped":2754,"failed":0}
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:17:57.350: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override all
Mar 27 10:17:57.578: INFO: Waiting up to 5m0s for pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c" in namespace "containers-5289" to be "success or failure"
Mar 27 10:17:57.891: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 312.837609ms
Mar 27 10:17:59.893: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.314847025s
Mar 27 10:18:01.895: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.316884218s
Mar 27 10:18:03.897: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.319129888s
Mar 27 10:18:05.899: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.321167766s
Mar 27 10:18:07.911: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.332704311s
Mar 27 10:18:09.930: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.352139042s
STEP: Saw pod success
Mar 27 10:18:09.930: INFO: Pod "client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c" satisfied condition "success or failure"
Mar 27 10:18:09.932: INFO: Trying to get logs from node 172.22.33.41 pod client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c container test-container: <nil>
STEP: delete the pod
Mar 27 10:18:10.012: INFO: Waiting for pod client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c to disappear
Mar 27 10:18:10.128: INFO: Pod client-containers-3b8c318d-0351-4f24-9035-6c7d00d2ea4c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:18:10.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5289" for this suite.

• [SLOW TEST:12.783 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":280,"completed":166,"skipped":2757,"failed":0}
SSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:18:10.133: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-projected-all-test-volume-634e4b43-8a8c-4ad0-bc95-035808a7942d
STEP: Creating secret with name secret-projected-all-test-volume-edd67c71-e525-4031-be3f-6a4aaa032681
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar 27 10:18:11.021: INFO: Waiting up to 5m0s for pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74" in namespace "projected-3695" to be "success or failure"
Mar 27 10:18:11.042: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 21.184753ms
Mar 27 10:18:13.044: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023436699s
Mar 27 10:18:15.046: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025492206s
Mar 27 10:18:17.048: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 6.027524226s
Mar 27 10:18:19.050: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 8.029572535s
Mar 27 10:18:21.052: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Pending", Reason="", readiness=false. Elapsed: 10.031615122s
Mar 27 10:18:23.055: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.033778977s
STEP: Saw pod success
Mar 27 10:18:23.055: INFO: Pod "projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74" satisfied condition "success or failure"
Mar 27 10:18:23.056: INFO: Trying to get logs from node 172.22.33.41 pod projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar 27 10:18:23.247: INFO: Waiting for pod projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74 to disappear
Mar 27 10:18:23.265: INFO: Pod projected-volume-99c06011-b4c0-4e55-a8de-eb367a00ad74 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:18:23.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3695" for this suite.

• [SLOW TEST:13.136 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":280,"completed":167,"skipped":2760,"failed":0}
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:18:23.269: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Mar 27 10:18:23.419: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Mar 27 10:18:36.779: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 10:18:39.894: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:18:51.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1044" for this suite.

• [SLOW TEST:27.951 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":280,"completed":168,"skipped":2762,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:18:51.220: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar 27 10:19:04.352: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:19:05.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-348" for this suite.

• [SLOW TEST:14.171 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":280,"completed":169,"skipped":2789,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:19:05.392: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-7a157190-9a1b-4d81-9308-59928d3d6dd5
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7a157190-9a1b-4d81-9308-59928d3d6dd5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:19:20.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4488" for this suite.

• [SLOW TEST:14.970 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":170,"skipped":2790,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:19:20.364: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-1740
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 10:19:20.495: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 10:20:02.771: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.33.86:8080/dial?request=hostname&protocol=udp&host=172.22.33.84&port=8081&tries=1'] Namespace:pod-network-test-1740 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 10:20:02.771: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 10:20:02.836: INFO: Waiting for responses: map[]
Mar 27 10:20:02.838: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.33.86:8080/dial?request=hostname&protocol=udp&host=172.22.33.85&port=8081&tries=1'] Namespace:pod-network-test-1740 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 10:20:02.838: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 10:20:02.897: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:20:02.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1740" for this suite.

• [SLOW TEST:42.537 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":171,"skipped":2850,"failed":0}
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:20:02.902: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-secret-jvbn
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 10:20:03.036: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-jvbn" in namespace "subpath-1197" to be "success or failure"
Mar 27 10:20:03.047: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.61071ms
Mar 27 10:20:05.049: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012769559s
Mar 27 10:20:07.051: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015144679s
Mar 27 10:20:09.080: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.043701829s
Mar 27 10:20:11.082: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.045907068s
Mar 27 10:20:13.084: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.047873678s
Mar 27 10:20:15.086: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.049958709s
Mar 27 10:20:17.088: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.052205681s
Mar 27 10:20:19.090: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 16.054364739s
Mar 27 10:20:21.092: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 18.05653022s
Mar 27 10:20:23.094: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 20.058591057s
Mar 27 10:20:25.097: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 22.060774294s
Mar 27 10:20:27.099: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 24.06291612s
Mar 27 10:20:29.101: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 26.065164176s
Mar 27 10:20:31.103: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 28.067387945s
Mar 27 10:20:33.107: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Pending", Reason="", readiness=false. Elapsed: 30.071021998s
Mar 27 10:20:35.109: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 32.073206646s
Mar 27 10:20:37.111: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 34.0755182s
Mar 27 10:20:39.114: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 36.077737835s
Mar 27 10:20:41.116: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 38.079700279s
Mar 27 10:20:43.118: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 40.081940621s
Mar 27 10:20:45.120: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 42.084262637s
Mar 27 10:20:47.122: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 44.08655328s
Mar 27 10:20:49.125: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 46.088714981s
Mar 27 10:20:51.127: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 48.091492381s
Mar 27 10:20:53.130: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Running", Reason="", readiness=true. Elapsed: 50.093704028s
Mar 27 10:20:55.132: INFO: Pod "pod-subpath-test-secret-jvbn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 52.095734751s
STEP: Saw pod success
Mar 27 10:20:55.132: INFO: Pod "pod-subpath-test-secret-jvbn" satisfied condition "success or failure"
Mar 27 10:20:55.133: INFO: Trying to get logs from node 172.22.33.41 pod pod-subpath-test-secret-jvbn container test-container-subpath-secret-jvbn: <nil>
STEP: delete the pod
Mar 27 10:20:55.395: INFO: Waiting for pod pod-subpath-test-secret-jvbn to disappear
Mar 27 10:20:55.436: INFO: Pod pod-subpath-test-secret-jvbn no longer exists
STEP: Deleting pod pod-subpath-test-secret-jvbn
Mar 27 10:20:55.436: INFO: Deleting pod "pod-subpath-test-secret-jvbn" in namespace "subpath-1197"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:20:55.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1197" for this suite.

• [SLOW TEST:52.826 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":280,"completed":172,"skipped":2853,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:20:55.729: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6699
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6699
STEP: creating replication controller externalsvc in namespace services-6699
I0327 10:20:56.166534      24 runners.go:189] Created replication controller with name: externalsvc, namespace: services-6699, replica count: 2
I0327 10:20:59.216827      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:21:02.216948      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:21:05.217119      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:21:08.217258      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:21:11.217425      24 runners.go:189] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Mar 27 10:21:11.388: INFO: Creating new exec pod
Mar 27 10:21:23.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-6699 execpodcc8vs -- /bin/sh -x -c nslookup clusterip-service'
Mar 27 10:21:23.599: INFO: stderr: "+ nslookup clusterip-service\n"
Mar 27 10:21:23.599: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nclusterip-service.services-6699.svc.cluster.local\tcanonical name = externalsvc.services-6699.svc.cluster.local.\nName:\texternalsvc.services-6699.svc.cluster.local\nAddress: 10.254.234.192\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6699, will wait for the garbage collector to delete the pods
Mar 27 10:21:23.653: INFO: Deleting ReplicationController externalsvc took: 2.965402ms
Mar 27 10:21:24.154: INFO: Terminating ReplicationController externalsvc pods took: 500.173689ms
Mar 27 10:21:29.704: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:21:30.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6699" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:34.295 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":280,"completed":173,"skipped":2874,"failed":0}
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:21:30.024: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 10:21:30.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c" in namespace "downward-api-9483" to be "success or failure"
Mar 27 10:21:30.288: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.946273ms
Mar 27 10:21:32.290: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018986061s
Mar 27 10:21:34.292: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020930427s
Mar 27 10:21:36.295: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.023589833s
Mar 27 10:21:38.297: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.025769257s
Mar 27 10:21:40.528: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.25632865s
Mar 27 10:21:42.530: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.258236263s
STEP: Saw pod success
Mar 27 10:21:42.530: INFO: Pod "downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c" satisfied condition "success or failure"
Mar 27 10:21:42.531: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c container client-container: <nil>
STEP: delete the pod
Mar 27 10:21:42.642: INFO: Waiting for pod downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c to disappear
Mar 27 10:21:42.679: INFO: Pod downwardapi-volume-8b7a29be-9001-4033-9f8f-c86d6ddb760c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:21:42.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9483" for this suite.

• [SLOW TEST:12.659 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":280,"completed":174,"skipped":2874,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:21:42.683: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Mar 27 10:21:43.044: INFO: Created pod &Pod{ObjectMeta:{dns-6548  dns-6548 /api/v1/namespaces/dns-6548/pods/dns-6548 86aa51f0-dbcb-4820-a731-aa4ce56f6a2c 347155 0 2020-03-27 10:21:43 +0000 UTC <nil> <nil> map[] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-t6v9c,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-t6v9c,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-t6v9c,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
STEP: Verifying customized DNS suffix list is configured on pod...
Mar 27 10:21:53.092: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6548 PodName:dns-6548 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 10:21:53.092: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Verifying customized DNS server is configured on pod...
Mar 27 10:21:53.154: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6548 PodName:dns-6548 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 10:21:53.154: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 10:21:53.215: INFO: Deleting pod dns-6548...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:21:53.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6548" for this suite.

• [SLOW TEST:10.852 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":280,"completed":175,"skipped":2903,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:21:53.535: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-f3de022c-ce18-4ce3-89c2-46c82381cb38
STEP: Creating a pod to test consume secrets
Mar 27 10:21:53.744: INFO: Waiting up to 5m0s for pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5" in namespace "secrets-77" to be "success or failure"
Mar 27 10:21:53.837: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 93.472309ms
Mar 27 10:21:55.839: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.095588024s
Mar 27 10:21:57.841: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097558643s
Mar 27 10:21:59.893: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.149454334s
Mar 27 10:22:01.895: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.151415208s
Mar 27 10:22:03.897: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.153591384s
Mar 27 10:22:05.914: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.170133757s
Mar 27 10:22:07.916: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.172271695s
STEP: Saw pod success
Mar 27 10:22:07.916: INFO: Pod "pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5" satisfied condition "success or failure"
Mar 27 10:22:07.917: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:22:08.038: INFO: Waiting for pod pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5 to disappear
Mar 27 10:22:08.094: INFO: Pod pod-secrets-3af6e5e8-6fa6-4ffb-aa46-799d3e1cbaf5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:22:08.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-77" for this suite.

• [SLOW TEST:14.564 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":176,"skipped":2913,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:22:08.100: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Mar 27 10:22:08.794: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:22:25.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8332" for this suite.

• [SLOW TEST:17.424 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":280,"completed":177,"skipped":2943,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:22:25.525: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar 27 10:22:26.140: INFO: Waiting up to 5m0s for pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171" in namespace "emptydir-9118" to be "success or failure"
Mar 27 10:22:26.193: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 53.26565ms
Mar 27 10:22:28.195: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05558393s
Mar 27 10:22:30.221: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081375047s
Mar 27 10:22:32.223: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 6.083503934s
Mar 27 10:22:34.225: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 8.08559018s
Mar 27 10:22:36.227: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 10.087689134s
Mar 27 10:22:38.229: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 12.089668678s
Mar 27 10:22:40.458: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 14.318623712s
Mar 27 10:22:42.460: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 16.320492595s
Mar 27 10:22:44.462: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 18.322388006s
Mar 27 10:22:46.464: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 20.324245394s
Mar 27 10:22:48.466: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 22.326275432s
Mar 27 10:22:50.468: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 24.328417952s
Mar 27 10:22:52.470: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 26.330308692s
Mar 27 10:22:54.472: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 28.332099832s
Mar 27 10:22:56.506: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Pending", Reason="", readiness=false. Elapsed: 30.365930538s
Mar 27 10:22:58.508: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.368173792s
STEP: Saw pod success
Mar 27 10:22:58.508: INFO: Pod "pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171" satisfied condition "success or failure"
Mar 27 10:22:58.509: INFO: Trying to get logs from node 172.22.33.41 pod pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171 container test-container: <nil>
STEP: delete the pod
Mar 27 10:22:58.862: INFO: Waiting for pod pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171 to disappear
Mar 27 10:22:59.123: INFO: Pod pod-6bb860f4-e3c4-4f9e-9d04-7a52a39b3171 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:22:59.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9118" for this suite.

• [SLOW TEST:33.972 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":178,"skipped":2949,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:22:59.497: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:23:00.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6859" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":280,"completed":179,"skipped":2949,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:23:00.101: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 27 10:23:00.317: INFO: Waiting up to 5m0s for pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1" in namespace "downward-api-2033" to be "success or failure"
Mar 27 10:23:00.348: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 31.779305ms
Mar 27 10:23:02.351: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034021055s
Mar 27 10:23:04.353: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036193352s
Mar 27 10:23:06.355: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.038587149s
Mar 27 10:23:08.357: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.040763446s
Mar 27 10:23:10.378: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.061368552s
Mar 27 10:23:12.380: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.063596012s
STEP: Saw pod success
Mar 27 10:23:12.380: INFO: Pod "downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1" satisfied condition "success or failure"
Mar 27 10:23:12.381: INFO: Trying to get logs from node 172.22.33.41 pod downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1 container dapi-container: <nil>
STEP: delete the pod
Mar 27 10:23:12.763: INFO: Waiting for pod downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1 to disappear
Mar 27 10:23:12.843: INFO: Pod downward-api-19ebf2db-d395-41f0-8dae-040d8c4a71a1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:23:12.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2033" for this suite.

• [SLOW TEST:12.745 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":280,"completed":180,"skipped":2950,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:23:12.848: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:23:15.327: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:23:17.332: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:23:19.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:23:21.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:23:23.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:23:25.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901395, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:23:28.497: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:23:28.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5267" for this suite.
STEP: Destroying namespace "webhook-5267-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.909 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":280,"completed":181,"skipped":2976,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:23:29.758: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Mar 27 10:23:30.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-9334'
Mar 27 10:23:30.590: INFO: stderr: ""
Mar 27 10:23:30.590: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 10:23:30.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:30.806: INFO: stderr: ""
Mar 27 10:23:30.806: INFO: stdout: "update-demo-nautilus-trhjv "
STEP: Replicas for name=update-demo: expected=2 actual=1
Mar 27 10:23:35.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:35.903: INFO: stderr: ""
Mar 27 10:23:35.903: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-trhjv "
Mar 27 10:23:35.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:35.986: INFO: stderr: ""
Mar 27 10:23:35.986: INFO: stdout: ""
Mar 27 10:23:35.986: INFO: update-demo-nautilus-6t27r is created but not running
Mar 27 10:23:40.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:41.084: INFO: stderr: ""
Mar 27 10:23:41.084: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-trhjv "
Mar 27 10:23:41.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:41.178: INFO: stderr: ""
Mar 27 10:23:41.178: INFO: stdout: ""
Mar 27 10:23:41.178: INFO: update-demo-nautilus-6t27r is created but not running
Mar 27 10:23:46.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:46.258: INFO: stderr: ""
Mar 27 10:23:46.258: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-trhjv "
Mar 27 10:23:46.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:46.335: INFO: stderr: ""
Mar 27 10:23:46.335: INFO: stdout: "true"
Mar 27 10:23:46.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:46.411: INFO: stderr: ""
Mar 27 10:23:46.411: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:23:46.411: INFO: validating pod update-demo-nautilus-6t27r
Mar 27 10:23:46.416: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:23:46.416: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:23:46.416: INFO: update-demo-nautilus-6t27r is verified up and running
Mar 27 10:23:46.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-trhjv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:46.497: INFO: stderr: ""
Mar 27 10:23:46.497: INFO: stdout: "true"
Mar 27 10:23:46.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-trhjv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:46.577: INFO: stderr: ""
Mar 27 10:23:46.577: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:23:46.577: INFO: validating pod update-demo-nautilus-trhjv
Mar 27 10:23:46.582: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:23:46.582: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:23:46.582: INFO: update-demo-nautilus-trhjv is verified up and running
STEP: scaling down the replication controller
Mar 27 10:23:46.583: INFO: scanned /root for discovery docs: <nil>
Mar 27 10:23:46.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9334'
Mar 27 10:23:47.714: INFO: stderr: ""
Mar 27 10:23:47.714: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 10:23:47.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:47.800: INFO: stderr: ""
Mar 27 10:23:47.800: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-trhjv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar 27 10:23:52.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:52.889: INFO: stderr: ""
Mar 27 10:23:52.889: INFO: stdout: "update-demo-nautilus-6t27r "
Mar 27 10:23:52.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:52.961: INFO: stderr: ""
Mar 27 10:23:52.961: INFO: stdout: "true"
Mar 27 10:23:52.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:53.046: INFO: stderr: ""
Mar 27 10:23:53.046: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:23:53.046: INFO: validating pod update-demo-nautilus-6t27r
Mar 27 10:23:53.048: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:23:53.048: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:23:53.048: INFO: update-demo-nautilus-6t27r is verified up and running
STEP: scaling up the replication controller
Mar 27 10:23:53.049: INFO: scanned /root for discovery docs: <nil>
Mar 27 10:23:53.049: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9334'
Mar 27 10:23:54.544: INFO: stderr: ""
Mar 27 10:23:54.544: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 10:23:54.544: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:23:54.687: INFO: stderr: ""
Mar 27 10:23:54.687: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-fbjgh "
Mar 27 10:23:54.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:54.762: INFO: stderr: ""
Mar 27 10:23:54.762: INFO: stdout: "true"
Mar 27 10:23:54.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:54.841: INFO: stderr: ""
Mar 27 10:23:54.841: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:23:54.841: INFO: validating pod update-demo-nautilus-6t27r
Mar 27 10:23:54.843: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:23:54.843: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:23:54.843: INFO: update-demo-nautilus-6t27r is verified up and running
Mar 27 10:23:54.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-fbjgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:23:55.245: INFO: stderr: ""
Mar 27 10:23:55.245: INFO: stdout: ""
Mar 27 10:23:55.245: INFO: update-demo-nautilus-fbjgh is created but not running
Mar 27 10:24:00.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:24:00.380: INFO: stderr: ""
Mar 27 10:24:00.381: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-fbjgh "
Mar 27 10:24:00.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:00.461: INFO: stderr: ""
Mar 27 10:24:00.461: INFO: stdout: "true"
Mar 27 10:24:00.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:00.555: INFO: stderr: ""
Mar 27 10:24:00.555: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:24:00.555: INFO: validating pod update-demo-nautilus-6t27r
Mar 27 10:24:00.557: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:24:00.557: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:24:00.557: INFO: update-demo-nautilus-6t27r is verified up and running
Mar 27 10:24:00.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-fbjgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:00.647: INFO: stderr: ""
Mar 27 10:24:00.647: INFO: stdout: ""
Mar 27 10:24:00.647: INFO: update-demo-nautilus-fbjgh is created but not running
Mar 27 10:24:05.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9334'
Mar 27 10:24:05.729: INFO: stderr: ""
Mar 27 10:24:05.729: INFO: stdout: "update-demo-nautilus-6t27r update-demo-nautilus-fbjgh "
Mar 27 10:24:05.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:05.812: INFO: stderr: ""
Mar 27 10:24:05.812: INFO: stdout: "true"
Mar 27 10:24:05.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-6t27r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:05.887: INFO: stderr: ""
Mar 27 10:24:05.887: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:24:05.887: INFO: validating pod update-demo-nautilus-6t27r
Mar 27 10:24:05.889: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:24:05.889: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:24:05.889: INFO: update-demo-nautilus-6t27r is verified up and running
Mar 27 10:24:05.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-fbjgh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:05.965: INFO: stderr: ""
Mar 27 10:24:05.965: INFO: stdout: "true"
Mar 27 10:24:05.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-fbjgh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9334'
Mar 27 10:24:06.041: INFO: stderr: ""
Mar 27 10:24:06.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:24:06.041: INFO: validating pod update-demo-nautilus-fbjgh
Mar 27 10:24:06.045: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:24:06.045: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:24:06.045: INFO: update-demo-nautilus-fbjgh is verified up and running
STEP: using delete to clean up resources
Mar 27 10:24:06.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-9334'
Mar 27 10:24:06.126: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 10:24:06.126: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 27 10:24:06.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9334'
Mar 27 10:24:06.213: INFO: stderr: "No resources found in kubectl-9334 namespace.\n"
Mar 27 10:24:06.213: INFO: stdout: ""
Mar 27 10:24:06.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -l name=update-demo --namespace=kubectl-9334 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 10:24:06.292: INFO: stderr: ""
Mar 27 10:24:06.292: INFO: stdout: "update-demo-nautilus-6t27r\nupdate-demo-nautilus-fbjgh\n"
Mar 27 10:24:06.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9334'
Mar 27 10:24:06.925: INFO: stderr: "No resources found in kubectl-9334 namespace.\n"
Mar 27 10:24:06.925: INFO: stdout: ""
Mar 27 10:24:06.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -l name=update-demo --namespace=kubectl-9334 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 10:24:07.010: INFO: stderr: ""
Mar 27 10:24:07.010: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:24:07.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9334" for this suite.

• [SLOW TEST:37.256 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":280,"completed":182,"skipped":2977,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:24:07.014: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 10:24:07.985: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904" in namespace "downward-api-8699" to be "success or failure"
Mar 27 10:24:08.096: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 110.384345ms
Mar 27 10:24:10.098: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 2.112248605s
Mar 27 10:24:12.209: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 4.223445217s
Mar 27 10:24:14.211: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 6.225577008s
Mar 27 10:24:16.213: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 8.227755883s
Mar 27 10:24:18.215: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 10.229828963s
Mar 27 10:24:20.217: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Pending", Reason="", readiness=false. Elapsed: 12.231679501s
Mar 27 10:24:22.219: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.233699039s
STEP: Saw pod success
Mar 27 10:24:22.219: INFO: Pod "downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904" satisfied condition "success or failure"
Mar 27 10:24:22.220: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904 container client-container: <nil>
STEP: delete the pod
Mar 27 10:24:22.273: INFO: Waiting for pod downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904 to disappear
Mar 27 10:24:22.289: INFO: Pod downwardapi-volume-b5b8f3b1-8c03-472d-8381-e986904fa904 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:24:22.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8699" for this suite.

• [SLOW TEST:15.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":183,"skipped":2987,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:24:22.292: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-map-f562a8cc-d2e1-4b6f-8d8d-512807449b63
STEP: Creating a pod to test consume configMaps
Mar 27 10:24:22.451: INFO: Waiting up to 5m0s for pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418" in namespace "configmap-3262" to be "success or failure"
Mar 27 10:24:22.460: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 9.378322ms
Mar 27 10:24:24.462: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011464719s
Mar 27 10:24:26.471: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 4.02067648s
Mar 27 10:24:28.473: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022847838s
Mar 27 10:24:30.475: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024875188s
Mar 27 10:24:32.484: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Pending", Reason="", readiness=false. Elapsed: 10.033210255s
Mar 27 10:24:34.486: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.035465721s
STEP: Saw pod success
Mar 27 10:24:34.486: INFO: Pod "pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418" satisfied condition "success or failure"
Mar 27 10:24:34.488: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:24:34.652: INFO: Waiting for pod pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418 to disappear
Mar 27 10:24:34.724: INFO: Pod pod-configmaps-8e9cb97e-ac0c-478e-b376-bd297855c418 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:24:34.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3262" for this suite.

• [SLOW TEST:12.436 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":184,"skipped":2998,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:24:34.729: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-configmap-nc5g
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 10:24:35.114: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-nc5g" in namespace "subpath-348" to be "success or failure"
Mar 27 10:24:35.180: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 66.529488ms
Mar 27 10:24:37.183: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068588908s
Mar 27 10:24:39.185: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 4.070563022s
Mar 27 10:24:41.237: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 6.123225269s
Mar 27 10:24:43.239: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 8.125259232s
Mar 27 10:24:45.244: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 10.130471689s
Mar 27 10:24:47.246: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 12.132382041s
Mar 27 10:24:49.248: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 14.134406916s
Mar 27 10:24:51.250: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 16.136466035s
Mar 27 10:24:53.253: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 18.138631453s
Mar 27 10:24:55.255: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 20.140660929s
Mar 27 10:24:57.257: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 22.142604497s
Mar 27 10:24:59.261: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 24.14700935s
Mar 27 10:25:01.292: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 26.177989065s
Mar 27 10:25:03.294: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Pending", Reason="", readiness=false. Elapsed: 28.180142829s
Mar 27 10:25:05.296: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 30.182173269s
Mar 27 10:25:07.298: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 32.18410781s
Mar 27 10:25:09.300: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 34.186161157s
Mar 27 10:25:11.308: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 36.193876025s
Mar 27 10:25:13.310: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 38.196105812s
Mar 27 10:25:15.312: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 40.198347177s
Mar 27 10:25:17.314: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 42.200406161s
Mar 27 10:25:19.316: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 44.20245999s
Mar 27 10:25:21.319: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 46.204572062s
Mar 27 10:25:23.321: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Running", Reason="", readiness=true. Elapsed: 48.20670564s
Mar 27 10:25:25.364: INFO: Pod "pod-subpath-test-configmap-nc5g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 50.250526836s
STEP: Saw pod success
Mar 27 10:25:25.365: INFO: Pod "pod-subpath-test-configmap-nc5g" satisfied condition "success or failure"
Mar 27 10:25:25.369: INFO: Trying to get logs from node 172.22.33.41 pod pod-subpath-test-configmap-nc5g container test-container-subpath-configmap-nc5g: <nil>
STEP: delete the pod
Mar 27 10:25:25.422: INFO: Waiting for pod pod-subpath-test-configmap-nc5g to disappear
Mar 27 10:25:25.434: INFO: Pod pod-subpath-test-configmap-nc5g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-nc5g
Mar 27 10:25:25.434: INFO: Deleting pod "pod-subpath-test-configmap-nc5g" in namespace "subpath-348"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:25:25.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-348" for this suite.

• [SLOW TEST:50.711 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":280,"completed":185,"skipped":3033,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:25:25.442: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 10:25:26.116: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5" in namespace "projected-1047" to be "success or failure"
Mar 27 10:25:26.524: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 407.905791ms
Mar 27 10:25:28.526: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409934085s
Mar 27 10:25:30.630: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.513354435s
Mar 27 10:25:32.632: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.515382995s
Mar 27 10:25:34.634: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.517607032s
Mar 27 10:25:36.795: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.678990694s
Mar 27 10:25:38.797: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.681114894s
STEP: Saw pod success
Mar 27 10:25:38.798: INFO: Pod "downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5" satisfied condition "success or failure"
Mar 27 10:25:38.799: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5 container client-container: <nil>
STEP: delete the pod
Mar 27 10:25:38.945: INFO: Waiting for pod downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5 to disappear
Mar 27 10:25:38.993: INFO: Pod downwardapi-volume-64679f99-3e46-4c23-a163-9f272c62cfc5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:25:38.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1047" for this suite.

• [SLOW TEST:13.555 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":280,"completed":186,"skipped":3045,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:25:38.998: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating service endpoint-test2 in namespace services-9737
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9737 to expose endpoints map[]
Mar 27 10:25:40.527: INFO: successfully validated that service endpoint-test2 in namespace services-9737 exposes endpoints map[] (322.042865ms elapsed)
STEP: Creating pod pod1 in namespace services-9737
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9737 to expose endpoints map[pod1:[80]]
Mar 27 10:25:45.453: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.472892241s elapsed, will retry)
Mar 27 10:25:50.470: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (9.489503241s elapsed, will retry)
Mar 27 10:25:52.546: INFO: successfully validated that service endpoint-test2 in namespace services-9737 exposes endpoints map[pod1:[80]] (11.565699878s elapsed)
STEP: Creating pod pod2 in namespace services-9737
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9737 to expose endpoints map[pod1:[80] pod2:[80]]
Mar 27 10:25:57.332: INFO: Unexpected endpoints: found map[e59028b6-0a84-4c48-878f-ebdda7e21caf:[80]], expected map[pod1:[80] pod2:[80]] (4.783775795s elapsed, will retry)
Mar 27 10:26:02.416: INFO: Unexpected endpoints: found map[e59028b6-0a84-4c48-878f-ebdda7e21caf:[80]], expected map[pod1:[80] pod2:[80]] (9.868140631s elapsed, will retry)
Mar 27 10:26:05.451: INFO: successfully validated that service endpoint-test2 in namespace services-9737 exposes endpoints map[pod1:[80] pod2:[80]] (12.90280953s elapsed)
STEP: Deleting pod pod1 in namespace services-9737
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9737 to expose endpoints map[pod2:[80]]
Mar 27 10:26:06.543: INFO: successfully validated that service endpoint-test2 in namespace services-9737 exposes endpoints map[pod2:[80]] (1.090369788s elapsed)
STEP: Deleting pod pod2 in namespace services-9737
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9737 to expose endpoints map[]
Mar 27 10:26:06.568: INFO: successfully validated that service endpoint-test2 in namespace services-9737 exposes endpoints map[] (21.923959ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:26:07.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9737" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:28.438 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":280,"completed":187,"skipped":3072,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:26:07.436: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 27 10:26:07.608: INFO: Waiting up to 5m0s for pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427" in namespace "emptydir-3336" to be "success or failure"
Mar 27 10:26:07.619: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 11.032558ms
Mar 27 10:26:09.621: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013061739s
Mar 27 10:26:11.624: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015884605s
Mar 27 10:26:13.788: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 6.179945343s
Mar 27 10:26:15.790: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 8.182046612s
Mar 27 10:26:17.792: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18410392s
Mar 27 10:26:19.794: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 12.186243251s
Mar 27 10:26:21.798: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 14.189842526s
Mar 27 10:26:23.800: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 16.192147933s
Mar 27 10:26:25.802: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 18.194162778s
Mar 27 10:26:27.814: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 20.205737077s
Mar 27 10:26:29.816: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 22.207740644s
Mar 27 10:26:31.818: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 24.209528683s
Mar 27 10:26:33.853: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 26.245139506s
Mar 27 10:26:35.855: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 28.247471299s
Mar 27 10:26:37.858: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 30.249522568s
Mar 27 10:26:39.981: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Pending", Reason="", readiness=false. Elapsed: 32.37252041s
Mar 27 10:26:41.983: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.374647973s
STEP: Saw pod success
Mar 27 10:26:41.983: INFO: Pod "pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427" satisfied condition "success or failure"
Mar 27 10:26:41.984: INFO: Trying to get logs from node 172.22.33.41 pod pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427 container test-container: <nil>
STEP: delete the pod
Mar 27 10:26:42.022: INFO: Waiting for pod pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427 to disappear
Mar 27 10:26:42.129: INFO: Pod pod-2b1c9cd1-3a5d-46fb-9d84-411c7857d427 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:26:42.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3336" for this suite.

• [SLOW TEST:34.696 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":188,"skipped":3073,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:26:42.133: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 27 10:26:42.302: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 10:26:42.341: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 10:26:42.342: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.40 before test
Mar 27 10:26:42.354: INFO: sonobuoy-e2e-job-d8cb2578911a4e68 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 10:26:42.354: INFO: 	Container e2e ready: true, restart count 0
Mar 27 10:26:42.354: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 10:26:42.354: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 10:26:42.354: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 27 10:26:42.354: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 10:26:42.354: INFO: coredns-f589df4f5-d98zd from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 10:26:42.354: INFO: 	Container coredns ready: true, restart count 19
Mar 27 10:26:42.354: INFO: sonobuoy from sonobuoy started at 2020-03-27 08:57:47 +0000 UTC (1 container statuses recorded)
Mar 27 10:26:42.354: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 10:26:42.354: INFO: zte-k8s-eviction-68f598776b-qxjnw from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 10:26:42.354: INFO: 	Container zte-k8s-eviction ready: true, restart count 0
Mar 27 10:26:42.354: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.41 before test
Mar 27 10:26:42.357: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s from sonobuoy started at 2020-03-27 08:58:18 +0000 UTC (2 container statuses recorded)
Mar 27 10:26:42.357: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 27 10:26:42.357: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 10:26:42.357: INFO: iag-172.22.33.41 from kube-system started at 2020-03-26 02:05:47 +0000 UTC (1 container statuses recorded)
Mar 27 10:26:42.357: INFO: 	Container iag ready: true, restart count 3
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1600225185b3b62d], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:26:43.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7614" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":280,"completed":189,"skipped":3089,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:26:43.523: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:26:44.469: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:26:46.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:26:48.476: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:26:50.476: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:26:52.477: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:26:54.488: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:26:56.688: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720901604, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:26:59.517: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Mar 27 10:27:13.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 attach --namespace=webhook-3730 to-be-attached-pod -i -c=container1'
Mar 27 10:27:16.728: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:27:16.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3730" for this suite.
STEP: Destroying namespace "webhook-3730-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:33.572 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":280,"completed":190,"skipped":3119,"failed":0}
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:27:17.094: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating the pod
Mar 27 10:27:30.010: INFO: Successfully updated pod "annotationupdate6c1ecab9-5d43-47a0-a382-80fcd64a868e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:27:34.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3934" for this suite.

• [SLOW TEST:17.020 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":280,"completed":191,"skipped":3122,"failed":0}
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:27:34.114: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward api env vars
Mar 27 10:27:34.472: INFO: Waiting up to 5m0s for pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f" in namespace "downward-api-2026" to be "success or failure"
Mar 27 10:27:34.685: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 212.977066ms
Mar 27 10:27:36.688: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215214402s
Mar 27 10:27:38.690: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.217426063s
Mar 27 10:27:40.749: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.276619383s
Mar 27 10:27:42.751: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.278617088s
Mar 27 10:27:44.759: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.28625075s
Mar 27 10:27:46.813: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.340649452s
STEP: Saw pod success
Mar 27 10:27:46.813: INFO: Pod "downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f" satisfied condition "success or failure"
Mar 27 10:27:46.815: INFO: Trying to get logs from node 172.22.33.41 pod downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f container dapi-container: <nil>
STEP: delete the pod
Mar 27 10:27:46.857: INFO: Waiting for pod downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f to disappear
Mar 27 10:27:46.879: INFO: Pod downward-api-57b2c233-bdd2-450f-b898-e80eec0fb70f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:27:46.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2026" for this suite.

• [SLOW TEST:12.768 seconds]
[sig-node] Downward API
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:33
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":280,"completed":192,"skipped":3123,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:27:46.883: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:27:59.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-219" for this suite.

• [SLOW TEST:12.976 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":280,"completed":193,"skipped":3131,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:27:59.860: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating projection with secret that has name secret-emptykey-test-66eea74a-ff60-4be8-adcf-a0b86ebdcbaf
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:28:00.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6590" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":280,"completed":194,"skipped":3142,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:28:00.948: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Mar 27 10:28:01.130: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 10:28:04.173: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:28:17.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4329" for this suite.

• [SLOW TEST:16.358 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":280,"completed":195,"skipped":3178,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:28:17.306: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0327 10:28:19.528680      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 10:28:19.528: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:28:19.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8435" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":280,"completed":196,"skipped":3192,"failed":0}
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:28:19.534: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-volume-20dc7680-647c-43e5-a59e-1a42b083e24b
STEP: Creating a pod to test consume configMaps
Mar 27 10:28:20.111: INFO: Waiting up to 5m0s for pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7" in namespace "configmap-8443" to be "success or failure"
Mar 27 10:28:20.145: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 34.490118ms
Mar 27 10:28:22.147: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036580992s
Mar 27 10:28:24.149: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.03855602s
Mar 27 10:28:26.151: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.040530936s
Mar 27 10:28:28.153: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.042449888s
Mar 27 10:28:30.266: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.155200651s
Mar 27 10:28:32.268: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.157193934s
STEP: Saw pod success
Mar 27 10:28:32.268: INFO: Pod "pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7" satisfied condition "success or failure"
Mar 27 10:28:32.269: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7 container configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:28:32.440: INFO: Waiting for pod pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7 to disappear
Mar 27 10:28:32.591: INFO: Pod pod-configmaps-906d2b12-0f77-4775-97f4-36ceff3a9ca7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:28:32.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8443" for this suite.

• [SLOW TEST:13.061 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":197,"skipped":3194,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:28:32.597: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:330
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a replication controller
Mar 27 10:28:33.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-6715'
Mar 27 10:28:34.205: INFO: stderr: ""
Mar 27 10:28:34.205: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar 27 10:28:34.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6715'
Mar 27 10:28:34.664: INFO: stderr: ""
Mar 27 10:28:34.664: INFO: stdout: "update-demo-nautilus-qd25h update-demo-nautilus-xpj9n "
Mar 27 10:28:34.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-qd25h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:34.747: INFO: stderr: ""
Mar 27 10:28:34.747: INFO: stdout: ""
Mar 27 10:28:34.747: INFO: update-demo-nautilus-qd25h is created but not running
Mar 27 10:28:39.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6715'
Mar 27 10:28:39.829: INFO: stderr: ""
Mar 27 10:28:39.829: INFO: stdout: "update-demo-nautilus-qd25h update-demo-nautilus-xpj9n "
Mar 27 10:28:39.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-qd25h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:39.918: INFO: stderr: ""
Mar 27 10:28:39.918: INFO: stdout: ""
Mar 27 10:28:39.918: INFO: update-demo-nautilus-qd25h is created but not running
Mar 27 10:28:44.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6715'
Mar 27 10:28:45.004: INFO: stderr: ""
Mar 27 10:28:45.004: INFO: stdout: "update-demo-nautilus-qd25h update-demo-nautilus-xpj9n "
Mar 27 10:28:45.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-qd25h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:45.156: INFO: stderr: ""
Mar 27 10:28:45.156: INFO: stdout: ""
Mar 27 10:28:45.156: INFO: update-demo-nautilus-qd25h is created but not running
Mar 27 10:28:50.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6715'
Mar 27 10:28:50.443: INFO: stderr: ""
Mar 27 10:28:50.443: INFO: stdout: "update-demo-nautilus-qd25h update-demo-nautilus-xpj9n "
Mar 27 10:28:50.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-qd25h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:50.520: INFO: stderr: ""
Mar 27 10:28:50.520: INFO: stdout: "true"
Mar 27 10:28:50.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-qd25h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:50.674: INFO: stderr: ""
Mar 27 10:28:50.674: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:28:50.674: INFO: validating pod update-demo-nautilus-qd25h
Mar 27 10:28:50.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:28:50.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:28:50.680: INFO: update-demo-nautilus-qd25h is verified up and running
Mar 27 10:28:50.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-xpj9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:50.759: INFO: stderr: ""
Mar 27 10:28:50.759: INFO: stdout: "true"
Mar 27 10:28:50.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods update-demo-nautilus-xpj9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6715'
Mar 27 10:28:50.834: INFO: stderr: ""
Mar 27 10:28:50.834: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Mar 27 10:28:50.834: INFO: validating pod update-demo-nautilus-xpj9n
Mar 27 10:28:50.839: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar 27 10:28:50.839: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar 27 10:28:50.839: INFO: update-demo-nautilus-xpj9n is verified up and running
STEP: using delete to clean up resources
Mar 27 10:28:50.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-6715'
Mar 27 10:28:50.967: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 10:28:50.967: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar 27 10:28:50.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6715'
Mar 27 10:28:51.088: INFO: stderr: "No resources found in kubectl-6715 namespace.\n"
Mar 27 10:28:51.088: INFO: stdout: ""
Mar 27 10:28:51.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -l name=update-demo --namespace=kubectl-6715 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 10:28:51.173: INFO: stderr: ""
Mar 27 10:28:51.173: INFO: stdout: "update-demo-nautilus-qd25h\nupdate-demo-nautilus-xpj9n\n"
Mar 27 10:28:51.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6715'
Mar 27 10:28:51.756: INFO: stderr: "No resources found in kubectl-6715 namespace.\n"
Mar 27 10:28:51.756: INFO: stdout: ""
Mar 27 10:28:51.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -l name=update-demo --namespace=kubectl-6715 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 10:28:51.998: INFO: stderr: ""
Mar 27 10:28:51.998: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:28:51.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6715" for this suite.

• [SLOW TEST:19.406 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:328
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":280,"completed":198,"skipped":3212,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:28:52.003: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl label
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1382
STEP: creating the pod
Mar 27 10:28:52.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-4052'
Mar 27 10:28:52.655: INFO: stderr: ""
Mar 27 10:28:52.655: INFO: stdout: "pod/pause created\n"
Mar 27 10:28:52.655: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar 27 10:28:52.656: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4052" to be "running and ready"
Mar 27 10:28:52.734: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 78.735501ms
Mar 27 10:28:54.736: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080612235s
Mar 27 10:28:56.738: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.082603204s
Mar 27 10:28:58.740: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.084632345s
Mar 27 10:29:00.742: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.08686249s
Mar 27 10:29:02.753: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.097595446s
Mar 27 10:29:04.763: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 12.107881526s
Mar 27 10:29:04.763: INFO: Pod "pause" satisfied condition "running and ready"
Mar 27 10:29:04.763: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: adding the label testing-label with value testing-label-value to a pod
Mar 27 10:29:04.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 label pods pause testing-label=testing-label-value --namespace=kubectl-4052'
Mar 27 10:29:04.842: INFO: stderr: ""
Mar 27 10:29:04.842: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar 27 10:29:04.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pod pause -L testing-label --namespace=kubectl-4052'
Mar 27 10:29:04.914: INFO: stderr: ""
Mar 27 10:29:04.914: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          12s   testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar 27 10:29:04.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 label pods pause testing-label- --namespace=kubectl-4052'
Mar 27 10:29:04.992: INFO: stderr: ""
Mar 27 10:29:04.992: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar 27 10:29:04.992: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pod pause -L testing-label --namespace=kubectl-4052'
Mar 27 10:29:05.075: INFO: stderr: ""
Mar 27 10:29:05.075: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          13s   \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1389
STEP: using delete to clean up resources
Mar 27 10:29:05.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete --grace-period=0 --force -f - --namespace=kubectl-4052'
Mar 27 10:29:05.206: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar 27 10:29:05.206: INFO: stdout: "pod \"pause\" force deleted\n"
Mar 27 10:29:05.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get rc,svc -l name=pause --no-headers --namespace=kubectl-4052'
Mar 27 10:29:05.292: INFO: stderr: "No resources found in kubectl-4052 namespace.\n"
Mar 27 10:29:05.292: INFO: stdout: ""
Mar 27 10:29:05.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 get pods -l name=pause --namespace=kubectl-4052 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar 27 10:29:05.378: INFO: stderr: ""
Mar 27 10:29:05.378: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:29:05.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4052" for this suite.

• [SLOW TEST:13.379 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1379
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":280,"completed":199,"skipped":3230,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:29:05.382: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:29:05.563: INFO: (0) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.946559ms)
Mar 27 10:29:05.565: INFO: (1) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.733526ms)
Mar 27 10:29:05.567: INFO: (2) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.553159ms)
Mar 27 10:29:05.568: INFO: (3) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.591566ms)
Mar 27 10:29:05.570: INFO: (4) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.787609ms)
Mar 27 10:29:05.572: INFO: (5) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.804883ms)
Mar 27 10:29:05.574: INFO: (6) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.69216ms)
Mar 27 10:29:05.575: INFO: (7) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.581131ms)
Mar 27 10:29:05.577: INFO: (8) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.581663ms)
Mar 27 10:29:05.578: INFO: (9) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.676679ms)
Mar 27 10:29:05.580: INFO: (10) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.613183ms)
Mar 27 10:29:05.582: INFO: (11) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.546611ms)
Mar 27 10:29:05.583: INFO: (12) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.612685ms)
Mar 27 10:29:05.586: INFO: (13) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 2.37617ms)
Mar 27 10:29:05.589: INFO: (14) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 3.720791ms)
Mar 27 10:29:05.592: INFO: (15) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 2.222733ms)
Mar 27 10:29:05.593: INFO: (16) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.722139ms)
Mar 27 10:29:05.595: INFO: (17) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.620014ms)
Mar 27 10:29:05.597: INFO: (18) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.576991ms)
Mar 27 10:29:05.598: INFO: (19) /api/v1/nodes/172.22.33.41/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="bashhistory.log">b... (200; 1.586673ms)
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:29:05.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8641" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":280,"completed":200,"skipped":3238,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:29:05.601: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-6512
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6512
STEP: Creating statefulset with conflicting port in namespace statefulset-6512
STEP: Waiting until pod test-pod will start running in namespace statefulset-6512
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6512
Mar 27 10:29:21.983: INFO: Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 08880fc9-aaae-4e56-93f0-984340bb971d, status phase: Pending. Waiting for statefulset controller to delete.
Mar 27 10:29:21.984: INFO: Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 08880fc9-aaae-4e56-93f0-984340bb971d, status phase: Failed. Waiting for statefulset controller to delete.
Mar 27 10:29:22.010: INFO: Observed stateful pod in namespace: statefulset-6512, name: ss-0, uid: 08880fc9-aaae-4e56-93f0-984340bb971d, status phase: Failed. Waiting for statefulset controller to delete.
Mar 27 10:29:22.053: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6512
STEP: Removing pod with conflicting port in namespace statefulset-6512
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6512 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 10:29:34.457: INFO: Deleting all statefulset in ns statefulset-6512
Mar 27 10:29:34.458: INFO: Scaling statefulset ss to 0
Mar 27 10:29:44.602: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:29:44.603: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:29:44.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6512" for this suite.

• [SLOW TEST:39.048 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":280,"completed":201,"skipped":3261,"failed":0}
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:29:44.650: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:29:44.854: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar 27 10:29:46.910: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:29:48.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5737" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":280,"completed":202,"skipped":3262,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:29:48.175: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-9040
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Mar 27 10:29:48.384: INFO: Found 0 stateful pods, waiting for 3
Mar 27 10:29:58.391: INFO: Found 1 stateful pods, waiting for 3
Mar 27 10:30:08.389: INFO: Found 2 stateful pods, waiting for 3
Mar 27 10:30:18.387: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:30:18.387: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:30:18.387: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 10:30:28.389: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:30:28.389: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:30:28.389: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 10:30:28.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-9040 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:30:28.589: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:30:28.589: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:30:28.589: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar 27 10:30:38.613: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar 27 10:30:48.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-9040 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:30:48.809: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 10:30:48.809: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 10:30:48.809: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 10:30:58.821: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:30:58.821: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 10:30:58.821: INFO: Waiting for Pod statefulset-9040/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 10:31:08.826: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:31:08.826: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 10:31:18.889: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:31:18.889: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 10:31:28.828: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
STEP: Rolling back to a previous revision
Mar 27 10:31:38.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-9040 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 10:31:39.063: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 10:31:39.063: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 10:31:39.063: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 10:31:49.115: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar 27 10:31:59.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-9040 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 10:31:59.558: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 10:31:59.558: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 10:31:59.558: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 10:32:09.568: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:32:09.568: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar 27 10:32:09.568: INFO: Waiting for Pod statefulset-9040/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar 27 10:32:20.010: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:32:20.010: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar 27 10:32:29.724: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
Mar 27 10:32:29.724: INFO: Waiting for Pod statefulset-9040/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Mar 27 10:32:39.572: INFO: Waiting for StatefulSet statefulset-9040/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 10:32:49.572: INFO: Deleting all statefulset in ns statefulset-9040
Mar 27 10:32:49.573: INFO: Scaling statefulset ss2 to 0
Mar 27 10:33:09.597: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:33:09.598: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:33:09.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9040" for this suite.

• [SLOW TEST:201.973 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":280,"completed":203,"skipped":3264,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:33:10.152: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:33:11.411: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:33:25.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4940" for this suite.

• [SLOW TEST:15.411 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":280,"completed":204,"skipped":3330,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:33:25.563: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating cluster-info
Mar 27 10:33:25.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 cluster-info'
Mar 27 10:33:25.761: INFO: stderr: ""
Mar 27 10:33:25.761: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:33:25.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7518" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":280,"completed":205,"skipped":3359,"failed":0}

------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:33:25.764: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar 27 10:33:25.874: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349575 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 10:33:25.874: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349575 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar 27 10:33:35.880: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349602 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 27 10:33:35.880: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349602 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar 27 10:33:45.885: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349614 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 10:33:45.885: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349614 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar 27 10:33:55.890: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349627 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 10:33:55.890: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-a 267c7f81-8f75-4265-9f2e-34c2d0092e8c 349627 0 2020-03-27 10:33:25 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar 27 10:34:05.894: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-b eb9a54e9-a6c1-4c91-9bcc-8b7c078d29ec 349646 0 2020-03-27 10:34:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 10:34:05.894: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-b eb9a54e9-a6c1-4c91-9bcc-8b7c078d29ec 349646 0 2020-03-27 10:34:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar 27 10:34:15.899: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-b eb9a54e9-a6c1-4c91-9bcc-8b7c078d29ec 349665 0 2020-03-27 10:34:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 10:34:15.899: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8045 /api/v1/namespaces/watch-8045/configmaps/e2e-watch-test-configmap-b eb9a54e9-a6c1-4c91-9bcc-8b7c078d29ec 349665 0 2020-03-27 10:34:05 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:34:25.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8045" for this suite.

• [SLOW TEST:60.141 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":280,"completed":206,"skipped":3359,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:34:25.906: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-8ec07810-a34c-407e-b197-a9dcbe7d80f8
STEP: Creating a pod to test consume secrets
Mar 27 10:34:26.347: INFO: Waiting up to 5m0s for pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476" in namespace "secrets-6033" to be "success or failure"
Mar 27 10:34:26.359: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 12.131768ms
Mar 27 10:34:28.361: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014211882s
Mar 27 10:34:30.519: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 4.17167727s
Mar 27 10:34:32.521: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 6.174112185s
Mar 27 10:34:34.523: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 8.176211806s
Mar 27 10:34:36.525: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Pending", Reason="", readiness=false. Elapsed: 10.178211746s
Mar 27 10:34:38.527: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.180314739s
STEP: Saw pod success
Mar 27 10:34:38.527: INFO: Pod "pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476" satisfied condition "success or failure"
Mar 27 10:34:38.529: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476 container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:34:38.729: INFO: Waiting for pod pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476 to disappear
Mar 27 10:34:38.787: INFO: Pod pod-secrets-12bf9c51-a911-4644-a67c-e9e23c6bb476 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:34:38.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6033" for this suite.
STEP: Destroying namespace "secret-namespace-4903" for this suite.

• [SLOW TEST:12.996 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":280,"completed":207,"skipped":3371,"failed":0}
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:34:38.903: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-3cd9dec5-beea-468a-9f60-7bdbb443365f
STEP: Creating a pod to test consume configMaps
Mar 27 10:34:39.068: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76" in namespace "projected-3337" to be "success or failure"
Mar 27 10:34:39.110: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 42.014225ms
Mar 27 10:34:41.112: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04402037s
Mar 27 10:34:43.115: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 4.046153233s
Mar 27 10:34:45.117: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 6.048297175s
Mar 27 10:34:47.119: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 8.05036813s
Mar 27 10:34:49.121: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Pending", Reason="", readiness=false. Elapsed: 10.052603959s
Mar 27 10:34:51.123: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.054766689s
STEP: Saw pod success
Mar 27 10:34:51.123: INFO: Pod "pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76" satisfied condition "success or failure"
Mar 27 10:34:51.125: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:34:51.147: INFO: Waiting for pod pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76 to disappear
Mar 27 10:34:51.237: INFO: Pod pod-projected-configmaps-6074b1f4-8909-4a99-9e27-3ee06e288d76 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:34:51.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3337" for this suite.

• [SLOW TEST:12.338 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":280,"completed":208,"skipped":3374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:34:51.243: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6957, will wait for the garbage collector to delete the pods
Mar 27 10:35:27.454: INFO: Deleting Job.batch foo took: 2.815489ms
Mar 27 10:35:27.854: INFO: Terminating Job.batch foo pods took: 400.195208ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:36:07.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6957" for this suite.

• [SLOW TEST:76.217 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":280,"completed":209,"skipped":3404,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:36:07.461: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:36:08.160: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:36:10.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:36:12.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:36:14.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:36:16.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:36:18.295: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:36:20.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902168, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:36:23.591: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:36:23.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7630" for this suite.
STEP: Destroying namespace "webhook-7630-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.982 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":280,"completed":210,"skipped":3417,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:36:24.444: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 10:37:02.190: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:02.192: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:02.192: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:07.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:07.195: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:07.195: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:12.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:12.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:12.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:17.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:17.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:17.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:22.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:22.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:22.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:27.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:27.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:27.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:32.322: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:32.324: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:32.324: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:37.476: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:37.477: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:37.477: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:42.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:42.203: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:42.203: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:47.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains ';; connection timed out; no servers could be reached
' instead of 'foo.example.com.'
Mar 27 10:37:47.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains ';; connection timed out; no servers could be reached
' instead of 'foo.example.com.'
Mar 27 10:37:47.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:52.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:52.197: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:52.197: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:37:57.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:57.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:37:57.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:02.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:02.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:02.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:07.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:07.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:07.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:12.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:12.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:12.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:17.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:17.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:17.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:22.200: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:22.201: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:22.201: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:27.199: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:27.201: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:27.201: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:32.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:32.195: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:32.195: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:37.233: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:37.243: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:37.243: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:42.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:42.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:42.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:47.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:47.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:47.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:52.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:52.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:52.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:38:57.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:57.195: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:38:57.195: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:02.232: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:02.234: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:02.234: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:07.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains ';; connection timed out; no servers could be reached
' instead of 'foo.example.com.'
Mar 27 10:39:07.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains ';; connection timed out; no servers could be reached
' instead of 'foo.example.com.'
Mar 27 10:39:07.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:12.308: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:12.310: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:12.310: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:17.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:17.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:17.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:22.194: INFO: File wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:22.196: INFO: File jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local from pod  dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 contains '' instead of 'foo.example.com.'
Mar 27 10:39:22.196: INFO: Lookups using dns-1011/dns-test-362548ce-b923-46a6-81c9-d14267d13b65 failed for: [wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local]

Mar 27 10:39:27.196: INFO: DNS probes using dns-test-362548ce-b923-46a6-81c9-d14267d13b65 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 10:40:01.565: INFO: DNS probes using dns-test-35331285-12cc-400a-9cb6-143aee1a7dbe succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1011.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1011.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 10:40:37.084: INFO: DNS probes using dns-test-998f5a69-89b6-45ca-8948-f0ce78dbd99c succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:40:37.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1011" for this suite.

• [SLOW TEST:253.375 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":280,"completed":211,"skipped":3422,"failed":0}
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:40:37.820: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:40:38.037: INFO: Create a RollingUpdate DaemonSet
Mar 27 10:40:38.039: INFO: Check that daemon pods launch on every node of the cluster
Mar 27 10:40:38.101: INFO: Number of nodes with available pods: 0
Mar 27 10:40:38.101: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:39.246: INFO: Number of nodes with available pods: 0
Mar 27 10:40:39.246: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:40.105: INFO: Number of nodes with available pods: 0
Mar 27 10:40:40.105: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:41.105: INFO: Number of nodes with available pods: 0
Mar 27 10:40:41.105: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:42.105: INFO: Number of nodes with available pods: 0
Mar 27 10:40:42.105: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:43.306: INFO: Number of nodes with available pods: 0
Mar 27 10:40:43.306: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:44.198: INFO: Number of nodes with available pods: 0
Mar 27 10:40:44.198: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:45.105: INFO: Number of nodes with available pods: 0
Mar 27 10:40:45.106: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:46.107: INFO: Number of nodes with available pods: 0
Mar 27 10:40:46.107: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:47.105: INFO: Number of nodes with available pods: 0
Mar 27 10:40:47.105: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:48.110: INFO: Number of nodes with available pods: 0
Mar 27 10:40:48.110: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 10:40:49.143: INFO: Number of nodes with available pods: 1
Mar 27 10:40:49.143: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:40:50.105: INFO: Number of nodes with available pods: 2
Mar 27 10:40:50.105: INFO: Number of running nodes: 2, number of available pods: 2
Mar 27 10:40:50.105: INFO: Update the DaemonSet to trigger a rollout
Mar 27 10:40:50.108: INFO: Updating DaemonSet daemon-set
Mar 27 10:40:53.229: INFO: Roll back the DaemonSet before rollout is complete
Mar 27 10:40:53.232: INFO: Updating DaemonSet daemon-set
Mar 27 10:40:53.232: INFO: Make sure DaemonSet rollback is complete
Mar 27 10:40:53.242: INFO: Wrong image for pod: daemon-set-mpwsd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar 27 10:40:53.242: INFO: Pod daemon-set-mpwsd is not available
Mar 27 10:40:54.385: INFO: Pod daemon-set-bl5tn is not available
Mar 27 10:40:55.309: INFO: Pod daemon-set-bl5tn is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1377, will wait for the garbage collector to delete the pods
Mar 27 10:40:55.491: INFO: Deleting DaemonSet.extensions daemon-set took: 125.556311ms
Mar 27 10:40:55.891: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.173886ms
Mar 27 10:40:59.452: INFO: Number of nodes with available pods: 0
Mar 27 10:40:59.452: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 10:40:59.454: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1377/daemonsets","resourceVersion":"350499"},"items":null}

Mar 27 10:40:59.521: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1377/pods","resourceVersion":"350500"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:40:59.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1377" for this suite.

• [SLOW TEST:21.709 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","total":280,"completed":212,"skipped":3425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:40:59.531: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-7aa09414-90a1-4b34-a7f9-01fb488aa7b1
STEP: Creating a pod to test consume secrets
Mar 27 10:41:00.108: INFO: Waiting up to 5m0s for pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7" in namespace "secrets-9879" to be "success or failure"
Mar 27 10:41:00.121: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.226691ms
Mar 27 10:41:02.275: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.166430832s
Mar 27 10:41:04.277: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.168677457s
Mar 27 10:41:06.376: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.267555601s
Mar 27 10:41:08.378: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269914465s
Mar 27 10:41:10.380: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.272259767s
Mar 27 10:41:12.492: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.383830563s
Mar 27 10:41:14.494: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.386166484s
STEP: Saw pod success
Mar 27 10:41:14.494: INFO: Pod "pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7" satisfied condition "success or failure"
Mar 27 10:41:14.496: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7 container secret-env-test: <nil>
STEP: delete the pod
Mar 27 10:41:14.857: INFO: Waiting for pod pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7 to disappear
Mar 27 10:41:14.923: INFO: Pod pod-secrets-b57ae4bb-3398-49ba-b12d-d7cd02fa77d7 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:41:14.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9879" for this suite.

• [SLOW TEST:15.553 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":280,"completed":213,"skipped":3468,"failed":0}
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:41:15.085: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap configmap-1916/configmap-test-e5cfd76b-6062-41f6-bae5-df7a755e4614
STEP: Creating a pod to test consume configMaps
Mar 27 10:41:15.307: INFO: Waiting up to 5m0s for pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094" in namespace "configmap-1916" to be "success or failure"
Mar 27 10:41:15.352: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 45.612045ms
Mar 27 10:41:17.354: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047774457s
Mar 27 10:41:19.357: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050689903s
Mar 27 10:41:21.426: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 6.118957386s
Mar 27 10:41:23.428: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 8.121141198s
Mar 27 10:41:25.430: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Pending", Reason="", readiness=false. Elapsed: 10.123332894s
Mar 27 10:41:27.432: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.125456081s
STEP: Saw pod success
Mar 27 10:41:27.432: INFO: Pod "pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094" satisfied condition "success or failure"
Mar 27 10:41:27.434: INFO: Trying to get logs from node 172.22.33.41 pod pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094 container env-test: <nil>
STEP: delete the pod
Mar 27 10:41:27.538: INFO: Waiting for pod pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094 to disappear
Mar 27 10:41:27.590: INFO: Pod pod-configmaps-cae2a24c-52b1-49a7-abb7-54d921863094 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:41:27.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1916" for this suite.

• [SLOW TEST:12.510 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":280,"completed":214,"skipped":3471,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:41:27.595: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:41:34.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3130" for this suite.
STEP: Destroying namespace "nsdeletetest-1131" for this suite.
Mar 27 10:41:34.996: INFO: Namespace nsdeletetest-1131 was already deleted
STEP: Destroying namespace "nsdeletetest-3861" for this suite.

• [SLOW TEST:7.404 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":280,"completed":215,"skipped":3506,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:41:34.999: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:139
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3112
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3112
I0327 10:41:35.134473      24 runners.go:189] Created replication controller with name: externalname-service, namespace: services-3112, replica count: 2
I0327 10:41:38.184758      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:41:41.184920      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:41:44.185197      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:41:47.185455      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0327 10:41:50.185800      24 runners.go:189] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar 27 10:41:50.185: INFO: Creating new exec pod
Mar 27 10:42:03.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-3112 execpodmmjt2 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar 27 10:42:06.224: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar 27 10:42:06.224: INFO: stdout: ""
Mar 27 10:42:06.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=services-3112 execpodmmjt2 -- /bin/sh -x -c nc -zv -t -w 2 10.254.93.161 80'
Mar 27 10:42:06.363: INFO: stderr: "+ nc -zv -t -w 2 10.254.93.161 80\nConnection to 10.254.93.161 80 port [tcp/http] succeeded!\n"
Mar 27 10:42:06.363: INFO: stdout: ""
Mar 27 10:42:06.363: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:42:06.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3112" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:143

• [SLOW TEST:31.418 seconds]
[sig-network] Services
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":280,"completed":216,"skipped":3518,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:42:06.417: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-a22e07df-3a35-43a9-95b7-f5bbd94d8a63 in namespace container-probe-772
Mar 27 10:42:18.775: INFO: Started pod busybox-a22e07df-3a35-43a9-95b7-f5bbd94d8a63 in namespace container-probe-772
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 10:42:18.777: INFO: Initial restart count of pod busybox-a22e07df-3a35-43a9-95b7-f5bbd94d8a63 is 0
Mar 27 10:43:05.077: INFO: Restart count of pod container-probe-772/busybox-a22e07df-3a35-43a9-95b7-f5bbd94d8a63 is now 1 (46.300784063s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:43:05.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-772" for this suite.

• [SLOW TEST:58.764 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":217,"skipped":3563,"failed":0}
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:43:05.182: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-7886
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating statefulset ss in namespace statefulset-7886
Mar 27 10:43:05.426: INFO: Found 0 stateful pods, waiting for 1
Mar 27 10:43:15.446: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 10:43:25.430: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 10:43:25.520: INFO: Deleting all statefulset in ns statefulset-7886
Mar 27 10:43:25.569: INFO: Scaling statefulset ss to 0
Mar 27 10:43:45.697: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 10:43:45.699: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:43:45.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7886" for this suite.

• [SLOW TEST:40.559 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":280,"completed":218,"skipped":3570,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:43:45.742: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:43:46.176: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:43:48.181: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:43:50.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:43:52.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:43:54.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:43:56.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902626, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:43:59.295: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:43:59.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3865" for this suite.
STEP: Destroying namespace "webhook-3865-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:13.902 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":280,"completed":219,"skipped":3576,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:43:59.645: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name configmap-test-upd-f1b3240e-74ee-4ac4-bdc9-9340254f7588
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:44:16.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8628" for this suite.

• [SLOW TEST:16.359 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:33
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":280,"completed":220,"skipped":3603,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:44:16.005: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:44:16.151: INFO: (0) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 10.287638ms)
Mar 27 10:44:16.153: INFO: (1) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 2.031393ms)
Mar 27 10:44:16.155: INFO: (2) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 2.010383ms)
Mar 27 10:44:16.157: INFO: (3) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.92087ms)
Mar 27 10:44:16.159: INFO: (4) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.776404ms)
Mar 27 10:44:16.160: INFO: (5) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.623565ms)
Mar 27 10:44:16.162: INFO: (6) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.736145ms)
Mar 27 10:44:16.164: INFO: (7) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.938994ms)
Mar 27 10:44:16.166: INFO: (8) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.691992ms)
Mar 27 10:44:16.167: INFO: (9) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.636671ms)
Mar 27 10:44:16.169: INFO: (10) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.694414ms)
Mar 27 10:44:16.171: INFO: (11) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.749367ms)
Mar 27 10:44:16.173: INFO: (12) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.721367ms)
Mar 27 10:44:16.175: INFO: (13) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 2.358168ms)
Mar 27 10:44:16.177: INFO: (14) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 2.018386ms)
Mar 27 10:44:16.179: INFO: (15) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 2.005271ms)
Mar 27 10:44:16.181: INFO: (16) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.857634ms)
Mar 27 10:44:16.183: INFO: (17) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.725644ms)
Mar 27 10:44:16.184: INFO: (18) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.683472ms)
Mar 27 10:44:16.186: INFO: (19) /api/v1/nodes/172.22.33.40:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="bashhistory.log">bashhistory.log</a>
<a href="boot.log">... (200; 1.743219ms)
[AfterEach] version v1
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:44:16.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2268" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":280,"completed":221,"skipped":3642,"failed":0}
S
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:44:16.189: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:45:26.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8732" for this suite.

• [SLOW TEST:70.123 seconds]
[sig-apps] Job
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":280,"completed":222,"skipped":3643,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:45:26.314: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:45:38.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8475" for this suite.

• [SLOW TEST:11.822 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":280,"completed":223,"skipped":3663,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:45:38.137: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1171.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-1171.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1171.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 10:46:10.410: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.412: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.414: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.415: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.420: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.422: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.423: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.424: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:10.427: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:15.430: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.435: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.437: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.438: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.442: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.444: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.453: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.454: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:15.457: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:20.430: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.431: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.433: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.435: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.439: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.440: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.441: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.443: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:20.445: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:25.430: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.432: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.433: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.435: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.440: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.441: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.442: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.444: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:25.473: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:30.430: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.432: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.433: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.435: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.439: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.440: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.441: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.442: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:30.445: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:35.430: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.431: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.432: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.434: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.437: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.439: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.440: INFO: Unable to read jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.441: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local from pod dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61: the server could not find the requested resource (get pods dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61)
Mar 27 10:46:35.444: INFO: Lookups using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local wheezy_udp@dns-test-service-2.dns-1171.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-1171.svc.cluster.local jessie_udp@dns-test-service-2.dns-1171.svc.cluster.local jessie_tcp@dns-test-service-2.dns-1171.svc.cluster.local]

Mar 27 10:46:40.445: INFO: DNS probes using dns-1171/dns-test-a319a98f-bb5e-43ea-bb4a-c3b5f03f8b61 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:46:41.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1171" for this suite.

• [SLOW TEST:62.976 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":280,"completed":224,"skipped":3670,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:46:41.113: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1464
STEP: creating an pod
Mar 27 10:46:41.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.8 --namespace=kubectl-6084 -- logs-generator --log-lines-total 100 --run-duration 20s'
Mar 27 10:46:41.613: INFO: stderr: ""
Mar 27 10:46:41.613: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Waiting for log generator to start.
Mar 27 10:46:41.613: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Mar 27 10:46:41.613: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6084" to be "running and ready, or succeeded"
Mar 27 10:46:41.712: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 99.633574ms
Mar 27 10:46:43.714: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101608544s
Mar 27 10:46:45.717: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.104649737s
Mar 27 10:46:47.721: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.107984823s
Mar 27 10:46:49.723: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 8.109889439s
Mar 27 10:46:51.725: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 10.111825313s
Mar 27 10:46:53.727: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 12.113783845s
Mar 27 10:46:53.727: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Mar 27 10:46:53.727: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Mar 27 10:46:53.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084'
Mar 27 10:46:53.829: INFO: stderr: ""
Mar 27 10:46:53.829: INFO: stdout: "I0327 10:46:53.444292       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/d2cj 363\nI0327 10:46:53.644394       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/rjt 500\n"
Mar 27 10:46:55.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084'
Mar 27 10:46:55.916: INFO: stderr: ""
Mar 27 10:46:55.916: INFO: stdout: "I0327 10:46:53.444292       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/d2cj 363\nI0327 10:46:53.644394       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/rjt 500\nI0327 10:46:53.844427       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/m8rl 310\nI0327 10:46:54.044512       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/zng4 219\nI0327 10:46:54.244424       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/rq4c 441\nI0327 10:46:54.444422       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xw6k 351\nI0327 10:46:54.644408       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/q89d 412\nI0327 10:46:54.844421       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/st5h 309\nI0327 10:46:55.044424       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/mt5 579\nI0327 10:46:55.244441       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/vvjb 364\nI0327 10:46:55.444420       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8nz 239\nI0327 10:46:55.644415       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/nx9k 212\nI0327 10:46:55.844410       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/fjx 354\n"
STEP: limiting log lines
Mar 27 10:46:55.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084 --tail=1'
Mar 27 10:46:56.005: INFO: stderr: ""
Mar 27 10:46:56.005: INFO: stdout: "I0327 10:46:55.844410       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/fjx 354\n"
Mar 27 10:46:56.005: INFO: got output "I0327 10:46:55.844410       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/fjx 354\n"
STEP: limiting log bytes
Mar 27 10:46:56.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084 --limit-bytes=1'
Mar 27 10:46:56.090: INFO: stderr: ""
Mar 27 10:46:56.090: INFO: stdout: "I"
Mar 27 10:46:56.090: INFO: got output "I"
STEP: exposing timestamps
Mar 27 10:46:56.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084 --tail=1 --timestamps'
Mar 27 10:46:56.173: INFO: stderr: ""
Mar 27 10:46:56.173: INFO: stdout: "2020-03-27T10:46:56.044596132Z I0327 10:46:56.044417       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/mwx2 327\n"
Mar 27 10:46:56.173: INFO: got output "2020-03-27T10:46:56.044596132Z I0327 10:46:56.044417       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/mwx2 327\n"
STEP: restricting to a time range
Mar 27 10:46:58.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084 --since=1s'
Mar 27 10:46:58.755: INFO: stderr: ""
Mar 27 10:46:58.755: INFO: stdout: "I0327 10:46:57.844415       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/5wmt 323\nI0327 10:46:58.044409       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/jqp 203\nI0327 10:46:58.244434       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/s7pl 235\nI0327 10:46:58.444406       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/ckcl 425\nI0327 10:46:58.644413       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/sq8 267\n"
Mar 27 10:46:58.755: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs logs-generator logs-generator --namespace=kubectl-6084 --since=24h'
Mar 27 10:46:58.842: INFO: stderr: ""
Mar 27 10:46:58.842: INFO: stdout: "I0327 10:46:53.444292       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/d2cj 363\nI0327 10:46:53.644394       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/rjt 500\nI0327 10:46:53.844427       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/ns/pods/m8rl 310\nI0327 10:46:54.044512       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/zng4 219\nI0327 10:46:54.244424       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/rq4c 441\nI0327 10:46:54.444422       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/xw6k 351\nI0327 10:46:54.644408       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/q89d 412\nI0327 10:46:54.844421       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/st5h 309\nI0327 10:46:55.044424       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/mt5 579\nI0327 10:46:55.244441       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/vvjb 364\nI0327 10:46:55.444420       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/ns/pods/8nz 239\nI0327 10:46:55.644415       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/nx9k 212\nI0327 10:46:55.844410       1 logs_generator.go:76] 12 GET /api/v1/namespaces/default/pods/fjx 354\nI0327 10:46:56.044417       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/mwx2 327\nI0327 10:46:56.244412       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/7cz 300\nI0327 10:46:56.444409       1 logs_generator.go:76] 15 POST /api/v1/namespaces/ns/pods/8ck 368\nI0327 10:46:56.644417       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/zr5t 571\nI0327 10:46:56.844419       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/glj 454\nI0327 10:46:57.044411       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/qkj 352\nI0327 10:46:57.244422       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/4r7 413\nI0327 10:46:57.444418       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/2dk 569\nI0327 10:46:57.644406       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/f8h 268\nI0327 10:46:57.844415       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/5wmt 323\nI0327 10:46:58.044409       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/jqp 203\nI0327 10:46:58.244434       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/s7pl 235\nI0327 10:46:58.444406       1 logs_generator.go:76] 25 PUT /api/v1/namespaces/kube-system/pods/ckcl 425\nI0327 10:46:58.644413       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/kube-system/pods/sq8 267\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1470
Mar 27 10:46:58.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete pod logs-generator --namespace=kubectl-6084'
Mar 27 10:47:02.093: INFO: stderr: ""
Mar 27 10:47:02.093: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:47:02.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6084" for this suite.

• [SLOW TEST:21.053 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1460
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":280,"completed":225,"skipped":3680,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:47:02.166: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:47:04.295: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:47:06.299: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:47:08.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:47:10.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:47:12.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:47:14.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:47:16.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902824, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:47:19.372: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:47:30.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7039" for this suite.
STEP: Destroying namespace "webhook-7039-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:29.102 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":280,"completed":226,"skipped":3694,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:47:31.268: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar 27 10:48:02.932: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0327 10:48:02.932087      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:48:02.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1348" for this suite.

• [SLOW TEST:31.668 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":280,"completed":227,"skipped":3700,"failed":0}
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:48:02.937: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar 27 10:48:15.092: INFO: &Pod{ObjectMeta:{send-events-b94e8cde-adaf-4ece-94aa-aecc2d4be4a9  events-6751 /api/v1/namespaces/events-6751/pods/send-events-b94e8cde-adaf-4ece-94aa-aecc2d4be4a9 3e8e716d-4390-49a2-89ed-c12e854dcc84 351745 0 2020-03-27 10:48:03 +0000 UTC <nil> <nil> map[name:foo time:23582732] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.161","ipv6_address":"","layer_type":"layer3"}]}] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ctk6w,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ctk6w,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ctk6w,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:48:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:48:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:48:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:48:03 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.161,StartTime:2020-03-27 10:48:03 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:48:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:agnhost:2.12,ImageID:docker://sha256:21140f8e943083beda4f999e416557c8aa43ba360b0d288e6562f322f42abaf7,ContainerID:docker://1b5385fd9732f35cfe30f246df1b67149af0324c619d014c4fcc6f36c58c7748,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.161,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Mar 27 10:48:17.095: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar 27 10:48:19.097: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:48:19.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6751" for this suite.

• [SLOW TEST:16.252 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":280,"completed":228,"skipped":3706,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:48:19.189: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:48:20.229: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:48:22.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:48:24.238: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:48:26.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:48:28.236: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:48:30.332: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720902900, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:48:33.262: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:48:34.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9505" for this suite.
STEP: Destroying namespace "webhook-9505-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.892 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":280,"completed":229,"skipped":3711,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:48:35.083: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 27 10:48:36.319: INFO: Waiting up to 5m0s for pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f" in namespace "emptydir-4701" to be "success or failure"
Mar 27 10:48:36.714: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 394.340902ms
Mar 27 10:48:38.716: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.39651542s
Mar 27 10:48:40.844: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.524673547s
Mar 27 10:48:42.846: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.526818199s
Mar 27 10:48:44.848: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.528906946s
Mar 27 10:48:46.850: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.531086135s
Mar 27 10:48:48.852: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.533094289s
Mar 27 10:48:50.855: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.535309384s
Mar 27 10:48:52.857: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.537510726s
Mar 27 10:48:54.905: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.585404011s
Mar 27 10:48:56.907: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.587446766s
Mar 27 10:48:58.909: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.589517503s
Mar 27 10:49:00.911: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.591550524s
Mar 27 10:49:02.924: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.605118758s
Mar 27 10:49:04.927: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 28.607292141s
Mar 27 10:49:07.051: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Pending", Reason="", readiness=false. Elapsed: 30.731794218s
Mar 27 10:49:09.053: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.734072606s
STEP: Saw pod success
Mar 27 10:49:09.053: INFO: Pod "pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f" satisfied condition "success or failure"
Mar 27 10:49:09.055: INFO: Trying to get logs from node 172.22.33.41 pod pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f container test-container: <nil>
STEP: delete the pod
Mar 27 10:49:09.408: INFO: Waiting for pod pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f to disappear
Mar 27 10:49:09.600: INFO: Pod pod-1e1392a5-cd90-4cc1-ac72-6305e42b857f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:49:09.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4701" for this suite.

• [SLOW TEST:34.522 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":230,"skipped":3745,"failed":0}
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:49:09.605: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:50:10.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8713" for this suite.

• [SLOW TEST:61.385 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":280,"completed":231,"skipped":3746,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:50:10.990: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:50:11.169: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar 27 10:50:11.225: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar 27 10:50:16.247: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 10:50:22.265: INFO: Creating deployment "test-rolling-update-deployment"
Mar 27 10:50:22.267: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar 27 10:50:22.284: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar 27 10:50:24.288: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar 27 10:50:24.289: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:26.292: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:28.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:30.291: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:32.450: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:34.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903033, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903022, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-67cf4f6444\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:50:36.291: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 27 10:50:36.295: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3721 /apis/apps/v1/namespaces/deployment-3721/deployments/test-rolling-update-deployment 25117535-bcc6-44f6-a964-ca9358a7a10d 352088 1 2020-03-27 10:50:22 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006e28748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-27 10:50:22 +0000 UTC,LastTransitionTime:2020-03-27 10:50:22 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-67cf4f6444" has successfully progressed.,LastUpdateTime:2020-03-27 10:50:34 +0000 UTC,LastTransitionTime:2020-03-27 10:50:22 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar 27 10:50:36.297: INFO: New ReplicaSet "test-rolling-update-deployment-67cf4f6444" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-67cf4f6444  deployment-3721 /apis/apps/v1/namespaces/deployment-3721/replicasets/test-rolling-update-deployment-67cf4f6444 54306a9b-0abf-4181-a224-5cf8e1a7c35f 352075 1 2020-03-27 10:50:22 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 25117535-bcc6-44f6-a964-ca9358a7a10d 0xc006e28bf7 0xc006e28bf8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 67cf4f6444,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006e28c68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 27 10:50:36.297: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar 27 10:50:36.297: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3721 /apis/apps/v1/namespaces/deployment-3721/replicasets/test-rolling-update-controller 95c35139-1f25-468f-8db3-8c69b3f87feb 352086 2 2020-03-27 10:50:11 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 25117535-bcc6-44f6-a964-ca9358a7a10d 0xc006e28b27 0xc006e28b28}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006e28b88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 10:50:36.298: INFO: Pod "test-rolling-update-deployment-67cf4f6444-jxxjs" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-67cf4f6444-jxxjs test-rolling-update-deployment-67cf4f6444- deployment-3721 /api/v1/namespaces/deployment-3721/pods/test-rolling-update-deployment-67cf4f6444-jxxjs 09d28b66-6738-43b4-ac7a-86b3a023a1a3 352074 0 2020-03-27 10:50:22 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:67cf4f6444] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.166","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet test-rolling-update-deployment-67cf4f6444 54306a9b-0abf-4181-a224-5cf8e1a7c35f 0xc006e290f7 0xc006e290f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xrwqg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xrwqg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xrwqg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:50:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:50:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:50:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 10:50:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.166,StartTime:2020-03-27 10:50:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 10:50:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:agnhost:2.12,ImageID:docker://sha256:21140f8e943083beda4f999e416557c8aa43ba360b0d288e6562f322f42abaf7,ContainerID:docker://84a0f48cfaa4120d50f715679c3b7617239d6e72718a810a865206354bb33e7a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:50:36.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3721" for this suite.

• [SLOW TEST:25.312 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":280,"completed":232,"skipped":3757,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:50:36.304: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: validating api versions
Mar 27 10:50:36.916: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 api-versions'
Mar 27 10:50:37.135: INFO: stderr: ""
Mar 27 10:50:37.135: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:50:37.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2564" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":280,"completed":233,"skipped":3758,"failed":0}

------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:50:37.139: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:39
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:50:37.487: INFO: Waiting up to 5m0s for pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c" in namespace "security-context-test-2358" to be "success or failure"
Mar 27 10:50:37.633: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 146.485404ms
Mar 27 10:50:39.773: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.286208066s
Mar 27 10:50:41.807: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.320357326s
Mar 27 10:50:43.902: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.414593633s
Mar 27 10:50:45.903: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.416530631s
Mar 27 10:50:47.905: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 10.418096367s
Mar 27 10:50:49.907: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.420157667s
Mar 27 10:50:51.909: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.422155884s
Mar 27 10:50:51.909: INFO: Pod "busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:50:51.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2358" for this suite.

• [SLOW TEST:14.775 seconds]
[k8s.io] Security Context
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  When creating a container with runAsUser
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:43
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":234,"skipped":3758,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:50:51.914: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:86
Mar 27 10:50:51.994: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar 27 10:50:52.012: INFO: Waiting for terminating namespaces to be deleted...
Mar 27 10:50:52.013: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.40 before test
Mar 27 10:50:52.027: INFO: sonobuoy-e2e-job-d8cb2578911a4e68 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 10:50:52.027: INFO: 	Container e2e ready: true, restart count 0
Mar 27 10:50:52.027: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar 27 10:50:52.027: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 from sonobuoy started at 2020-03-27 08:58:17 +0000 UTC (2 container statuses recorded)
Mar 27 10:50:52.027: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 27 10:50:52.027: INFO: 	Container systemd-logs ready: true, restart count 0
Mar 27 10:50:52.027: INFO: coredns-f589df4f5-d98zd from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 10:50:52.027: INFO: 	Container coredns ready: true, restart count 26
Mar 27 10:50:52.027: INFO: sonobuoy from sonobuoy started at 2020-03-27 08:57:47 +0000 UTC (1 container statuses recorded)
Mar 27 10:50:52.027: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar 27 10:50:52.027: INFO: zte-k8s-eviction-68f598776b-qxjnw from kube-system started at 2020-03-27 01:51:07 +0000 UTC (1 container statuses recorded)
Mar 27 10:50:52.027: INFO: 	Container zte-k8s-eviction ready: true, restart count 0
Mar 27 10:50:52.027: INFO: 
Logging pods the kubelet thinks is on node 172.22.33.41 before test
Mar 27 10:50:52.037: INFO: iag-172.22.33.41 from kube-system started at 2020-03-26 02:05:47 +0000 UTC (1 container statuses recorded)
Mar 27 10:50:52.037: INFO: 	Container iag ready: true, restart count 3
Mar 27 10:50:52.037: INFO: busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c from security-context-test-2358 started at 2020-03-27 10:50:37 +0000 UTC (1 container statuses recorded)
Mar 27 10:50:52.037: INFO: 	Container busybox-user-65534-88606a2b-061b-4a1f-9b36-55b753bc8d2c ready: false, restart count 0
Mar 27 10:50:52.037: INFO: sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s from sonobuoy started at 2020-03-27 08:58:18 +0000 UTC (2 container statuses recorded)
Mar 27 10:50:52.037: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar 27 10:50:52.037: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: verifying the node has the label node 172.22.33.40
STEP: verifying the node has the label node 172.22.33.41
Mar 27 10:50:52.151: INFO: Pod coredns-f589df4f5-d98zd requesting resource cpu=100m on Node 172.22.33.40
Mar 27 10:50:52.151: INFO: Pod iag-172.22.33.41 requesting resource cpu=0m on Node 172.22.33.41
Mar 27 10:50:52.151: INFO: Pod zte-k8s-eviction-68f598776b-qxjnw requesting resource cpu=0m on Node 172.22.33.40
Mar 27 10:50:52.151: INFO: Pod sonobuoy requesting resource cpu=0m on Node 172.22.33.40
Mar 27 10:50:52.151: INFO: Pod sonobuoy-e2e-job-d8cb2578911a4e68 requesting resource cpu=0m on Node 172.22.33.40
Mar 27 10:50:52.151: INFO: Pod sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-pvw5s requesting resource cpu=0m on Node 172.22.33.41
Mar 27 10:50:52.151: INFO: Pod sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8 requesting resource cpu=0m on Node 172.22.33.40
STEP: Starting Pods to consume most of the cluster CPU.
Mar 27 10:50:52.151: INFO: Creating a pod which consumes cpu=4830m on Node 172.22.33.40
Mar 27 10:50:52.154: INFO: Creating a pod which consumes cpu=4900m on Node 172.22.33.41
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-421244fd-110b-44b9-a583-99d4f258d185.160023a3159fbbef], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1802/filler-pod-421244fd-110b-44b9-a583-99d4f258d185 to 172.22.33.40]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-421244fd-110b-44b9-a583-99d4f258d185.160023a5b32dd03e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-421244fd-110b-44b9-a583-99d4f258d185.160023a5bdb3b2a9], Reason = [Created], Message = [Created container filler-pod-421244fd-110b-44b9-a583-99d4f258d185]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-421244fd-110b-44b9-a583-99d4f258d185.160023a5c50e0317], Reason = [Started], Message = [Started container filler-pod-421244fd-110b-44b9-a583-99d4f258d185]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319.160023a31a4128cc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1802/filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319 to 172.22.33.41]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319.160023a543f23d51], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319.160023a559043a4c], Reason = [Created], Message = [Created container filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319.160023a563df4420], Reason = [Started], Message = [Started container filler-pod-75746f36-d30a-43e2-8b91-8f6bf378d319]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.160023a65d2ed125], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 172.22.33.41
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 172.22.33.40
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:51:07.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1802" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:77

• [SLOW TEST:15.572 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":280,"completed":235,"skipped":3771,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:51:07.486: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name secret-test-map-2b8e7f20-71bd-4017-9400-9553590f6205
STEP: Creating a pod to test consume secrets
Mar 27 10:51:07.734: INFO: Waiting up to 5m0s for pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef" in namespace "secrets-9136" to be "success or failure"
Mar 27 10:51:07.780: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 45.948917ms
Mar 27 10:51:09.782: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048093347s
Mar 27 10:51:11.784: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050295566s
Mar 27 10:51:14.085: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.350807339s
Mar 27 10:51:16.087: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.352897336s
Mar 27 10:51:18.089: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.355034713s
Mar 27 10:51:20.091: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.357299129s
STEP: Saw pod success
Mar 27 10:51:20.091: INFO: Pod "pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef" satisfied condition "success or failure"
Mar 27 10:51:20.093: INFO: Trying to get logs from node 172.22.33.41 pod pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:51:20.182: INFO: Waiting for pod pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef to disappear
Mar 27 10:51:20.208: INFO: Pod pod-secrets-2afa937e-76f5-4355-8815-40b0678268ef no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:51:20.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9136" for this suite.

• [SLOW TEST:13.163 seconds]
[sig-storage] Secrets
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:34
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":236,"skipped":3787,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:51:20.651: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test hostPath mode
Mar 27 10:51:21.128: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4628" to be "success or failure"
Mar 27 10:51:21.139: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.502449ms
Mar 27 10:51:23.141: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013428753s
Mar 27 10:51:25.143: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015463624s
Mar 27 10:51:27.145: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017459192s
Mar 27 10:51:29.147: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019422622s
Mar 27 10:51:31.259: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.131536612s
Mar 27 10:51:33.261: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.133546883s
STEP: Saw pod success
Mar 27 10:51:33.262: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar 27 10:51:33.263: INFO: Trying to get logs from node 172.22.33.41 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar 27 10:51:33.403: INFO: Waiting for pod pod-host-path-test to disappear
Mar 27 10:51:33.424: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:51:33.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4628" for this suite.

• [SLOW TEST:12.778 seconds]
[sig-storage] HostPath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":237,"skipped":3830,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:51:33.430: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating Agnhost RC
Mar 27 10:51:33.660: INFO: namespace kubectl-4108
Mar 27 10:51:33.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-4108'
Mar 27 10:51:33.917: INFO: stderr: ""
Mar 27 10:51:33.917: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 27 10:51:35.239: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:35.239: INFO: Found 0 / 1
Mar 27 10:51:35.919: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:35.920: INFO: Found 0 / 1
Mar 27 10:51:36.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:36.920: INFO: Found 0 / 1
Mar 27 10:51:37.919: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:37.919: INFO: Found 0 / 1
Mar 27 10:51:38.936: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:38.936: INFO: Found 0 / 1
Mar 27 10:51:39.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:39.920: INFO: Found 0 / 1
Mar 27 10:51:40.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:40.920: INFO: Found 0 / 1
Mar 27 10:51:41.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:41.920: INFO: Found 0 / 1
Mar 27 10:51:42.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:42.920: INFO: Found 0 / 1
Mar 27 10:51:43.919: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:43.920: INFO: Found 0 / 1
Mar 27 10:51:44.920: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:44.920: INFO: Found 0 / 1
Mar 27 10:51:45.947: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:45.947: INFO: Found 0 / 1
Mar 27 10:51:46.919: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:46.919: INFO: Found 1 / 1
Mar 27 10:51:46.919: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 27 10:51:46.921: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 10:51:46.921: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 10:51:46.921: INFO: wait on agnhost-master startup in kubectl-4108 
Mar 27 10:51:46.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs agnhost-master-6crlm agnhost-master --namespace=kubectl-4108'
Mar 27 10:51:47.039: INFO: stderr: ""
Mar 27 10:51:47.039: INFO: stdout: "Paused\n"
STEP: exposing RC
Mar 27 10:51:47.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4108'
Mar 27 10:51:47.204: INFO: stderr: ""
Mar 27 10:51:47.204: INFO: stdout: "service/rm2 exposed\n"
Mar 27 10:51:47.236: INFO: Service rm2 in namespace kubectl-4108 found.
STEP: exposing service
Mar 27 10:51:49.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4108'
Mar 27 10:51:49.363: INFO: stderr: ""
Mar 27 10:51:49.363: INFO: stdout: "service/rm3 exposed\n"
Mar 27 10:51:49.390: INFO: Service rm3 in namespace kubectl-4108 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:51:51.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4108" for this suite.

• [SLOW TEST:18.016 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1295
    should create services for rc  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":280,"completed":238,"skipped":3858,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:51:51.447: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:51:52.735: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:51:54.739: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:51:56.830: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:51:58.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:52:00.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:52:02.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903112, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:52:05.831: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:52:05.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3303" for this suite.
STEP: Destroying namespace "webhook-3303-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:14.900 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":280,"completed":239,"skipped":3871,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:52:06.347: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating configMap with name projected-configmap-test-volume-ad400b12-20db-488a-86e2-6e1b2324a7db
STEP: Creating a pod to test consume configMaps
Mar 27 10:52:06.622: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281" in namespace "projected-1874" to be "success or failure"
Mar 27 10:52:06.688: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 65.275635ms
Mar 27 10:52:08.690: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067500959s
Mar 27 10:52:10.692: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 4.069812413s
Mar 27 10:52:12.696: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 6.074101592s
Mar 27 10:52:14.698: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 8.076144861s
Mar 27 10:52:16.703: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Pending", Reason="", readiness=false. Elapsed: 10.080362552s
Mar 27 10:52:18.902: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.279488487s
STEP: Saw pod success
Mar 27 10:52:18.902: INFO: Pod "pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281" satisfied condition "success or failure"
Mar 27 10:52:18.904: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar 27 10:52:19.157: INFO: Waiting for pod pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281 to disappear
Mar 27 10:52:19.235: INFO: Pod pod-projected-configmaps-788ed6f6-5a96-4195-92ba-e5afae409281 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:52:19.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1874" for this suite.

• [SLOW TEST:12.893 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:34
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":280,"completed":240,"skipped":3910,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:52:19.240: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar 27 10:52:20.152: INFO: Waiting up to 5m0s for pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48" in namespace "emptydir-2794" to be "success or failure"
Mar 27 10:52:20.219: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 67.615022ms
Mar 27 10:52:22.222: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069713322s
Mar 27 10:52:24.224: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071868126s
Mar 27 10:52:26.226: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 6.073849846s
Mar 27 10:52:28.228: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 8.075994859s
Mar 27 10:52:30.419: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.267331091s
Mar 27 10:52:32.421: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 12.269392044s
Mar 27 10:52:34.423: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 14.271450805s
Mar 27 10:52:36.425: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 16.273386646s
Mar 27 10:52:38.427: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.275473547s
Mar 27 10:52:40.447: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 20.294874708s
Mar 27 10:52:42.449: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 22.296890331s
Mar 27 10:52:44.451: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 24.298934495s
Mar 27 10:52:46.453: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 26.300939437s
Mar 27 10:52:48.455: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 28.303004573s
Mar 27 10:52:50.457: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Pending", Reason="", readiness=false. Elapsed: 30.304995709s
Mar 27 10:52:52.575: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.423051628s
STEP: Saw pod success
Mar 27 10:52:52.575: INFO: Pod "pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48" satisfied condition "success or failure"
Mar 27 10:52:52.576: INFO: Trying to get logs from node 172.22.33.41 pod pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48 container test-container: <nil>
STEP: delete the pod
Mar 27 10:52:52.725: INFO: Waiting for pod pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48 to disappear
Mar 27 10:52:52.748: INFO: Pod pod-a0e7242a-20dc-482f-bbe5-1a5cf2af4b48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:52:52.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2794" for this suite.

• [SLOW TEST:33.511 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":241,"skipped":3911,"failed":0}
SSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:52:52.751: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar 27 10:53:05.537: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6899 pod-service-account-0053827f-86f1-4613-80ac-84e6b0a074da -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar 27 10:53:08.327: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6899 pod-service-account-0053827f-86f1-4613-80ac-84e6b0a074da -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar 27 10:53:08.463: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6899 pod-service-account-0053827f-86f1-4613-80ac-84e6b0a074da -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:53:08.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6899" for this suite.

• [SLOW TEST:15.855 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":280,"completed":242,"skipped":3921,"failed":0}
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:53:08.606: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1009.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1009.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1009.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1009.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1009.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1009.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar 27 10:53:42.771: INFO: Unable to read jessie_hosts@dns-querier-2 from pod dns-1009/dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673: the server could not find the requested resource (get pods dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673)
Mar 27 10:53:42.772: INFO: Unable to read jessie_udp@PodARecord from pod dns-1009/dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673: the server could not find the requested resource (get pods dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673)
Mar 27 10:53:42.773: INFO: Unable to read jessie_tcp@PodARecord from pod dns-1009/dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673: the server could not find the requested resource (get pods dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673)
Mar 27 10:53:42.773: INFO: Lookups using dns-1009/dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673 failed for: [jessie_hosts@dns-querier-2 jessie_udp@PodARecord jessie_tcp@PodARecord]

Mar 27 10:53:47.785: INFO: DNS probes using dns-1009/dns-test-5c6a3725-eb3c-465c-a979-08fdddc75673 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:53:48.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1009" for this suite.

• [SLOW TEST:40.387 seconds]
[sig-network] DNS
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":280,"completed":243,"skipped":3924,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:53:48.993: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:53:49.197: INFO: Creating ReplicaSet my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652
Mar 27 10:53:49.235: INFO: Pod name my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652: Found 0 pods out of 1
Mar 27 10:53:54.239: INFO: Pod name my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652: Found 1 pods out of 1
Mar 27 10:53:54.239: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652" is running
Mar 27 10:54:04.246: INFO: Pod "my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652-272xm" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 10:53:49 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 10:53:49 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 10:53:49 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-27 10:53:49 +0000 UTC Reason: Message:}])
Mar 27 10:54:04.246: INFO: Trying to dial the pod
Mar 27 10:54:09.253: INFO: Controller my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652: Got expected result from replica 1 [my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652-272xm]: "my-hostname-basic-b51e16c5-672f-4faf-97e5-e7140a525652-272xm", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:54:09.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2180" for this suite.

• [SLOW TEST:20.263 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":280,"completed":244,"skipped":4019,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:54:09.257: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod liveness-f5da1ce1-e282-411a-97b2-73e4a72d8726 in namespace container-probe-284
Mar 27 10:54:21.389: INFO: Started pod liveness-f5da1ce1-e282-411a-97b2-73e4a72d8726 in namespace container-probe-284
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 10:54:21.391: INFO: Initial restart count of pod liveness-f5da1ce1-e282-411a-97b2-73e4a72d8726 is 0
Mar 27 10:54:43.668: INFO: Restart count of pod container-probe-284/liveness-f5da1ce1-e282-411a-97b2-73e4a72d8726 is now 1 (22.277071261s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:54:43.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-284" for this suite.

• [SLOW TEST:34.539 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":280,"completed":245,"skipped":4058,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:54:43.796: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test downward API volume plugin
Mar 27 10:54:44.424: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e" in namespace "projected-6927" to be "success or failure"
Mar 27 10:54:44.600: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 175.921836ms
Mar 27 10:54:46.602: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.178005675s
Mar 27 10:54:48.604: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.180146638s
Mar 27 10:54:50.607: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.182256766s
Mar 27 10:54:52.609: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.184311933s
Mar 27 10:54:54.678: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.253293536s
Mar 27 10:54:56.680: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.255405405s
STEP: Saw pod success
Mar 27 10:54:56.680: INFO: Pod "downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e" satisfied condition "success or failure"
Mar 27 10:54:56.681: INFO: Trying to get logs from node 172.22.33.41 pod downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e container client-container: <nil>
STEP: delete the pod
Mar 27 10:54:56.838: INFO: Waiting for pod downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e to disappear
Mar 27 10:54:56.849: INFO: Pod downwardapi-volume-eb2af815-4e36-470b-a591-70b66dc7d85e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:54:56.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6927" for this suite.

• [SLOW TEST:13.057 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":246,"skipped":4059,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:54:56.854: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir volume type on node default medium
Mar 27 10:54:57.046: INFO: Waiting up to 5m0s for pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519" in namespace "emptydir-4876" to be "success or failure"
Mar 27 10:54:57.056: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 10.214128ms
Mar 27 10:54:59.058: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012377926s
Mar 27 10:55:01.060: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014438423s
Mar 27 10:55:03.062: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016561165s
Mar 27 10:55:05.064: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 8.018587643s
Mar 27 10:55:07.066: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020684978s
Mar 27 10:55:09.068: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 12.022765093s
Mar 27 10:55:11.071: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 14.025003921s
Mar 27 10:55:13.073: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 16.027258731s
Mar 27 10:55:15.075: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 18.029476424s
Mar 27 10:55:17.077: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 20.031569369s
Mar 27 10:55:19.079: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 22.033636657s
Mar 27 10:55:21.081: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 24.035730967s
Mar 27 10:55:23.083: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 26.03762281s
Mar 27 10:55:25.276: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 28.230062304s
Mar 27 10:55:27.291: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Pending", Reason="", readiness=false. Elapsed: 30.245488263s
Mar 27 10:55:29.293: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.247586697s
STEP: Saw pod success
Mar 27 10:55:29.293: INFO: Pod "pod-839b8c70-37ff-4b40-9bf5-83c9274bd519" satisfied condition "success or failure"
Mar 27 10:55:29.295: INFO: Trying to get logs from node 172.22.33.41 pod pod-839b8c70-37ff-4b40-9bf5-83c9274bd519 container test-container: <nil>
STEP: delete the pod
Mar 27 10:55:29.447: INFO: Waiting for pod pod-839b8c70-37ff-4b40-9bf5-83c9274bd519 to disappear
Mar 27 10:55:29.515: INFO: Pod pod-839b8c70-37ff-4b40-9bf5-83c9274bd519 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:55:29.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4876" for this suite.

• [SLOW TEST:32.664 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":247,"skipped":4079,"failed":0}
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:55:29.519: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Mar 27 10:55:35.824: INFO: 7 pods remaining
Mar 27 10:55:35.824: INFO: 0 pods has nil DeletionTimestamp
Mar 27 10:55:35.824: INFO: 
STEP: Gathering metrics
W0327 10:55:36.780816      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Mar 27 10:55:36.780: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:55:36.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1208" for this suite.

• [SLOW TEST:7.266 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":280,"completed":248,"skipped":4082,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:55:36.787: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:55:37.484: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar 27 10:55:37.520: INFO: Number of nodes with available pods: 0
Mar 27 10:55:37.521: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar 27 10:55:37.711: INFO: Number of nodes with available pods: 0
Mar 27 10:55:37.711: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:38.714: INFO: Number of nodes with available pods: 0
Mar 27 10:55:38.714: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:39.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:39.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:40.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:40.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:41.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:41.714: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:43.088: INFO: Number of nodes with available pods: 0
Mar 27 10:55:43.088: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:43.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:43.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:44.722: INFO: Number of nodes with available pods: 0
Mar 27 10:55:44.722: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:45.723: INFO: Number of nodes with available pods: 0
Mar 27 10:55:45.723: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:46.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:46.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:47.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:47.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:48.714: INFO: Number of nodes with available pods: 0
Mar 27 10:55:48.715: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:49.713: INFO: Number of nodes with available pods: 0
Mar 27 10:55:49.713: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:50.723: INFO: Number of nodes with available pods: 0
Mar 27 10:55:50.723: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:51.895: INFO: Number of nodes with available pods: 1
Mar 27 10:55:51.895: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar 27 10:55:51.980: INFO: Number of nodes with available pods: 1
Mar 27 10:55:51.980: INFO: Number of running nodes: 0, number of available pods: 1
Mar 27 10:55:52.982: INFO: Number of nodes with available pods: 0
Mar 27 10:55:52.982: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar 27 10:55:53.084: INFO: Number of nodes with available pods: 0
Mar 27 10:55:53.084: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:54.086: INFO: Number of nodes with available pods: 0
Mar 27 10:55:54.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:55.087: INFO: Number of nodes with available pods: 0
Mar 27 10:55:55.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:56.086: INFO: Number of nodes with available pods: 0
Mar 27 10:55:56.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:57.104: INFO: Number of nodes with available pods: 0
Mar 27 10:55:57.104: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:58.087: INFO: Number of nodes with available pods: 0
Mar 27 10:55:58.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:55:59.087: INFO: Number of nodes with available pods: 0
Mar 27 10:55:59.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:00.087: INFO: Number of nodes with available pods: 0
Mar 27 10:56:00.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:01.086: INFO: Number of nodes with available pods: 0
Mar 27 10:56:01.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:02.086: INFO: Number of nodes with available pods: 0
Mar 27 10:56:02.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:03.086: INFO: Number of nodes with available pods: 0
Mar 27 10:56:03.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:04.117: INFO: Number of nodes with available pods: 0
Mar 27 10:56:04.117: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:05.087: INFO: Number of nodes with available pods: 0
Mar 27 10:56:05.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:06.086: INFO: Number of nodes with available pods: 0
Mar 27 10:56:06.087: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:07.086: INFO: Number of nodes with available pods: 0
Mar 27 10:56:07.086: INFO: Node 172.22.33.41 is running more than one daemon pod
Mar 27 10:56:08.087: INFO: Number of nodes with available pods: 1
Mar 27 10:56:08.087: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5258, will wait for the garbage collector to delete the pods
Mar 27 10:56:08.145: INFO: Deleting DaemonSet.extensions daemon-set took: 4.422087ms
Mar 27 10:56:08.445: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.236498ms
Mar 27 10:56:12.355: INFO: Number of nodes with available pods: 0
Mar 27 10:56:12.355: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 10:56:12.356: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5258/daemonsets","resourceVersion":"353172"},"items":null}

Mar 27 10:56:12.357: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5258/pods","resourceVersion":"353172"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:56:12.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5258" for this suite.

• [SLOW TEST:35.621 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":280,"completed":249,"skipped":4094,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:56:12.409: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar 27 10:56:12.546: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353179 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar 27 10:56:12.546: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353180 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar 27 10:56:12.546: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353181 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar 27 10:56:22.573: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353212 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar 27 10:56:22.573: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353213 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar 27 10:56:22.573: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-2016 /api/v1/namespaces/watch-2016/configmaps/e2e-watch-test-label-changed e7dbcb8f-85f8-4cc6-a5db-fe2071e37782 353214 0 2020-03-27 10:56:12 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:56:22.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2016" for this suite.

• [SLOW TEST:10.170 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":280,"completed":250,"skipped":4124,"failed":0}
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:56:22.581: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:56:22.804: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:56:24.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4580" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":280,"completed":251,"skipped":4124,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:56:24.031: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test override command
Mar 27 10:56:24.087: INFO: Waiting up to 5m0s for pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447" in namespace "containers-7399" to be "success or failure"
Mar 27 10:56:24.096: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777417ms
Mar 27 10:56:26.099: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011215166s
Mar 27 10:56:28.101: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013406862s
Mar 27 10:56:30.125: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 6.037960456s
Mar 27 10:56:32.128: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 8.04034949s
Mar 27 10:56:34.203: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 10.115895656s
Mar 27 10:56:36.205: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Pending", Reason="", readiness=false. Elapsed: 12.118038273s
Mar 27 10:56:38.208: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.120478461s
STEP: Saw pod success
Mar 27 10:56:38.208: INFO: Pod "client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447" satisfied condition "success or failure"
Mar 27 10:56:38.209: INFO: Trying to get logs from node 172.22.33.41 pod client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447 container test-container: <nil>
STEP: delete the pod
Mar 27 10:56:38.234: INFO: Waiting for pod client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447 to disappear
Mar 27 10:56:38.278: INFO: Pod client-containers-b9a02f6d-56ad-4743-bbc7-8a836e577447 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:56:38.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7399" for this suite.

• [SLOW TEST:14.344 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":280,"completed":252,"skipped":4133,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:56:38.375: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating secret with name projected-secret-test-83b1b67f-4d0a-44d5-91f2-839c1d895b0b
STEP: Creating a pod to test consume secrets
Mar 27 10:56:38.582: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db" in namespace "projected-4046" to be "success or failure"
Mar 27 10:56:38.690: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 108.153391ms
Mar 27 10:56:40.692: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 2.110362154s
Mar 27 10:56:42.694: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.112590239s
Mar 27 10:56:44.815: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 6.23276s
Mar 27 10:56:46.817: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 8.234831546s
Mar 27 10:56:48.819: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Pending", Reason="", readiness=false. Elapsed: 10.237067868s
Mar 27 10:56:50.821: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.239549139s
STEP: Saw pod success
Mar 27 10:56:50.821: INFO: Pod "pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db" satisfied condition "success or failure"
Mar 27 10:56:50.823: INFO: Trying to get logs from node 172.22.33.41 pod pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db container secret-volume-test: <nil>
STEP: delete the pod
Mar 27 10:56:51.032: INFO: Waiting for pod pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db to disappear
Mar 27 10:56:51.090: INFO: Pod pod-projected-secrets-263be748-fb53-4c44-9655-53261d7713db no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:56:51.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4046" for this suite.

• [SLOW TEST:13.186 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:34
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":280,"completed":253,"skipped":4139,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:56:51.562: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar 27 10:56:54.871: INFO: Pod name wrapped-volume-race-f04fff1e-5095-4697-bdde-1fcc695b196a: Found 0 pods out of 5
Mar 27 10:56:59.884: INFO: Pod name wrapped-volume-race-f04fff1e-5095-4697-bdde-1fcc695b196a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f04fff1e-5095-4697-bdde-1fcc695b196a in namespace emptydir-wrapper-239, will wait for the garbage collector to delete the pods
Mar 27 10:57:13.956: INFO: Deleting ReplicationController wrapped-volume-race-f04fff1e-5095-4697-bdde-1fcc695b196a took: 5.69759ms
Mar 27 10:57:15.157: INFO: Terminating ReplicationController wrapped-volume-race-f04fff1e-5095-4697-bdde-1fcc695b196a pods took: 1.200202484s
STEP: Creating RC which spawns configmap-volume pods
Mar 27 10:57:24.520: INFO: Pod name wrapped-volume-race-dc250bd6-8d96-40e7-a05a-fba0345e543e: Found 0 pods out of 5
Mar 27 10:57:29.525: INFO: Pod name wrapped-volume-race-dc250bd6-8d96-40e7-a05a-fba0345e543e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dc250bd6-8d96-40e7-a05a-fba0345e543e in namespace emptydir-wrapper-239, will wait for the garbage collector to delete the pods
Mar 27 10:57:41.625: INFO: Deleting ReplicationController wrapped-volume-race-dc250bd6-8d96-40e7-a05a-fba0345e543e took: 3.224502ms
Mar 27 10:57:42.125: INFO: Terminating ReplicationController wrapped-volume-race-dc250bd6-8d96-40e7-a05a-fba0345e543e pods took: 500.158796ms
STEP: Creating RC which spawns configmap-volume pods
Mar 27 10:57:48.323: INFO: Pod name wrapped-volume-race-58434799-8f67-47df-b098-2b04dcac9784: Found 0 pods out of 5
Mar 27 10:57:53.394: INFO: Pod name wrapped-volume-race-58434799-8f67-47df-b098-2b04dcac9784: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-58434799-8f67-47df-b098-2b04dcac9784 in namespace emptydir-wrapper-239, will wait for the garbage collector to delete the pods
Mar 27 10:58:07.462: INFO: Deleting ReplicationController wrapped-volume-race-58434799-8f67-47df-b098-2b04dcac9784 took: 3.227023ms
Mar 27 10:58:07.762: INFO: Terminating ReplicationController wrapped-volume-race-58434799-8f67-47df-b098-2b04dcac9784 pods took: 300.157779ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:58:16.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-239" for this suite.

• [SLOW TEST:85.437 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":280,"completed":254,"skipped":4150,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:58:16.999: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar 27 10:58:17.854: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar 27 10:58:19.859: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:58:21.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:58:23.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:58:25.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 10:58:27.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720903497, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5f65f8c764\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar 27 10:58:31.120: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 10:58:31.122: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2855-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:58:32.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7624" for this suite.
STEP: Destroying namespace "webhook-7624-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:16.151 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":280,"completed":255,"skipped":4154,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:58:33.151: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar 27 10:58:47.836: INFO: Successfully updated pod "pod-update-activedeadlineseconds-fdd8ab75-f8c6-4172-b40d-1412a8546737"
Mar 27 10:58:47.836: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-fdd8ab75-f8c6-4172-b40d-1412a8546737" in namespace "pods-3209" to be "terminated due to deadline exceeded"
Mar 27 10:58:47.868: INFO: Pod "pod-update-activedeadlineseconds-fdd8ab75-f8c6-4172-b40d-1412a8546737": Phase="Running", Reason="", readiness=true. Elapsed: 32.14474ms
Mar 27 10:58:49.870: INFO: Pod "pod-update-activedeadlineseconds-fdd8ab75-f8c6-4172-b40d-1412a8546737": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.034317161s
Mar 27 10:58:49.871: INFO: Pod "pod-update-activedeadlineseconds-fdd8ab75-f8c6-4172-b40d-1412a8546737" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:58:49.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3209" for this suite.

• [SLOW TEST:16.724 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":280,"completed":256,"skipped":4161,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:58:49.876: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 10:59:02.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5504" for this suite.

• [SLOW TEST:12.221 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":280,"completed":257,"skipped":4168,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 10:59:02.097: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:163
Mar 27 10:59:02.232: INFO: Waiting up to 1m0s for all nodes to be ready
Mar 27 11:00:02.240: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:00:02.671: INFO: Starting informer...
STEP: Starting pod...
Mar 27 11:00:03.269: INFO: Pod is running on 172.22.33.41. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Mar 27 11:00:04.032: INFO: Pod wasn't evicted. Proceeding
Mar 27 11:00:04.032: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Mar 27 11:01:19.294: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:01:19.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-1214" for this suite.

• [SLOW TEST:137.201 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-scheduling] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":280,"completed":258,"skipped":4189,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:01:19.299: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: set up a multi version CRD
Mar 27 11:01:19.385: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:01:38.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5713" for this suite.

• [SLOW TEST:18.864 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":280,"completed":259,"skipped":4192,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:01:38.163: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar 27 11:01:38.267: INFO: Waiting up to 5m0s for pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0" in namespace "emptydir-6576" to be "success or failure"
Mar 27 11:01:38.275: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010333ms
Mar 27 11:01:40.333: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066275367s
Mar 27 11:01:42.335: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.068424397s
Mar 27 11:01:44.337: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.070512867s
Mar 27 11:01:46.340: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.072745773s
Mar 27 11:01:48.342: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.074917645s
Mar 27 11:01:50.359: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 12.091860904s
Mar 27 11:01:52.361: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.094089264s
Mar 27 11:01:54.363: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.096260174s
Mar 27 11:01:56.365: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.09835275s
Mar 27 11:01:58.368: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.100765643s
Mar 27 11:02:00.370: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.102813985s
Mar 27 11:02:02.372: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.104853459s
Mar 27 11:02:04.374: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 26.106868837s
Mar 27 11:02:06.376: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 28.109058958s
Mar 27 11:02:08.469: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Pending", Reason="", readiness=false. Elapsed: 30.201704784s
Mar 27 11:02:10.471: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 32.203755544s
STEP: Saw pod success
Mar 27 11:02:10.471: INFO: Pod "pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0" satisfied condition "success or failure"
Mar 27 11:02:10.472: INFO: Trying to get logs from node 172.22.33.41 pod pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0 container test-container: <nil>
STEP: delete the pod
Mar 27 11:02:10.501: INFO: Waiting for pod pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0 to disappear
Mar 27 11:02:10.635: INFO: Pod pod-ff6df479-623b-4b3c-a4ca-8f1033d6b8d0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:02:10.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6576" for this suite.

• [SLOW TEST:32.476 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":260,"skipped":4193,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:02:10.641: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:02:10.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 version'
Mar 27 11:02:11.042: INFO: stderr: ""
Mar 27 11:02:11.042: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.2\", GitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", GitTreeState:\"clean\", BuildDate:\"2020-01-18T23:30:10Z\", GoVersion:\"go1.13.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"17\", GitVersion:\"v1.17.2\", GitCommit:\"59603c6e503c87169aea6106f57b9f242f64df89\", GitTreeState:\"archive\", BuildDate:\"2020-03-25T07:25:48Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:02:11.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8683" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":280,"completed":261,"skipped":4216,"failed":0}
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:02:11.211: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:02:23.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5471" for this suite.

• [SLOW TEST:12.104 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":280,"completed":262,"skipped":4218,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:02:23.315: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod busybox-14c906b4-61db-4732-9038-4f3897470eec in namespace container-probe-4262
Mar 27 11:02:35.392: INFO: Started pod busybox-14c906b4-61db-4732-9038-4f3897470eec in namespace container-probe-4262
STEP: checking the pod's current state and verifying that restartCount is present
Mar 27 11:02:35.393: INFO: Initial restart count of pod busybox-14c906b4-61db-4732-9038-4f3897470eec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:06:37.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4262" for this suite.

• [SLOW TEST:253.952 seconds]
[k8s.io] Probing container
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":280,"completed":263,"skipped":4241,"failed":0}
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:06:37.268: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Performing setup for networking test in namespace pod-network-test-7400
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar 27 11:06:37.619: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar 27 11:07:18.028: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.33.214:8080/dial?request=hostname&protocol=http&host=172.22.33.212&port=8080&tries=1'] Namespace:pod-network-test-7400 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 11:07:18.028: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 11:07:18.091: INFO: Waiting for responses: map[]
Mar 27 11:07:18.092: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.22.33.214:8080/dial?request=hostname&protocol=http&host=172.22.33.213&port=8080&tries=1'] Namespace:pod-network-test-7400 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar 27 11:07:18.092: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
Mar 27 11:07:18.149: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:07:18.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7400" for this suite.

• [SLOW TEST:40.885 seconds]
[sig-network] Networking
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":264,"skipped":4246,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:07:18.153: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:133
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar 27 11:07:18.359: INFO: Number of nodes with available pods: 0
Mar 27 11:07:18.359: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:19.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:19.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:20.465: INFO: Number of nodes with available pods: 0
Mar 27 11:07:20.465: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:21.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:21.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:22.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:22.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:23.510: INFO: Number of nodes with available pods: 0
Mar 27 11:07:23.510: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:24.569: INFO: Number of nodes with available pods: 0
Mar 27 11:07:24.570: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:25.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:25.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:26.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:26.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:27.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:27.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:28.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:28.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:29.531: INFO: Number of nodes with available pods: 0
Mar 27 11:07:29.531: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:30.363: INFO: Number of nodes with available pods: 0
Mar 27 11:07:30.363: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:31.363: INFO: Number of nodes with available pods: 2
Mar 27 11:07:31.363: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar 27 11:07:31.572: INFO: Number of nodes with available pods: 1
Mar 27 11:07:31.572: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:32.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:32.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:33.611: INFO: Number of nodes with available pods: 1
Mar 27 11:07:33.611: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:34.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:34.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:35.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:35.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:36.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:36.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:37.575: INFO: Number of nodes with available pods: 1
Mar 27 11:07:37.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:38.655: INFO: Number of nodes with available pods: 1
Mar 27 11:07:38.655: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:39.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:39.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:40.586: INFO: Number of nodes with available pods: 1
Mar 27 11:07:40.586: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:41.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:41.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:42.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:42.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:43.761: INFO: Number of nodes with available pods: 1
Mar 27 11:07:43.761: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:44.576: INFO: Number of nodes with available pods: 1
Mar 27 11:07:44.576: INFO: Node 172.22.33.40 is running more than one daemon pod
Mar 27 11:07:45.576: INFO: Number of nodes with available pods: 2
Mar 27 11:07:45.576: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:99
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8586, will wait for the garbage collector to delete the pods
Mar 27 11:07:45.632: INFO: Deleting DaemonSet.extensions daemon-set took: 2.857605ms
Mar 27 11:07:46.232: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.208318ms
Mar 27 11:07:49.434: INFO: Number of nodes with available pods: 0
Mar 27 11:07:49.434: INFO: Number of running nodes: 0, number of available pods: 0
Mar 27 11:07:49.435: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8586/daemonsets","resourceVersion":"354932"},"items":null}

Mar 27 11:07:49.436: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8586/pods","resourceVersion":"354932"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:07:49.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8586" for this suite.

• [SLOW TEST:31.290 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":280,"completed":265,"skipped":4286,"failed":0}
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:07:49.444: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: getting the auto-created API token
Mar 27 11:07:50.301: INFO: created pod pod-service-account-defaultsa
Mar 27 11:07:50.301: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar 27 11:07:50.359: INFO: created pod pod-service-account-mountsa
Mar 27 11:07:50.359: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar 27 11:07:50.374: INFO: created pod pod-service-account-nomountsa
Mar 27 11:07:50.374: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar 27 11:07:50.474: INFO: created pod pod-service-account-defaultsa-mountspec
Mar 27 11:07:50.474: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar 27 11:07:50.477: INFO: created pod pod-service-account-mountsa-mountspec
Mar 27 11:07:50.477: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar 27 11:07:50.544: INFO: created pod pod-service-account-nomountsa-mountspec
Mar 27 11:07:50.544: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar 27 11:07:50.729: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar 27 11:07:50.729: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar 27 11:07:50.775: INFO: created pod pod-service-account-mountsa-nomountspec
Mar 27 11:07:50.775: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar 27 11:07:50.941: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar 27 11:07:50.941: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:07:50.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3858" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":280,"completed":266,"skipped":4288,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:07:51.393: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:177
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:07:52.462: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:08:10.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4724" for this suite.

• [SLOW TEST:19.148 seconds]
[k8s.io] Pods
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":280,"completed":267,"skipped":4316,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:08:10.543: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Mar 27 11:08:10.660: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Registering the sample API server.
Mar 27 11:08:11.252: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar 27 11:08:13.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 11:08:15.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 11:08:17.386: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 11:08:19.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 11:08:21.387: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63720904091, loc:(*time.Location)(0x7db4bc0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-867766ffc6\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar 27 11:08:30.412: INFO: Waited 6.806511128s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:08:31.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4480" for this suite.

• [SLOW TEST:20.520 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]","total":280,"completed":268,"skipped":4325,"failed":0}
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:08:31.063: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar 27 11:08:45.526: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:08:45.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5617" for this suite.

• [SLOW TEST:14.639 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  blackbox test
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:131
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":280,"completed":269,"skipped":4334,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:08:45.704: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar 27 11:08:46.084: INFO: Waiting up to 5m0s for pod "pod-91570434-53a6-447a-8558-383ccf56f124" in namespace "emptydir-5423" to be "success or failure"
Mar 27 11:08:46.405: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 321.534018ms
Mar 27 11:08:48.408: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 2.323768456s
Mar 27 11:08:50.540: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 4.456673726s
Mar 27 11:08:52.543: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 6.458938974s
Mar 27 11:08:54.545: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 8.461183979s
Mar 27 11:08:56.547: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 10.463407293s
Mar 27 11:08:58.549: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 12.465703951s
Mar 27 11:09:00.552: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 14.467807643s
Mar 27 11:09:02.554: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 16.469840027s
Mar 27 11:09:04.557: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 18.472950126s
Mar 27 11:09:06.559: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 20.475359394s
Mar 27 11:09:08.562: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 22.477928444s
Mar 27 11:09:10.572: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 24.48821097s
Mar 27 11:09:12.574: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 26.490502953s
Mar 27 11:09:14.576: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 28.492640762s
Mar 27 11:09:16.717: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 30.633356897s
Mar 27 11:09:18.719: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Pending", Reason="", readiness=false. Elapsed: 32.635391173s
Mar 27 11:09:20.721: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124": Phase="Succeeded", Reason="", readiness=false. Elapsed: 34.637441927s
STEP: Saw pod success
Mar 27 11:09:20.721: INFO: Pod "pod-91570434-53a6-447a-8558-383ccf56f124" satisfied condition "success or failure"
Mar 27 11:09:20.723: INFO: Trying to get logs from node 172.22.33.41 pod pod-91570434-53a6-447a-8558-383ccf56f124 container test-container: <nil>
STEP: delete the pod
Mar 27 11:09:20.768: INFO: Waiting for pod pod-91570434-53a6-447a-8558-383ccf56f124 to disappear
Mar 27 11:09:20.792: INFO: Pod pod-91570434-53a6-447a-8558-383ccf56f124 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:09:20.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5423" for this suite.

• [SLOW TEST:35.092 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:40
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":280,"completed":270,"skipped":4364,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:09:20.797: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a pod to test substitution in container's command
Mar 27 11:09:21.036: INFO: Waiting up to 5m0s for pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9" in namespace "var-expansion-6012" to be "success or failure"
Mar 27 11:09:21.181: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 144.32424ms
Mar 27 11:09:23.183: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.146537006s
Mar 27 11:09:25.185: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.148514339s
Mar 27 11:09:27.187: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.1508623s
Mar 27 11:09:29.190: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.153067878s
Mar 27 11:09:31.192: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.155466412s
Mar 27 11:09:33.194: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.157719829s
STEP: Saw pod success
Mar 27 11:09:33.194: INFO: Pod "var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9" satisfied condition "success or failure"
Mar 27 11:09:33.196: INFO: Trying to get logs from node 172.22.33.41 pod var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9 container dapi-container: <nil>
STEP: delete the pod
Mar 27 11:09:33.546: INFO: Waiting for pod var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9 to disappear
Mar 27 11:09:33.867: INFO: Pod var-expansion-cc0ec80c-791c-4b70-a720-30e9d9ad24c9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:09:33.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6012" for this suite.

• [SLOW TEST:13.075 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":280,"completed":271,"skipped":4370,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:09:33.873: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:69
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:09:34.320: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar 27 11:09:39.322: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar 27 11:09:45.325: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:63
Mar 27 11:09:45.364: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2072 /apis/apps/v1/namespaces/deployment-2072/deployments/test-cleanup-deployment 094f5ca3-76bc-4246-aed0-0f2f01035566 355381 1 2020-03-27 11:09:45 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0051fe7a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Mar 27 11:09:45.371: INFO: New ReplicaSet "test-cleanup-deployment-55ffc6b7b6" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6  deployment-2072 /apis/apps/v1/namespaces/deployment-2072/replicasets/test-cleanup-deployment-55ffc6b7b6 667d4b07-9bdc-4cab-99ab-32511e5026a4 355383 1 2020-03-27 11:09:45 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 094f5ca3-76bc-4246-aed0-0f2f01035566 0xc0051febc7 0xc0051febc8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55ffc6b7b6,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [] []  []} {[] [] [{agnhost gcr.io/kubernetes-e2e-test-images/agnhost:2.8 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0051fec38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar 27 11:09:45.371: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar 27 11:09:45.371: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2072 /apis/apps/v1/namespaces/deployment-2072/replicasets/test-cleanup-controller 30328e01-ba15-42af-8e6e-4e9349dad8b2 355382 1 2020-03-27 11:09:34 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 094f5ca3-76bc-4246-aed0-0f2f01035566 0xc0051feaf7 0xc0051feaf8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0051feb58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar 27 11:09:45.457: INFO: Pod "test-cleanup-controller-85ssz" is available:
&Pod{ObjectMeta:{test-cleanup-controller-85ssz test-cleanup-controller- deployment-2072 /api/v1/namespaces/deployment-2072/pods/test-cleanup-controller-85ssz 96c2848a-9623-41f8-9086-4bb17ccc5a79 355379 0 2020-03-27 11:09:34 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[network.knitter.io/configuration-result:{"version":"v1","ports":[{"function":"std","network_name":"net_api","ip_address":"172.22.33.233","ipv6_address":"","layer_type":"layer3"}]}] [{apps/v1 ReplicaSet test-cleanup-controller 30328e01-ba15-42af-8e6e-4e9349dad8b2 0xc0051ff087 0xc0051ff088}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cndrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cndrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cndrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 11:09:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 11:09:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 11:09:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 11:09:34 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.22.33.41,PodIP:172.22.33.233,StartTime:2020-03-27 11:09:34 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-27 11:09:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5b4a2e29c6745034ad075c14d2869e52eecf9bd7145a3527660ab8e4e332722e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.22.33.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar 27 11:09:45.457: INFO: Pod "test-cleanup-deployment-55ffc6b7b6-gmj47" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-55ffc6b7b6-gmj47 test-cleanup-deployment-55ffc6b7b6- deployment-2072 /api/v1/namespaces/deployment-2072/pods/test-cleanup-deployment-55ffc6b7b6-gmj47 eb760136-bc36-43d3-b4bb-0e5457757fcf 355388 0 2020-03-27 11:09:45 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:55ffc6b7b6] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-55ffc6b7b6 667d4b07-9bdc-4cab-99ab-32511e5026a4 0xc0051ff2a7 0xc0051ff2a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cndrc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cndrc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.8,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cndrc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.22.33.41,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-27 11:09:45 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:09:45.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2072" for this suite.

• [SLOW TEST:11.637 seconds]
[sig-apps] Deployment
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":280,"completed":272,"skipped":4384,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:09:45.510: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1691
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1691
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1691
Mar 27 11:09:45.908: INFO: Found 0 stateful pods, waiting for 1
Mar 27 11:09:55.910: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 11:10:05.913: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar 27 11:10:05.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 11:10:09.074: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 11:10:09.074: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 11:10:09.074: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 11:10:09.076: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar 27 11:10:19.081: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 11:10:19.081: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 11:10:19.107: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999744s
Mar 27 11:10:20.109: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.978208593s
Mar 27 11:10:21.112: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.976009689s
Mar 27 11:10:22.114: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.973922271s
Mar 27 11:10:23.116: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.971654847s
Mar 27 11:10:24.118: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.969542879s
Mar 27 11:10:25.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.967531926s
Mar 27 11:10:26.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.964644821s
Mar 27 11:10:27.125: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.962499265s
Mar 27 11:10:28.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 960.383563ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1691
Mar 27 11:10:29.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 11:10:29.273: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 11:10:29.273: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 11:10:29.273: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 11:10:29.275: INFO: Found 1 stateful pods, waiting for 3
Mar 27 11:10:39.346: INFO: Found 2 stateful pods, waiting for 3
Mar 27 11:10:49.278: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:10:49.278: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:10:49.278: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 11:10:59.277: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:10:59.277: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:10:59.277: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar 27 11:10:59.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 11:10:59.416: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 11:10:59.416: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 11:10:59.416: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 11:10:59.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 11:10:59.589: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 11:10:59.589: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 11:10:59.589: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 11:10:59.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar 27 11:10:59.773: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar 27 11:10:59.773: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar 27 11:10:59.773: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar 27 11:10:59.773: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 11:10:59.775: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Mar 27 11:11:09.780: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 11:11:09.780: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 11:11:09.780: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar 27 11:11:09.796: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999695s
Mar 27 11:11:10.949: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.985722605s
Mar 27 11:11:11.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.833475566s
Mar 27 11:11:12.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.830839686s
Mar 27 11:11:14.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.825687877s
Mar 27 11:11:15.104: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.706198624s
Mar 27 11:11:16.106: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.678009642s
Mar 27 11:11:17.109: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.675863336s
Mar 27 11:11:18.141: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.672992966s
Mar 27 11:11:19.160: INFO: Verifying statefulset ss doesn't scale past 3 for another 640.817472ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1691
Mar 27 11:11:20.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 11:11:20.380: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 11:11:20.380: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 11:11:20.380: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 11:11:20.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 11:11:20.560: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 11:11:20.560: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 11:11:20.560: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 11:11:20.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 exec --namespace=statefulset-1691 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar 27 11:11:20.701: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar 27 11:11:20.701: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar 27 11:11:20.701: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar 27 11:11:20.701: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 11:11:40.709: INFO: Deleting all statefulset in ns statefulset-1691
Mar 27 11:11:40.710: INFO: Scaling statefulset ss to 0
Mar 27 11:11:40.714: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 11:11:40.715: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:11:40.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1691" for this suite.

• [SLOW TEST:115.279 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":280,"completed":273,"skipped":4418,"failed":0}
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:11:40.790: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:11:58.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3940" for this suite.

• [SLOW TEST:17.586 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":280,"completed":274,"skipped":4426,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:11:58.378: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:12:10.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-273" for this suite.

• [SLOW TEST:12.133 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
  when scheduling a busybox command in a pod
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":280,"completed":275,"skipped":4468,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:12:10.512: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating pod pod-subpath-test-projected-7shp
STEP: Creating a pod to test atomic-volume-subpath
Mar 27 11:12:10.948: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-7shp" in namespace "subpath-9077" to be "success or failure"
Mar 27 11:12:10.964: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 15.862728ms
Mar 27 11:12:12.966: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017910676s
Mar 27 11:12:14.968: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.0199393s
Mar 27 11:12:16.970: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022006536s
Mar 27 11:12:18.973: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 8.024343909s
Mar 27 11:12:20.975: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 10.026738762s
Mar 27 11:12:22.977: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 12.028968935s
Mar 27 11:12:24.979: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 14.031054469s
Mar 27 11:12:26.981: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 16.033098011s
Mar 27 11:12:28.986: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 18.037990793s
Mar 27 11:12:30.989: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 20.040354695s
Mar 27 11:12:32.991: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 22.042484697s
Mar 27 11:12:34.993: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 24.044764138s
Mar 27 11:12:36.995: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 26.046945397s
Mar 27 11:12:38.997: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 28.049151422s
Mar 27 11:12:41.000: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Pending", Reason="", readiness=false. Elapsed: 30.051352292s
Mar 27 11:12:43.007: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 32.058580392s
Mar 27 11:12:45.009: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 34.060768373s
Mar 27 11:12:47.011: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 36.062911827s
Mar 27 11:12:49.013: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 38.065226982s
Mar 27 11:12:51.016: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 40.067468064s
Mar 27 11:12:53.018: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 42.069509947s
Mar 27 11:12:55.020: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 44.071677655s
Mar 27 11:12:57.022: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 46.073847908s
Mar 27 11:12:59.024: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 48.076025313s
Mar 27 11:13:01.027: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Running", Reason="", readiness=true. Elapsed: 50.078365035s
Mar 27 11:13:03.029: INFO: Pod "pod-subpath-test-projected-7shp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 52.080594607s
STEP: Saw pod success
Mar 27 11:13:03.029: INFO: Pod "pod-subpath-test-projected-7shp" satisfied condition "success or failure"
Mar 27 11:13:03.030: INFO: Trying to get logs from node 172.22.33.41 pod pod-subpath-test-projected-7shp container test-container-subpath-projected-7shp: <nil>
STEP: delete the pod
Mar 27 11:13:03.084: INFO: Waiting for pod pod-subpath-test-projected-7shp to disappear
Mar 27 11:13:03.144: INFO: Pod pod-subpath-test-projected-7shp no longer exists
STEP: Deleting pod pod-subpath-test-projected-7shp
Mar 27 11:13:03.144: INFO: Deleting pod "pod-subpath-test-projected-7shp" in namespace "subpath-9077"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:13:03.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9077" for this suite.

• [SLOW TEST:52.638 seconds]
[sig-storage] Subpath
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":280,"completed":276,"skipped":4481,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:13:03.151: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1632
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Mar 27 11:13:04.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1862'
Mar 27 11:13:04.241: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar 27 11:13:04.241: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Mar 27 11:13:04.485: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-5gdjx]
Mar 27 11:13:04.485: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-5gdjx" in namespace "kubectl-1862" to be "running and ready"
Mar 27 11:13:04.528: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 42.473094ms
Mar 27 11:13:06.529: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04433881s
Mar 27 11:13:08.533: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 4.048064685s
Mar 27 11:13:10.535: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049967964s
Mar 27 11:13:12.537: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.052083951s
Mar 27 11:13:14.754: INFO: Pod "e2e-test-httpd-rc-5gdjx": Phase="Running", Reason="", readiness=true. Elapsed: 10.269030483s
Mar 27 11:13:14.754: INFO: Pod "e2e-test-httpd-rc-5gdjx" satisfied condition "running and ready"
Mar 27 11:13:14.754: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-5gdjx]
Mar 27 11:13:14.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 logs rc/e2e-test-httpd-rc --namespace=kubectl-1862'
Mar 27 11:13:14.872: INFO: stderr: ""
Mar 27 11:13:14.872: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.22.33.24. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.22.33.24. Set the 'ServerName' directive globally to suppress this message\n[Fri Mar 27 11:13:13.890315 2020] [mpm_event:notice] [pid 1:tid 140513887906664] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Mar 27 11:13:13.890355 2020] [core:notice] [pid 1:tid 140513887906664] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1637
Mar 27 11:13:14.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 delete rc e2e-test-httpd-rc --namespace=kubectl-1862'
Mar 27 11:13:14.960: INFO: stderr: ""
Mar 27 11:13:14.960: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:13:14.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1862" for this suite.

• [SLOW TEST:11.813 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1628
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run rc should create an rc from an image  [Conformance]","total":280,"completed":277,"skipped":4488,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:13:14.964: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:64
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:79
STEP: Creating service test in namespace statefulset-1206
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
STEP: Creating a new StatefulSet
Mar 27 11:13:15.073: INFO: Found 0 stateful pods, waiting for 3
Mar 27 11:13:25.077: INFO: Found 1 stateful pods, waiting for 3
Mar 27 11:13:35.077: INFO: Found 2 stateful pods, waiting for 3
Mar 27 11:13:45.080: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:13:45.080: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:13:45.080: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 11:13:55.077: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:13:55.077: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:13:55.077: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Mar 27 11:13:55.094: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar 27 11:14:05.160: INFO: Updating stateful set ss2
Mar 27 11:14:05.333: INFO: Waiting for Pod statefulset-1206/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Mar 27 11:14:15.663: INFO: Found 2 stateful pods, waiting for 3
Mar 27 11:14:25.667: INFO: Found 2 stateful pods, waiting for 3
Mar 27 11:14:35.672: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:35.672: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:35.672: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 11:14:45.666: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:45.666: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:45.666: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Mar 27 11:14:55.666: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:55.666: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar 27 11:14:55.666: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar 27 11:14:55.683: INFO: Updating stateful set ss2
Mar 27 11:14:55.899: INFO: Waiting for Pod statefulset-1206/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 11:15:05.917: INFO: Updating stateful set ss2
Mar 27 11:15:05.990: INFO: Waiting for StatefulSet statefulset-1206/ss2 to complete update
Mar 27 11:15:05.990: INFO: Waiting for Pod statefulset-1206/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Mar 27 11:15:15.994: INFO: Waiting for StatefulSet statefulset-1206/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:90
Mar 27 11:15:25.994: INFO: Deleting all statefulset in ns statefulset-1206
Mar 27 11:15:25.995: INFO: Scaling statefulset ss2 to 0
Mar 27 11:15:36.056: INFO: Waiting for statefulset status.replicas updated to 0
Mar 27 11:15:36.058: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:15:36.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1206" for this suite.

• [SLOW TEST:141.138 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:716
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":280,"completed":278,"skipped":4516,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:15:36.103: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:278
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:15:36.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-3628'
Mar 27 11:15:36.762: INFO: stderr: ""
Mar 27 11:15:36.762: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Mar 27 11:15:36.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 create -f - --namespace=kubectl-3628'
Mar 27 11:15:37.349: INFO: stderr: ""
Mar 27 11:15:37.349: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Mar 27 11:15:38.481: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:38.481: INFO: Found 0 / 1
Mar 27 11:15:39.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:39.351: INFO: Found 0 / 1
Mar 27 11:15:40.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:40.351: INFO: Found 0 / 1
Mar 27 11:15:41.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:41.351: INFO: Found 0 / 1
Mar 27 11:15:42.354: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:42.354: INFO: Found 0 / 1
Mar 27 11:15:43.359: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:43.359: INFO: Found 0 / 1
Mar 27 11:15:44.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:44.351: INFO: Found 0 / 1
Mar 27 11:15:45.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:45.351: INFO: Found 0 / 1
Mar 27 11:15:46.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:46.351: INFO: Found 0 / 1
Mar 27 11:15:47.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:47.351: INFO: Found 0 / 1
Mar 27 11:15:48.403: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:48.403: INFO: Found 0 / 1
Mar 27 11:15:49.351: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:49.351: INFO: Found 1 / 1
Mar 27 11:15:49.351: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar 27 11:15:49.352: INFO: Selector matched 1 pods for map[app:agnhost]
Mar 27 11:15:49.352: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar 27 11:15:49.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 describe pod agnhost-master-dm8fd --namespace=kubectl-3628'
Mar 27 11:15:49.443: INFO: stderr: ""
Mar 27 11:15:49.443: INFO: stdout: "Name:         agnhost-master-dm8fd\nNamespace:    kubectl-3628\nPriority:     0\nNode:         172.22.33.41/172.22.33.41\nStart Time:   Fri, 27 Mar 2020 11:15:37 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  network.knitter.io/configuration-result:\n                {\"version\":\"v1\",\"ports\":[{\"function\":\"std\",\"network_name\":\"net_api\",\"ip_address\":\"172.22.33.243\",\"ipv6_address\":\"\",\"layer_type\":\"layer3\"}]...\nStatus:       Running\nIP:           172.22.33.243\nIPs:\n  IP:           172.22.33.243\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://985fc81a8bff9a55e466b62b8666253d4058da2d408c42418b2e6945fb444346\n    Image:          gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Image ID:       docker://sha256:21140f8e943083beda4f999e416557c8aa43ba360b0d288e6562f322f42abaf7\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 27 Mar 2020 11:15:48 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rx8lt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-rx8lt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-rx8lt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                   Message\n  ----    ------     ----  ----                   -------\n  Normal  Scheduled  12s   default-scheduler      Successfully assigned kubectl-3628/agnhost-master-dm8fd to 172.22.33.41\n  Normal  Pulled     2s    kubelet, 172.22.33.41  Container image \"gcr.io/kubernetes-e2e-test-images/agnhost:2.8\" already present on machine\n  Normal  Created    2s    kubelet, 172.22.33.41  Created container agnhost-master\n  Normal  Started    1s    kubelet, 172.22.33.41  Started container agnhost-master\n"
Mar 27 11:15:49.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 describe rc agnhost-master --namespace=kubectl-3628'
Mar 27 11:15:49.535: INFO: stderr: ""
Mar 27 11:15:49.535: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-3628\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/agnhost:2.8\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  13s   replication-controller  Created pod: agnhost-master-dm8fd\n"
Mar 27 11:15:49.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 describe service agnhost-master --namespace=kubectl-3628'
Mar 27 11:15:49.620: INFO: stderr: ""
Mar 27 11:15:49.620: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-3628\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.254.69.162\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         172.22.33.243:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar 27 11:15:49.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 describe node 172.22.33.40'
Mar 27 11:15:49.717: INFO: stderr: ""
Mar 27 11:15:49.717: INFO: stdout: "Name:               172.22.33.40\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=172.22.33.40\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 25 Mar 2020 07:40:33 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  172.22.33.40\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 27 Mar 2020 11:15:48 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 27 Mar 2020 11:11:04 +0000   Thu, 26 Mar 2020 07:53:44 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 27 Mar 2020 11:11:04 +0000   Thu, 26 Mar 2020 07:53:44 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 27 Mar 2020 11:11:04 +0000   Thu, 26 Mar 2020 07:53:44 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 27 Mar 2020 11:11:04 +0000   Thu, 26 Mar 2020 07:53:44 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.22.33.40\n  Hostname:    172.22.33.40\nCapacity:\n  cpu:                8\n  ephemeral-storage:  62879748Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             7992636Ki\n  pods:               180\nAllocatable:\n  cpu:                7\n  ephemeral-storage:  62879748Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             6944060Ki\n  pods:               180\nSystem Info:\n  Machine ID:                 0468020bd9ef4f759a0c3f2ac3efa474\n  System UUID:                059D9F17-1B18-4730-8168-2D267C198BD9\n  Boot ID:                    ddec72e3-2c47-4600-8745-3e9aaf21d5b0\n  Kernel Version:             3.10.0-693.21.1.el7.x86_64\n  OS Image:                   NewStart Carrier Grade Server Linux Core 5.04\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://17.3.3\n  Kubelet Version:            v1.17.2\n  Kube-Proxy Version:         v1.17.2\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                 coredns-f589df4f5-d98zd                                    100m (1%)     0 (0%)      70Mi (1%)        170Mi (2%)     9h\n  kube-system                 zte-k8s-eviction-68f598776b-qxjnw                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         9h\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         138m\n  sonobuoy                    sonobuoy-e2e-job-d8cb2578911a4e68                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         137m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-560f4b8540b8492c-stmt8    0 (0%)        0 (0%)      0 (0%)           0 (0%)         137m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests   Limits\n  --------           --------   ------\n  cpu                100m (1%)  0 (0%)\n  memory             70Mi (1%)  170Mi (2%)\n  ephemeral-storage  0 (0%)     0 (0%)\nEvents:              <none>\n"
Mar 27 11:15:49.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 describe namespace kubectl-3628'
Mar 27 11:15:49.798: INFO: stderr: ""
Mar 27 11:15:49.798: INFO: stdout: "Name:         kubectl-3628\nLabels:       e2e-framework=kubectl\n              e2e-run=58c0ab2d-58bf-4b5a-b4b8-d309fc9a315e\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:15:49.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3628" for this suite.

• [SLOW TEST:13.698 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1154
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":280,"completed":279,"skipped":4534,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar 27 11:15:49.802: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
Mar 27 11:15:49.956: INFO: >>> kubeConfig: /tmp/kubeconfig-894470212
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Mar 27 11:15:53.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 create -f -'
Mar 27 11:15:56.876: INFO: stderr: ""
Mar 27 11:15:56.876: INFO: stdout: "e2e-test-crd-publish-openapi-5577-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar 27 11:15:56.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 delete e2e-test-crd-publish-openapi-5577-crds test-foo'
Mar 27 11:15:57.117: INFO: stderr: ""
Mar 27 11:15:57.117: INFO: stdout: "e2e-test-crd-publish-openapi-5577-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Mar 27 11:15:57.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 apply -f -'
Mar 27 11:15:57.482: INFO: stderr: ""
Mar 27 11:15:57.482: INFO: stdout: "e2e-test-crd-publish-openapi-5577-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar 27 11:15:57.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 delete e2e-test-crd-publish-openapi-5577-crds test-foo'
Mar 27 11:15:57.600: INFO: stderr: ""
Mar 27 11:15:57.600: INFO: stdout: "e2e-test-crd-publish-openapi-5577-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Mar 27 11:15:57.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 create -f -'
Mar 27 11:15:57.887: INFO: rc: 1
Mar 27 11:15:57.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 apply -f -'
Mar 27 11:15:58.228: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Mar 27 11:15:58.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 create -f -'
Mar 27 11:15:58.571: INFO: rc: 1
Mar 27 11:15:58.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 --namespace=crd-publish-openapi-3701 apply -f -'
Mar 27 11:15:58.835: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Mar 27 11:15:58.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-5577-crds'
Mar 27 11:15:59.103: INFO: stderr: ""
Mar 27 11:15:59.103: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5577-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Mar 27 11:15:59.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-5577-crds.metadata'
Mar 27 11:15:59.554: INFO: stderr: ""
Mar 27 11:15:59.554: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5577-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Mar 27 11:15:59.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-5577-crds.spec'
Mar 27 11:15:59.829: INFO: stderr: ""
Mar 27 11:15:59.829: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5577-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Mar 27 11:15:59.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-5577-crds.spec.bars'
Mar 27 11:16:00.184: INFO: stderr: ""
Mar 27 11:16:00.184: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5577-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Mar 27 11:16:00.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-894470212 explain e2e-test-crd-publish-openapi-5577-crds.spec.bars2'
Mar 27 11:16:00.540: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar 27 11:16:04.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3701" for this suite.

• [SLOW TEST:14.235 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.17.2-beta.0.2+59603c6e503c87/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:721
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":280,"completed":280,"skipped":4563,"failed":0}
Mar 27 11:16:04.036: INFO: Running AfterSuite actions on all nodes
Mar 27 11:16:04.036: INFO: Running AfterSuite actions on node 1
Mar 27 11:16:04.036: INFO: Skipping dumping logs from cluster
{"msg":"Test Suite completed","total":280,"completed":280,"skipped":4563,"failed":0}

Ran 280 of 4843 Specs in 8219.286 seconds
SUCCESS! -- 280 Passed | 0 Failed | 0 Pending | 4563 Skipped
PASS

Ginkgo ran 1 suite in 2h17m1.073681374s
Test Suite Passed
