I0626 13:01:01.337292      24 test_context.go:410] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-107382027
I0626 13:01:01.337386      24 test_context.go:423] Tolerating taints "node-role.kubernetes.io/master" when considering if nodes are ready
I0626 13:01:01.337689      24 e2e.go:124] Starting e2e run "d19e42d1-cbd6-46a4-9d55-dd4b50a27e47" on Ginkgo node 1
{"msg":"Test Suite starting","total":276,"completed":0,"skipped":0,"failed":0}
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1593176460 - Will randomize all specs
Will run 276 of 4992 specs

Jun 26 13:01:01.382: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:01:01.384: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 26 13:01:01.402: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 26 13:01:01.428: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 26 13:01:01.428: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Jun 26 13:01:01.428: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun 26 13:01:01.442: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jun 26 13:01:01.442: INFO: e2e test version: v1.18.3
Jun 26 13:01:01.443: INFO: kube-apiserver version: v1.18.3
Jun 26 13:01:01.443: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:01:01.449: INFO: Cluster IP family: ipv4
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:01:01.450: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
Jun 26 13:01:01.514: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating cluster-info
Jun 26 13:01:01.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 cluster-info'
Jun 26 13:01:01.830: INFO: stderr: ""
Jun 26 13:01:01.830: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:01:01.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8838" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes master services is included in cluster-info  [Conformance]","total":276,"completed":1,"skipped":1,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:01:01.847: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-df47a9c1-6473-4ec6-aee8-83c24ebd4b44
STEP: Creating a pod to test consume secrets
Jun 26 13:01:01.886: INFO: Waiting up to 5m0s for pod "pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6" in namespace "secrets-4763" to be "Succeeded or Failed"
Jun 26 13:01:01.890: INFO: Pod "pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.306995ms
Jun 26 13:01:03.895: INFO: Pod "pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008877663s
Jun 26 13:01:05.898: INFO: Pod "pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011811405s
STEP: Saw pod success
Jun 26 13:01:05.898: INFO: Pod "pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6" satisfied condition "Succeeded or Failed"
Jun 26 13:01:05.902: INFO: Trying to get logs from node docker-desktop pod pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6 container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:01:05.927: INFO: Waiting for pod pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6 to disappear
Jun 26 13:01:05.930: INFO: Pod pod-secrets-1179515e-cc56-49f2-86e4-67dde106d6b6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:01:05.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4763" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":2,"skipped":6,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:01:05.940: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:01:05.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-3469" for this suite.
•{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","total":276,"completed":3,"skipped":20,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:01:05.982: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:01:06.068: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"050fc9b7-6eaa-454b-89ef-9b4783190596", Controller:(*bool)(0xc00298af66), BlockOwnerDeletion:(*bool)(0xc00298af67)}}
Jun 26 13:01:06.076: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"235d93bd-29b7-480a-baec-6726a17f0a3c", Controller:(*bool)(0xc002a228f6), BlockOwnerDeletion:(*bool)(0xc002a228f7)}}
Jun 26 13:01:06.083: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"8dace6dd-34c9-4b1f-acc5-a00b1a16ef32", Controller:(*bool)(0xc002871ff6), BlockOwnerDeletion:(*bool)(0xc002871ff7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:01:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3256" for this suite.

• [SLOW TEST:5.117 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","total":276,"completed":4,"skipped":29,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:01:11.100: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:164
Jun 26 13:01:11.128: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 26 13:02:11.153: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:02:11.156: INFO: Starting informer...
STEP: Starting pod...
Jun 26 13:02:11.368: INFO: Pod is running on docker-desktop. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Jun 26 13:02:11.384: INFO: Pod wasn't evicted. Proceeding
Jun 26 13:02:11.385: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Jun 26 13:03:26.537: INFO: Pod wasn't evicted. Test successful
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:03:26.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4118" for this suite.

• [SLOW TEST:135.437 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  removing taint cancels eviction [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","total":276,"completed":5,"skipped":64,"failed":0}
S
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:03:26.546: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6265.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6265.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:03:44.607: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.611: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.614: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.617: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.625: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.627: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.630: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.632: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:44.642: INFO: Lookups using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local]

Jun 26 13:03:49.646: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.649: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.653: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.655: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.663: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.666: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.669: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.671: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:49.676: INFO: Lookups using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local]

Jun 26 13:03:54.646: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.648: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.651: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.654: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.663: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.665: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.668: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.672: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:54.677: INFO: Lookups using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local]

Jun 26 13:03:59.646: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.649: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.651: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.654: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.663: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.668: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.671: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.674: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:03:59.680: INFO: Lookups using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6265.svc.cluster.local jessie_udp@dns-test-service-2.dns-6265.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6265.svc.cluster.local]

Jun 26 13:04:04.651: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local from pod dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8: the server could not find the requested resource (get pods dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8)
Jun 26 13:04:04.673: INFO: Lookups using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 failed for: [wheezy_udp@dns-test-service-2.dns-6265.svc.cluster.local]

Jun 26 13:04:09.673: INFO: DNS probes using dns-6265/dns-test-ee5de7ee-fe49-4be2-a995-9b4834185ec8 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:04:09.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6265" for this suite.

• [SLOW TEST:43.195 seconds]
[sig-network] DNS
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","total":276,"completed":6,"skipped":65,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:04:09.748: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
STEP: reading a file in the container
Jun 26 13:04:14.312: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2962 pod-service-account-414f70a1-f23e-4cef-9a91-fe4823132b3e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jun 26 13:04:14.562: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2962 pod-service-account-414f70a1-f23e-4cef-9a91-fe4823132b3e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jun 26 13:04:14.741: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2962 pod-service-account-414f70a1-f23e-4cef-9a91-fe4823132b3e -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:04:15.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2962" for this suite.

• [SLOW TEST:5.270 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","total":276,"completed":7,"skipped":117,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:04:15.018: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:04:31.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3521" for this suite.

• [SLOW TEST:16.072 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","total":276,"completed":8,"skipped":135,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:04:31.099: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-1730
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating stateful set ss in namespace statefulset-1730
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1730
Jun 26 13:04:31.137: INFO: Found 0 stateful pods, waiting for 1
Jun 26 13:04:41.143: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 26 13:04:41.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:04:41.330: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:04:41.330: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:04:41.330: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:04:41.334: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 26 13:04:51.339: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:04:51.339: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:04:51.351: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:04:51.351: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:41 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:04:51.355: INFO: 
Jun 26 13:04:51.355: INFO: StatefulSet ss has not reached scale 3, at 1
Jun 26 13:04:52.358: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.993496331s
Jun 26 13:04:53.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989367471s
Jun 26 13:04:54.367: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98488077s
Jun 26 13:04:55.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98104027s
Jun 26 13:04:56.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978199999s
Jun 26 13:04:57.381: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.972198172s
Jun 26 13:04:58.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967439742s
Jun 26 13:04:59.389: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.963320396s
Jun 26 13:05:00.397: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.317521ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1730
Jun 26 13:05:01.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:05:01.595: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:05:01.595: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:05:01.595: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:05:01.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:05:01.792: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 26 13:05:01.792: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:05:01.792: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:05:01.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:05:01.987: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 26 13:05:01.987: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:05:01.987: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:05:01.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:05:01.991: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:05:01.991: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 26 13:05:01.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:05:02.174: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:05:02.174: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:05:02.174: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:05:02.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:05:02.376: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:05:02.377: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:05:02.377: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:05:02.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-1730 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:05:02.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:05:02.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:05:02.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:05:02.573: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:05:02.578: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 26 13:05:12.584: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:05:12.584: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:05:12.584: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:05:12.596: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:12.596: INFO: ss-0  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:12.596: INFO: ss-1  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:12.596: INFO: ss-2  docker-desktop  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:12.597: INFO: 
Jun 26 13:05:12.597: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:13.600: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:13.600: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:13.600: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:13.600: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:13.600: INFO: 
Jun 26 13:05:13.600: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:14.604: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:14.604: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:14.604: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:14.604: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:14.604: INFO: 
Jun 26 13:05:14.604: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:15.608: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:15.608: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:15.608: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:15.608: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:15.608: INFO: 
Jun 26 13:05:15.608: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:16.612: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:16.612: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:16.612: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:16.612: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:16.612: INFO: 
Jun 26 13:05:16.612: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:17.616: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:17.616: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:17.616: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:17.616: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:17.616: INFO: 
Jun 26 13:05:17.616: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:18.621: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Jun 26 13:05:18.621: INFO: ss-0  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:31 +0000 UTC  }]
Jun 26 13:05:18.621: INFO: ss-1  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:03 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:18.621: INFO: ss-2  docker-desktop  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:05:02 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-26 13:04:51 +0000 UTC  }]
Jun 26 13:05:18.621: INFO: 
Jun 26 13:05:18.621: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 26 13:05:19.625: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.971737081s
Jun 26 13:05:20.628: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.967647754s
Jun 26 13:05:21.633: INFO: Verifying statefulset ss doesn't scale past 0 for another 962.857631ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1730
Jun 26 13:05:22.637: INFO: Scaling statefulset ss to 0
Jun 26 13:05:22.644: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:05:22.646: INFO: Deleting all statefulset in ns statefulset-1730
Jun 26 13:05:22.648: INFO: Scaling statefulset ss to 0
Jun 26 13:05:22.656: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:05:22.657: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:22.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1730" for this suite.

• [SLOW TEST:51.581 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","total":276,"completed":9,"skipped":182,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1418
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 26 13:05:22.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 run e2e-test-httpd-pod --restart=Never --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1321'
Jun 26 13:05:22.823: INFO: stderr: ""
Jun 26 13:05:22.823: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1423
Jun 26 13:05:22.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete pods e2e-test-httpd-pod --namespace=kubectl-1321'
Jun 26 13:05:29.510: INFO: stderr: ""
Jun 26 13:05:29.510: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:29.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1321" for this suite.

• [SLOW TEST:6.837 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1414
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","total":276,"completed":10,"skipped":201,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:29.522: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7673
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-7673
I0626 13:05:29.632528      24 runners.go:190] Created replication controller with name: externalname-service, namespace: services-7673, replica count: 2
I0626 13:05:32.686980      24 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 26 13:05:32.687: INFO: Creating new exec pod
Jun 26 13:05:35.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-7673 execpodldn7h -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Jun 26 13:05:35.929: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jun 26 13:05:35.930: INFO: stdout: ""
Jun 26 13:05:35.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-7673 execpodldn7h -- /bin/sh -x -c nc -zv -t -w 2 10.111.5.215 80'
Jun 26 13:05:36.127: INFO: stderr: "+ nc -zv -t -w 2 10.111.5.215 80\nConnection to 10.111.5.215 80 port [tcp/http] succeeded!\n"
Jun 26 13:05:36.127: INFO: stdout: ""
Jun 26 13:05:36.127: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:36.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7673" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:6.629 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","total":276,"completed":11,"skipped":243,"failed":0}
SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:36.152: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-6b36291d-ced4-4c9d-a89d-12039105ea87
STEP: Creating a pod to test consume secrets
Jun 26 13:05:36.217: INFO: Waiting up to 5m0s for pod "pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667" in namespace "secrets-3954" to be "Succeeded or Failed"
Jun 26 13:05:36.227: INFO: Pod "pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667": Phase="Pending", Reason="", readiness=false. Elapsed: 9.815082ms
Jun 26 13:05:38.231: INFO: Pod "pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013842374s
STEP: Saw pod success
Jun 26 13:05:38.231: INFO: Pod "pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667" satisfied condition "Succeeded or Failed"
Jun 26 13:05:38.234: INFO: Trying to get logs from node docker-desktop pod pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667 container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:05:38.269: INFO: Waiting for pod pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667 to disappear
Jun 26 13:05:38.273: INFO: Pod pod-secrets-39d58aeb-7ac1-4421-9ca4-4dfa9f6ba667 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:38.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3954" for this suite.
STEP: Destroying namespace "secret-namespace-8402" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","total":276,"completed":12,"skipped":248,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:38.292: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override command
Jun 26 13:05:38.328: INFO: Waiting up to 5m0s for pod "client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c" in namespace "containers-5273" to be "Succeeded or Failed"
Jun 26 13:05:38.331: INFO: Pod "client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.31636ms
Jun 26 13:05:40.334: INFO: Pod "client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00517508s
STEP: Saw pod success
Jun 26 13:05:40.334: INFO: Pod "client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c" satisfied condition "Succeeded or Failed"
Jun 26 13:05:40.337: INFO: Trying to get logs from node docker-desktop pod client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c container test-container: <nil>
STEP: delete the pod
Jun 26 13:05:40.355: INFO: Waiting for pod client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c to disappear
Jun 26 13:05:40.361: INFO: Pod client-containers-3e834646-d2a9-414c-ba2a-23cae8cd877c no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:40.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5273" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]","total":276,"completed":13,"skipped":272,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:40.370: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6060
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6060
I0626 13:05:40.436987      24 runners.go:190] Created replication controller with name: externalname-service, namespace: services-6060, replica count: 2
Jun 26 13:05:43.488: INFO: Creating new exec pod
I0626 13:05:43.488177      24 runners.go:190] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 26 13:05:46.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-6060 execpod62njn -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Jun 26 13:05:46.718: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jun 26 13:05:46.718: INFO: stdout: ""
Jun 26 13:05:46.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-6060 execpod62njn -- /bin/sh -x -c nc -zv -t -w 2 10.103.250.34 80'
Jun 26 13:05:46.909: INFO: stderr: "+ nc -zv -t -w 2 10.103.250.34 80\nConnection to 10.103.250.34 80 port [tcp/http] succeeded!\n"
Jun 26 13:05:46.909: INFO: stdout: ""
Jun 26 13:05:46.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-6060 execpod62njn -- /bin/sh -x -c nc -zv -t -w 2 192.168.65.3 30364'
Jun 26 13:05:47.097: INFO: stderr: "+ nc -zv -t -w 2 192.168.65.3 30364\nConnection to 192.168.65.3 30364 port [tcp/30364] succeeded!\n"
Jun 26 13:05:47.097: INFO: stdout: ""
Jun 26 13:05:47.097: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:05:47.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6060" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:6.751 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","total":276,"completed":14,"skipped":286,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:05:47.122: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7251, will wait for the garbage collector to delete the pods
Jun 26 13:05:49.226: INFO: Deleting Job.batch foo took: 6.785969ms
Jun 26 13:05:49.327: INFO: Terminating Job.batch foo pods took: 100.96661ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:06:22.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7251" for this suite.

• [SLOW TEST:35.216 seconds]
[sig-apps] Job
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","total":276,"completed":15,"skipped":327,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:06:22.339: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Jun 26 13:06:22.363: INFO: Waiting up to 5m0s for pod "downward-api-90844e50-ef59-4aae-b299-bce3945f249c" in namespace "downward-api-2908" to be "Succeeded or Failed"
Jun 26 13:06:22.366: INFO: Pod "downward-api-90844e50-ef59-4aae-b299-bce3945f249c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.807357ms
Jun 26 13:06:24.371: INFO: Pod "downward-api-90844e50-ef59-4aae-b299-bce3945f249c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007514003s
STEP: Saw pod success
Jun 26 13:06:24.371: INFO: Pod "downward-api-90844e50-ef59-4aae-b299-bce3945f249c" satisfied condition "Succeeded or Failed"
Jun 26 13:06:24.373: INFO: Trying to get logs from node docker-desktop pod downward-api-90844e50-ef59-4aae-b299-bce3945f249c container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:06:24.393: INFO: Waiting for pod downward-api-90844e50-ef59-4aae-b299-bce3945f249c to disappear
Jun 26 13:06:24.398: INFO: Pod downward-api-90844e50-ef59-4aae-b299-bce3945f249c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:06:24.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2908" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","total":276,"completed":16,"skipped":347,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:06:24.406: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:06:24.431: INFO: Waiting up to 5m0s for pod "downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934" in namespace "downward-api-9758" to be "Succeeded or Failed"
Jun 26 13:06:24.433: INFO: Pod "downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014737ms
Jun 26 13:06:26.437: INFO: Pod "downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006678712s
STEP: Saw pod success
Jun 26 13:06:26.438: INFO: Pod "downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934" satisfied condition "Succeeded or Failed"
Jun 26 13:06:26.440: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934 container client-container: <nil>
STEP: delete the pod
Jun 26 13:06:26.454: INFO: Waiting for pod downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934 to disappear
Jun 26 13:06:26.457: INFO: Pod downwardapi-volume-27e2db38-f002-45ad-b888-d507739bf934 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:06:26.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9758" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":276,"completed":17,"skipped":350,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:06:26.465: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:06:29.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8986" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","total":276,"completed":18,"skipped":380,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:06:29.510: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9057.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9057.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9057.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9057.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 255.126.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.126.255_udp@PTR;check="$$(dig +tcp +noall +answer +search 255.126.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.126.255_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9057.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9057.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9057.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9057.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9057.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9057.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 255.126.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.126.255_udp@PTR;check="$$(dig +tcp +noall +answer +search 255.126.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.126.255_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:06:31.574: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.579: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.583: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.588: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.604: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.606: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.611: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.613: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:31.623: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:06:36.628: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.631: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.633: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.649: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.651: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.653: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.655: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:36.668: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:06:41.627: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.629: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.630: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.632: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.642: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.643: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.644: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.646: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:41.662: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:06:46.627: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.630: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.633: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.650: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.652: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.654: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.656: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:46.667: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:06:51.628: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.631: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.633: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.648: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.649: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.651: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.652: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:51.660: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:06:56.628: INFO: Unable to read wheezy_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.630: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.633: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.638: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.655: INFO: Unable to read jessie_udp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.657: INFO: Unable to read jessie_tcp@dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.659: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.661: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local from pod dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b: the server could not find the requested resource (get pods dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b)
Jun 26 13:06:56.672: INFO: Lookups using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b failed for: [wheezy_udp@dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@dns-test-service.dns-9057.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_udp@dns-test-service.dns-9057.svc.cluster.local jessie_tcp@dns-test-service.dns-9057.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9057.svc.cluster.local]

Jun 26 13:07:01.675: INFO: DNS probes using dns-9057/dns-test-6dbe6a4b-e429-4d32-9407-1f1e65d47a5b succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:01.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9057" for this suite.

• [SLOW TEST:32.273 seconds]
[sig-network] DNS
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","total":276,"completed":19,"skipped":391,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:01.784: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:07:02.110: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 26 13:07:04.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728773622, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728773622, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728773622, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728773622, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:07:07.137: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:17.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-677" for this suite.
STEP: Destroying namespace "webhook-677-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.542 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","total":276,"completed":20,"skipped":417,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:17.327: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5985
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5985
STEP: creating replication controller externalsvc in namespace services-5985
I0626 13:07:17.373369      24 runners.go:190] Created replication controller with name: externalsvc, namespace: services-5985, replica count: 2
I0626 13:07:20.424987      24 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Jun 26 13:07:20.440: INFO: Creating new exec pod
Jun 26 13:07:22.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-5985 execpodtzjcg -- /bin/sh -x -c nslookup clusterip-service'
Jun 26 13:07:22.637: INFO: stderr: "+ nslookup clusterip-service\n"
Jun 26 13:07:22.637: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-5985.svc.cluster.local\tcanonical name = externalsvc.services-5985.svc.cluster.local.\nName:\texternalsvc.services-5985.svc.cluster.local\nAddress: 10.110.3.242\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5985, will wait for the garbage collector to delete the pods
Jun 26 13:07:22.700: INFO: Deleting ReplicationController externalsvc took: 7.892179ms
Jun 26 13:07:22.800: INFO: Terminating ReplicationController externalsvc pods took: 100.546383ms
Jun 26 13:07:26.324: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:26.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5985" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.013 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","total":276,"completed":21,"skipped":430,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:26.341: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-projected-all-test-volume-d6da791f-4954-4bec-a987-8fa4982662b2
STEP: Creating secret with name secret-projected-all-test-volume-ad57d74b-f5a0-4513-80bf-bf2a7c157780
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 26 13:07:26.372: INFO: Waiting up to 5m0s for pod "projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a" in namespace "projected-6097" to be "Succeeded or Failed"
Jun 26 13:07:26.374: INFO: Pod "projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.860244ms
Jun 26 13:07:28.379: INFO: Pod "projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006336484s
STEP: Saw pod success
Jun 26 13:07:28.379: INFO: Pod "projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a" satisfied condition "Succeeded or Failed"
Jun 26 13:07:28.381: INFO: Trying to get logs from node docker-desktop pod projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 26 13:07:28.395: INFO: Waiting for pod projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a to disappear
Jun 26 13:07:28.397: INFO: Pod projected-volume-0152fb35-856e-4bda-9aba-b0967147ee1a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:28.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6097" for this suite.
•{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","total":276,"completed":22,"skipped":461,"failed":0}
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:28.405: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating replication controller my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080
Jun 26 13:07:28.430: INFO: Pod name my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080: Found 0 pods out of 1
Jun 26 13:07:33.433: INFO: Pod name my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080: Found 1 pods out of 1
Jun 26 13:07:33.434: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080" are running
Jun 26 13:07:33.436: INFO: Pod "my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080-9xn4j" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:07:28 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:07:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:07:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:07:28 +0000 UTC Reason: Message:}])
Jun 26 13:07:33.436: INFO: Trying to dial the pod
Jun 26 13:07:38.444: INFO: Controller my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080: Got expected result from replica 1 [my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080-9xn4j]: "my-hostname-basic-32960b77-7f17-4345-a86c-362866f4e080-9xn4j", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:38.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4091" for this suite.

• [SLOW TEST:10.045 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","total":276,"completed":23,"skipped":464,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:38.450: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Jun 26 13:07:38.470: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:07:40.863: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:07:51.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7493" for this suite.

• [SLOW TEST:13.352 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","total":276,"completed":24,"skipped":469,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:07:51.803: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-9122
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 26 13:07:51.821: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jun 26 13:07:51.829: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 13:07:53.833: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:07:55.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:07:57.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:07:59.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:01.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:03.834: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:05.833: INFO: The status of Pod netserver-0 is Running (Ready = true)
STEP: Creating test pods
Jun 26 13:08:07.846: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.0.44:8080/dial?request=hostname&protocol=http&host=10.1.0.43&port=8080&tries=1'] Namespace:pod-network-test-9122 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:07.846: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:07.946: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:07.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9122" for this suite.

• [SLOW TEST:16.151 seconds]
[sig-network] Networking
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","total":276,"completed":25,"skipped":482,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:07.955: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl label
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1206
STEP: creating the pod
Jun 26 13:08:07.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-4350'
Jun 26 13:08:08.176: INFO: stderr: ""
Jun 26 13:08:08.176: INFO: stdout: "pod/pause created\n"
Jun 26 13:08:08.176: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun 26 13:08:08.176: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4350" to be "running and ready"
Jun 26 13:08:08.179: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.823789ms
Jun 26 13:08:10.184: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007454854s
Jun 26 13:08:12.186: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.009802523s
Jun 26 13:08:12.186: INFO: Pod "pause" satisfied condition "running and ready"
Jun 26 13:08:12.186: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: adding the label testing-label with value testing-label-value to a pod
Jun 26 13:08:12.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 label pods pause testing-label=testing-label-value --namespace=kubectl-4350'
Jun 26 13:08:12.266: INFO: stderr: ""
Jun 26 13:08:12.266: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun 26 13:08:12.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pod pause -L testing-label --namespace=kubectl-4350'
Jun 26 13:08:12.336: INFO: stderr: ""
Jun 26 13:08:12.336: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun 26 13:08:12.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 label pods pause testing-label- --namespace=kubectl-4350'
Jun 26 13:08:12.416: INFO: stderr: ""
Jun 26 13:08:12.416: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun 26 13:08:12.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pod pause -L testing-label --namespace=kubectl-4350'
Jun 26 13:08:12.486: INFO: stderr: ""
Jun 26 13:08:12.486: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1213
STEP: using delete to clean up resources
Jun 26 13:08:12.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-4350'
Jun 26 13:08:12.555: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:08:12.555: INFO: stdout: "pod \"pause\" force deleted\n"
Jun 26 13:08:12.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get rc,svc -l name=pause --no-headers --namespace=kubectl-4350'
Jun 26 13:08:12.658: INFO: stderr: "No resources found in kubectl-4350 namespace.\n"
Jun 26 13:08:12.658: INFO: stdout: ""
Jun 26 13:08:12.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -l name=pause --namespace=kubectl-4350 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 26 13:08:12.733: INFO: stderr: ""
Jun 26 13:08:12.733: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:12.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4350" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","total":276,"completed":26,"skipped":514,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:12.739: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:08:12.764: INFO: Creating deployment "webserver-deployment"
Jun 26 13:08:12.767: INFO: Waiting for observed generation 1
Jun 26 13:08:14.779: INFO: Waiting for all required pods to come up
Jun 26 13:08:14.782: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun 26 13:08:22.794: INFO: Waiting for deployment "webserver-deployment" to complete
Jun 26 13:08:22.798: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jun 26 13:08:22.802: INFO: Updating deployment webserver-deployment
Jun 26 13:08:22.802: INFO: Waiting for observed generation 2
Jun 26 13:08:24.810: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun 26 13:08:24.812: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun 26 13:08:24.814: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jun 26 13:08:24.820: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun 26 13:08:24.820: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun 26 13:08:24.821: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jun 26 13:08:24.823: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jun 26 13:08:24.823: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jun 26 13:08:24.830: INFO: Updating deployment webserver-deployment
Jun 26 13:08:24.831: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jun 26 13:08:24.835: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun 26 13:08:24.838: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Jun 26 13:08:24.847: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9258 /apis/apps/v1/namespaces/deployment-9258/deployments/webserver-deployment 77a2c4d5-6d7c-43d9-8258-8bf82a98e492 5105 3 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e465e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-6676bcd6d4" is progressing.,LastUpdateTime:2020-06-26 13:08:22 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-06-26 13:08:24 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jun 26 13:08:24.860: INFO: New ReplicaSet "webserver-deployment-6676bcd6d4" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-6676bcd6d4  deployment-9258 /apis/apps/v1/namespaces/deployment-9258/replicasets/webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 5101 3 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 77a2c4d5-6d7c-43d9-8258-8bf82a98e492 0xc003e46d47 0xc003e46d48}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 55 97 50 99 52 100 53 45 54 100 55 99 45 52 51 100 57 45 56 50 53 56 45 56 98 102 56 50 97 57 56 101 52 57 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 6676bcd6d4,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e46e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:08:24.860: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jun 26 13:08:24.860: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-84855cf797  deployment-9258 /apis/apps/v1/namespaces/deployment-9258/replicasets/webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 5099 3 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 77a2c4d5-6d7c-43d9-8258-8bf82a98e492 0xc003e46e97 0xc003e46e98}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 55 55 97 50 99 52 100 53 45 54 100 55 99 45 52 51 100 57 45 56 50 53 56 45 56 98 102 56 50 97 57 56 101 52 57 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 84855cf797,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e46f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:08:24.922: INFO: Pod "webserver-deployment-6676bcd6d4-29vx6" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-29vx6 webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-29vx6 f45eb340-54fd-4571-8e04-6384939b0cdb 5070 0 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e994d0 0xc003e994d1}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:08:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.922: INFO: Pod "webserver-deployment-6676bcd6d4-97wc7" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-97wc7 webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-97wc7 14355525-40cd-441e-97fa-a143a8235955 5120 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e99797 0xc003e99798}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.923: INFO: Pod "webserver-deployment-6676bcd6d4-9wlwk" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-9wlwk webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-9wlwk 96ba7043-ffc9-45b9-97d9-7551ec4e09b9 5053 0 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e99957 0xc003e99958}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:08:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.924: INFO: Pod "webserver-deployment-6676bcd6d4-cbsxs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-cbsxs webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-cbsxs d8a1cc93-7502-4ac3-b9b8-e568ac4e4996 5059 0 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e99b67 0xc003e99b68}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:08:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.924: INFO: Pod "webserver-deployment-6676bcd6d4-gn72t" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-gn72t webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-gn72t ec073909-a719-4e91-92fb-f515c27dd718 5086 0 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e99db7 0xc003e99db8}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:08:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.924: INFO: Pod "webserver-deployment-6676bcd6d4-k4bgv" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-k4bgv webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-k4bgv e1c69600-eaa4-4e09-9914-e731134b1f1d 5119 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c057 0xc003e1c058}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.926: INFO: Pod "webserver-deployment-6676bcd6d4-nxtpj" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-nxtpj webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-nxtpj 3c49803b-47eb-4b85-9bfd-6d4ca3923d50 5121 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c187 0xc003e1c188}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.926: INFO: Pod "webserver-deployment-6676bcd6d4-pnsvq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-pnsvq webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-pnsvq 3d62690a-afdf-45a5-a697-991fcc7882f2 5127 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c330 0xc003e1c331}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.926: INFO: Pod "webserver-deployment-6676bcd6d4-r8fkq" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-r8fkq webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-r8fkq 1e9c5ac0-374c-4e7a-9d49-0eeb7e102d6c 5111 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c487 0xc003e1c488}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.926: INFO: Pod "webserver-deployment-6676bcd6d4-s5l46" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-s5l46 webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-s5l46 f5b5ada9-87d7-43e1-a9ab-aea7db460e88 5117 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c640 0xc003e1c641}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.927: INFO: Pod "webserver-deployment-6676bcd6d4-vddbw" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-vddbw webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-vddbw d1755933-c724-4a5c-9d80-8a5f3866a333 5126 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c810 0xc003e1c811}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.927: INFO: Pod "webserver-deployment-6676bcd6d4-wnjvs" is not available:
&Pod{ObjectMeta:{webserver-deployment-6676bcd6d4-wnjvs webserver-deployment-6676bcd6d4- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-6676bcd6d4-wnjvs 0f6bc59b-3ceb-4686-bd27-8fbee75a296f 5087 0 2020-06-26 13:08:22 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:6676bcd6d4] map[] [{apps/v1 ReplicaSet webserver-deployment-6676bcd6d4 d025eed4-b847-4478-861d-2250698b300e 0xc003e1c9a7 0xc003e1c9a8}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:22 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 48 50 53 101 101 100 52 45 98 56 52 55 45 52 52 55 56 45 56 54 49 100 45 50 50 53 48 54 57 56 98 51 48 48 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:23 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:08:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.927: INFO: Pod "webserver-deployment-84855cf797-5b5hs" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5b5hs webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-5b5hs 1fd099aa-166e-4181-95b5-8cbc29689615 5125 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1cc67 0xc003e1cc68}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.927: INFO: Pod "webserver-deployment-84855cf797-5r2sx" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-5r2sx webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-5r2sx 25d684cb-90d2-4d3e-b4f9-2e80e05c2e66 5118 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1cdf7 0xc003e1cdf8}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.936: INFO: Pod "webserver-deployment-84855cf797-9mbws" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9mbws webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-9mbws 324fb017-8b5e-42cd-9fff-4ec4049371c8 5115 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1cf47 0xc003e1cf48}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.936: INFO: Pod "webserver-deployment-84855cf797-9zb4r" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-9zb4r webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-9zb4r af043f02-8d51-4aae-9e0c-0a434fa34f2a 5109 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d087 0xc003e1d088}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.936: INFO: Pod "webserver-deployment-84855cf797-fv25l" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-fv25l webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-fv25l f9270bc5-b717-4edb-91cb-c43c1407b927 5022 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d270 0xc003e1d271}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 49 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.51,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9aef66f9baec0e01a0ba2360b73b35b99ece081ffa8591e7c4064d875f157faf,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.51,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.936: INFO: Pod "webserver-deployment-84855cf797-gt5hx" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-gt5hx webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-gt5hx 3a2233e3-5bdd-4165-a957-c3a75bcab4a3 5025 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d540 0xc003e1d541}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 50 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.52,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://03402161644d4a1b23bec199858ec201c7335d5182b989ac178e517b231625ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.52,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.938: INFO: Pod "webserver-deployment-84855cf797-hzvf6" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-hzvf6 webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-hzvf6 a42cb563-fbc5-4976-b731-d2f6206d6790 5122 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d720 0xc003e1d721}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.938: INFO: Pod "webserver-deployment-84855cf797-jqhrh" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-jqhrh webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-jqhrh af31d0d3-0675-4bd3-a849-8162dfb94bf7 5124 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d880 0xc003e1d881}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.938: INFO: Pod "webserver-deployment-84855cf797-k52gb" is not available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-k52gb webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-k52gb 60073583-cfc0-42eb-81b3-7ffeaa6a3533 5123 0 2020-06-26 13:08:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1d9b7 0xc003e1d9b8}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.938: INFO: Pod "webserver-deployment-84855cf797-kqj8x" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-kqj8x webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-kqj8x 78b37983-51b0-4e11-869a-946fa225c825 4998 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1dba0 0xc003e1dba1}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 48 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.50,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://30cd37ea940a37f1646671acae5c559bb8340618e5fb8ebc68383f70b65cfd8c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.940: INFO: Pod "webserver-deployment-84855cf797-m5955" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-m5955 webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-m5955 8f1e6172-1cef-4332-b806-a68ee1bba1f4 4980 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003e1ddc0 0xc003e1ddc1}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 52 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.48,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://85257c879d2e598bf39cba92b4d85117a0d9032ff2043ec6eaa94acf2470599c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.940: INFO: Pod "webserver-deployment-84855cf797-n2knh" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-n2knh webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-n2knh 57ebc681-522b-4ae7-9c1c-8515e7229f9b 5005 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003dfc030 0xc003dfc031}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:18 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.54,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://6dce37c539e0170e246ceb52819f557f91a9554d61fa0e54f1328b1bfdcbb90d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.54,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.944: INFO: Pod "webserver-deployment-84855cf797-nxbv4" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-nxbv4 webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-nxbv4 12462406-c2d1-48b7-aa21-b7eedf9aa2c0 4969 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003dfc2e0 0xc003dfc2e1}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:16 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 52 57 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.49,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://e8625dcc45bd038fc59b7d83cbbb1fc821cdcbec0b8f6963df14e2a48689047d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.946: INFO: Pod "webserver-deployment-84855cf797-rrfdn" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-rrfdn webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-rrfdn 420c563a-dd6a-4e96-bc94-493c189e13ae 5028 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003dfc600 0xc003dfc601}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:20 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.55,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ea39746d98ec65d5886ec951698b6169cc7ff0bda1b948398748ab8b534dc5c4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.55,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 13:08:24.947: INFO: Pod "webserver-deployment-84855cf797-sbwpf" is available:
&Pod{ObjectMeta:{webserver-deployment-84855cf797-sbwpf webserver-deployment-84855cf797- deployment-9258 /api/v1/namespaces/deployment-9258/pods/webserver-deployment-84855cf797-sbwpf 08cf0f44-826f-4841-b47c-339119d85b1b 5015 0 2020-06-26 13:08:12 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:84855cf797] map[] [{apps/v1 ReplicaSet webserver-deployment-84855cf797 c17552b4-4c71-45e3-acee-7606392ccf06 0xc003dfc8c0 0xc003dfc8c1}] []  [{kube-controller-manager Update v1 2020-06-26 13:08:12 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 49 55 53 53 50 98 52 45 52 99 55 49 45 52 53 101 51 45 97 99 101 101 45 55 54 48 54 51 57 50 99 99 102 48 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:08:19 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 53 54 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mf4ln,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mf4ln,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mf4ln,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:08:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.56,StartTime:2020-06-26 13:08:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:08:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://82739e68d0eb348a3b3c98e710f15b79f1a9a0e53485fd6349d6ba1937831781,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.56,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:24.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9258" for this suite.

• [SLOW TEST:12.244 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","total":276,"completed":27,"skipped":552,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:24.986: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:08:25.028: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Jun 26 13:08:28.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 create -f -'
Jun 26 13:08:29.379: INFO: stderr: ""
Jun 26 13:08:29.379: INFO: stdout: "e2e-test-crd-publish-openapi-1924-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jun 26 13:08:29.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 delete e2e-test-crd-publish-openapi-1924-crds test-foo'
Jun 26 13:08:29.482: INFO: stderr: ""
Jun 26 13:08:29.482: INFO: stdout: "e2e-test-crd-publish-openapi-1924-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jun 26 13:08:29.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 apply -f -'
Jun 26 13:08:29.631: INFO: stderr: ""
Jun 26 13:08:29.631: INFO: stdout: "e2e-test-crd-publish-openapi-1924-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jun 26 13:08:29.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 delete e2e-test-crd-publish-openapi-1924-crds test-foo'
Jun 26 13:08:29.708: INFO: stderr: ""
Jun 26 13:08:29.708: INFO: stdout: "e2e-test-crd-publish-openapi-1924-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Jun 26 13:08:29.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 create -f -'
Jun 26 13:08:29.832: INFO: rc: 1
Jun 26 13:08:29.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 apply -f -'
Jun 26 13:08:29.969: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Jun 26 13:08:29.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 create -f -'
Jun 26 13:08:30.134: INFO: rc: 1
Jun 26 13:08:30.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-1983 apply -f -'
Jun 26 13:08:30.323: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Jun 26 13:08:30.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1924-crds'
Jun 26 13:08:30.693: INFO: stderr: ""
Jun 26 13:08:30.693: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1924-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Jun 26 13:08:30.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1924-crds.metadata'
Jun 26 13:08:31.651: INFO: stderr: ""
Jun 26 13:08:31.651: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1924-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jun 26 13:08:31.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1924-crds.spec'
Jun 26 13:08:32.467: INFO: stderr: ""
Jun 26 13:08:32.467: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1924-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jun 26 13:08:32.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1924-crds.spec.bars'
Jun 26 13:08:32.912: INFO: stderr: ""
Jun 26 13:08:32.912: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1924-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Jun 26 13:08:32.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1924-crds.spec.bars2'
Jun 26 13:08:33.344: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:36.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1983" for this suite.

• [SLOW TEST:11.148 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","total":276,"completed":28,"skipped":582,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:36.135: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W0626 13:08:36.706938      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 26 13:08:36.707: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:36.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8390" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","total":276,"completed":29,"skipped":592,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:36.718: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 26 13:08:42.769: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:42.770: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:42.879: INFO: Exec stderr: ""
Jun 26 13:08:42.879: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:42.879: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:42.966: INFO: Exec stderr: ""
Jun 26 13:08:42.966: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:42.967: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.053: INFO: Exec stderr: ""
Jun 26 13:08:43.053: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.053: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.151: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 26 13:08:43.151: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.151: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.247: INFO: Exec stderr: ""
Jun 26 13:08:43.247: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.247: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.333: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 26 13:08:43.333: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.333: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.422: INFO: Exec stderr: ""
Jun 26 13:08:43.422: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.422: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.520: INFO: Exec stderr: ""
Jun 26 13:08:43.521: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.521: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.600: INFO: Exec stderr: ""
Jun 26 13:08:43.600: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6467 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:08:43.601: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:08:43.686: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:08:43.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6467" for this suite.

• [SLOW TEST:6.975 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":30,"skipped":603,"failed":0}
SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:08:43.693: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-7014
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 26 13:08:43.714: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jun 26 13:08:43.722: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 13:08:45.727: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:47.727: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:49.726: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:51.727: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:53.729: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:55.727: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:57.728: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:08:59.728: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:09:01.727: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:09:03.728: INFO: The status of Pod netserver-0 is Running (Ready = true)
STEP: Creating test pods
Jun 26 13:09:05.771: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.1.0.83 8081 | grep -v '^\s*$'] Namespace:pod-network-test-7014 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:09:05.771: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:09:06.872: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:06.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7014" for this suite.

• [SLOW TEST:23.187 seconds]
[sig-network] Networking
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":31,"skipped":607,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:06.886: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Jun 26 13:09:06.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-6818'
Jun 26 13:09:07.124: INFO: stderr: ""
Jun 26 13:09:07.124: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Jun 26 13:09:08.128: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:09:08.128: INFO: Found 1 / 1
Jun 26 13:09:08.128: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun 26 13:09:08.131: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:09:08.131: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 26 13:09:08.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 patch pod agnhost-master-n4k7l --namespace=kubectl-6818 -p {"metadata":{"annotations":{"x":"y"}}}'
Jun 26 13:09:08.217: INFO: stderr: ""
Jun 26 13:09:08.217: INFO: stdout: "pod/agnhost-master-n4k7l patched\n"
STEP: checking annotations
Jun 26 13:09:08.220: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:09:08.220: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:08.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6818" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","total":276,"completed":32,"skipped":608,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:08.225: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:19.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2932" for this suite.

• [SLOW TEST:11.078 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","total":276,"completed":33,"skipped":608,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:19.306: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-0fe48742-300a-4264-845b-5fda17345116
STEP: Creating a pod to test consume secrets
Jun 26 13:09:19.336: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8" in namespace "projected-2109" to be "Succeeded or Failed"
Jun 26 13:09:19.343: INFO: Pod "pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.736418ms
Jun 26 13:09:21.346: INFO: Pod "pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010351663s
STEP: Saw pod success
Jun 26 13:09:21.347: INFO: Pod "pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8" satisfied condition "Succeeded or Failed"
Jun 26 13:09:21.349: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:09:21.367: INFO: Waiting for pod pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8 to disappear
Jun 26 13:09:21.369: INFO: Pod pod-projected-secrets-806e034a-b14b-445c-be4a-4390e536daa8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:21.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2109" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":34,"skipped":620,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:21.373: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:09:21.393: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-4ce25591-9f1d-4ea3-bf4c-f101c005d4b4" in namespace "security-context-test-1804" to be "Succeeded or Failed"
Jun 26 13:09:21.397: INFO: Pod "alpine-nnp-false-4ce25591-9f1d-4ea3-bf4c-f101c005d4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 3.49845ms
Jun 26 13:09:23.403: INFO: Pod "alpine-nnp-false-4ce25591-9f1d-4ea3-bf4c-f101c005d4b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009605107s
Jun 26 13:09:25.406: INFO: Pod "alpine-nnp-false-4ce25591-9f1d-4ea3-bf4c-f101c005d4b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013043077s
Jun 26 13:09:25.407: INFO: Pod "alpine-nnp-false-4ce25591-9f1d-4ea3-bf4c-f101c005d4b4" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:25.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1804" for this suite.
•{"msg":"PASSED [k8s.io] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":35,"skipped":627,"failed":0}
SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:25.419: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:27.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2483" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","total":276,"completed":36,"skipped":629,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:27.472: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a service nodeport-service with the type=NodePort in namespace services-6026
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6026
STEP: creating replication controller externalsvc in namespace services-6026
I0626 13:09:27.523486      24 runners.go:190] Created replication controller with name: externalsvc, namespace: services-6026, replica count: 2
I0626 13:09:30.574892      24 runners.go:190] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Jun 26 13:09:30.616: INFO: Creating new exec pod
Jun 26 13:09:32.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-6026 execpodvhpf5 -- /bin/sh -x -c nslookup nodeport-service'
Jun 26 13:09:32.821: INFO: stderr: "+ nslookup nodeport-service\n"
Jun 26 13:09:32.821: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-6026.svc.cluster.local\tcanonical name = externalsvc.services-6026.svc.cluster.local.\nName:\texternalsvc.services-6026.svc.cluster.local\nAddress: 10.110.24.92\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6026, will wait for the garbage collector to delete the pods
Jun 26 13:09:32.881: INFO: Deleting ReplicationController externalsvc took: 6.3698ms
Jun 26 13:09:32.981: INFO: Terminating ReplicationController externalsvc pods took: 100.452212ms
Jun 26 13:09:49.626: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:09:49.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6026" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:22.176 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","total":276,"completed":37,"skipped":637,"failed":0}
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:09:49.649: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9525
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-9525
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9525
Jun 26 13:09:49.694: INFO: Found 0 stateful pods, waiting for 1
Jun 26 13:09:59.698: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 26 13:09:59.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:09:59.856: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:09:59.856: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:09:59.856: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:09:59.858: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 26 13:10:09.862: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:10:09.862: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:10:09.871: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999685s
Jun 26 13:10:10.875: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997827993s
Jun 26 13:10:11.879: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993506027s
Jun 26 13:10:12.881: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989997689s
Jun 26 13:10:13.885: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987153303s
Jun 26 13:10:14.891: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.982834943s
Jun 26 13:10:15.896: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977468416s
Jun 26 13:10:16.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.973150708s
Jun 26 13:10:17.906: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.968244437s
Jun 26 13:10:18.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 962.544233ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9525
Jun 26 13:10:19.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:10:20.073: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:10:20.073: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:10:20.073: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:10:20.075: INFO: Found 1 stateful pods, waiting for 3
Jun 26 13:10:30.080: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:10:30.080: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:10:30.080: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 26 13:10:30.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:10:30.238: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:10:30.238: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:10:30.238: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:10:30.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:10:30.382: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:10:30.382: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:10:30.382: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:10:30.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:10:30.530: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:10:30.530: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:10:30.530: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:10:30.530: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:10:30.533: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 26 13:10:40.544: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:10:40.544: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:10:40.544: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 26 13:10:40.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999612s
Jun 26 13:10:41.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996133742s
Jun 26 13:10:42.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992416292s
Jun 26 13:10:43.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987303168s
Jun 26 13:10:44.572: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982747929s
Jun 26 13:10:45.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978013103s
Jun 26 13:10:46.581: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973550466s
Jun 26 13:10:47.586: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.96952399s
Jun 26 13:10:48.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.965127519s
Jun 26 13:10:49.593: INFO: Verifying statefulset ss doesn't scale past 3 for another 961.521193ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9525
Jun 26 13:10:50.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:10:50.770: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:10:50.770: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:10:50.770: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:10:50.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:10:50.941: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:10:50.941: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:10:50.941: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:10:50.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9525 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:10:51.103: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:10:51.103: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:10:51.103: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:10:51.103: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:11:21.117: INFO: Deleting all statefulset in ns statefulset-9525
Jun 26 13:11:21.119: INFO: Scaling statefulset ss to 0
Jun 26 13:11:21.125: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:11:21.126: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:11:21.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9525" for this suite.

• [SLOW TEST:91.492 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","total":276,"completed":38,"skipped":642,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:11:21.144: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Jun 26 13:11:21.170: INFO: Waiting up to 5m0s for pod "downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d" in namespace "downward-api-8882" to be "Succeeded or Failed"
Jun 26 13:11:21.181: INFO: Pod "downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.224392ms
Jun 26 13:11:23.184: INFO: Pod "downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013499022s
STEP: Saw pod success
Jun 26 13:11:23.184: INFO: Pod "downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d" satisfied condition "Succeeded or Failed"
Jun 26 13:11:23.185: INFO: Trying to get logs from node docker-desktop pod downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:11:23.202: INFO: Waiting for pod downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d to disappear
Jun 26 13:11:23.205: INFO: Pod downward-api-e7a11e9f-7ce8-4b1f-9123-1878b78a257d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:11:23.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8882" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","total":276,"completed":39,"skipped":687,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:11:23.210: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/taints.go:345
Jun 26 13:11:23.227: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 26 13:12:23.239: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:12:23.241: INFO: Starting informer...
STEP: Starting pods...
Jun 26 13:12:23.456: INFO: Pod1 is running on docker-desktop. Tainting Node
Jun 26 13:12:25.676: INFO: Pod2 is running on docker-desktop. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Jun 26 13:12:39.496: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jun 26 13:12:59.491: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:12:59.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-6851" for this suite.

• [SLOW TEST:96.297 seconds]
[k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","total":276,"completed":40,"skipped":705,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:12:59.509: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:12:59.529: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:00.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5516" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","total":276,"completed":41,"skipped":710,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:00.072: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 26 13:13:02.107: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:02.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4482" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":276,"completed":42,"skipped":730,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:02.129: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun 26 13:13:05.172: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:06.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8127" for this suite.
•{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","total":276,"completed":43,"skipped":744,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:06.196: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: getting the auto-created API token
Jun 26 13:13:06.729: INFO: created pod pod-service-account-defaultsa
Jun 26 13:13:06.729: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 26 13:13:06.734: INFO: created pod pod-service-account-mountsa
Jun 26 13:13:06.734: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 26 13:13:06.744: INFO: created pod pod-service-account-nomountsa
Jun 26 13:13:06.745: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 26 13:13:06.752: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 26 13:13:06.752: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 26 13:13:06.756: INFO: created pod pod-service-account-mountsa-mountspec
Jun 26 13:13:06.756: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 26 13:13:06.770: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 26 13:13:06.770: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 26 13:13:06.796: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 26 13:13:06.796: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 26 13:13:06.801: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 26 13:13:06.802: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 26 13:13:06.806: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 26 13:13:06.807: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:06.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3988" for this suite.
•{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","total":276,"completed":44,"skipped":768,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:06.834: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Jun 26 13:13:06.860: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 26 13:13:06.866: INFO: Waiting for terminating namespaces to be deleted...
Jun 26 13:13:06.870: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Jun 26 13:13:07.158: INFO: pod-service-account-nomountsa-nomountspec from svcaccounts-3988 started at <nil> (0 container statuses recorded)
Jun 26 13:13:07.158: INFO: pod-service-account-nomountsa from svcaccounts-3988 started at 2020-06-26 13:13:06 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.158: INFO: 	Container token-test ready: false, restart count 0
Jun 26 13:13:07.158: INFO: pod-service-account-nomountsa-mountspec from svcaccounts-3988 started at <nil> (0 container statuses recorded)
Jun 26 13:13:07.158: INFO: pod-service-account-mountsa-nomountspec from svcaccounts-3988 started at <nil> (0 container statuses recorded)
Jun 26 13:13:07.159: INFO: pod-service-account-defaultsa from svcaccounts-3988 started at 2020-06-26 13:13:06 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container token-test ready: false, restart count 0
Jun 26 13:13:07.159: INFO: kube-scheduler-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container kube-scheduler ready: true, restart count 0
Jun 26 13:13:07.159: INFO: kube-apiserver-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container kube-apiserver ready: true, restart count 0
Jun 26 13:13:07.159: INFO: pod-adoption-release-92lnn from replicaset-8127 started at 2020-06-26 13:13:05 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container pod-adoption-release ready: false, restart count 0
Jun 26 13:13:07.159: INFO: pod-service-account-mountsa-mountspec from svcaccounts-3988 started at <nil> (0 container statuses recorded)
Jun 26 13:13:07.159: INFO: etcd-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container etcd ready: true, restart count 0
Jun 26 13:13:07.159: INFO: pod-service-account-defaultsa-nomountspec from svcaccounts-3988 started at <nil> (0 container statuses recorded)
Jun 26 13:13:07.159: INFO: sonobuoy from sonobuoy started at 2020-06-26 13:00:36 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 26 13:13:07.159: INFO: sonobuoy-e2e-job-ad77c8f3bad64e56 from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container e2e ready: true, restart count 0
Jun 26 13:13:07.159: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:13:07.159: INFO: sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:13:07.159: INFO: 	Container systemd-logs ready: false, restart count 7
Jun 26 13:13:07.159: INFO: kube-controller-manager-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container kube-controller-manager ready: true, restart count 0
Jun 26 13:13:07.159: INFO: pod-adoption-release from replicaset-8127 started at 2020-06-26 13:13:02 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container pod-adoption-release ready: true, restart count 0
Jun 26 13:13:07.159: INFO: pod-service-account-mountsa from svcaccounts-3988 started at 2020-06-26 13:13:06 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container token-test ready: false, restart count 0
Jun 26 13:13:07.159: INFO: pod-service-account-defaultsa-mountspec from svcaccounts-3988 started at 2020-06-26 13:13:06 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container token-test ready: false, restart count 0
Jun 26 13:13:07.159: INFO: kube-proxy-tzb5b from kube-system started at 2020-06-26 12:48:45 +0000 UTC (1 container statuses recorded)
Jun 26 13:13:07.159: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-f05ed161-4294-4773-bbd0-6d6581fe4862 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-f05ed161-4294-4773-bbd0-6d6581fe4862 off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f05ed161-4294-4773-bbd0-6d6581fe4862
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:25.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9637" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:18.422 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]","total":276,"completed":45,"skipped":791,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:25.257: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 26 13:13:25.287: INFO: Waiting up to 5m0s for pod "pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5" in namespace "emptydir-4911" to be "Succeeded or Failed"
Jun 26 13:13:25.289: INFO: Pod "pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603755ms
Jun 26 13:13:27.293: INFO: Pod "pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006431422s
Jun 26 13:13:29.296: INFO: Pod "pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00920754s
STEP: Saw pod success
Jun 26 13:13:29.296: INFO: Pod "pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5" satisfied condition "Succeeded or Failed"
Jun 26 13:13:29.298: INFO: Trying to get logs from node docker-desktop pod pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5 container test-container: <nil>
STEP: delete the pod
Jun 26 13:13:29.310: INFO: Waiting for pod pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5 to disappear
Jun 26 13:13:29.314: INFO: Pod pod-9a59bb7c-3f0a-4f84-bd98-cb798ba999e5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:13:29.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4911" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":46,"skipped":805,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:13:29.321: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod test-webserver-b1edd815-f19d-4779-928d-117ad5e24b96 in namespace container-probe-2601
Jun 26 13:13:31.347: INFO: Started pod test-webserver-b1edd815-f19d-4779-928d-117ad5e24b96 in namespace container-probe-2601
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 13:13:31.349: INFO: Initial restart count of pod test-webserver-b1edd815-f19d-4779-928d-117ad5e24b96 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:17:31.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2601" for this suite.

• [SLOW TEST:242.546 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":276,"completed":47,"skipped":816,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:17:31.873: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 26 13:17:31.929: INFO: Number of nodes with available pods: 0
Jun 26 13:17:31.929: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:17:32.934: INFO: Number of nodes with available pods: 0
Jun 26 13:17:32.934: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:17:33.934: INFO: Number of nodes with available pods: 1
Jun 26 13:17:33.934: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 26 13:17:33.950: INFO: Number of nodes with available pods: 0
Jun 26 13:17:33.950: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:17:34.959: INFO: Number of nodes with available pods: 0
Jun 26 13:17:34.959: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:17:35.957: INFO: Number of nodes with available pods: 1
Jun 26 13:17:35.957: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7939, will wait for the garbage collector to delete the pods
Jun 26 13:17:36.020: INFO: Deleting DaemonSet.extensions daemon-set took: 6.674058ms
Jun 26 13:17:36.522: INFO: Terminating DaemonSet.extensions daemon-set pods took: 501.069043ms
Jun 26 13:17:49.526: INFO: Number of nodes with available pods: 0
Jun 26 13:17:49.526: INFO: Number of running nodes: 0, number of available pods: 0
Jun 26 13:17:49.530: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7939/daemonsets","resourceVersion":"7876"},"items":null}

Jun 26 13:17:49.531: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7939/pods","resourceVersion":"7876"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:17:49.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7939" for this suite.

• [SLOW TEST:17.667 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","total":276,"completed":48,"skipped":824,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:17:49.541: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test hostPath mode
Jun 26 13:17:49.567: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7384" to be "Succeeded or Failed"
Jun 26 13:17:49.570: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 3.069745ms
Jun 26 13:17:51.573: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006944825s
STEP: Saw pod success
Jun 26 13:17:51.574: INFO: Pod "pod-host-path-test" satisfied condition "Succeeded or Failed"
Jun 26 13:17:51.576: INFO: Trying to get logs from node docker-desktop pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 26 13:17:51.596: INFO: Waiting for pod pod-host-path-test to disappear
Jun 26 13:17:51.601: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:17:51.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7384" for this suite.
•{"msg":"PASSED [sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":49,"skipped":862,"failed":0}

------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:17:51.608: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun 26 13:17:51.891: INFO: Pod name wrapped-volume-race-261a0d99-28b5-4066-9aa0-e3a41c3b87f7: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-261a0d99-28b5-4066-9aa0-e3a41c3b87f7 in namespace emptydir-wrapper-8405, will wait for the garbage collector to delete the pods
Jun 26 13:18:05.993: INFO: Deleting ReplicationController wrapped-volume-race-261a0d99-28b5-4066-9aa0-e3a41c3b87f7 took: 11.427611ms
Jun 26 13:18:06.494: INFO: Terminating ReplicationController wrapped-volume-race-261a0d99-28b5-4066-9aa0-e3a41c3b87f7 pods took: 500.597344ms
STEP: Creating RC which spawns configmap-volume pods
Jun 26 13:18:19.608: INFO: Pod name wrapped-volume-race-f0f72074-47ab-4c57-84bb-87320fd13067: Found 0 pods out of 5
Jun 26 13:18:24.615: INFO: Pod name wrapped-volume-race-f0f72074-47ab-4c57-84bb-87320fd13067: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f0f72074-47ab-4c57-84bb-87320fd13067 in namespace emptydir-wrapper-8405, will wait for the garbage collector to delete the pods
Jun 26 13:18:34.688: INFO: Deleting ReplicationController wrapped-volume-race-f0f72074-47ab-4c57-84bb-87320fd13067 took: 5.995528ms
Jun 26 13:18:35.190: INFO: Terminating ReplicationController wrapped-volume-race-f0f72074-47ab-4c57-84bb-87320fd13067 pods took: 501.347446ms
STEP: Creating RC which spawns configmap-volume pods
Jun 26 13:18:49.603: INFO: Pod name wrapped-volume-race-d4c4e646-d683-4d9d-a024-b2802bee8823: Found 0 pods out of 5
Jun 26 13:18:54.610: INFO: Pod name wrapped-volume-race-d4c4e646-d683-4d9d-a024-b2802bee8823: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d4c4e646-d683-4d9d-a024-b2802bee8823 in namespace emptydir-wrapper-8405, will wait for the garbage collector to delete the pods
Jun 26 13:19:04.687: INFO: Deleting ReplicationController wrapped-volume-race-d4c4e646-d683-4d9d-a024-b2802bee8823 took: 6.100637ms
Jun 26 13:19:05.188: INFO: Terminating ReplicationController wrapped-volume-race-d4c4e646-d683-4d9d-a024-b2802bee8823 pods took: 501.34431ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:19:09.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8405" for this suite.

• [SLOW TEST:78.138 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","total":276,"completed":50,"skipped":862,"failed":0}
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:19:09.748: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-jjm5
STEP: Creating a pod to test atomic-volume-subpath
Jun 26 13:19:09.774: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jjm5" in namespace "subpath-8682" to be "Succeeded or Failed"
Jun 26 13:19:09.778: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.150465ms
Jun 26 13:19:11.782: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 2.008463421s
Jun 26 13:19:13.788: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 4.014022326s
Jun 26 13:19:15.792: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 6.01766572s
Jun 26 13:19:17.798: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 8.022915883s
Jun 26 13:19:19.801: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 10.026076009s
Jun 26 13:19:21.804: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 12.029439553s
Jun 26 13:19:23.808: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 14.033466673s
Jun 26 13:19:25.812: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 16.037706141s
Jun 26 13:19:27.816: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 18.041648274s
Jun 26 13:19:29.820: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Running", Reason="", readiness=true. Elapsed: 20.045183107s
Jun 26 13:19:31.823: INFO: Pod "pod-subpath-test-configmap-jjm5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.047853355s
STEP: Saw pod success
Jun 26 13:19:31.823: INFO: Pod "pod-subpath-test-configmap-jjm5" satisfied condition "Succeeded or Failed"
Jun 26 13:19:31.825: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-jjm5 container test-container-subpath-configmap-jjm5: <nil>
STEP: delete the pod
Jun 26 13:19:31.851: INFO: Waiting for pod pod-subpath-test-configmap-jjm5 to disappear
Jun 26 13:19:31.854: INFO: Pod pod-subpath-test-configmap-jjm5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jjm5
Jun 26 13:19:31.854: INFO: Deleting pod "pod-subpath-test-configmap-jjm5" in namespace "subpath-8682"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:19:31.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8682" for this suite.

• [SLOW TEST:22.116 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]","total":276,"completed":51,"skipped":863,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:19:31.865: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 26 13:19:31.893: INFO: Waiting up to 5m0s for pod "pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf" in namespace "emptydir-9653" to be "Succeeded or Failed"
Jun 26 13:19:31.896: INFO: Pod "pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.400561ms
Jun 26 13:19:33.899: INFO: Pod "pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00629238s
STEP: Saw pod success
Jun 26 13:19:33.899: INFO: Pod "pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf" satisfied condition "Succeeded or Failed"
Jun 26 13:19:33.901: INFO: Trying to get logs from node docker-desktop pod pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf container test-container: <nil>
STEP: delete the pod
Jun 26 13:19:33.915: INFO: Waiting for pod pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf to disappear
Jun 26 13:19:33.917: INFO: Pod pod-cbba2c23-ac1c-4b6c-a6cb-a139c3b4b7cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:19:33.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9653" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":52,"skipped":885,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:19:33.924: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:19:34.507: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:19:37.521: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:19:37.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9998" for this suite.
STEP: Destroying namespace "webhook-9998-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","total":276,"completed":53,"skipped":922,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:19:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:19:37.939: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:19:40.964: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:19:40.967: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:19:42.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2177" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","total":276,"completed":54,"skipped":937,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:19:42.191: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-secret-6ntp
STEP: Creating a pod to test atomic-volume-subpath
Jun 26 13:19:42.231: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6ntp" in namespace "subpath-2235" to be "Succeeded or Failed"
Jun 26 13:19:42.246: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Pending", Reason="", readiness=false. Elapsed: 14.841043ms
Jun 26 13:19:44.250: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 2.018853441s
Jun 26 13:19:46.254: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 4.02294784s
Jun 26 13:19:48.258: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 6.026944575s
Jun 26 13:19:50.262: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 8.030937618s
Jun 26 13:19:52.267: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 10.035714021s
Jun 26 13:19:54.271: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 12.039336686s
Jun 26 13:19:56.275: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 14.043869742s
Jun 26 13:19:58.280: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 16.048137722s
Jun 26 13:20:00.283: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 18.051664761s
Jun 26 13:20:02.289: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Running", Reason="", readiness=true. Elapsed: 20.057169749s
Jun 26 13:20:04.291: INFO: Pod "pod-subpath-test-secret-6ntp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.059871237s
STEP: Saw pod success
Jun 26 13:20:04.291: INFO: Pod "pod-subpath-test-secret-6ntp" satisfied condition "Succeeded or Failed"
Jun 26 13:20:04.293: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-secret-6ntp container test-container-subpath-secret-6ntp: <nil>
STEP: delete the pod
Jun 26 13:20:04.306: INFO: Waiting for pod pod-subpath-test-secret-6ntp to disappear
Jun 26 13:20:04.307: INFO: Pod pod-subpath-test-secret-6ntp no longer exists
STEP: Deleting pod pod-subpath-test-secret-6ntp
Jun 26 13:20:04.308: INFO: Deleting pod "pod-subpath-test-secret-6ntp" in namespace "subpath-2235"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:20:04.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2235" for this suite.

• [SLOW TEST:22.123 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [LinuxOnly] [Conformance]","total":276,"completed":55,"skipped":953,"failed":0}
SSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:20:04.315: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:21:04.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-834" for this suite.

• [SLOW TEST:60.031 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","total":276,"completed":56,"skipped":960,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:21:04.347: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 in namespace container-probe-7755
Jun 26 13:21:06.381: INFO: Started pod liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 in namespace container-probe-7755
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 13:21:06.384: INFO: Initial restart count of pod liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is 0
Jun 26 13:21:16.409: INFO: Restart count of pod container-probe-7755/liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is now 1 (10.024862149s elapsed)
Jun 26 13:21:36.458: INFO: Restart count of pod container-probe-7755/liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is now 2 (30.073342524s elapsed)
Jun 26 13:21:56.506: INFO: Restart count of pod container-probe-7755/liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is now 3 (50.121170609s elapsed)
Jun 26 13:22:16.550: INFO: Restart count of pod container-probe-7755/liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is now 4 (1m10.164910146s elapsed)
Jun 26 13:23:28.705: INFO: Restart count of pod container-probe-7755/liveness-e8e5274a-bba3-4aac-9214-63e7113256c3 is now 5 (2m22.317559004s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:28.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7755" for this suite.

• [SLOW TEST:144.371 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","total":276,"completed":57,"skipped":963,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] LimitRange 
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:28.723: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename limitrange
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a LimitRange
STEP: Setting up watch
STEP: Submitting a LimitRange
Jun 26 13:23:28.749: INFO: observed the limitRanges list
STEP: Verifying LimitRange creation was observed
STEP: Fetching the LimitRange to ensure it has proper values
Jun 26 13:23:28.757: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jun 26 13:23:28.757: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements
STEP: Ensuring Pod has resource requirements applied from LimitRange
Jun 26 13:23:28.769: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Jun 26 13:23:28.769: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements
STEP: Ensuring Pod has merged resource requirements applied from LimitRange
Jun 26 13:23:28.779: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Jun 26 13:23:28.779: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources
STEP: Failing to create a Pod with more than max resources
STEP: Updating a LimitRange
STEP: Verifying LimitRange updating is effective
STEP: Creating a Pod with less than former min resources
STEP: Failing to create a Pod with more than max resources
STEP: Deleting a LimitRange
STEP: Verifying the LimitRange was deleted
Jun 26 13:23:35.810: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources
[AfterEach] [sig-scheduling] LimitRange
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:35.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-88" for this suite.

• [SLOW TEST:7.101 seconds]
[sig-scheduling] LimitRange
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","total":276,"completed":58,"skipped":1012,"failed":0}
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:35.828: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:23:35.850: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1446
I0626 13:23:35.876427      24 runners.go:190] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1446, replica count: 1
I0626 13:23:36.927167      24 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0626 13:23:37.928385      24 runners.go:190] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 26 13:23:38.040: INFO: Created: latency-svc-s8dx8
Jun 26 13:23:38.050: INFO: Got endpoints: latency-svc-s8dx8 [20.721885ms]
Jun 26 13:23:38.070: INFO: Created: latency-svc-97p6w
Jun 26 13:23:38.078: INFO: Got endpoints: latency-svc-97p6w [27.28513ms]
Jun 26 13:23:38.089: INFO: Created: latency-svc-pmrqk
Jun 26 13:23:38.092: INFO: Got endpoints: latency-svc-pmrqk [41.84266ms]
Jun 26 13:23:38.100: INFO: Created: latency-svc-qng9q
Jun 26 13:23:38.101: INFO: Got endpoints: latency-svc-qng9q [49.392753ms]
Jun 26 13:23:38.108: INFO: Created: latency-svc-7n86f
Jun 26 13:23:38.114: INFO: Got endpoints: latency-svc-7n86f [62.731346ms]
Jun 26 13:23:38.119: INFO: Created: latency-svc-6wd2v
Jun 26 13:23:38.123: INFO: Got endpoints: latency-svc-6wd2v [71.691202ms]
Jun 26 13:23:38.131: INFO: Created: latency-svc-nf27f
Jun 26 13:23:38.132: INFO: Got endpoints: latency-svc-nf27f [80.973495ms]
Jun 26 13:23:38.139: INFO: Created: latency-svc-58qs9
Jun 26 13:23:38.144: INFO: Got endpoints: latency-svc-58qs9 [92.764952ms]
Jun 26 13:23:38.163: INFO: Created: latency-svc-mrl2q
Jun 26 13:23:38.171: INFO: Got endpoints: latency-svc-mrl2q [119.84235ms]
Jun 26 13:23:38.176: INFO: Created: latency-svc-6p55f
Jun 26 13:23:38.176: INFO: Got endpoints: latency-svc-6p55f [125.006424ms]
Jun 26 13:23:38.178: INFO: Created: latency-svc-j2l6m
Jun 26 13:23:38.183: INFO: Got endpoints: latency-svc-j2l6m [131.875293ms]
Jun 26 13:23:38.189: INFO: Created: latency-svc-tbnlc
Jun 26 13:23:38.193: INFO: Got endpoints: latency-svc-tbnlc [142.672237ms]
Jun 26 13:23:38.200: INFO: Created: latency-svc-l899w
Jun 26 13:23:38.201: INFO: Got endpoints: latency-svc-l899w [149.293058ms]
Jun 26 13:23:38.208: INFO: Created: latency-svc-xg52x
Jun 26 13:23:38.212: INFO: Got endpoints: latency-svc-xg52x [160.58019ms]
Jun 26 13:23:38.221: INFO: Created: latency-svc-772n7
Jun 26 13:23:38.229: INFO: Created: latency-svc-hf7zd
Jun 26 13:23:38.231: INFO: Got endpoints: latency-svc-772n7 [179.333605ms]
Jun 26 13:23:38.234: INFO: Got endpoints: latency-svc-hf7zd [183.753706ms]
Jun 26 13:23:38.242: INFO: Created: latency-svc-ksgnz
Jun 26 13:23:38.246: INFO: Got endpoints: latency-svc-ksgnz [167.717687ms]
Jun 26 13:23:38.249: INFO: Created: latency-svc-7wn2v
Jun 26 13:23:38.253: INFO: Got endpoints: latency-svc-7wn2v [159.717509ms]
Jun 26 13:23:38.265: INFO: Created: latency-svc-ksrz6
Jun 26 13:23:38.270: INFO: Got endpoints: latency-svc-ksrz6 [168.775351ms]
Jun 26 13:23:38.273: INFO: Created: latency-svc-7vnvj
Jun 26 13:23:38.277: INFO: Got endpoints: latency-svc-7vnvj [163.417344ms]
Jun 26 13:23:38.281: INFO: Created: latency-svc-hq5fk
Jun 26 13:23:38.288: INFO: Got endpoints: latency-svc-hq5fk [165.192454ms]
Jun 26 13:23:38.290: INFO: Created: latency-svc-hl6xz
Jun 26 13:23:38.297: INFO: Got endpoints: latency-svc-hl6xz [164.554074ms]
Jun 26 13:23:38.301: INFO: Created: latency-svc-bkmqc
Jun 26 13:23:38.303: INFO: Got endpoints: latency-svc-bkmqc [158.817464ms]
Jun 26 13:23:38.308: INFO: Created: latency-svc-9qx5k
Jun 26 13:23:38.312: INFO: Got endpoints: latency-svc-9qx5k [141.317552ms]
Jun 26 13:23:38.315: INFO: Created: latency-svc-t8nlh
Jun 26 13:23:38.319: INFO: Got endpoints: latency-svc-t8nlh [142.873234ms]
Jun 26 13:23:38.322: INFO: Created: latency-svc-gfrpp
Jun 26 13:23:38.326: INFO: Got endpoints: latency-svc-gfrpp [142.937751ms]
Jun 26 13:23:38.328: INFO: Created: latency-svc-4lb75
Jun 26 13:23:38.334: INFO: Got endpoints: latency-svc-4lb75 [140.195098ms]
Jun 26 13:23:38.338: INFO: Created: latency-svc-zqfrl
Jun 26 13:23:38.343: INFO: Got endpoints: latency-svc-zqfrl [142.024322ms]
Jun 26 13:23:38.349: INFO: Created: latency-svc-fhsnf
Jun 26 13:23:38.353: INFO: Got endpoints: latency-svc-fhsnf [141.073665ms]
Jun 26 13:23:38.360: INFO: Created: latency-svc-h75lf
Jun 26 13:23:38.370: INFO: Got endpoints: latency-svc-h75lf [139.574611ms]
Jun 26 13:23:38.374: INFO: Created: latency-svc-8czwh
Jun 26 13:23:38.379: INFO: Got endpoints: latency-svc-8czwh [144.773232ms]
Jun 26 13:23:38.382: INFO: Created: latency-svc-kplxm
Jun 26 13:23:38.387: INFO: Got endpoints: latency-svc-kplxm [141.410188ms]
Jun 26 13:23:38.391: INFO: Created: latency-svc-8czx9
Jun 26 13:23:38.397: INFO: Got endpoints: latency-svc-8czx9 [143.704216ms]
Jun 26 13:23:38.402: INFO: Created: latency-svc-n7gqw
Jun 26 13:23:38.404: INFO: Got endpoints: latency-svc-n7gqw [134.23511ms]
Jun 26 13:23:38.411: INFO: Created: latency-svc-b87l9
Jun 26 13:23:38.416: INFO: Got endpoints: latency-svc-b87l9 [138.250503ms]
Jun 26 13:23:38.421: INFO: Created: latency-svc-m9fkx
Jun 26 13:23:38.450: INFO: Created: latency-svc-dhctc
Jun 26 13:23:38.450: INFO: Got endpoints: latency-svc-dhctc [153.282629ms]
Jun 26 13:23:38.450: INFO: Got endpoints: latency-svc-m9fkx [162.351703ms]
Jun 26 13:23:38.463: INFO: Created: latency-svc-kb6wh
Jun 26 13:23:38.463: INFO: Got endpoints: latency-svc-kb6wh [160.264751ms]
Jun 26 13:23:38.482: INFO: Created: latency-svc-9ztt8
Jun 26 13:23:38.483: INFO: Created: latency-svc-4ffqx
Jun 26 13:23:38.490: INFO: Created: latency-svc-g5hcb
Jun 26 13:23:38.494: INFO: Got endpoints: latency-svc-4ffqx [181.395585ms]
Jun 26 13:23:38.502: INFO: Created: latency-svc-hqwhj
Jun 26 13:23:38.511: INFO: Created: latency-svc-95dr6
Jun 26 13:23:38.517: INFO: Created: latency-svc-tvw8n
Jun 26 13:23:38.521: INFO: Created: latency-svc-qpjpw
Jun 26 13:23:38.526: INFO: Created: latency-svc-thhlt
Jun 26 13:23:38.530: INFO: Created: latency-svc-7tqtr
Jun 26 13:23:38.535: INFO: Created: latency-svc-29gsf
Jun 26 13:23:38.543: INFO: Got endpoints: latency-svc-9ztt8 [223.829064ms]
Jun 26 13:23:38.543: INFO: Created: latency-svc-vd4z6
Jun 26 13:23:38.548: INFO: Created: latency-svc-sm4d5
Jun 26 13:23:38.555: INFO: Created: latency-svc-7cwvn
Jun 26 13:23:38.564: INFO: Created: latency-svc-c6k96
Jun 26 13:23:38.568: INFO: Created: latency-svc-2lnr6
Jun 26 13:23:38.575: INFO: Created: latency-svc-ld2nd
Jun 26 13:23:38.583: INFO: Created: latency-svc-psjbc
Jun 26 13:23:38.592: INFO: Got endpoints: latency-svc-g5hcb [266.056217ms]
Jun 26 13:23:38.609: INFO: Created: latency-svc-5ftqb
Jun 26 13:23:38.642: INFO: Got endpoints: latency-svc-hqwhj [308.231459ms]
Jun 26 13:23:38.651: INFO: Created: latency-svc-n878p
Jun 26 13:23:38.692: INFO: Got endpoints: latency-svc-95dr6 [349.385105ms]
Jun 26 13:23:38.700: INFO: Created: latency-svc-w9frr
Jun 26 13:23:38.768: INFO: Got endpoints: latency-svc-tvw8n [415.269551ms]
Jun 26 13:23:38.778: INFO: Created: latency-svc-4kvhh
Jun 26 13:23:38.792: INFO: Got endpoints: latency-svc-qpjpw [421.227362ms]
Jun 26 13:23:38.800: INFO: Created: latency-svc-k6zk4
Jun 26 13:23:38.842: INFO: Got endpoints: latency-svc-thhlt [462.678847ms]
Jun 26 13:23:38.849: INFO: Created: latency-svc-ljb2v
Jun 26 13:23:38.892: INFO: Got endpoints: latency-svc-7tqtr [504.4117ms]
Jun 26 13:23:38.900: INFO: Created: latency-svc-rfm6v
Jun 26 13:23:38.942: INFO: Got endpoints: latency-svc-29gsf [545.199802ms]
Jun 26 13:23:38.953: INFO: Created: latency-svc-ntcqq
Jun 26 13:23:38.993: INFO: Got endpoints: latency-svc-vd4z6 [589.040472ms]
Jun 26 13:23:39.001: INFO: Created: latency-svc-x92fv
Jun 26 13:23:39.042: INFO: Got endpoints: latency-svc-sm4d5 [626.253254ms]
Jun 26 13:23:39.051: INFO: Created: latency-svc-g2dwk
Jun 26 13:23:39.095: INFO: Got endpoints: latency-svc-7cwvn [644.654445ms]
Jun 26 13:23:39.102: INFO: Created: latency-svc-zmxtb
Jun 26 13:23:39.142: INFO: Got endpoints: latency-svc-c6k96 [692.071507ms]
Jun 26 13:23:39.155: INFO: Created: latency-svc-ph276
Jun 26 13:23:39.191: INFO: Got endpoints: latency-svc-2lnr6 [728.13607ms]
Jun 26 13:23:39.207: INFO: Created: latency-svc-8kn2p
Jun 26 13:23:39.246: INFO: Got endpoints: latency-svc-ld2nd [752.090207ms]
Jun 26 13:23:39.255: INFO: Created: latency-svc-66kv2
Jun 26 13:23:39.292: INFO: Got endpoints: latency-svc-psjbc [749.131521ms]
Jun 26 13:23:39.302: INFO: Created: latency-svc-z9n82
Jun 26 13:23:39.343: INFO: Got endpoints: latency-svc-5ftqb [750.454819ms]
Jun 26 13:23:39.355: INFO: Created: latency-svc-lshl9
Jun 26 13:23:39.393: INFO: Got endpoints: latency-svc-n878p [750.907199ms]
Jun 26 13:23:39.409: INFO: Created: latency-svc-x7gmd
Jun 26 13:23:39.441: INFO: Got endpoints: latency-svc-w9frr [749.129529ms]
Jun 26 13:23:39.449: INFO: Created: latency-svc-8cvjc
Jun 26 13:23:39.492: INFO: Got endpoints: latency-svc-4kvhh [723.633042ms]
Jun 26 13:23:39.514: INFO: Created: latency-svc-56pb2
Jun 26 13:23:39.543: INFO: Got endpoints: latency-svc-k6zk4 [749.945049ms]
Jun 26 13:23:39.553: INFO: Created: latency-svc-c7kkh
Jun 26 13:23:39.592: INFO: Got endpoints: latency-svc-ljb2v [750.433265ms]
Jun 26 13:23:39.599: INFO: Created: latency-svc-hdbdx
Jun 26 13:23:39.644: INFO: Got endpoints: latency-svc-rfm6v [751.729273ms]
Jun 26 13:23:39.652: INFO: Created: latency-svc-rsvk5
Jun 26 13:23:39.695: INFO: Got endpoints: latency-svc-ntcqq [752.952274ms]
Jun 26 13:23:39.702: INFO: Created: latency-svc-b7g7x
Jun 26 13:23:39.742: INFO: Got endpoints: latency-svc-x92fv [748.734587ms]
Jun 26 13:23:39.751: INFO: Created: latency-svc-rcq74
Jun 26 13:23:39.792: INFO: Got endpoints: latency-svc-g2dwk [749.675114ms]
Jun 26 13:23:39.808: INFO: Created: latency-svc-hlfch
Jun 26 13:23:39.842: INFO: Got endpoints: latency-svc-zmxtb [746.697601ms]
Jun 26 13:23:39.851: INFO: Created: latency-svc-tbzwz
Jun 26 13:23:39.895: INFO: Got endpoints: latency-svc-ph276 [752.608174ms]
Jun 26 13:23:39.905: INFO: Created: latency-svc-qm49f
Jun 26 13:23:39.943: INFO: Got endpoints: latency-svc-8kn2p [751.085055ms]
Jun 26 13:23:39.954: INFO: Created: latency-svc-svn4s
Jun 26 13:23:39.993: INFO: Got endpoints: latency-svc-66kv2 [746.709957ms]
Jun 26 13:23:39.998: INFO: Created: latency-svc-6rpsj
Jun 26 13:23:40.045: INFO: Got endpoints: latency-svc-z9n82 [752.192326ms]
Jun 26 13:23:40.052: INFO: Created: latency-svc-p9j8r
Jun 26 13:23:40.095: INFO: Got endpoints: latency-svc-lshl9 [751.700387ms]
Jun 26 13:23:40.103: INFO: Created: latency-svc-grd2m
Jun 26 13:23:40.142: INFO: Got endpoints: latency-svc-x7gmd [748.970493ms]
Jun 26 13:23:40.154: INFO: Created: latency-svc-zsm4j
Jun 26 13:23:40.193: INFO: Got endpoints: latency-svc-8cvjc [751.286209ms]
Jun 26 13:23:40.203: INFO: Created: latency-svc-7fdq4
Jun 26 13:23:40.244: INFO: Got endpoints: latency-svc-56pb2 [751.151008ms]
Jun 26 13:23:40.251: INFO: Created: latency-svc-nz6cc
Jun 26 13:23:40.292: INFO: Got endpoints: latency-svc-c7kkh [749.144961ms]
Jun 26 13:23:40.307: INFO: Created: latency-svc-7cqsz
Jun 26 13:23:40.341: INFO: Got endpoints: latency-svc-hdbdx [748.882784ms]
Jun 26 13:23:40.349: INFO: Created: latency-svc-9tj9v
Jun 26 13:23:40.393: INFO: Got endpoints: latency-svc-rsvk5 [749.528025ms]
Jun 26 13:23:40.402: INFO: Created: latency-svc-xkbfg
Jun 26 13:23:40.442: INFO: Got endpoints: latency-svc-b7g7x [747.061108ms]
Jun 26 13:23:40.453: INFO: Created: latency-svc-crmf7
Jun 26 13:23:40.492: INFO: Got endpoints: latency-svc-rcq74 [750.482766ms]
Jun 26 13:23:40.506: INFO: Created: latency-svc-l24zv
Jun 26 13:23:40.543: INFO: Got endpoints: latency-svc-hlfch [751.234403ms]
Jun 26 13:23:40.555: INFO: Created: latency-svc-xknfd
Jun 26 13:23:40.593: INFO: Got endpoints: latency-svc-tbzwz [750.911122ms]
Jun 26 13:23:40.602: INFO: Created: latency-svc-2jx44
Jun 26 13:23:40.642: INFO: Got endpoints: latency-svc-qm49f [745.942449ms]
Jun 26 13:23:40.650: INFO: Created: latency-svc-4cw8b
Jun 26 13:23:40.693: INFO: Got endpoints: latency-svc-svn4s [749.908394ms]
Jun 26 13:23:40.703: INFO: Created: latency-svc-dvkkd
Jun 26 13:23:40.744: INFO: Got endpoints: latency-svc-6rpsj [751.182211ms]
Jun 26 13:23:40.757: INFO: Created: latency-svc-wbmq9
Jun 26 13:23:40.793: INFO: Got endpoints: latency-svc-p9j8r [748.168906ms]
Jun 26 13:23:40.805: INFO: Created: latency-svc-dxhlh
Jun 26 13:23:40.847: INFO: Got endpoints: latency-svc-grd2m [752.639339ms]
Jun 26 13:23:40.862: INFO: Created: latency-svc-dvd6t
Jun 26 13:23:40.896: INFO: Got endpoints: latency-svc-zsm4j [753.044612ms]
Jun 26 13:23:40.913: INFO: Created: latency-svc-57v6r
Jun 26 13:23:40.945: INFO: Got endpoints: latency-svc-7fdq4 [752.286331ms]
Jun 26 13:23:40.968: INFO: Created: latency-svc-s8sc6
Jun 26 13:23:40.998: INFO: Got endpoints: latency-svc-nz6cc [754.381317ms]
Jun 26 13:23:41.019: INFO: Created: latency-svc-qwvrs
Jun 26 13:23:41.042: INFO: Got endpoints: latency-svc-7cqsz [749.931471ms]
Jun 26 13:23:41.056: INFO: Created: latency-svc-fbj6z
Jun 26 13:23:41.093: INFO: Got endpoints: latency-svc-9tj9v [751.595883ms]
Jun 26 13:23:41.119: INFO: Created: latency-svc-kvhcx
Jun 26 13:23:41.143: INFO: Got endpoints: latency-svc-xkbfg [749.465642ms]
Jun 26 13:23:41.154: INFO: Created: latency-svc-jtrrx
Jun 26 13:23:41.194: INFO: Got endpoints: latency-svc-crmf7 [751.026833ms]
Jun 26 13:23:41.204: INFO: Created: latency-svc-hc2p8
Jun 26 13:23:41.243: INFO: Got endpoints: latency-svc-l24zv [750.297597ms]
Jun 26 13:23:41.268: INFO: Created: latency-svc-22mcq
Jun 26 13:23:41.293: INFO: Got endpoints: latency-svc-xknfd [749.840806ms]
Jun 26 13:23:41.305: INFO: Created: latency-svc-r29wc
Jun 26 13:23:41.343: INFO: Got endpoints: latency-svc-2jx44 [750.082004ms]
Jun 26 13:23:41.358: INFO: Created: latency-svc-vvt4c
Jun 26 13:23:41.392: INFO: Got endpoints: latency-svc-4cw8b [749.893378ms]
Jun 26 13:23:41.405: INFO: Created: latency-svc-67x8v
Jun 26 13:23:41.442: INFO: Got endpoints: latency-svc-dvkkd [748.97372ms]
Jun 26 13:23:41.453: INFO: Created: latency-svc-2jpjg
Jun 26 13:23:41.493: INFO: Got endpoints: latency-svc-wbmq9 [748.73201ms]
Jun 26 13:23:41.510: INFO: Created: latency-svc-dgg2d
Jun 26 13:23:41.543: INFO: Got endpoints: latency-svc-dxhlh [750.457901ms]
Jun 26 13:23:41.555: INFO: Created: latency-svc-4wblt
Jun 26 13:23:41.591: INFO: Got endpoints: latency-svc-dvd6t [743.766664ms]
Jun 26 13:23:41.601: INFO: Created: latency-svc-zqkrl
Jun 26 13:23:41.643: INFO: Got endpoints: latency-svc-57v6r [747.093791ms]
Jun 26 13:23:41.654: INFO: Created: latency-svc-k69b9
Jun 26 13:23:41.692: INFO: Got endpoints: latency-svc-s8sc6 [747.033543ms]
Jun 26 13:23:41.734: INFO: Created: latency-svc-z5mmv
Jun 26 13:23:41.744: INFO: Got endpoints: latency-svc-qwvrs [745.607978ms]
Jun 26 13:23:41.753: INFO: Created: latency-svc-z4fhp
Jun 26 13:23:41.792: INFO: Got endpoints: latency-svc-fbj6z [750.032823ms]
Jun 26 13:23:41.800: INFO: Created: latency-svc-8zfzw
Jun 26 13:23:41.843: INFO: Got endpoints: latency-svc-kvhcx [749.385321ms]
Jun 26 13:23:41.852: INFO: Created: latency-svc-qn6p9
Jun 26 13:23:41.892: INFO: Got endpoints: latency-svc-jtrrx [749.513711ms]
Jun 26 13:23:41.901: INFO: Created: latency-svc-gd6wb
Jun 26 13:23:41.941: INFO: Got endpoints: latency-svc-hc2p8 [747.152796ms]
Jun 26 13:23:41.947: INFO: Created: latency-svc-9qvq8
Jun 26 13:23:41.993: INFO: Got endpoints: latency-svc-22mcq [750.019833ms]
Jun 26 13:23:42.004: INFO: Created: latency-svc-qpl6k
Jun 26 13:23:42.043: INFO: Got endpoints: latency-svc-r29wc [749.572294ms]
Jun 26 13:23:42.051: INFO: Created: latency-svc-sktc5
Jun 26 13:23:42.092: INFO: Got endpoints: latency-svc-vvt4c [749.417496ms]
Jun 26 13:23:42.103: INFO: Created: latency-svc-gt5tq
Jun 26 13:23:42.143: INFO: Got endpoints: latency-svc-67x8v [751.337927ms]
Jun 26 13:23:42.150: INFO: Created: latency-svc-6tzlt
Jun 26 13:23:42.192: INFO: Got endpoints: latency-svc-2jpjg [750.103242ms]
Jun 26 13:23:42.198: INFO: Created: latency-svc-cckt8
Jun 26 13:23:42.241: INFO: Got endpoints: latency-svc-dgg2d [748.607266ms]
Jun 26 13:23:42.250: INFO: Created: latency-svc-bbl2m
Jun 26 13:23:42.292: INFO: Got endpoints: latency-svc-4wblt [749.075572ms]
Jun 26 13:23:42.302: INFO: Created: latency-svc-bnbb7
Jun 26 13:23:42.342: INFO: Got endpoints: latency-svc-zqkrl [750.522491ms]
Jun 26 13:23:42.356: INFO: Created: latency-svc-4whvf
Jun 26 13:23:42.393: INFO: Got endpoints: latency-svc-k69b9 [749.672889ms]
Jun 26 13:23:42.407: INFO: Created: latency-svc-p6dwr
Jun 26 13:23:42.442: INFO: Got endpoints: latency-svc-z5mmv [750.124161ms]
Jun 26 13:23:42.450: INFO: Created: latency-svc-lj7qd
Jun 26 13:23:42.495: INFO: Got endpoints: latency-svc-z4fhp [750.904471ms]
Jun 26 13:23:42.504: INFO: Created: latency-svc-lmc55
Jun 26 13:23:42.542: INFO: Got endpoints: latency-svc-8zfzw [750.318344ms]
Jun 26 13:23:42.553: INFO: Created: latency-svc-z245t
Jun 26 13:23:42.592: INFO: Got endpoints: latency-svc-qn6p9 [749.494793ms]
Jun 26 13:23:42.604: INFO: Created: latency-svc-96fvz
Jun 26 13:23:42.642: INFO: Got endpoints: latency-svc-gd6wb [749.997133ms]
Jun 26 13:23:42.651: INFO: Created: latency-svc-svc84
Jun 26 13:23:42.694: INFO: Got endpoints: latency-svc-9qvq8 [752.678959ms]
Jun 26 13:23:42.703: INFO: Created: latency-svc-kr2mg
Jun 26 13:23:42.743: INFO: Got endpoints: latency-svc-qpl6k [749.665918ms]
Jun 26 13:23:42.754: INFO: Created: latency-svc-2w65p
Jun 26 13:23:42.794: INFO: Got endpoints: latency-svc-sktc5 [751.45311ms]
Jun 26 13:23:42.801: INFO: Created: latency-svc-mmdlh
Jun 26 13:23:42.842: INFO: Got endpoints: latency-svc-gt5tq [749.738326ms]
Jun 26 13:23:42.852: INFO: Created: latency-svc-58s5k
Jun 26 13:23:42.892: INFO: Got endpoints: latency-svc-6tzlt [748.91024ms]
Jun 26 13:23:42.898: INFO: Created: latency-svc-2qsfl
Jun 26 13:23:42.942: INFO: Got endpoints: latency-svc-cckt8 [749.64954ms]
Jun 26 13:23:42.949: INFO: Created: latency-svc-cq2gw
Jun 26 13:23:42.993: INFO: Got endpoints: latency-svc-bbl2m [750.461116ms]
Jun 26 13:23:43.000: INFO: Created: latency-svc-gbzd6
Jun 26 13:23:43.042: INFO: Got endpoints: latency-svc-bnbb7 [749.238461ms]
Jun 26 13:23:43.050: INFO: Created: latency-svc-vxh2z
Jun 26 13:23:43.094: INFO: Got endpoints: latency-svc-4whvf [752.18971ms]
Jun 26 13:23:43.103: INFO: Created: latency-svc-2v7th
Jun 26 13:23:43.144: INFO: Got endpoints: latency-svc-p6dwr [751.465873ms]
Jun 26 13:23:43.155: INFO: Created: latency-svc-wqnkq
Jun 26 13:23:43.192: INFO: Got endpoints: latency-svc-lj7qd [749.258939ms]
Jun 26 13:23:43.201: INFO: Created: latency-svc-7nsb6
Jun 26 13:23:43.242: INFO: Got endpoints: latency-svc-lmc55 [747.421029ms]
Jun 26 13:23:43.250: INFO: Created: latency-svc-mbp7b
Jun 26 13:23:43.294: INFO: Got endpoints: latency-svc-z245t [751.196463ms]
Jun 26 13:23:43.302: INFO: Created: latency-svc-k7nnl
Jun 26 13:23:43.343: INFO: Got endpoints: latency-svc-96fvz [750.197738ms]
Jun 26 13:23:43.355: INFO: Created: latency-svc-dvzwx
Jun 26 13:23:43.395: INFO: Got endpoints: latency-svc-svc84 [752.446598ms]
Jun 26 13:23:43.405: INFO: Created: latency-svc-qlbws
Jun 26 13:23:43.443: INFO: Got endpoints: latency-svc-kr2mg [749.048178ms]
Jun 26 13:23:43.455: INFO: Created: latency-svc-6h4cj
Jun 26 13:23:43.493: INFO: Got endpoints: latency-svc-2w65p [750.329671ms]
Jun 26 13:23:43.514: INFO: Created: latency-svc-rjh9m
Jun 26 13:23:43.541: INFO: Got endpoints: latency-svc-mmdlh [747.387291ms]
Jun 26 13:23:43.550: INFO: Created: latency-svc-8tz5q
Jun 26 13:23:43.592: INFO: Got endpoints: latency-svc-58s5k [749.393344ms]
Jun 26 13:23:43.599: INFO: Created: latency-svc-zptsc
Jun 26 13:23:43.642: INFO: Got endpoints: latency-svc-2qsfl [749.711974ms]
Jun 26 13:23:43.649: INFO: Created: latency-svc-tl6lc
Jun 26 13:23:43.693: INFO: Got endpoints: latency-svc-cq2gw [751.23792ms]
Jun 26 13:23:43.702: INFO: Created: latency-svc-ttkr7
Jun 26 13:23:43.741: INFO: Got endpoints: latency-svc-gbzd6 [748.153747ms]
Jun 26 13:23:43.751: INFO: Created: latency-svc-fgbcl
Jun 26 13:23:43.792: INFO: Got endpoints: latency-svc-vxh2z [750.201754ms]
Jun 26 13:23:43.799: INFO: Created: latency-svc-b24rj
Jun 26 13:23:43.842: INFO: Got endpoints: latency-svc-2v7th [747.430832ms]
Jun 26 13:23:43.850: INFO: Created: latency-svc-jqbfh
Jun 26 13:23:43.892: INFO: Got endpoints: latency-svc-wqnkq [747.498868ms]
Jun 26 13:23:43.899: INFO: Created: latency-svc-qpg8s
Jun 26 13:23:43.943: INFO: Got endpoints: latency-svc-7nsb6 [749.382285ms]
Jun 26 13:23:43.953: INFO: Created: latency-svc-7c5xw
Jun 26 13:23:43.994: INFO: Got endpoints: latency-svc-mbp7b [751.027711ms]
Jun 26 13:23:44.002: INFO: Created: latency-svc-lbsqd
Jun 26 13:23:44.044: INFO: Got endpoints: latency-svc-k7nnl [750.266028ms]
Jun 26 13:23:44.056: INFO: Created: latency-svc-727jv
Jun 26 13:23:44.094: INFO: Got endpoints: latency-svc-dvzwx [751.423573ms]
Jun 26 13:23:44.102: INFO: Created: latency-svc-bclmr
Jun 26 13:23:44.142: INFO: Got endpoints: latency-svc-qlbws [746.986435ms]
Jun 26 13:23:44.151: INFO: Created: latency-svc-vwgj8
Jun 26 13:23:44.193: INFO: Got endpoints: latency-svc-6h4cj [749.857284ms]
Jun 26 13:23:44.208: INFO: Created: latency-svc-7rbgw
Jun 26 13:23:44.243: INFO: Got endpoints: latency-svc-rjh9m [749.525341ms]
Jun 26 13:23:44.253: INFO: Created: latency-svc-ddj4r
Jun 26 13:23:44.293: INFO: Got endpoints: latency-svc-8tz5q [751.018618ms]
Jun 26 13:23:44.303: INFO: Created: latency-svc-hf7d8
Jun 26 13:23:44.344: INFO: Got endpoints: latency-svc-zptsc [751.781908ms]
Jun 26 13:23:44.352: INFO: Created: latency-svc-72jff
Jun 26 13:23:44.393: INFO: Got endpoints: latency-svc-tl6lc [750.773546ms]
Jun 26 13:23:44.401: INFO: Created: latency-svc-bpltl
Jun 26 13:23:44.442: INFO: Got endpoints: latency-svc-ttkr7 [749.067065ms]
Jun 26 13:23:44.451: INFO: Created: latency-svc-99fb5
Jun 26 13:23:44.493: INFO: Got endpoints: latency-svc-fgbcl [752.066529ms]
Jun 26 13:23:44.505: INFO: Created: latency-svc-wnbf5
Jun 26 13:23:44.543: INFO: Got endpoints: latency-svc-b24rj [750.803127ms]
Jun 26 13:23:44.554: INFO: Created: latency-svc-vhm2p
Jun 26 13:23:44.593: INFO: Got endpoints: latency-svc-jqbfh [751.091415ms]
Jun 26 13:23:44.601: INFO: Created: latency-svc-ffkpx
Jun 26 13:23:44.642: INFO: Got endpoints: latency-svc-qpg8s [749.771765ms]
Jun 26 13:23:44.651: INFO: Created: latency-svc-nr8hr
Jun 26 13:23:44.694: INFO: Got endpoints: latency-svc-7c5xw [750.646459ms]
Jun 26 13:23:44.701: INFO: Created: latency-svc-28tb6
Jun 26 13:23:44.743: INFO: Got endpoints: latency-svc-lbsqd [749.456964ms]
Jun 26 13:23:44.755: INFO: Created: latency-svc-xlbtg
Jun 26 13:23:44.793: INFO: Got endpoints: latency-svc-727jv [749.322464ms]
Jun 26 13:23:44.800: INFO: Created: latency-svc-9f77q
Jun 26 13:23:44.843: INFO: Got endpoints: latency-svc-bclmr [749.344762ms]
Jun 26 13:23:44.853: INFO: Created: latency-svc-5qf79
Jun 26 13:23:44.892: INFO: Got endpoints: latency-svc-vwgj8 [749.893234ms]
Jun 26 13:23:44.903: INFO: Created: latency-svc-fnqsd
Jun 26 13:23:44.941: INFO: Got endpoints: latency-svc-7rbgw [748.452182ms]
Jun 26 13:23:44.958: INFO: Created: latency-svc-68p9d
Jun 26 13:23:44.991: INFO: Got endpoints: latency-svc-ddj4r [748.424752ms]
Jun 26 13:23:45.000: INFO: Created: latency-svc-p6jdt
Jun 26 13:23:45.042: INFO: Got endpoints: latency-svc-hf7d8 [749.351414ms]
Jun 26 13:23:45.051: INFO: Created: latency-svc-msv67
Jun 26 13:23:45.093: INFO: Got endpoints: latency-svc-72jff [749.625277ms]
Jun 26 13:23:45.100: INFO: Created: latency-svc-8qwhd
Jun 26 13:23:45.144: INFO: Got endpoints: latency-svc-bpltl [751.251004ms]
Jun 26 13:23:45.156: INFO: Created: latency-svc-bzv6s
Jun 26 13:23:45.191: INFO: Got endpoints: latency-svc-99fb5 [748.115413ms]
Jun 26 13:23:45.199: INFO: Created: latency-svc-nnj7d
Jun 26 13:23:45.243: INFO: Got endpoints: latency-svc-wnbf5 [749.314576ms]
Jun 26 13:23:45.249: INFO: Created: latency-svc-qgdrb
Jun 26 13:23:45.293: INFO: Got endpoints: latency-svc-vhm2p [749.948525ms]
Jun 26 13:23:45.302: INFO: Created: latency-svc-j9d94
Jun 26 13:23:45.343: INFO: Got endpoints: latency-svc-ffkpx [749.984649ms]
Jun 26 13:23:45.355: INFO: Created: latency-svc-6wdqg
Jun 26 13:23:45.392: INFO: Got endpoints: latency-svc-nr8hr [749.833949ms]
Jun 26 13:23:45.399: INFO: Created: latency-svc-q4hrj
Jun 26 13:23:45.441: INFO: Got endpoints: latency-svc-28tb6 [747.447219ms]
Jun 26 13:23:45.449: INFO: Created: latency-svc-cswx7
Jun 26 13:23:45.495: INFO: Got endpoints: latency-svc-xlbtg [752.101382ms]
Jun 26 13:23:45.525: INFO: Created: latency-svc-xsxc2
Jun 26 13:23:45.546: INFO: Got endpoints: latency-svc-9f77q [752.843264ms]
Jun 26 13:23:45.556: INFO: Created: latency-svc-bwhwk
Jun 26 13:23:45.592: INFO: Got endpoints: latency-svc-5qf79 [748.54404ms]
Jun 26 13:23:45.601: INFO: Created: latency-svc-d65lb
Jun 26 13:23:45.642: INFO: Got endpoints: latency-svc-fnqsd [749.823206ms]
Jun 26 13:23:45.651: INFO: Created: latency-svc-w5r8m
Jun 26 13:23:45.693: INFO: Got endpoints: latency-svc-68p9d [751.356647ms]
Jun 26 13:23:45.701: INFO: Created: latency-svc-brvg4
Jun 26 13:23:45.742: INFO: Got endpoints: latency-svc-p6jdt [750.78573ms]
Jun 26 13:23:45.751: INFO: Created: latency-svc-btbwx
Jun 26 13:23:45.793: INFO: Got endpoints: latency-svc-msv67 [750.368362ms]
Jun 26 13:23:45.801: INFO: Created: latency-svc-8tffd
Jun 26 13:23:45.845: INFO: Got endpoints: latency-svc-8qwhd [751.431832ms]
Jun 26 13:23:45.856: INFO: Created: latency-svc-q44sx
Jun 26 13:23:45.893: INFO: Got endpoints: latency-svc-bzv6s [748.240842ms]
Jun 26 13:23:45.945: INFO: Got endpoints: latency-svc-nnj7d [753.132542ms]
Jun 26 13:23:45.992: INFO: Got endpoints: latency-svc-qgdrb [748.56823ms]
Jun 26 13:23:46.046: INFO: Got endpoints: latency-svc-j9d94 [752.138642ms]
Jun 26 13:23:46.095: INFO: Got endpoints: latency-svc-6wdqg [750.518024ms]
Jun 26 13:23:46.143: INFO: Got endpoints: latency-svc-q4hrj [750.8742ms]
Jun 26 13:23:46.193: INFO: Got endpoints: latency-svc-cswx7 [750.579683ms]
Jun 26 13:23:46.245: INFO: Got endpoints: latency-svc-xsxc2 [748.982786ms]
Jun 26 13:23:46.292: INFO: Got endpoints: latency-svc-bwhwk [745.509892ms]
Jun 26 13:23:46.343: INFO: Got endpoints: latency-svc-d65lb [750.543632ms]
Jun 26 13:23:46.397: INFO: Got endpoints: latency-svc-w5r8m [754.939644ms]
Jun 26 13:23:46.443: INFO: Got endpoints: latency-svc-brvg4 [749.371562ms]
Jun 26 13:23:46.493: INFO: Got endpoints: latency-svc-btbwx [749.603192ms]
Jun 26 13:23:46.545: INFO: Got endpoints: latency-svc-8tffd [751.388506ms]
Jun 26 13:23:46.593: INFO: Got endpoints: latency-svc-q44sx [748.046266ms]
Jun 26 13:23:46.594: INFO: Latencies: [27.28513ms 41.84266ms 49.392753ms 62.731346ms 71.691202ms 80.973495ms 92.764952ms 119.84235ms 125.006424ms 131.875293ms 134.23511ms 138.250503ms 139.574611ms 140.195098ms 141.073665ms 141.317552ms 141.410188ms 142.024322ms 142.672237ms 142.873234ms 142.937751ms 143.704216ms 144.773232ms 149.293058ms 153.282629ms 158.817464ms 159.717509ms 160.264751ms 160.58019ms 162.351703ms 163.417344ms 164.554074ms 165.192454ms 167.717687ms 168.775351ms 179.333605ms 181.395585ms 183.753706ms 223.829064ms 266.056217ms 308.231459ms 349.385105ms 415.269551ms 421.227362ms 462.678847ms 504.4117ms 545.199802ms 589.040472ms 626.253254ms 644.654445ms 692.071507ms 723.633042ms 728.13607ms 743.766664ms 745.509892ms 745.607978ms 745.942449ms 746.697601ms 746.709957ms 746.986435ms 747.033543ms 747.061108ms 747.093791ms 747.152796ms 747.387291ms 747.421029ms 747.430832ms 747.447219ms 747.498868ms 748.046266ms 748.115413ms 748.153747ms 748.168906ms 748.240842ms 748.424752ms 748.452182ms 748.54404ms 748.56823ms 748.607266ms 748.73201ms 748.734587ms 748.882784ms 748.91024ms 748.970493ms 748.97372ms 748.982786ms 749.048178ms 749.067065ms 749.075572ms 749.129529ms 749.131521ms 749.144961ms 749.238461ms 749.258939ms 749.314576ms 749.322464ms 749.344762ms 749.351414ms 749.371562ms 749.382285ms 749.385321ms 749.393344ms 749.417496ms 749.456964ms 749.465642ms 749.494793ms 749.513711ms 749.525341ms 749.528025ms 749.572294ms 749.603192ms 749.625277ms 749.64954ms 749.665918ms 749.672889ms 749.675114ms 749.711974ms 749.738326ms 749.771765ms 749.823206ms 749.833949ms 749.840806ms 749.857284ms 749.893234ms 749.893378ms 749.908394ms 749.931471ms 749.945049ms 749.948525ms 749.984649ms 749.997133ms 750.019833ms 750.032823ms 750.082004ms 750.103242ms 750.124161ms 750.197738ms 750.201754ms 750.266028ms 750.297597ms 750.318344ms 750.329671ms 750.368362ms 750.433265ms 750.454819ms 750.457901ms 750.461116ms 750.482766ms 750.518024ms 750.522491ms 750.543632ms 750.579683ms 750.646459ms 750.773546ms 750.78573ms 750.803127ms 750.8742ms 750.904471ms 750.907199ms 750.911122ms 751.018618ms 751.026833ms 751.027711ms 751.085055ms 751.091415ms 751.151008ms 751.182211ms 751.196463ms 751.234403ms 751.23792ms 751.251004ms 751.286209ms 751.337927ms 751.356647ms 751.388506ms 751.423573ms 751.431832ms 751.45311ms 751.465873ms 751.595883ms 751.700387ms 751.729273ms 751.781908ms 752.066529ms 752.090207ms 752.101382ms 752.138642ms 752.18971ms 752.192326ms 752.286331ms 752.446598ms 752.608174ms 752.639339ms 752.678959ms 752.843264ms 752.952274ms 753.044612ms 753.132542ms 754.381317ms 754.939644ms]
Jun 26 13:23:46.594: INFO: 50 %ile: 749.385321ms
Jun 26 13:23:46.594: INFO: 90 %ile: 751.700387ms
Jun 26 13:23:46.594: INFO: 99 %ile: 754.381317ms
Jun 26 13:23:46.594: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:46.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1446" for this suite.

• [SLOW TEST:10.775 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","total":276,"completed":59,"skipped":1014,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:46.603: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-7e60ded0-91c1-47bb-a22d-a12107dff73e
STEP: Creating a pod to test consume secrets
Jun 26 13:23:46.635: INFO: Waiting up to 5m0s for pod "pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f" in namespace "secrets-9035" to be "Succeeded or Failed"
Jun 26 13:23:46.637: INFO: Pod "pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.200247ms
Jun 26 13:23:48.641: INFO: Pod "pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006483254s
Jun 26 13:23:50.646: INFO: Pod "pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011155984s
STEP: Saw pod success
Jun 26 13:23:50.646: INFO: Pod "pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f" satisfied condition "Succeeded or Failed"
Jun 26 13:23:50.649: INFO: Trying to get logs from node docker-desktop pod pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:23:50.669: INFO: Waiting for pod pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f to disappear
Jun 26 13:23:50.672: INFO: Pod pod-secrets-c92a2831-1670-4528-bf9a-ed3e4b568f1f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:50.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9035" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","total":276,"completed":60,"skipped":1038,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:50.679: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Jun 26 13:23:52.732: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-7989 PodName:pod-sharedvolume-136def5e-1faa-442d-8bef-114ea79eb771 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:23:52.732: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:23:52.898: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:52.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7989" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","total":276,"completed":61,"skipped":1052,"failed":0}
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:52.910: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 26 13:23:54.958: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:23:54.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2811" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","total":276,"completed":62,"skipped":1054,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:23:54.986: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:23:55.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-779fdc84d9\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:23:57.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728774635, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:24:00.965: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Jun 26 13:24:00.981: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:00.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-11" for this suite.
STEP: Destroying namespace "webhook-11-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.040 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","total":276,"completed":63,"skipped":1066,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:01.027: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 26 13:24:01.060: INFO: Waiting up to 5m0s for pod "pod-2b1473b1-545c-49b2-a859-4baa474b9b08" in namespace "emptydir-5355" to be "Succeeded or Failed"
Jun 26 13:24:01.072: INFO: Pod "pod-2b1473b1-545c-49b2-a859-4baa474b9b08": Phase="Pending", Reason="", readiness=false. Elapsed: 11.781992ms
Jun 26 13:24:03.074: INFO: Pod "pod-2b1473b1-545c-49b2-a859-4baa474b9b08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014085091s
STEP: Saw pod success
Jun 26 13:24:03.074: INFO: Pod "pod-2b1473b1-545c-49b2-a859-4baa474b9b08" satisfied condition "Succeeded or Failed"
Jun 26 13:24:03.076: INFO: Trying to get logs from node docker-desktop pod pod-2b1473b1-545c-49b2-a859-4baa474b9b08 container test-container: <nil>
STEP: delete the pod
Jun 26 13:24:03.090: INFO: Waiting for pod pod-2b1473b1-545c-49b2-a859-4baa474b9b08 to disappear
Jun 26 13:24:03.096: INFO: Pod pod-2b1473b1-545c-49b2-a859-4baa474b9b08 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:03.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5355" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":64,"skipped":1081,"failed":0}
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:03.107: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 26 13:24:03.146: INFO: Number of nodes with available pods: 0
Jun 26 13:24:03.146: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:04.153: INFO: Number of nodes with available pods: 0
Jun 26 13:24:04.153: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:05.155: INFO: Number of nodes with available pods: 1
Jun 26 13:24:05.155: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 26 13:24:05.167: INFO: Number of nodes with available pods: 0
Jun 26 13:24:05.167: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:06.171: INFO: Number of nodes with available pods: 0
Jun 26 13:24:06.172: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:07.172: INFO: Number of nodes with available pods: 0
Jun 26 13:24:07.172: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:08.171: INFO: Number of nodes with available pods: 0
Jun 26 13:24:08.171: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:09.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:09.173: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:10.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:10.173: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:11.175: INFO: Number of nodes with available pods: 0
Jun 26 13:24:11.175: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:12.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:12.174: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:13.172: INFO: Number of nodes with available pods: 0
Jun 26 13:24:13.172: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:14.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:14.174: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:15.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:15.173: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:16.175: INFO: Number of nodes with available pods: 0
Jun 26 13:24:16.175: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:17.174: INFO: Number of nodes with available pods: 0
Jun 26 13:24:17.174: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:18.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:18.173: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:19.175: INFO: Number of nodes with available pods: 0
Jun 26 13:24:19.175: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:20.173: INFO: Number of nodes with available pods: 0
Jun 26 13:24:20.173: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:21.176: INFO: Number of nodes with available pods: 0
Jun 26 13:24:21.176: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:24:22.174: INFO: Number of nodes with available pods: 1
Jun 26 13:24:22.174: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1471, will wait for the garbage collector to delete the pods
Jun 26 13:24:22.236: INFO: Deleting DaemonSet.extensions daemon-set took: 6.066112ms
Jun 26 13:24:22.736: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.663693ms
Jun 26 13:24:29.542: INFO: Number of nodes with available pods: 0
Jun 26 13:24:29.542: INFO: Number of running nodes: 0, number of available pods: 0
Jun 26 13:24:29.544: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1471/daemonsets","resourceVersion":"11879"},"items":null}

Jun 26 13:24:29.546: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1471/pods","resourceVersion":"11879"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:29.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1471" for this suite.

• [SLOW TEST:26.450 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","total":276,"completed":65,"skipped":1086,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:29.560: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:24:29.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd" in namespace "projected-8793" to be "Succeeded or Failed"
Jun 26 13:24:29.587: INFO: Pod "downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009135ms
Jun 26 13:24:31.591: INFO: Pod "downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005406814s
STEP: Saw pod success
Jun 26 13:24:31.591: INFO: Pod "downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd" satisfied condition "Succeeded or Failed"
Jun 26 13:24:31.593: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd container client-container: <nil>
STEP: delete the pod
Jun 26 13:24:31.608: INFO: Waiting for pod downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd to disappear
Jun 26 13:24:31.612: INFO: Pod downwardapi-volume-08bf9675-535e-41e9-bebd-44d801e2c3fd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:31.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8793" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","total":276,"completed":66,"skipped":1097,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:31.622: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service nodeport-test with type=NodePort in namespace services-5719
STEP: creating replication controller nodeport-test in namespace services-5719
I0626 13:24:31.661752      24 runners.go:190] Created replication controller with name: nodeport-test, namespace: services-5719, replica count: 2
Jun 26 13:24:34.712: INFO: Creating new exec pod
I0626 13:24:34.712842      24 runners.go:190] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 26 13:24:39.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-5719 execpodh462q -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Jun 26 13:24:39.999: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jun 26 13:24:39.999: INFO: stdout: ""
Jun 26 13:24:40.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-5719 execpodh462q -- /bin/sh -x -c nc -zv -t -w 2 10.99.153.156 80'
Jun 26 13:24:40.153: INFO: stderr: "+ nc -zv -t -w 2 10.99.153.156 80\nConnection to 10.99.153.156 80 port [tcp/http] succeeded!\n"
Jun 26 13:24:40.153: INFO: stdout: ""
Jun 26 13:24:40.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=services-5719 execpodh462q -- /bin/sh -x -c nc -zv -t -w 2 192.168.65.3 30396'
Jun 26 13:24:40.306: INFO: stderr: "+ nc -zv -t -w 2 192.168.65.3 30396\nConnection to 192.168.65.3 30396 port [tcp/30396] succeeded!\n"
Jun 26 13:24:40.306: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:40.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5719" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:8.693 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","total":276,"completed":67,"skipped":1150,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:40.315: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name projected-secret-test-4df03d83-2eb2-4fd8-8529-837e340229f3
STEP: Creating a pod to test consume secrets
Jun 26 13:24:40.342: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be" in namespace "projected-8812" to be "Succeeded or Failed"
Jun 26 13:24:40.345: INFO: Pod "pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.886023ms
Jun 26 13:24:42.350: INFO: Pod "pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007744857s
STEP: Saw pod success
Jun 26 13:24:42.350: INFO: Pod "pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be" satisfied condition "Succeeded or Failed"
Jun 26 13:24:42.352: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:24:42.371: INFO: Waiting for pod pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be to disappear
Jun 26 13:24:42.376: INFO: Pod pod-projected-secrets-19dc2df1-c6de-4d7f-a8a6-feb3d9b2c9be no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:42.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8812" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":276,"completed":68,"skipped":1168,"failed":0}
S
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:42.382: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:24:42.408: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121" in namespace "security-context-test-3951" to be "Succeeded or Failed"
Jun 26 13:24:42.413: INFO: Pod "busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121": Phase="Pending", Reason="", readiness=false. Elapsed: 5.070926ms
Jun 26 13:24:44.417: INFO: Pod "busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009115745s
Jun 26 13:24:44.417: INFO: Pod "busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121" satisfied condition "Succeeded or Failed"
Jun 26 13:24:44.424: INFO: Got logs for pod "busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:44.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3951" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":69,"skipped":1169,"failed":0}
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:44.432: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Jun 26 13:24:44.456: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 26 13:24:44.465: INFO: Waiting for terminating namespaces to be deleted...
Jun 26 13:24:44.467: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Jun 26 13:24:44.474: INFO: sonobuoy from sonobuoy started at 2020-06-26 13:00:36 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.474: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 26 13:24:44.474: INFO: nodeport-test-hj786 from services-5719 started at 2020-06-26 13:24:31 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.474: INFO: 	Container nodeport-test ready: true, restart count 0
Jun 26 13:24:44.474: INFO: busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121 from security-context-test-3951 started at 2020-06-26 13:24:42 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.474: INFO: 	Container busybox-privileged-false-3c514295-e212-454f-9ad6-8e6b201ec121 ready: false, restart count 0
Jun 26 13:24:44.475: INFO: kube-controller-manager-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.475: INFO: 	Container kube-controller-manager ready: true, restart count 0
Jun 26 13:24:44.475: INFO: sonobuoy-e2e-job-ad77c8f3bad64e56 from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:24:44.475: INFO: 	Container e2e ready: true, restart count 0
Jun 26 13:24:44.475: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:24:44.475: INFO: sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:24:44.475: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:24:44.475: INFO: 	Container systemd-logs ready: false, restart count 9
Jun 26 13:24:44.475: INFO: compose-api-767cd94f6-wd2l9 from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.475: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:24:44.475: INFO: coredns-66bff467f8-rcx2v from kube-system started at 2020-06-26 13:13:08 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.476: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:24:44.476: INFO: coredns-66bff467f8-dfrnp from kube-system started at 2020-06-26 13:13:09 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.476: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:24:44.476: INFO: kube-proxy-tzb5b from kube-system started at 2020-06-26 12:48:45 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.476: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 26 13:24:44.476: INFO: nodeport-test-mhbgm from services-5719 started at 2020-06-26 13:24:31 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.476: INFO: 	Container nodeport-test ready: true, restart count 0
Jun 26 13:24:44.476: INFO: compose-858b8f86cc-tx2ld from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.476: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:24:44.477: INFO: kube-apiserver-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.477: INFO: 	Container kube-apiserver ready: true, restart count 0
Jun 26 13:24:44.477: INFO: kube-scheduler-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.477: INFO: 	Container kube-scheduler ready: true, restart count 0
Jun 26 13:24:44.477: INFO: etcd-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.477: INFO: 	Container etcd ready: true, restart count 0
Jun 26 13:24:44.477: INFO: execpodh462q from services-5719 started at 2020-06-26 13:24:34 +0000 UTC (1 container statuses recorded)
Jun 26 13:24:44.477: INFO: 	Container agnhost-pause ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-fa3562df-1f41-4b98-9f49-6d4cb6c494d4 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-fa3562df-1f41-4b98-9f49-6d4cb6c494d4 off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-fa3562df-1f41-4b98-9f49-6d4cb6c494d4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:24:48.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2915" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","total":276,"completed":70,"skipped":1170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:24:48.546: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-6128
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Jun 26 13:24:48.575: INFO: Found 0 stateful pods, waiting for 3
Jun 26 13:24:58.581: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:24:58.581: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:24:58.581: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Jun 26 13:24:58.606: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 26 13:25:08.635: INFO: Updating stateful set ss2
Jun 26 13:25:08.647: INFO: Waiting for Pod statefulset-6128/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:25:18.656: INFO: Waiting for Pod statefulset-6128/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Jun 26 13:25:28.708: INFO: Found 2 stateful pods, waiting for 3
Jun 26 13:25:38.726: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:25:38.726: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:25:38.726: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 26 13:25:38.749: INFO: Updating stateful set ss2
Jun 26 13:25:38.770: INFO: Waiting for Pod statefulset-6128/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:25:48.795: INFO: Updating stateful set ss2
Jun 26 13:25:48.803: INFO: Waiting for StatefulSet statefulset-6128/ss2 to complete update
Jun 26 13:25:48.804: INFO: Waiting for Pod statefulset-6128/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:25:58.811: INFO: Deleting all statefulset in ns statefulset-6128
Jun 26 13:25:58.814: INFO: Scaling statefulset ss2 to 0
Jun 26 13:26:18.827: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:26:18.829: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:18.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6128" for this suite.

• [SLOW TEST:90.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","total":276,"completed":71,"skipped":1204,"failed":0}
SSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:18.852: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:26:18.878: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:21.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8722" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","total":276,"completed":72,"skipped":1210,"failed":0}
SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:21.009: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-f939caf3-43da-44e0-8890-27420127d996
STEP: Creating a pod to test consume secrets
Jun 26 13:26:21.046: INFO: Waiting up to 5m0s for pod "pod-secrets-203ac650-f839-460b-9eec-78eacfd54835" in namespace "secrets-6841" to be "Succeeded or Failed"
Jun 26 13:26:21.048: INFO: Pod "pod-secrets-203ac650-f839-460b-9eec-78eacfd54835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.212691ms
Jun 26 13:26:23.052: INFO: Pod "pod-secrets-203ac650-f839-460b-9eec-78eacfd54835": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006368307s
Jun 26 13:26:25.058: INFO: Pod "pod-secrets-203ac650-f839-460b-9eec-78eacfd54835": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011586466s
STEP: Saw pod success
Jun 26 13:26:25.058: INFO: Pod "pod-secrets-203ac650-f839-460b-9eec-78eacfd54835" satisfied condition "Succeeded or Failed"
Jun 26 13:26:25.060: INFO: Trying to get logs from node docker-desktop pod pod-secrets-203ac650-f839-460b-9eec-78eacfd54835 container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:26:25.081: INFO: Waiting for pod pod-secrets-203ac650-f839-460b-9eec-78eacfd54835 to disappear
Jun 26 13:26:25.083: INFO: Pod pod-secrets-203ac650-f839-460b-9eec-78eacfd54835 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:25.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6841" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","total":276,"completed":73,"skipped":1216,"failed":0}
SSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:25.087: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating pod
Jun 26 13:26:27.115: INFO: Pod pod-hostip-f73be209-13f8-48d6-9f74-2723e49f2329 has hostIP: 192.168.65.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:27.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5371" for this suite.
•{"msg":"PASSED [k8s.io] Pods should get a host IP [NodeConformance] [Conformance]","total":276,"completed":74,"skipped":1220,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:27.121: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Jun 26 13:26:27.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-3936'
Jun 26 13:26:27.348: INFO: stderr: ""
Jun 26 13:26:27.348: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 26 13:26:27.348: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3936'
Jun 26 13:26:27.434: INFO: stderr: ""
Jun 26 13:26:27.434: INFO: stdout: "update-demo-nautilus-7gkh5 update-demo-nautilus-ztbjr "
Jun 26 13:26:27.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-7gkh5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3936'
Jun 26 13:26:27.512: INFO: stderr: ""
Jun 26 13:26:27.512: INFO: stdout: ""
Jun 26 13:26:27.512: INFO: update-demo-nautilus-7gkh5 is created but not running
Jun 26 13:26:32.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3936'
Jun 26 13:26:32.603: INFO: stderr: ""
Jun 26 13:26:32.603: INFO: stdout: "update-demo-nautilus-7gkh5 update-demo-nautilus-ztbjr "
Jun 26 13:26:32.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-7gkh5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3936'
Jun 26 13:26:32.682: INFO: stderr: ""
Jun 26 13:26:32.682: INFO: stdout: "true"
Jun 26 13:26:32.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-7gkh5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3936'
Jun 26 13:26:32.770: INFO: stderr: ""
Jun 26 13:26:32.770: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 13:26:32.770: INFO: validating pod update-demo-nautilus-7gkh5
Jun 26 13:26:32.773: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 13:26:32.773: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 13:26:32.773: INFO: update-demo-nautilus-7gkh5 is verified up and running
Jun 26 13:26:32.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-ztbjr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3936'
Jun 26 13:26:32.847: INFO: stderr: ""
Jun 26 13:26:32.847: INFO: stdout: "true"
Jun 26 13:26:32.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-ztbjr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3936'
Jun 26 13:26:32.919: INFO: stderr: ""
Jun 26 13:26:32.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 13:26:32.919: INFO: validating pod update-demo-nautilus-ztbjr
Jun 26 13:26:32.922: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 13:26:32.922: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 13:26:32.922: INFO: update-demo-nautilus-ztbjr is verified up and running
STEP: using delete to clean up resources
Jun 26 13:26:32.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-3936'
Jun 26 13:26:33.002: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:26:33.002: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 26 13:26:33.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3936'
Jun 26 13:26:33.122: INFO: stderr: "No resources found in kubectl-3936 namespace.\n"
Jun 26 13:26:33.122: INFO: stdout: ""
Jun 26 13:26:33.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -l name=update-demo --namespace=kubectl-3936 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 26 13:26:33.237: INFO: stderr: ""
Jun 26 13:26:33.237: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:33.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3936" for this suite.

• [SLOW TEST:6.124 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","total":276,"completed":75,"skipped":1224,"failed":0}
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:33.246: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:26:33.276: INFO: Waiting up to 5m0s for pod "busybox-user-65534-0c83255c-be88-4612-ae68-0bf80188e373" in namespace "security-context-test-7408" to be "Succeeded or Failed"
Jun 26 13:26:33.278: INFO: Pod "busybox-user-65534-0c83255c-be88-4612-ae68-0bf80188e373": Phase="Pending", Reason="", readiness=false. Elapsed: 2.481457ms
Jun 26 13:26:35.282: INFO: Pod "busybox-user-65534-0c83255c-be88-4612-ae68-0bf80188e373": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006602136s
Jun 26 13:26:35.282: INFO: Pod "busybox-user-65534-0c83255c-be88-4612-ae68-0bf80188e373" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:35.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7408" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":76,"skipped":1237,"failed":0}
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:35.295: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 26 13:26:39.363: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 26 13:26:39.366: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 26 13:26:41.366: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 26 13:26:41.371: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 26 13:26:43.367: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 26 13:26:43.370: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:43.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3508" for this suite.

• [SLOW TEST:8.083 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","total":276,"completed":77,"skipped":1242,"failed":0}
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:43.378: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: validating api versions
Jun 26 13:26:43.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 api-versions'
Jun 26 13:26:43.496: INFO: stderr: ""
Jun 26 13:26:43.496: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncompose.docker.com/v1alpha3\ncompose.docker.com/v1beta1\ncompose.docker.com/v1beta2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndiscovery.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:43.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1835" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","total":276,"completed":78,"skipped":1249,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:43.504: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:26:43.541: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6" in namespace "downward-api-8341" to be "Succeeded or Failed"
Jun 26 13:26:43.545: INFO: Pod "downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.596226ms
Jun 26 13:26:45.547: INFO: Pod "downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006198168s
STEP: Saw pod success
Jun 26 13:26:45.547: INFO: Pod "downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6" satisfied condition "Succeeded or Failed"
Jun 26 13:26:45.549: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6 container client-container: <nil>
STEP: delete the pod
Jun 26 13:26:45.564: INFO: Waiting for pod downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6 to disappear
Jun 26 13:26:45.566: INFO: Pod downwardapi-volume-2ed39eb4-938e-4ef1-8fa8-b41b85382ed6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:45.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8341" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":276,"completed":79,"skipped":1264,"failed":0}
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:45.573: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-966e58a5-87a6-4ddc-8426-144bbb0e678c
STEP: Creating configMap with name cm-test-opt-upd-6e0429df-485d-4bcc-9c1b-6dd86f91294a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-966e58a5-87a6-4ddc-8426-144bbb0e678c
STEP: Updating configmap cm-test-opt-upd-6e0429df-485d-4bcc-9c1b-6dd86f91294a
STEP: Creating configMap with name cm-test-opt-create-bcf1470a-b358-4770-a472-7bd5ff63f3c0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:49.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6349" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":80,"skipped":1272,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:49.693: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-53e5f672-3538-40fa-ba4d-3d592c088cb8
STEP: Creating a pod to test consume configMaps
Jun 26 13:26:49.719: INFO: Waiting up to 5m0s for pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141" in namespace "configmap-3137" to be "Succeeded or Failed"
Jun 26 13:26:49.722: INFO: Pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541073ms
Jun 26 13:26:51.725: INFO: Pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005937077s
Jun 26 13:26:53.730: INFO: Pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010169705s
Jun 26 13:26:55.733: INFO: Pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013543586s
STEP: Saw pod success
Jun 26 13:26:55.733: INFO: Pod "pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141" satisfied condition "Succeeded or Failed"
Jun 26 13:26:55.735: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:26:55.753: INFO: Waiting for pod pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141 to disappear
Jun 26 13:26:55.755: INFO: Pod pod-configmaps-643e0b75-4ca5-4b9b-ad4f-2165e0d1a141 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:26:55.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3137" for this suite.

• [SLOW TEST:6.069 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":276,"completed":81,"skipped":1293,"failed":0}
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:26:55.762: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:26:55.791: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun 26 13:27:00.800: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 26 13:27:00.800: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Jun 26 13:27:02.843: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-6847 /apis/apps/v1/namespaces/deployment-6847/deployments/test-cleanup-deployment 5d1313e3-2b7d-49c4-8e6f-bce030e2412d 13094 1 2020-06-26 13:27:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  [{e2e.test Update apps/v1 2020-06-26 13:27:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 13:27:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b78e38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-26 13:27:00 +0000 UTC,LastTransitionTime:2020-06-26 13:27:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-b4867b47f" has successfully progressed.,LastUpdateTime:2020-06-26 13:27:02 +0000 UTC,LastTransitionTime:2020-06-26 13:27:00 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jun 26 13:27:02.845: INFO: New ReplicaSet "test-cleanup-deployment-b4867b47f" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-b4867b47f  deployment-6847 /apis/apps/v1/namespaces/deployment-6847/replicasets/test-cleanup-deployment-b4867b47f 13149257-bcf1-4c5b-8b31-122ea9c2423b 13083 1 2020-06-26 13:27:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 5d1313e3-2b7d-49c4-8e6f-bce030e2412d 0xc002b796d0 0xc002b796d1}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:27:02 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 100 49 51 49 51 101 51 45 50 98 55 100 45 52 57 99 52 45 56 101 54 102 45 98 99 101 48 51 48 101 50 52 49 50 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: b4867b47f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b79818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:27:02.848: INFO: Pod "test-cleanup-deployment-b4867b47f-mlz4w" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-b4867b47f-mlz4w test-cleanup-deployment-b4867b47f- deployment-6847 /api/v1/namespaces/deployment-6847/pods/test-cleanup-deployment-b4867b47f-mlz4w f64a779b-8e09-4f48-8cf4-7aedfcc2885d 13082 0 2020-06-26 13:27:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:b4867b47f] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-b4867b47f 13149257-bcf1-4c5b-8b31-122ea9c2423b 0xc002b79eb0 0xc002b79eb1}] []  [{kube-controller-manager Update v1 2020-06-26 13:27:00 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 51 49 52 57 50 53 55 45 98 99 102 49 45 52 99 53 98 45 56 98 51 49 45 49 50 50 101 97 57 99 50 52 50 51 98 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:27:02 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 48 46 49 56 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8jjjc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8jjjc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8jjjc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:27:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:27:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:27:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:27:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.0.183,StartTime:2020-06-26 13:27:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:27:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://3d66ef9f9f9aaa511e553940af469d8274e68bded2c466959e0406a1dbffff96,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.0.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:02.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6847" for this suite.

• [SLOW TEST:7.096 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","total":276,"completed":82,"skipped":1300,"failed":0}
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:02.859: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl replace
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1454
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 26 13:27:02.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 run e2e-test-httpd-pod --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-2711'
Jun 26 13:27:02.972: INFO: stderr: ""
Jun 26 13:27:02.972: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Jun 26 13:27:08.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pod e2e-test-httpd-pod --namespace=kubectl-2711 -o json'
Jun 26 13:27:08.146: INFO: stderr: ""
Jun 26 13:27:08.147: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-06-26T13:27:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"managedFields\": [\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:metadata\": {\n                        \"f:labels\": {\n                            \".\": {},\n                            \"f:run\": {}\n                        }\n                    },\n                    \"f:spec\": {\n                        \"f:containers\": {\n                            \"k:{\\\"name\\\":\\\"e2e-test-httpd-pod\\\"}\": {\n                                \".\": {},\n                                \"f:image\": {},\n                                \"f:imagePullPolicy\": {},\n                                \"f:name\": {},\n                                \"f:resources\": {},\n                                \"f:terminationMessagePath\": {},\n                                \"f:terminationMessagePolicy\": {}\n                            }\n                        },\n                        \"f:dnsPolicy\": {},\n                        \"f:enableServiceLinks\": {},\n                        \"f:restartPolicy\": {},\n                        \"f:schedulerName\": {},\n                        \"f:securityContext\": {},\n                        \"f:terminationGracePeriodSeconds\": {}\n                    }\n                },\n                \"manager\": \"kubectl\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-06-26T13:27:02Z\"\n            },\n            {\n                \"apiVersion\": \"v1\",\n                \"fieldsType\": \"FieldsV1\",\n                \"fieldsV1\": {\n                    \"f:status\": {\n                        \"f:conditions\": {\n                            \"k:{\\\"type\\\":\\\"ContainersReady\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Initialized\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            },\n                            \"k:{\\\"type\\\":\\\"Ready\\\"}\": {\n                                \".\": {},\n                                \"f:lastProbeTime\": {},\n                                \"f:lastTransitionTime\": {},\n                                \"f:status\": {},\n                                \"f:type\": {}\n                            }\n                        },\n                        \"f:containerStatuses\": {},\n                        \"f:hostIP\": {},\n                        \"f:phase\": {},\n                        \"f:podIP\": {},\n                        \"f:podIPs\": {\n                            \".\": {},\n                            \"k:{\\\"ip\\\":\\\"10.1.0.184\\\"}\": {\n                                \".\": {},\n                                \"f:ip\": {}\n                            }\n                        },\n                        \"f:startTime\": {}\n                    }\n                },\n                \"manager\": \"kubelet\",\n                \"operation\": \"Update\",\n                \"time\": \"2020-06-26T13:27:03Z\"\n            }\n        ],\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2711\",\n        \"resourceVersion\": \"13114\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2711/pods/e2e-test-httpd-pod\",\n        \"uid\": \"ad579c25-12c7-40d5-b1ab-422525bbf9fc\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-6mllb\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"docker-desktop\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-6mllb\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-6mllb\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-26T13:27:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-26T13:27:03Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-26T13:27:03Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-26T13:27:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://7a70e421336cd395796bc3ef92dfb9ae2395e6d4642288cb55551c6447fd1c5c\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-06-26T13:27:03Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"192.168.65.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.1.0.184\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.1.0.184\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-06-26T13:27:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun 26 13:27:08.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 replace -f - --namespace=kubectl-2711'
Jun 26 13:27:08.316: INFO: stderr: ""
Jun 26 13:27:08.316: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1459
Jun 26 13:27:08.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete pods e2e-test-httpd-pod --namespace=kubectl-2711'
Jun 26 13:27:19.525: INFO: stderr: ""
Jun 26 13:27:19.526: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:19.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2711" for this suite.

• [SLOW TEST:16.673 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1450
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","total":276,"completed":83,"skipped":1300,"failed":0}
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:19.534: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:32.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6954" for this suite.

• [SLOW TEST:13.089 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","total":276,"completed":84,"skipped":1300,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:32.625: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:32.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-436" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","total":276,"completed":85,"skipped":1328,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:32.676: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Jun 26 13:27:32.695: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:47.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8337" for this suite.

• [SLOW TEST:14.944 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","total":276,"completed":86,"skipped":1340,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:47.602: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating Agnhost RC
Jun 26 13:27:47.622: INFO: namespace kubectl-2387
Jun 26 13:27:47.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-2387'
Jun 26 13:27:47.801: INFO: stderr: ""
Jun 26 13:27:47.801: INFO: stdout: "replicationcontroller/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Jun 26 13:27:48.806: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:27:48.806: INFO: Found 0 / 1
Jun 26 13:27:49.806: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:27:49.806: INFO: Found 1 / 1
Jun 26 13:27:49.806: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 26 13:27:49.810: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 13:27:49.810: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 26 13:27:49.810: INFO: wait on agnhost-master startup in kubectl-2387 
Jun 26 13:27:49.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs agnhost-master-xgcpn agnhost-master --namespace=kubectl-2387'
Jun 26 13:27:49.889: INFO: stderr: ""
Jun 26 13:27:49.889: INFO: stdout: "Paused\n"
STEP: exposing RC
Jun 26 13:27:49.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 expose rc agnhost-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2387'
Jun 26 13:27:49.981: INFO: stderr: ""
Jun 26 13:27:49.981: INFO: stdout: "service/rm2 exposed\n"
Jun 26 13:27:49.983: INFO: Service rm2 in namespace kubectl-2387 found.
STEP: exposing service
Jun 26 13:27:51.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2387'
Jun 26 13:27:52.077: INFO: stderr: ""
Jun 26 13:27:52.077: INFO: stdout: "service/rm3 exposed\n"
Jun 26 13:27:52.079: INFO: Service rm3 in namespace kubectl-2387 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:54.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2387" for this suite.

• [SLOW TEST:6.491 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1119
    should create services for rc  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","total":276,"completed":87,"skipped":1374,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:54.093: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-669.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-669.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-669.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-669.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-669.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-669.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:27:56.153: INFO: DNS probes using dns-669/dns-test-254f6c1e-c982-4d91-8cac-2de242f01256 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:56.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-669" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]","total":276,"completed":88,"skipped":1398,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:56.179: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should find a service from listing all namespaces [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching services
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:56.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8916" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","total":276,"completed":89,"skipped":1436,"failed":0}
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:56.213: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:27:56.251: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 version'
Jun 26 13:27:56.313: INFO: stderr: ""
Jun 26 13:27:56.313: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.3\", GitCommit:\"2e7996e3e2712684bc73f0dec0200d64eec7fe40\", GitTreeState:\"clean\", BuildDate:\"2020-05-20T12:52:00Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"18\", GitVersion:\"v1.18.3\", GitCommit:\"2e7996e3e2712684bc73f0dec0200d64eec7fe40\", GitTreeState:\"clean\", BuildDate:\"2020-05-20T12:43:34Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:56.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3352" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","total":276,"completed":90,"skipped":1440,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:56.318: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:27:56.777: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:27:59.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:27:59.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7871" for this suite.
STEP: Destroying namespace "webhook-7871-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","total":276,"completed":91,"skipped":1466,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:27:59.883: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Jun 26 13:28:02.464: INFO: Successfully updated pod "annotationupdate416ae11b-4f35-4460-8de3-413b4fe32183"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:06.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8914" for this suite.

• [SLOW TEST:6.612 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","total":276,"completed":92,"skipped":1514,"failed":0}
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:06.496: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-4689
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-4689
STEP: Creating statefulset with conflicting port in namespace statefulset-4689
STEP: Waiting until pod test-pod will start running in namespace statefulset-4689
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-4689
Jun 26 13:28:10.549: INFO: Observed stateful pod in namespace: statefulset-4689, name: ss-0, uid: d7cd299d-38d3-4105-a8cb-45e6a556a471, status phase: Pending. Waiting for statefulset controller to delete.
Jun 26 13:28:10.939: INFO: Observed stateful pod in namespace: statefulset-4689, name: ss-0, uid: d7cd299d-38d3-4105-a8cb-45e6a556a471, status phase: Failed. Waiting for statefulset controller to delete.
Jun 26 13:28:10.945: INFO: Observed stateful pod in namespace: statefulset-4689, name: ss-0, uid: d7cd299d-38d3-4105-a8cb-45e6a556a471, status phase: Failed. Waiting for statefulset controller to delete.
Jun 26 13:28:10.952: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-4689
STEP: Removing pod with conflicting port in namespace statefulset-4689
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-4689 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:28:14.981: INFO: Deleting all statefulset in ns statefulset-4689
Jun 26 13:28:14.983: INFO: Scaling statefulset ss to 0
Jun 26 13:28:24.994: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:28:24.998: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:25.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4689" for this suite.

• [SLOW TEST:18.526 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","total":276,"completed":93,"skipped":1522,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:25.016: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Jun 26 13:28:26.067: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:26.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0626 13:28:26.067308      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4725" for this suite.
•{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","total":276,"completed":94,"skipped":1527,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:26.073: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:28:26.099: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 26 13:28:26.103: INFO: Number of nodes with available pods: 0
Jun 26 13:28:26.103: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 26 13:28:26.122: INFO: Number of nodes with available pods: 0
Jun 26 13:28:26.122: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:27.126: INFO: Number of nodes with available pods: 1
Jun 26 13:28:27.126: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 26 13:28:27.135: INFO: Number of nodes with available pods: 1
Jun 26 13:28:27.135: INFO: Number of running nodes: 0, number of available pods: 1
Jun 26 13:28:28.138: INFO: Number of nodes with available pods: 0
Jun 26 13:28:28.138: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 26 13:28:28.147: INFO: Number of nodes with available pods: 0
Jun 26 13:28:28.147: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:29.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:29.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:30.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:30.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:31.154: INFO: Number of nodes with available pods: 0
Jun 26 13:28:31.155: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:32.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:32.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:33.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:33.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:34.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:34.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:35.151: INFO: Number of nodes with available pods: 0
Jun 26 13:28:35.151: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:36.154: INFO: Number of nodes with available pods: 0
Jun 26 13:28:36.154: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:37.152: INFO: Number of nodes with available pods: 0
Jun 26 13:28:37.152: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:38.152: INFO: Number of nodes with available pods: 0
Jun 26 13:28:38.152: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:39.151: INFO: Number of nodes with available pods: 0
Jun 26 13:28:39.151: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:40.150: INFO: Number of nodes with available pods: 0
Jun 26 13:28:40.150: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:41.152: INFO: Number of nodes with available pods: 0
Jun 26 13:28:41.152: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 13:28:42.153: INFO: Number of nodes with available pods: 1
Jun 26 13:28:42.153: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-291, will wait for the garbage collector to delete the pods
Jun 26 13:28:42.216: INFO: Deleting DaemonSet.extensions daemon-set took: 5.678012ms
Jun 26 13:28:42.718: INFO: Terminating DaemonSet.extensions daemon-set pods took: 501.881201ms
Jun 26 13:28:49.521: INFO: Number of nodes with available pods: 0
Jun 26 13:28:49.521: INFO: Number of running nodes: 0, number of available pods: 0
Jun 26 13:28:49.523: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-291/daemonsets","resourceVersion":"13944"},"items":null}

Jun 26 13:28:49.525: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-291/pods","resourceVersion":"13944"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:49.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-291" for this suite.

• [SLOW TEST:23.466 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","total":276,"completed":95,"skipped":1550,"failed":0}
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:49.540: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Jun 26 13:28:49.563: INFO: Waiting up to 5m0s for pod "downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25" in namespace "downward-api-9180" to be "Succeeded or Failed"
Jun 26 13:28:49.564: INFO: Pod "downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25": Phase="Pending", Reason="", readiness=false. Elapsed: 1.324938ms
Jun 26 13:28:51.570: INFO: Pod "downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006973141s
STEP: Saw pod success
Jun 26 13:28:51.570: INFO: Pod "downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25" satisfied condition "Succeeded or Failed"
Jun 26 13:28:51.573: INFO: Trying to get logs from node docker-desktop pod downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:28:51.588: INFO: Waiting for pod downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25 to disappear
Jun 26 13:28:51.591: INFO: Pod downward-api-bac82014-e4eb-4fb7-9c1a-9a0b97e7ec25 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:51.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9180" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","total":276,"completed":96,"skipped":1554,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:51.600: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test env composition
Jun 26 13:28:51.679: INFO: Waiting up to 5m0s for pod "var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5" in namespace "var-expansion-5656" to be "Succeeded or Failed"
Jun 26 13:28:51.682: INFO: Pod "var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.288855ms
Jun 26 13:28:53.687: INFO: Pod "var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007657801s
STEP: Saw pod success
Jun 26 13:28:53.687: INFO: Pod "var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5" satisfied condition "Succeeded or Failed"
Jun 26 13:28:53.690: INFO: Trying to get logs from node docker-desktop pod var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:28:53.704: INFO: Waiting for pod var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5 to disappear
Jun 26 13:28:53.708: INFO: Pod var-expansion-99ba1636-255a-483e-91b5-c27bd827b0f5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:53.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5656" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","total":276,"completed":97,"skipped":1577,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:53.719: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:28:53.739: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 26 13:28:55.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-6952 create -f -'
Jun 26 13:28:55.720: INFO: stderr: ""
Jun 26 13:28:55.720: INFO: stdout: "e2e-test-crd-publish-openapi-1996-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jun 26 13:28:55.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-6952 delete e2e-test-crd-publish-openapi-1996-crds test-cr'
Jun 26 13:28:55.787: INFO: stderr: ""
Jun 26 13:28:55.787: INFO: stdout: "e2e-test-crd-publish-openapi-1996-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jun 26 13:28:55.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-6952 apply -f -'
Jun 26 13:28:55.919: INFO: stderr: ""
Jun 26 13:28:55.919: INFO: stdout: "e2e-test-crd-publish-openapi-1996-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jun 26 13:28:55.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-6952 delete e2e-test-crd-publish-openapi-1996-crds test-cr'
Jun 26 13:28:55.985: INFO: stderr: ""
Jun 26 13:28:55.986: INFO: stdout: "e2e-test-crd-publish-openapi-1996-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Jun 26 13:28:55.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-1996-crds'
Jun 26 13:28:56.099: INFO: stderr: ""
Jun 26 13:28:56.099: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1996-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:58.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6952" for this suite.

• [SLOW TEST:5.151 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","total":276,"completed":98,"skipped":1595,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:58.871: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:28:58.895: INFO: (0) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.208404ms)
Jun 26 13:28:58.897: INFO: (1) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.985085ms)
Jun 26 13:28:58.899: INFO: (2) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.590303ms)
Jun 26 13:28:58.900: INFO: (3) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.562894ms)
Jun 26 13:28:58.902: INFO: (4) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.392015ms)
Jun 26 13:28:58.903: INFO: (5) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.479672ms)
Jun 26 13:28:58.905: INFO: (6) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.680365ms)
Jun 26 13:28:58.906: INFO: (7) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.478486ms)
Jun 26 13:28:58.908: INFO: (8) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.812025ms)
Jun 26 13:28:58.910: INFO: (9) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.724781ms)
Jun 26 13:28:58.912: INFO: (10) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.074115ms)
Jun 26 13:28:58.915: INFO: (11) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.376952ms)
Jun 26 13:28:58.917: INFO: (12) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.095123ms)
Jun 26 13:28:58.919: INFO: (13) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.81435ms)
Jun 26 13:28:58.921: INFO: (14) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.287209ms)
Jun 26 13:28:58.923: INFO: (15) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.456285ms)
Jun 26 13:28:58.924: INFO: (16) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.424631ms)
Jun 26 13:28:58.925: INFO: (17) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.268252ms)
Jun 26 13:28:58.927: INFO: (18) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.53801ms)
Jun 26 13:28:58.928: INFO: (19) /api/v1/nodes/docker-desktop/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.480256ms)
[AfterEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:28:58.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8794" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Conformance]","total":276,"completed":99,"skipped":1603,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:28:58.935: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-map-23898c7e-1f8f-41fd-b8df-cf3e86e38ff7
STEP: Creating a pod to test consume secrets
Jun 26 13:28:58.956: INFO: Waiting up to 5m0s for pod "pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df" in namespace "secrets-1064" to be "Succeeded or Failed"
Jun 26 13:28:58.957: INFO: Pod "pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df": Phase="Pending", Reason="", readiness=false. Elapsed: 1.216078ms
Jun 26 13:29:00.962: INFO: Pod "pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006011756s
STEP: Saw pod success
Jun 26 13:29:00.962: INFO: Pod "pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df" satisfied condition "Succeeded or Failed"
Jun 26 13:29:00.964: INFO: Trying to get logs from node docker-desktop pod pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:29:00.978: INFO: Waiting for pod pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df to disappear
Jun 26 13:29:00.979: INFO: Pod pod-secrets-ef7b3147-440c-434a-9356-1d259d2132df no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:00.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1064" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":276,"completed":100,"skipped":1615,"failed":0}
SSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:00.986: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Kubectl logs
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1288
STEP: creating an pod
Jun 26 13:29:01.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 run logs-generator --image=us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 --namespace=kubectl-2959 -- logs-generator --log-lines-total 100 --run-duration 20s'
Jun 26 13:29:01.086: INFO: stderr: ""
Jun 26 13:29:01.086: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Waiting for log generator to start.
Jun 26 13:29:01.086: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jun 26 13:29:01.086: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-2959" to be "running and ready, or succeeded"
Jun 26 13:29:01.089: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765113ms
Jun 26 13:29:03.096: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009735975s
Jun 26 13:29:03.096: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jun 26 13:29:03.096: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Jun 26 13:29:03.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959'
Jun 26 13:29:03.180: INFO: stderr: ""
Jun 26 13:29:03.180: INFO: stdout: "I0626 13:29:01.808100       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/h7w 276\nI0626 13:29:02.009669       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/x4m 354\nI0626 13:29:02.209246       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/w879 434\nI0626 13:29:02.408884       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/q7l 347\nI0626 13:29:02.608535       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/vfj 492\nI0626 13:29:02.810579       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vbwx 216\nI0626 13:29:03.008868       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qjzv 200\n"
STEP: limiting log lines
Jun 26 13:29:03.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959 --tail=1'
Jun 26 13:29:03.265: INFO: stderr: ""
Jun 26 13:29:03.265: INFO: stdout: "I0626 13:29:03.209028       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/j4ln 307\n"
Jun 26 13:29:03.265: INFO: got output "I0626 13:29:03.209028       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/j4ln 307\n"
STEP: limiting log bytes
Jun 26 13:29:03.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959 --limit-bytes=1'
Jun 26 13:29:03.338: INFO: stderr: ""
Jun 26 13:29:03.339: INFO: stdout: "I"
Jun 26 13:29:03.339: INFO: got output "I"
STEP: exposing timestamps
Jun 26 13:29:03.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959 --tail=1 --timestamps'
Jun 26 13:29:03.413: INFO: stderr: ""
Jun 26 13:29:03.413: INFO: stdout: "2020-06-26T13:29:03.408998105Z I0626 13:29:03.408587       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2kh 345\n"
Jun 26 13:29:03.413: INFO: got output "2020-06-26T13:29:03.408998105Z I0626 13:29:03.408587       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2kh 345\n"
STEP: restricting to a time range
Jun 26 13:29:05.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959 --since=1s'
Jun 26 13:29:06.011: INFO: stderr: ""
Jun 26 13:29:06.011: INFO: stdout: "I0626 13:29:05.008556       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/mnsj 293\nI0626 13:29:05.209269       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/hxj 202\nI0626 13:29:05.408666       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/5ft8 596\nI0626 13:29:05.609667       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/59zf 331\nI0626 13:29:05.808907       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/vgbf 274\n"
Jun 26 13:29:06.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 logs logs-generator logs-generator --namespace=kubectl-2959 --since=24h'
Jun 26 13:29:06.122: INFO: stderr: ""
Jun 26 13:29:06.122: INFO: stdout: "I0626 13:29:01.808100       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/h7w 276\nI0626 13:29:02.009669       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/x4m 354\nI0626 13:29:02.209246       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/w879 434\nI0626 13:29:02.408884       1 logs_generator.go:76] 3 POST /api/v1/namespaces/kube-system/pods/q7l 347\nI0626 13:29:02.608535       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/vfj 492\nI0626 13:29:02.810579       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/vbwx 216\nI0626 13:29:03.008868       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/qjzv 200\nI0626 13:29:03.209028       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/j4ln 307\nI0626 13:29:03.408587       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/2kh 345\nI0626 13:29:03.608598       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/vt6 200\nI0626 13:29:03.808431       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/7l7l 227\nI0626 13:29:04.008359       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/vnn 546\nI0626 13:29:04.208636       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/mkr 595\nI0626 13:29:04.408885       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/kube-system/pods/cpx 421\nI0626 13:29:04.608959       1 logs_generator.go:76] 14 POST /api/v1/namespaces/kube-system/pods/mvn 427\nI0626 13:29:04.809409       1 logs_generator.go:76] 15 POST /api/v1/namespaces/kube-system/pods/2bbd 533\nI0626 13:29:05.008556       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/mnsj 293\nI0626 13:29:05.209269       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/hxj 202\nI0626 13:29:05.408666       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/5ft8 596\nI0626 13:29:05.609667       1 logs_generator.go:76] 19 GET /api/v1/namespaces/kube-system/pods/59zf 331\nI0626 13:29:05.808907       1 logs_generator.go:76] 20 POST /api/v1/namespaces/ns/pods/vgbf 274\nI0626 13:29:06.008248       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/b5sz 413\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1294
Jun 26 13:29:06.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete pod logs-generator --namespace=kubectl-2959'
Jun 26 13:29:07.695: INFO: stderr: ""
Jun 26 13:29:07.695: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:07.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2959" for this suite.

• [SLOW TEST:6.715 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1284
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","total":276,"completed":101,"skipped":1618,"failed":0}
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:07.702: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jun 26 13:29:17.776: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0626 13:29:17.776090      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:17.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-543" for this suite.

• [SLOW TEST:10.079 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","total":276,"completed":102,"skipped":1624,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:17.784: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:39.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8434" for this suite.

• [SLOW TEST:21.234 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  blackbox test
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
    when starting a container that exits
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:41
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","total":276,"completed":103,"skipped":1672,"failed":0}
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:39.019: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-map-690ec2b5-69d0-41ba-b81a-0c2445f792c9
STEP: Creating a pod to test consume secrets
Jun 26 13:29:39.053: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4" in namespace "projected-1341" to be "Succeeded or Failed"
Jun 26 13:29:39.063: INFO: Pod "pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.157588ms
Jun 26 13:29:41.066: INFO: Pod "pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013169222s
STEP: Saw pod success
Jun 26 13:29:41.066: INFO: Pod "pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4" satisfied condition "Succeeded or Failed"
Jun 26 13:29:41.071: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:29:41.087: INFO: Waiting for pod pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4 to disappear
Jun 26 13:29:41.089: INFO: Pod pod-projected-secrets-150766be-68bd-4339-bdf9-ca3114c8eaa4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:41.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1341" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":276,"completed":104,"skipped":1672,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:41.097: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:43.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-570" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":105,"skipped":1693,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:43.183: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Jun 26 13:29:45.740: INFO: Successfully updated pod "annotationupdate9690fb62-c85b-4f3f-a9c3-d3208d4a94fa"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:49.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5841" for this suite.

• [SLOW TEST:6.588 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:36
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","total":276,"completed":106,"skipped":1713,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:49.771: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:29:49.793: INFO: Creating deployment "test-recreate-deployment"
Jun 26 13:29:49.796: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun 26 13:29:49.803: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jun 26 13:29:51.811: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun 26 13:29:51.814: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun 26 13:29:51.821: INFO: Updating deployment test-recreate-deployment
Jun 26 13:29:51.821: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Jun 26 13:29:51.905: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-7612 /apis/apps/v1/namespaces/deployment-7612/deployments/test-recreate-deployment e837dcd1-a9b1-4419-9927-0a6845abbb14 14630 2 2020-06-26 13:29:49 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 110 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a265f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-06-26 13:29:51 +0000 UTC,LastTransitionTime:2020-06-26 13:29:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-d5667d9c7" is progressing.,LastUpdateTime:2020-06-26 13:29:51 +0000 UTC,LastTransitionTime:2020-06-26 13:29:49 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jun 26 13:29:51.909: INFO: New ReplicaSet "test-recreate-deployment-d5667d9c7" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-d5667d9c7  deployment-7612 /apis/apps/v1/namespaces/deployment-7612/replicasets/test-recreate-deployment-d5667d9c7 19960a97-cf84-45ba-af30-026a96ac3eff 14627 1 2020-06-26 13:29:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment e837dcd1-a9b1-4419-9927-0a6845abbb14 0xc003a26cb0 0xc003a26cb1}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 56 51 55 100 99 100 49 45 97 57 98 49 45 52 52 49 57 45 57 57 50 55 45 48 97 54 56 52 53 97 98 98 98 49 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: d5667d9c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a26d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:29:51.909: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun 26 13:29:51.909: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-74d98b5f7c  deployment-7612 /apis/apps/v1/namespaces/deployment-7612/replicasets/test-recreate-deployment-74d98b5f7c 3b5c983f-17ee-454e-9d90-6eaefcc350fd 14618 2 2020-06-26 13:29:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment e837dcd1-a9b1-4419-9927-0a6845abbb14 0xc003a26b87 0xc003a26b88}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 101 56 51 55 100 99 100 49 45 97 57 98 49 45 52 52 49 57 45 57 57 50 55 45 48 97 54 56 52 53 97 98 98 98 49 52 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 74d98b5f7c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:74d98b5f7c] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a26c28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:29:51.913: INFO: Pod "test-recreate-deployment-d5667d9c7-hhgpx" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-d5667d9c7-hhgpx test-recreate-deployment-d5667d9c7- deployment-7612 /api/v1/namespaces/deployment-7612/pods/test-recreate-deployment-d5667d9c7-hhgpx 6f5eb60e-17b6-4c5f-bd8f-ea57401fea34 14629 0 2020-06-26 13:29:51 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:d5667d9c7] map[] [{apps/v1 ReplicaSet test-recreate-deployment-d5667d9c7 19960a97-cf84-45ba-af30-026a96ac3eff 0xc003a274f0 0xc003a274f1}] []  [{kube-controller-manager Update v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 49 57 57 54 48 97 57 55 45 99 102 56 52 45 52 53 98 97 45 97 102 51 48 45 48 50 54 97 57 54 97 99 51 101 102 102 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:29:51 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mdzvv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mdzvv,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mdzvv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:29:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:29:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:29:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:29:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:,StartTime:2020-06-26 13:29:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:29:51.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7612" for this suite.
•{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","total":276,"completed":107,"skipped":1743,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:29:51.927: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name cm-test-opt-del-2017b352-ca44-47f3-9bb5-1c9fcc2ae444
STEP: Creating configMap with name cm-test-opt-upd-141083c2-aa12-46ac-8300-abf90ac8547b
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2017b352-ca44-47f3-9bb5-1c9fcc2ae444
STEP: Updating configmap cm-test-opt-upd-141083c2-aa12-46ac-8300-abf90ac8547b
STEP: Creating configMap with name cm-test-opt-create-15d7d14d-0a43-4601-9620-063f16224953
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:06.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4359" for this suite.

• [SLOW TEST:74.480 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":108,"skipped":1783,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:06.409: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 26 13:31:10.463: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:10.466: INFO: Pod pod-with-poststart-http-hook still exists
Jun 26 13:31:12.466: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:12.469: INFO: Pod pod-with-poststart-http-hook still exists
Jun 26 13:31:14.467: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:14.471: INFO: Pod pod-with-poststart-http-hook still exists
Jun 26 13:31:16.467: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:16.472: INFO: Pod pod-with-poststart-http-hook still exists
Jun 26 13:31:18.467: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:18.471: INFO: Pod pod-with-poststart-http-hook still exists
Jun 26 13:31:20.468: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 26 13:31:20.471: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:20.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7365" for this suite.

• [SLOW TEST:14.068 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","total":276,"completed":109,"skipped":1798,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:20.478: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:31:20.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9" in namespace "projected-3849" to be "Succeeded or Failed"
Jun 26 13:31:20.510: INFO: Pod "downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.759187ms
Jun 26 13:31:22.514: INFO: Pod "downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008739901s
STEP: Saw pod success
Jun 26 13:31:22.514: INFO: Pod "downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9" satisfied condition "Succeeded or Failed"
Jun 26 13:31:22.517: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9 container client-container: <nil>
STEP: delete the pod
Jun 26 13:31:22.531: INFO: Waiting for pod downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9 to disappear
Jun 26 13:31:22.534: INFO: Pod downwardapi-volume-44eabadb-47e4-4e64-b30a-1ed50bcf08d9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:22.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3849" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","total":276,"completed":110,"skipped":1811,"failed":0}
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:22.540: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3816.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3816.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3816.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3816.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3816.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3816.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:31:24.606: INFO: DNS probes using dns-3816/dns-test-2dba7c3e-f03e-425e-b8cd-38482bb86bf2 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:24.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3816" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [LinuxOnly] [Conformance]","total":276,"completed":111,"skipped":1816,"failed":0}
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:24.650: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Jun 26 13:31:24.675: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 26 13:31:24.683: INFO: Waiting for terminating namespaces to be deleted...
Jun 26 13:31:24.685: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Jun 26 13:31:24.696: INFO: coredns-66bff467f8-dfrnp from kube-system started at 2020-06-26 13:13:09 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:31:24.697: INFO: kube-proxy-tzb5b from kube-system started at 2020-06-26 12:48:45 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 26 13:31:24.697: INFO: coredns-66bff467f8-rcx2v from kube-system started at 2020-06-26 13:13:08 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:31:24.697: INFO: compose-858b8f86cc-tx2ld from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:31:24.697: INFO: pod-handle-http-request from container-lifecycle-hook-7365 started at 2020-06-26 13:31:06 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container pod-handle-http-request ready: true, restart count 0
Jun 26 13:31:24.697: INFO: kube-apiserver-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container kube-apiserver ready: true, restart count 0
Jun 26 13:31:24.697: INFO: kube-scheduler-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container kube-scheduler ready: true, restart count 0
Jun 26 13:31:24.697: INFO: etcd-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container etcd ready: true, restart count 0
Jun 26 13:31:24.697: INFO: sonobuoy from sonobuoy started at 2020-06-26 13:00:36 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 26 13:31:24.697: INFO: kube-controller-manager-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container kube-controller-manager ready: true, restart count 0
Jun 26 13:31:24.697: INFO: sonobuoy-e2e-job-ad77c8f3bad64e56 from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container e2e ready: true, restart count 0
Jun 26 13:31:24.697: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:31:24.697: INFO: sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:31:24.697: INFO: 	Container systemd-logs ready: false, restart count 10
Jun 26 13:31:24.697: INFO: compose-api-767cd94f6-wd2l9 from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:31:24.697: INFO: 	Container compose ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.161c1b357cc0a100], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:25.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6076" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","total":276,"completed":112,"skipped":1818,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:25.732: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-59b8ab93-987e-473f-b787-691f05adf3c2
STEP: Creating a pod to test consume configMaps
Jun 26 13:31:25.761: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f" in namespace "projected-3192" to be "Succeeded or Failed"
Jun 26 13:31:25.764: INFO: Pod "pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.765219ms
Jun 26 13:31:27.769: INFO: Pod "pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007414663s
STEP: Saw pod success
Jun 26 13:31:27.769: INFO: Pod "pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f" satisfied condition "Succeeded or Failed"
Jun 26 13:31:27.772: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:31:27.788: INFO: Waiting for pod pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f to disappear
Jun 26 13:31:27.792: INFO: Pod pod-projected-configmaps-4f62cbab-d2dd-40f4-8b19-410bf772b94f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:27.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3192" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":113,"skipped":1834,"failed":0}
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:27.801: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:31:27.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f" in namespace "projected-2668" to be "Succeeded or Failed"
Jun 26 13:31:27.827: INFO: Pod "downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.915107ms
Jun 26 13:31:29.830: INFO: Pod "downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004939602s
STEP: Saw pod success
Jun 26 13:31:29.830: INFO: Pod "downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f" satisfied condition "Succeeded or Failed"
Jun 26 13:31:29.833: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f container client-container: <nil>
STEP: delete the pod
Jun 26 13:31:29.846: INFO: Waiting for pod downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f to disappear
Jun 26 13:31:29.849: INFO: Pod downwardapi-volume-71b3ad62-081d-4d14-9c53-e2ebbdf7ff4f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:29.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2668" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","total":276,"completed":114,"skipped":1835,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:29.856: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:31:29.876: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 26 13:31:31.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-7285 create -f -'
Jun 26 13:31:31.857: INFO: stderr: ""
Jun 26 13:31:31.857: INFO: stdout: "e2e-test-crd-publish-openapi-9376-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jun 26 13:31:31.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-7285 delete e2e-test-crd-publish-openapi-9376-crds test-cr'
Jun 26 13:31:31.928: INFO: stderr: ""
Jun 26 13:31:31.928: INFO: stdout: "e2e-test-crd-publish-openapi-9376-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jun 26 13:31:31.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-7285 apply -f -'
Jun 26 13:31:32.063: INFO: stderr: ""
Jun 26 13:31:32.063: INFO: stdout: "e2e-test-crd-publish-openapi-9376-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jun 26 13:31:32.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-7285 delete e2e-test-crd-publish-openapi-9376-crds test-cr'
Jun 26 13:31:32.134: INFO: stderr: ""
Jun 26 13:31:32.134: INFO: stdout: "e2e-test-crd-publish-openapi-9376-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jun 26 13:31:32.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-9376-crds'
Jun 26 13:31:32.249: INFO: stderr: ""
Jun 26 13:31:32.249: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9376-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:35.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7285" for this suite.

• [SLOW TEST:5.209 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","total":276,"completed":115,"skipped":1842,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:35.065: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override all
Jun 26 13:31:35.086: INFO: Waiting up to 5m0s for pod "client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b" in namespace "containers-8496" to be "Succeeded or Failed"
Jun 26 13:31:35.088: INFO: Pod "client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.334695ms
Jun 26 13:31:37.091: INFO: Pod "client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004176585s
STEP: Saw pod success
Jun 26 13:31:37.091: INFO: Pod "client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b" satisfied condition "Succeeded or Failed"
Jun 26 13:31:37.093: INFO: Trying to get logs from node docker-desktop pod client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b container test-container: <nil>
STEP: delete the pod
Jun 26 13:31:37.107: INFO: Waiting for pod client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b to disappear
Jun 26 13:31:37.109: INFO: Pod client-containers-7eba9668-fe0a-461f-9134-06c33ef7c57b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:37.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8496" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","total":276,"completed":116,"skipped":1856,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:37.121: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test override arguments
Jun 26 13:31:37.170: INFO: Waiting up to 5m0s for pod "client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f" in namespace "containers-2864" to be "Succeeded or Failed"
Jun 26 13:31:37.172: INFO: Pod "client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015771ms
Jun 26 13:31:39.175: INFO: Pod "client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005832466s
STEP: Saw pod success
Jun 26 13:31:39.175: INFO: Pod "client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f" satisfied condition "Succeeded or Failed"
Jun 26 13:31:39.178: INFO: Trying to get logs from node docker-desktop pod client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f container test-container: <nil>
STEP: delete the pod
Jun 26 13:31:39.196: INFO: Waiting for pod client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f to disappear
Jun 26 13:31:39.201: INFO: Pod client-containers-2319a263-b01b-4258-967f-94d5fcba7f5f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:39.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2864" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]","total":276,"completed":117,"skipped":1880,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:39.210: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:31:39.239: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a" in namespace "downward-api-535" to be "Succeeded or Failed"
Jun 26 13:31:39.241: INFO: Pod "downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.454656ms
Jun 26 13:31:41.247: INFO: Pod "downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007884519s
STEP: Saw pod success
Jun 26 13:31:41.247: INFO: Pod "downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a" satisfied condition "Succeeded or Failed"
Jun 26 13:31:41.249: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a container client-container: <nil>
STEP: delete the pod
Jun 26 13:31:41.262: INFO: Waiting for pod downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a to disappear
Jun 26 13:31:41.268: INFO: Pod downwardapi-volume-0b498976-ff1a-4d9b-ac09-f11d8a0eb11a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:31:41.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-535" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","total":276,"completed":118,"skipped":1893,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:31:41.280: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 26 13:31:45.337: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:45.340: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:47.341: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:47.344: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:49.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:49.344: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:51.341: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:51.344: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:53.341: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:53.345: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:55.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:55.346: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:57.343: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:57.347: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:31:59.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:31:59.347: INFO: Pod pod-with-prestop-http-hook still exists
Jun 26 13:32:01.342: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 26 13:32:01.345: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:01.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-150" for this suite.

• [SLOW TEST:20.079 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","total":276,"completed":119,"skipped":1958,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:01.360: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:32:01.385: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed" in namespace "projected-1744" to be "Succeeded or Failed"
Jun 26 13:32:01.388: INFO: Pod "downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.315285ms
Jun 26 13:32:03.392: INFO: Pod "downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006622676s
STEP: Saw pod success
Jun 26 13:32:03.392: INFO: Pod "downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed" satisfied condition "Succeeded or Failed"
Jun 26 13:32:03.394: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed container client-container: <nil>
STEP: delete the pod
Jun 26 13:32:03.409: INFO: Waiting for pod downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed to disappear
Jun 26 13:32:03.412: INFO: Pod downwardapi-volume-61b779a6-0c2f-4f1a-99d9-d53541f1b5ed no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:03.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1744" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","total":276,"completed":120,"skipped":1964,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:03.420: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating all guestbook components
Jun 26 13:32:03.440: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-slave
  labels:
    app: agnhost
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: slave
    tier: backend

Jun 26 13:32:03.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:03.628: INFO: stderr: ""
Jun 26 13:32:03.629: INFO: stdout: "service/agnhost-slave created\n"
Jun 26 13:32:03.629: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-master
  labels:
    app: agnhost
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: master
    tier: backend

Jun 26 13:32:03.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:03.782: INFO: stderr: ""
Jun 26 13:32:03.782: INFO: stdout: "service/agnhost-master created\n"
Jun 26 13:32:03.783: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun 26 13:32:03.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:03.919: INFO: stderr: ""
Jun 26 13:32:03.919: INFO: stdout: "service/frontend created\n"
Jun 26 13:32:03.920: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Jun 26 13:32:03.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:04.069: INFO: stderr: ""
Jun 26 13:32:04.069: INFO: stdout: "deployment.apps/frontend created\n"
Jun 26 13:32:04.071: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 26 13:32:04.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:04.260: INFO: stderr: ""
Jun 26 13:32:04.260: INFO: stdout: "deployment.apps/agnhost-master created\n"
Jun 26 13:32:04.261: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12
        args: [ "guestbook", "--slaveof", "agnhost-master", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 26 13:32:04.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8347'
Jun 26 13:32:04.478: INFO: stderr: ""
Jun 26 13:32:04.478: INFO: stdout: "deployment.apps/agnhost-slave created\n"
STEP: validating guestbook app
Jun 26 13:32:04.478: INFO: Waiting for all frontend pods to be Running.
Jun 26 13:32:09.532: INFO: Waiting for frontend to serve content.
Jun 26 13:32:09.540: INFO: Trying to add a new entry to the guestbook.
Jun 26 13:32:09.550: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun 26 13:32:09.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:09.639: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:09.639: INFO: stdout: "service \"agnhost-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun 26 13:32:09.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:09.732: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:09.732: INFO: stdout: "service \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 26 13:32:09.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:09.828: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:09.829: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 26 13:32:09.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:09.910: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:09.910: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 26 13:32:09.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:09.995: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:09.996: INFO: stdout: "deployment.apps \"agnhost-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 26 13:32:09.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-8347'
Jun 26 13:32:10.134: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 13:32:10.134: INFO: stdout: "deployment.apps \"agnhost-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:10.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8347" for this suite.

• [SLOW TEST:6.735 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:310
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","total":276,"completed":121,"skipped":1975,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should patch a Namespace [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:10.156: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a Namespace [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a Namespace
STEP: patching the Namespace
STEP: get the Namespace and ensuring it has the label
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:10.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6137" for this suite.
STEP: Destroying namespace "nspatchtest-37271f41-43c4-4738-8d22-e33b36568b15-2561" for this suite.
•{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","total":276,"completed":122,"skipped":1976,"failed":0}
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:10.278: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Jun 26 13:32:12.860: INFO: Successfully updated pod "labelsupdate6a460523-5060-43a8-b7a4-fe9a31190958"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:16.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6340" for this suite.

• [SLOW TEST:6.614 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:37
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","total":276,"completed":123,"skipped":1980,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:16.896: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 26 13:32:16.916: INFO: Waiting up to 5m0s for pod "pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380" in namespace "emptydir-6373" to be "Succeeded or Failed"
Jun 26 13:32:16.921: INFO: Pod "pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380": Phase="Pending", Reason="", readiness=false. Elapsed: 4.147178ms
Jun 26 13:32:18.923: INFO: Pod "pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007050573s
STEP: Saw pod success
Jun 26 13:32:18.924: INFO: Pod "pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380" satisfied condition "Succeeded or Failed"
Jun 26 13:32:18.926: INFO: Trying to get logs from node docker-desktop pod pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380 container test-container: <nil>
STEP: delete the pod
Jun 26 13:32:18.944: INFO: Waiting for pod pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380 to disappear
Jun 26 13:32:18.948: INFO: Pod pod-cd5bbb4e-4979-42b8-b286-b6e0bbaa1380 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:18.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6373" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":124,"skipped":2019,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:18.954: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 26 13:32:18.978: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5951 /api/v1/namespaces/watch-5951/configmaps/e2e-watch-test-watch-closed 8e847210-7a79-4858-bead-4cb37bd8b944 15658 0 2020-06-26 13:32:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-06-26 13:32:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:32:18.978: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5951 /api/v1/namespaces/watch-5951/configmaps/e2e-watch-test-watch-closed 8e847210-7a79-4858-bead-4cb37bd8b944 15659 0 2020-06-26 13:32:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-06-26 13:32:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 26 13:32:18.985: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5951 /api/v1/namespaces/watch-5951/configmaps/e2e-watch-test-watch-closed 8e847210-7a79-4858-bead-4cb37bd8b944 15660 0 2020-06-26 13:32:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-06-26 13:32:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:32:18.986: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5951 /api/v1/namespaces/watch-5951/configmaps/e2e-watch-test-watch-closed 8e847210-7a79-4858-bead-4cb37bd8b944 15661 0 2020-06-26 13:32:18 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  [{e2e.test Update v1 2020-06-26 13:32:18 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:18.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5951" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","total":276,"completed":125,"skipped":2049,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:19.023: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:32:19.050: INFO: Waiting up to 5m0s for pod "downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023" in namespace "downward-api-8741" to be "Succeeded or Failed"
Jun 26 13:32:19.052: INFO: Pod "downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.443203ms
Jun 26 13:32:21.057: INFO: Pod "downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00741943s
Jun 26 13:32:23.060: INFO: Pod "downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0104038s
STEP: Saw pod success
Jun 26 13:32:23.061: INFO: Pod "downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023" satisfied condition "Succeeded or Failed"
Jun 26 13:32:23.063: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023 container client-container: <nil>
STEP: delete the pod
Jun 26 13:32:23.081: INFO: Waiting for pod downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023 to disappear
Jun 26 13:32:23.085: INFO: Pod downwardapi-volume-60e07c4e-661d-4bad-a30c-eecc2eaa1023 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:23.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8741" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":126,"skipped":2070,"failed":0}
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:23.091: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-38be95f8-f71c-4608-b245-bb30d8221f65
STEP: Creating secret with name s-test-opt-upd-56fc4c60-cc62-4e56-aefd-fb0fce27b544
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-38be95f8-f71c-4608-b245-bb30d8221f65
STEP: Updating secret s-test-opt-upd-56fc4c60-cc62-4e56-aefd-fb0fce27b544
STEP: Creating secret with name s-test-opt-create-90a0aa23-eccc-4d28-8845-258fab2976f7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:27.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9113" for this suite.
•{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":127,"skipped":2079,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:27.210: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:32:27.483: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Jun 26 13:32:29.492: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775147, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775147, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-65c6cd5fdf\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:32:32.503: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:32:32.505: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:33.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5737" for this suite.
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:6.451 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","total":276,"completed":128,"skipped":2102,"failed":0}
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:33.661: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:32:34.088: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:32:37.105: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:37.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6403" for this suite.
STEP: Destroying namespace "webhook-6403-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","total":276,"completed":129,"skipped":2106,"failed":0}
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:37.187: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Jun 26 13:32:37.226: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:32:40.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7736" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","total":276,"completed":130,"skipped":2108,"failed":0}
SSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:32:40.328: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-7ef6cc10-8443-4ba2-9a49-83f8e8566a41
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-7ef6cc10-8443-4ba2-9a49-83f8e8566a41
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:34:00.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8269" for this suite.

• [SLOW TEST:80.408 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":131,"skipped":2111,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:34:00.741: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap that has name configmap-test-emptyKey-282dbc20-0b18-4dc5-8fdb-3442f3867491
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:34:00.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-811" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","total":276,"completed":132,"skipped":2123,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:34:00.770: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-6ca8dbf8-7a2f-4aaa-b48c-7181e46d2ded
STEP: Creating a pod to test consume configMaps
Jun 26 13:34:00.795: INFO: Waiting up to 5m0s for pod "pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be" in namespace "configmap-9138" to be "Succeeded or Failed"
Jun 26 13:34:00.799: INFO: Pod "pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.605107ms
Jun 26 13:34:02.803: INFO: Pod "pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007860483s
STEP: Saw pod success
Jun 26 13:34:02.803: INFO: Pod "pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be" satisfied condition "Succeeded or Failed"
Jun 26 13:34:02.804: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:34:02.820: INFO: Waiting for pod pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be to disappear
Jun 26 13:34:02.824: INFO: Pod pod-configmaps-782283a7-6b89-4f47-99f2-85fc150cd1be no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:34:02.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9138" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":276,"completed":133,"skipped":2237,"failed":0}
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:34:02.830: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:34:03.293: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:34:06.310: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:34:06.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2258" for this suite.
STEP: Destroying namespace "webhook-2258-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","total":276,"completed":134,"skipped":2242,"failed":0}
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:34:06.484: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-fd77fd89-acf7-464b-add6-9d9e83de3006 in namespace container-probe-1769
Jun 26 13:34:08.521: INFO: Started pod busybox-fd77fd89-acf7-464b-add6-9d9e83de3006 in namespace container-probe-1769
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 13:34:08.523: INFO: Initial restart count of pod busybox-fd77fd89-acf7-464b-add6-9d9e83de3006 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:09.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1769" for this suite.

• [SLOW TEST:242.536 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":276,"completed":135,"skipped":2245,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:09.027: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 26 13:38:09.061: INFO: Waiting up to 5m0s for pod "pod-35fc0540-125e-4edc-8ece-1fd91c87c23d" in namespace "emptydir-2419" to be "Succeeded or Failed"
Jun 26 13:38:09.063: INFO: Pod "pod-35fc0540-125e-4edc-8ece-1fd91c87c23d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.220958ms
Jun 26 13:38:11.066: INFO: Pod "pod-35fc0540-125e-4edc-8ece-1fd91c87c23d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005308295s
STEP: Saw pod success
Jun 26 13:38:11.067: INFO: Pod "pod-35fc0540-125e-4edc-8ece-1fd91c87c23d" satisfied condition "Succeeded or Failed"
Jun 26 13:38:11.069: INFO: Trying to get logs from node docker-desktop pod pod-35fc0540-125e-4edc-8ece-1fd91c87c23d container test-container: <nil>
STEP: delete the pod
Jun 26 13:38:11.093: INFO: Waiting for pod pod-35fc0540-125e-4edc-8ece-1fd91c87c23d to disappear
Jun 26 13:38:11.096: INFO: Pod pod-35fc0540-125e-4edc-8ece-1fd91c87c23d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:11.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2419" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":136,"skipped":2266,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:11.103: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-a8238c92-c292-4665-810a-b16c20ba09ec
STEP: Creating a pod to test consume configMaps
Jun 26 13:38:11.142: INFO: Waiting up to 5m0s for pod "pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9" in namespace "configmap-6097" to be "Succeeded or Failed"
Jun 26 13:38:11.145: INFO: Pod "pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.497366ms
Jun 26 13:38:13.150: INFO: Pod "pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00827782s
STEP: Saw pod success
Jun 26 13:38:13.150: INFO: Pod "pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9" satisfied condition "Succeeded or Failed"
Jun 26 13:38:13.152: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:38:13.167: INFO: Waiting for pod pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9 to disappear
Jun 26 13:38:13.169: INFO: Pod pod-configmaps-303f03a7-1b78-49dc-903e-620ef214d4d9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:13.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6097" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":276,"completed":137,"skipped":2282,"failed":0}
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:13.176: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 26 13:38:13.202: INFO: Waiting up to 5m0s for pod "pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc" in namespace "emptydir-9851" to be "Succeeded or Failed"
Jun 26 13:38:13.204: INFO: Pod "pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626503ms
Jun 26 13:38:15.207: INFO: Pod "pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005564857s
STEP: Saw pod success
Jun 26 13:38:15.207: INFO: Pod "pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc" satisfied condition "Succeeded or Failed"
Jun 26 13:38:15.210: INFO: Trying to get logs from node docker-desktop pod pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc container test-container: <nil>
STEP: delete the pod
Jun 26 13:38:15.222: INFO: Waiting for pod pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc to disappear
Jun 26 13:38:15.226: INFO: Pod pod-8b2db364-a6fa-4f2f-937d-e5eca9c777cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:15.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9851" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":138,"skipped":2288,"failed":0}

------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:15.234: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:82
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:19.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7797" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","total":276,"completed":139,"skipped":2288,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:19.272: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:157
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:19.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-997" for this suite.
•{"msg":"PASSED [k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","total":276,"completed":140,"skipped":2304,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:19.321: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Jun 26 13:38:19.345: INFO: Waiting up to 5m0s for pod "downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2" in namespace "downward-api-3872" to be "Succeeded or Failed"
Jun 26 13:38:19.347: INFO: Pod "downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03261ms
Jun 26 13:38:21.350: INFO: Pod "downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004699085s
STEP: Saw pod success
Jun 26 13:38:21.350: INFO: Pod "downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2" satisfied condition "Succeeded or Failed"
Jun 26 13:38:21.352: INFO: Trying to get logs from node docker-desktop pod downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:38:21.365: INFO: Waiting for pod downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2 to disappear
Jun 26 13:38:21.366: INFO: Pod downward-api-12dc430e-bb0e-4a87-b896-cccf4e5140d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:21.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3872" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","total":276,"completed":141,"skipped":2351,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:21.371: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Jun 26 13:38:21.394: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:38:23.160: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:38:31.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5084" for this suite.

• [SLOW TEST:10.503 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","total":276,"completed":142,"skipped":2364,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:38:31.875: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Jun 26 13:38:31.892: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 26 13:38:31.897: INFO: Waiting for terminating namespaces to be deleted...
Jun 26 13:38:31.898: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Jun 26 13:38:31.903: INFO: kube-apiserver-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.903: INFO: 	Container kube-apiserver ready: true, restart count 0
Jun 26 13:38:31.903: INFO: kube-scheduler-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.903: INFO: 	Container kube-scheduler ready: true, restart count 0
Jun 26 13:38:31.903: INFO: etcd-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.903: INFO: 	Container etcd ready: true, restart count 0
Jun 26 13:38:31.903: INFO: sonobuoy from sonobuoy started at 2020-06-26 13:00:36 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.903: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 26 13:38:31.904: INFO: kube-controller-manager-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container kube-controller-manager ready: true, restart count 0
Jun 26 13:38:31.904: INFO: sonobuoy-e2e-job-ad77c8f3bad64e56 from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container e2e ready: true, restart count 0
Jun 26 13:38:31.904: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:38:31.904: INFO: sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:38:31.904: INFO: 	Container systemd-logs ready: false, restart count 12
Jun 26 13:38:31.904: INFO: compose-api-767cd94f6-wd2l9 from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:38:31.904: INFO: kube-proxy-tzb5b from kube-system started at 2020-06-26 12:48:45 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 26 13:38:31.904: INFO: coredns-66bff467f8-rcx2v from kube-system started at 2020-06-26 13:13:08 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:38:31.904: INFO: coredns-66bff467f8-dfrnp from kube-system started at 2020-06-26 13:13:09 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:38:31.904: INFO: compose-858b8f86cc-tx2ld from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:38:31.904: INFO: 	Container compose ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3fce19d6-6f82-4b64-ba55-3845a0376156 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-3fce19d6-6f82-4b64-ba55-3845a0376156 off the node docker-desktop
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3fce19d6-6f82-4b64-ba55-3845a0376156
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:37.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3064" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82

• [SLOW TEST:306.116 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","total":276,"completed":143,"skipped":2381,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:37.999: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8245.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8245.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:43:40.069: INFO: DNS probes using dns-8245/dns-test-d3ed7a92-f841-4634-a949-919caa0899ea succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:40.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8245" for this suite.
•{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","total":276,"completed":144,"skipped":2413,"failed":0}
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:40.099: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:43:40.132: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:41.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7272" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","total":276,"completed":145,"skipped":2414,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:41.159: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating secret secrets-9099/secret-test-6e347578-25f6-4bd0-9b76-ea8f5da99767
STEP: Creating a pod to test consume secrets
Jun 26 13:43:41.188: INFO: Waiting up to 5m0s for pod "pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d" in namespace "secrets-9099" to be "Succeeded or Failed"
Jun 26 13:43:41.190: INFO: Pod "pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.939941ms
Jun 26 13:43:43.192: INFO: Pod "pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004526593s
STEP: Saw pod success
Jun 26 13:43:43.193: INFO: Pod "pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d" satisfied condition "Succeeded or Failed"
Jun 26 13:43:43.196: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d container env-test: <nil>
STEP: delete the pod
Jun 26 13:43:43.226: INFO: Waiting for pod pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d to disappear
Jun 26 13:43:43.237: INFO: Pod pod-configmaps-edfd46c0-e459-4a09-8f37-cff7d592891d no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:43.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9099" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable via the environment [NodeConformance] [Conformance]","total":276,"completed":146,"skipped":2425,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:43.249: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jun 26 13:43:49.308: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:49.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0626 13:43:49.308690      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6902" for this suite.

• [SLOW TEST:6.071 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","total":276,"completed":147,"skipped":2429,"failed":0}
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:49.321: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:43:49.368: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:55.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2823" for this suite.

• [SLOW TEST:6.213 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:48
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","total":276,"completed":148,"skipped":2432,"failed":0}
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:55.535: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's command
Jun 26 13:43:55.562: INFO: Waiting up to 5m0s for pod "var-expansion-265a9060-162e-4f87-a012-9115a5311ab2" in namespace "var-expansion-2508" to be "Succeeded or Failed"
Jun 26 13:43:55.567: INFO: Pod "var-expansion-265a9060-162e-4f87-a012-9115a5311ab2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.021212ms
Jun 26 13:43:57.569: INFO: Pod "var-expansion-265a9060-162e-4f87-a012-9115a5311ab2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007527991s
STEP: Saw pod success
Jun 26 13:43:57.569: INFO: Pod "var-expansion-265a9060-162e-4f87-a012-9115a5311ab2" satisfied condition "Succeeded or Failed"
Jun 26 13:43:57.571: INFO: Trying to get logs from node docker-desktop pod var-expansion-265a9060-162e-4f87-a012-9115a5311ab2 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:43:57.590: INFO: Waiting for pod var-expansion-265a9060-162e-4f87-a012-9115a5311ab2 to disappear
Jun 26 13:43:57.594: INFO: Pod var-expansion-265a9060-162e-4f87-a012-9115a5311ab2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:43:57.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2508" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","total":276,"completed":149,"skipped":2438,"failed":0}

------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:43:57.601: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun 26 13:43:59.643: INFO: &Pod{ObjectMeta:{send-events-bb938d79-4b0a-4ae2-9663-8ad737c27115  events-3220 /api/v1/namespaces/events-3220/pods/send-events-bb938d79-4b0a-4ae2-9663-8ad737c27115 e8eabbca-e194-486a-a186-b3920dc7caf9 18260 0 2020-06-26 13:43:57 +0000 UTC <nil> <nil> map[name:foo time:624120449] map[] [] []  [{e2e.test Update v1 2020-06-26 13:43:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 116 105 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 112 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 114 116 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 99 111 110 116 97 105 110 101 114 80 111 114 116 92 34 58 56 48 44 92 34 112 114 111 116 111 99 111 108 92 34 58 92 34 84 67 80 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 99 111 110 116 97 105 110 101 114 80 111 114 116 34 58 123 125 44 34 102 58 112 114 111 116 111 99 111 108 34 58 123 125 125 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:43:58 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 49 46 49 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qw8bl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qw8bl,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qw8bl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:43:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:43:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:43:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:43:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.15,StartTime:2020-06-26 13:43:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:43:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://93605c24a8fddb7516cb5dff2b5d3dd706d5305b9a2cf0f57e023cfdeaf6e07a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.1.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Jun 26 13:44:01.647: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun 26 13:44:03.650: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:44:03.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3220" for this suite.

• [SLOW TEST:6.067 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]","total":276,"completed":150,"skipped":2438,"failed":0}
SSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:44:03.669: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:171
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating server pod server in namespace prestop-2123
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2123
STEP: Deleting pre-stop pod
Jun 26 13:44:12.733: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:44:12.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2123" for this suite.

• [SLOW TEST:9.083 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] [sig-node] PreStop should call prestop when killing a pod  [Conformance]","total":276,"completed":151,"skipped":2441,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:44:12.752: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:44:12.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8509" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702
•{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","total":276,"completed":152,"skipped":2478,"failed":0}
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:44:12.797: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] custom resource defaulting for requests and from storage works  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:44:12.838: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:44:13.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9214" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","total":276,"completed":153,"skipped":2488,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:44:13.978: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod busybox-62ba7a64-39c7-4a80-9078-183ee801bf71 in namespace container-probe-5060
Jun 26 13:44:16.014: INFO: Started pod busybox-62ba7a64-39c7-4a80-9078-183ee801bf71 in namespace container-probe-5060
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 13:44:16.017: INFO: Initial restart count of pod busybox-62ba7a64-39c7-4a80-9078-183ee801bf71 is 0
Jun 26 13:45:04.108: INFO: Restart count of pod container-probe-5060/busybox-62ba7a64-39c7-4a80-9078-183ee801bf71 is now 1 (48.090268864s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:04.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5060" for this suite.

• [SLOW TEST:50.150 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","total":276,"completed":154,"skipped":2512,"failed":0}
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:04.130: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:45:04.166: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657" in namespace "projected-5669" to be "Succeeded or Failed"
Jun 26 13:45:04.171: INFO: Pod "downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657": Phase="Pending", Reason="", readiness=false. Elapsed: 4.876641ms
Jun 26 13:45:06.175: INFO: Pod "downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008708058s
STEP: Saw pod success
Jun 26 13:45:06.175: INFO: Pod "downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657" satisfied condition "Succeeded or Failed"
Jun 26 13:45:06.178: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657 container client-container: <nil>
STEP: delete the pod
Jun 26 13:45:06.202: INFO: Waiting for pod downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657 to disappear
Jun 26 13:45:06.204: INFO: Pod downwardapi-volume-8d277b4e-ef2c-4b30-a925-6de6af13a657 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:06.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5669" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","total":276,"completed":155,"skipped":2517,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:06.217: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 26 13:45:06.259: INFO: Waiting up to 5m0s for pod "pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7" in namespace "emptydir-2382" to be "Succeeded or Failed"
Jun 26 13:45:06.264: INFO: Pod "pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.470324ms
Jun 26 13:45:08.267: INFO: Pod "pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00761397s
STEP: Saw pod success
Jun 26 13:45:08.267: INFO: Pod "pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7" satisfied condition "Succeeded or Failed"
Jun 26 13:45:08.269: INFO: Trying to get logs from node docker-desktop pod pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7 container test-container: <nil>
STEP: delete the pod
Jun 26 13:45:08.285: INFO: Waiting for pod pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7 to disappear
Jun 26 13:45:08.288: INFO: Pod pod-66c33ec4-2f5f-43ca-804b-4f69effbebb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:08.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2382" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":156,"skipped":2561,"failed":0}

------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:08.298: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:15.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3479" for this suite.

• [SLOW TEST:7.043 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","total":276,"completed":157,"skipped":2561,"failed":0}
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:15.341: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-3041
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating statefulset ss in namespace statefulset-3041
Jun 26 13:45:15.374: INFO: Found 0 stateful pods, waiting for 1
Jun 26 13:45:25.379: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:45:25.392: INFO: Deleting all statefulset in ns statefulset-3041
Jun 26 13:45:25.395: INFO: Scaling statefulset ss to 0
Jun 26 13:45:55.438: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:45:55.441: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:55.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3041" for this suite.

• [SLOW TEST:40.116 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","total":276,"completed":158,"skipped":2563,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:55.463: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 26 13:45:55.490: INFO: Waiting up to 5m0s for pod "pod-f264b777-082c-48d1-963b-f5c9c5782450" in namespace "emptydir-657" to be "Succeeded or Failed"
Jun 26 13:45:55.496: INFO: Pod "pod-f264b777-082c-48d1-963b-f5c9c5782450": Phase="Pending", Reason="", readiness=false. Elapsed: 6.003778ms
Jun 26 13:45:57.501: INFO: Pod "pod-f264b777-082c-48d1-963b-f5c9c5782450": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010540951s
STEP: Saw pod success
Jun 26 13:45:57.501: INFO: Pod "pod-f264b777-082c-48d1-963b-f5c9c5782450" satisfied condition "Succeeded or Failed"
Jun 26 13:45:57.504: INFO: Trying to get logs from node docker-desktop pod pod-f264b777-082c-48d1-963b-f5c9c5782450 container test-container: <nil>
STEP: delete the pod
Jun 26 13:45:57.523: INFO: Waiting for pod pod-f264b777-082c-48d1-963b-f5c9c5782450 to disappear
Jun 26 13:45:57.525: INFO: Pod pod-f264b777-082c-48d1-963b-f5c9c5782450 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:45:57.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-657" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":159,"skipped":2629,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:45:57.531: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 26 13:45:57.566: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18819 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:45:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:45:57.566: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18820 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:45:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:45:57.566: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18821 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:45:57 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 26 13:46:07.588: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18876 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:46:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:46:07.588: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18877 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:46:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:46:07.589: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6763 /api/v1/namespaces/watch-6763/configmaps/e2e-watch-test-label-changed d020ff01-6cea-4983-98d6-57e1162f3bf2 18878 0 2020-06-26 13:45:57 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  [{e2e.test Update v1 2020-06-26 13:46:07 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:07.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6763" for this suite.

• [SLOW TEST:10.063 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","total":276,"completed":160,"skipped":2655,"failed":0}
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:07.596: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:20.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5092" for this suite.
STEP: Destroying namespace "nsdeletetest-5138" for this suite.
Jun 26 13:46:20.697: INFO: Namespace nsdeletetest-5138 was already deleted
STEP: Destroying namespace "nsdeletetest-7696" for this suite.

• [SLOW TEST:13.104 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","total":276,"completed":161,"skipped":2656,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:20.701: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:20.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4064" for this suite.
•{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","total":276,"completed":162,"skipped":2667,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Lease 
  lease API should be available [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Lease
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:20.741: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename lease-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] lease API should be available [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Lease
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:20.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-6933" for this suite.
•{"msg":"PASSED [k8s.io] Lease lease API should be available [Conformance]","total":276,"completed":163,"skipped":2710,"failed":0}
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:20.815: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:46:20.845: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97" in namespace "projected-4219" to be "Succeeded or Failed"
Jun 26 13:46:20.847: INFO: Pod "downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.348242ms
Jun 26 13:46:22.850: INFO: Pod "downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005212554s
STEP: Saw pod success
Jun 26 13:46:22.850: INFO: Pod "downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97" satisfied condition "Succeeded or Failed"
Jun 26 13:46:22.852: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97 container client-container: <nil>
STEP: delete the pod
Jun 26 13:46:22.872: INFO: Waiting for pod downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97 to disappear
Jun 26 13:46:22.875: INFO: Pod downwardapi-volume-82e755e1-3183-4368-9622-55ca3bdb9d97 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:22.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4219" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":164,"skipped":2716,"failed":0}
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:22.887: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:46:23.245: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 26 13:46:25.252: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775983, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775983, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775983, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728775983, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:46:28.266: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:46:28.269: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9445-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:29.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1883" for this suite.
STEP: Destroying namespace "webhook-1883-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.547 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","total":276,"completed":165,"skipped":2717,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:29.435: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:46:29.473: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452" in namespace "downward-api-290" to be "Succeeded or Failed"
Jun 26 13:46:29.486: INFO: Pod "downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452": Phase="Pending", Reason="", readiness=false. Elapsed: 12.319321ms
Jun 26 13:46:31.490: INFO: Pod "downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016234837s
STEP: Saw pod success
Jun 26 13:46:31.490: INFO: Pod "downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452" satisfied condition "Succeeded or Failed"
Jun 26 13:46:31.493: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452 container client-container: <nil>
STEP: delete the pod
Jun 26 13:46:31.517: INFO: Waiting for pod downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452 to disappear
Jun 26 13:46:31.519: INFO: Pod downwardapi-volume-16ae4b6b-48ef-498f-bc98-7b77a4f35452 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:31.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-290" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","total":276,"completed":166,"skipped":2739,"failed":0}

------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:31.529: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 26 13:46:33.577: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:33.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3898" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":276,"completed":167,"skipped":2739,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:33.595: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun 26 13:46:33.628: INFO: Pod name pod-release: Found 0 pods out of 1
Jun 26 13:46:38.631: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:38.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3539" for this suite.

• [SLOW TEST:5.081 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","total":276,"completed":168,"skipped":2750,"failed":0}
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:38.679: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test substitution in container's args
Jun 26 13:46:38.711: INFO: Waiting up to 5m0s for pod "var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936" in namespace "var-expansion-142" to be "Succeeded or Failed"
Jun 26 13:46:38.715: INFO: Pod "var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936": Phase="Pending", Reason="", readiness=false. Elapsed: 4.441138ms
Jun 26 13:46:40.719: INFO: Pod "var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00793494s
STEP: Saw pod success
Jun 26 13:46:40.719: INFO: Pod "var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936" satisfied condition "Succeeded or Failed"
Jun 26 13:46:40.722: INFO: Trying to get logs from node docker-desktop pod var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:46:40.737: INFO: Waiting for pod var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936 to disappear
Jun 26 13:46:40.742: INFO: Pod var-expansion-53f6fd70-8a2a-4ec8-8bf2-88313e7cf936 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:40.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-142" for this suite.
•{"msg":"PASSED [k8s.io] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","total":276,"completed":169,"skipped":2755,"failed":0}
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:40.750: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:46:40.775: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:42.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-278" for this suite.
•{"msg":"PASSED [k8s.io] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","total":276,"completed":170,"skipped":2757,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:42.811: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:41
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:46:42.841: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d1963fa4-9412-4357-84df-5382923627c1" in namespace "security-context-test-2063" to be "Succeeded or Failed"
Jun 26 13:46:42.848: INFO: Pod "busybox-readonly-false-d1963fa4-9412-4357-84df-5382923627c1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.653184ms
Jun 26 13:46:44.852: INFO: Pod "busybox-readonly-false-d1963fa4-9412-4357-84df-5382923627c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010324643s
Jun 26 13:46:44.852: INFO: Pod "busybox-readonly-false-d1963fa4-9412-4357-84df-5382923627c1" satisfied condition "Succeeded or Failed"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:44.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2063" for this suite.
•{"msg":"PASSED [k8s.io] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","total":276,"completed":171,"skipped":2779,"failed":0}
SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:44.862: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:46:44.887: INFO: Creating ReplicaSet my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92
Jun 26 13:46:44.893: INFO: Pod name my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92: Found 0 pods out of 1
Jun 26 13:46:49.898: INFO: Pod name my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92: Found 1 pods out of 1
Jun 26 13:46:49.898: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92" is running
Jun 26 13:46:49.901: INFO: Pod "my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92-zjgbj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:46:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:46:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:46:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-26 13:46:44 +0000 UTC Reason: Message:}])
Jun 26 13:46:49.901: INFO: Trying to dial the pod
Jun 26 13:46:54.911: INFO: Controller my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92: Got expected result from replica 1 [my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92-zjgbj]: "my-hostname-basic-55a2acdb-529e-4af3-8991-d80447ff5c92-zjgbj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:54.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3614" for this suite.

• [SLOW TEST:10.054 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","total":276,"completed":172,"skipped":2788,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:54.918: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:46:55.398: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:46:58.415: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:46:58.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7734" for this suite.
STEP: Destroying namespace "webhook-7734-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","total":276,"completed":173,"skipped":2831,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:46:58.509: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-9c0a9c4b-9552-45a5-ade0-60a843981ae0
STEP: Creating a pod to test consume secrets
Jun 26 13:46:58.570: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511" in namespace "projected-2178" to be "Succeeded or Failed"
Jun 26 13:46:58.577: INFO: Pod "pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511": Phase="Pending", Reason="", readiness=false. Elapsed: 6.189307ms
Jun 26 13:47:00.580: INFO: Pod "pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009470282s
STEP: Saw pod success
Jun 26 13:47:00.580: INFO: Pod "pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511" satisfied condition "Succeeded or Failed"
Jun 26 13:47:00.582: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:47:00.600: INFO: Waiting for pod pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511 to disappear
Jun 26 13:47:00.602: INFO: Pod pod-projected-secrets-1b7e30b8-224b-4723-b1e3-7bc5c2d27511 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:47:00.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2178" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","total":276,"completed":174,"skipped":2866,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:47:00.610: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:47:01.215: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 26 13:47:03.224: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776021, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776021, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776021, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776021, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:47:06.238: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:47:06.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7729" for this suite.
STEP: Destroying namespace "webhook-7729-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:5.707 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","total":276,"completed":175,"skipped":2882,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:47:06.318: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:47:08.404: INFO: DNS probes using dns-test-269aea04-1ae4-4a43-80ab-2179a190b43b succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:47:10.469: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:10.475: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:10.475: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:15.479: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:15.482: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:15.482: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:20.482: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:20.485: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:20.485: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:25.478: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:25.483: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:25.483: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:30.480: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:30.483: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:30.483: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:35.480: INFO: File wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:35.483: INFO: File jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local from pod  dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd contains 'foo.example.com.
' instead of 'bar.example.com.'
Jun 26 13:47:35.483: INFO: Lookups using dns-8132/dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd failed for: [wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local]

Jun 26 13:47:40.482: INFO: DNS probes using dns-test-1437e1d6-c81a-4dcf-8beb-c7e3358451bd succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8132.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8132.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 13:47:44.546: INFO: DNS probes using dns-test-7df4f90f-271f-4031-8d7d-5e79e67ec5fd succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:47:44.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8132" for this suite.

• [SLOW TEST:38.276 seconds]
[sig-network] DNS
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","total":276,"completed":176,"skipped":2927,"failed":0}
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:47:44.597: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 26 13:47:44.643: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19716 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:47:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:47:44.644: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19716 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:47:44 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 26 13:47:54.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19785 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:47:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:47:54.653: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19785 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:47:54 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 26 13:48:04.659: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19808 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:48:04.659: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19808 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 26 13:48:14.665: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19832 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:48:14.665: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-a 8f128844-ef66-4a1a-82c1-36935451177b 19832 0 2020-06-26 13:47:44 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:04 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 26 13:48:24.672: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-b 2c972cb4-59b7-4c75-95de-3742b779f6fa 19856 0 2020-06-26 13:48:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:48:24.672: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-b 2c972cb4-59b7-4c75-95de-3742b779f6fa 19856 0 2020-06-26 13:48:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 26 13:48:34.678: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-b 2c972cb4-59b7-4c75-95de-3742b779f6fa 19880 0 2020-06-26 13:48:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 13:48:34.678: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4715 /api/v1/namespaces/watch-4715/configmaps/e2e-watch-test-configmap-b 2c972cb4-59b7-4c75-95de-3742b779f6fa 19880 0 2020-06-26 13:48:24 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  [{e2e.test Update v1 2020-06-26 13:48:24 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:48:44.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4715" for this suite.

• [SLOW TEST:60.087 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","total":276,"completed":177,"skipped":2931,"failed":0}
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:48:44.686: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Jun 26 13:48:54.731: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:48:54.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0626 13:48:54.731434      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-3843" for this suite.

• [SLOW TEST:10.051 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","total":276,"completed":178,"skipped":2940,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:48:54.742: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:91
Jun 26 13:48:54.768: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 26 13:48:54.772: INFO: Waiting for terminating namespaces to be deleted...
Jun 26 13:48:54.774: INFO: 
Logging pods the kubelet thinks is on node docker-desktop before test
Jun 26 13:48:54.788: INFO: coredns-66bff467f8-rcx2v from kube-system started at 2020-06-26 13:13:08 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:48:54.788: INFO: coredns-66bff467f8-dfrnp from kube-system started at 2020-06-26 13:13:09 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container coredns ready: true, restart count 0
Jun 26 13:48:54.788: INFO: kube-proxy-tzb5b from kube-system started at 2020-06-26 12:48:45 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 26 13:48:54.788: INFO: compose-858b8f86cc-tx2ld from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:48:54.788: INFO: kube-apiserver-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container kube-apiserver ready: true, restart count 0
Jun 26 13:48:54.788: INFO: kube-scheduler-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container kube-scheduler ready: true, restart count 0
Jun 26 13:48:54.788: INFO: etcd-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container etcd ready: true, restart count 0
Jun 26 13:48:54.788: INFO: sonobuoy from sonobuoy started at 2020-06-26 13:00:36 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 26 13:48:54.788: INFO: compose-api-767cd94f6-wd2l9 from docker started at 2020-06-26 13:13:07 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container compose ready: true, restart count 0
Jun 26 13:48:54.788: INFO: kube-controller-manager-docker-desktop from kube-system started at 2020-06-26 12:48:29 +0000 UTC (1 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container kube-controller-manager ready: true, restart count 0
Jun 26 13:48:54.788: INFO: sonobuoy-e2e-job-ad77c8f3bad64e56 from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container e2e ready: true, restart count 0
Jun 26 13:48:54.788: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:48:54.788: INFO: sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k from sonobuoy started at 2020-06-26 13:00:41 +0000 UTC (2 container statuses recorded)
Jun 26 13:48:54.788: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 26 13:48:54.788: INFO: 	Container systemd-logs ready: false, restart count 14
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: verifying the node has the label node docker-desktop
Jun 26 13:48:54.804: INFO: Pod compose-858b8f86cc-tx2ld requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod compose-api-767cd94f6-wd2l9 requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod coredns-66bff467f8-dfrnp requesting resource cpu=100m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod coredns-66bff467f8-rcx2v requesting resource cpu=100m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod etcd-docker-desktop requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod kube-apiserver-docker-desktop requesting resource cpu=250m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod kube-controller-manager-docker-desktop requesting resource cpu=200m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod kube-proxy-tzb5b requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod kube-scheduler-docker-desktop requesting resource cpu=100m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod sonobuoy requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod sonobuoy-e2e-job-ad77c8f3bad64e56 requesting resource cpu=0m on Node docker-desktop
Jun 26 13:48:54.804: INFO: Pod sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k requesting resource cpu=0m on Node docker-desktop
STEP: Starting Pods to consume most of the cluster CPU.
Jun 26 13:48:54.804: INFO: Creating a pod which consumes cpu=3675m on Node docker-desktop
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9.161c1c29fb0d3a95], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2214/filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9 to docker-desktop]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9.161c1c2a21b383ad], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.2" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9.161c1c2a247a5a70], Reason = [Created], Message = [Created container filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9.161c1c2a2c65bdbf], Reason = [Started], Message = [Started container filler-pod-b01004d1-86e9-42fb-8784-cd8c8472d5e9]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.161c1c2a73092e8a], Reason = [FailedScheduling], Message = [0/1 nodes are available: 1 Insufficient cpu.]
STEP: removing the label node off the node docker-desktop
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:48:57.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2214" for this suite.
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:82
•{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","total":276,"completed":179,"skipped":2994,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:48:57.846: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-6ebd0011-3fca-4aca-b69b-e20b2956b3e4
STEP: Creating a pod to test consume secrets
Jun 26 13:48:57.891: INFO: Waiting up to 5m0s for pod "pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295" in namespace "secrets-480" to be "Succeeded or Failed"
Jun 26 13:48:57.905: INFO: Pod "pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295": Phase="Pending", Reason="", readiness=false. Elapsed: 13.970485ms
Jun 26 13:48:59.909: INFO: Pod "pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017981063s
STEP: Saw pod success
Jun 26 13:48:59.909: INFO: Pod "pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295" satisfied condition "Succeeded or Failed"
Jun 26 13:48:59.911: INFO: Trying to get logs from node docker-desktop pod pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295 container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:48:59.932: INFO: Waiting for pod pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295 to disappear
Jun 26 13:48:59.935: INFO: Pod pod-secrets-5e329d26-d9d2-421c-8c2f-0ca73baa7295 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:48:59.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-480" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":180,"skipped":3013,"failed":0}
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:48:59.944: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:48:59.991: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 26 13:49:02.008: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun 26 13:49:04.012: INFO: Creating deployment "test-rollover-deployment"
Jun 26 13:49:04.021: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun 26 13:49:06.028: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun 26 13:49:06.033: INFO: Ensure that both replica sets have 1 created replica
Jun 26 13:49:06.038: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun 26 13:49:06.046: INFO: Updating deployment test-rollover-deployment
Jun 26 13:49:06.046: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun 26 13:49:08.056: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun 26 13:49:08.062: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun 26 13:49:08.066: INFO: all replica sets need to contain the pod-template-hash label
Jun 26 13:49:08.066: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:49:10.073: INFO: all replica sets need to contain the pod-template-hash label
Jun 26 13:49:10.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:49:12.072: INFO: all replica sets need to contain the pod-template-hash label
Jun 26 13:49:12.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:49:14.073: INFO: all replica sets need to contain the pod-template-hash label
Jun 26 13:49:14.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:49:16.072: INFO: all replica sets need to contain the pod-template-hash label
Jun 26 13:49:16.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776147, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776144, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-84f7f6f64b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 13:49:18.072: INFO: 
Jun 26 13:49:18.072: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Jun 26 13:49:18.079: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4953 /apis/apps/v1/namespaces/deployment-4953/deployments/test-rollover-deployment daf6dbf0-6382-48d5-86f4-0c2a2a75aba5 20175 2 2020-06-26 13:49:04 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  [{e2e.test Update apps/v1 2020-06-26 13:49:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 13:49:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005497978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-26 13:49:04 +0000 UTC,LastTransitionTime:2020-06-26 13:49:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-84f7f6f64b" has successfully progressed.,LastUpdateTime:2020-06-26 13:49:17 +0000 UTC,LastTransitionTime:2020-06-26 13:49:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jun 26 13:49:18.082: INFO: New ReplicaSet "test-rollover-deployment-84f7f6f64b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-84f7f6f64b  deployment-4953 /apis/apps/v1/namespaces/deployment-4953/replicasets/test-rollover-deployment-84f7f6f64b 3da5a8cb-6251-4ba8-8de7-42ea503be385 20164 2 2020-06-26 13:49:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment daf6dbf0-6382-48d5-86f4-0c2a2a75aba5 0xc00545a017 0xc00545a018}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:49:17 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 97 102 54 100 98 102 48 45 54 51 56 50 45 52 56 100 53 45 56 54 102 52 45 48 99 50 97 50 97 55 53 97 98 97 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 84f7f6f64b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00545a0a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:49:18.082: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun 26 13:49:18.082: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4953 /apis/apps/v1/namespaces/deployment-4953/replicasets/test-rollover-controller dfec9ef3-b24f-4f57-a1d3-e2f6cf70a103 20174 2 2020-06-26 13:48:59 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment daf6dbf0-6382-48d5-86f4-0c2a2a75aba5 0xc005497dc7 0xc005497dc8}] []  [{e2e.test Update apps/v1 2020-06-26 13:48:59 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 13:49:17 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 97 102 54 100 98 102 48 45 54 51 56 50 45 52 56 100 53 45 56 54 102 52 45 48 99 50 97 50 97 55 53 97 98 97 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005497e98 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:49:18.083: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-5686c4cfd5  deployment-4953 /apis/apps/v1/namespaces/deployment-4953/replicasets/test-rollover-deployment-5686c4cfd5 1589a788-91b5-4b4b-aeeb-dee732ec54c7 20128 2 2020-06-26 13:49:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment daf6dbf0-6382-48d5-86f4-0c2a2a75aba5 0xc005497f07 0xc005497f08}] []  [{kube-controller-manager Update apps/v1 2020-06-26 13:49:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 100 97 102 54 100 98 102 48 45 54 51 56 50 45 52 56 100 53 45 56 54 102 52 45 48 99 50 97 50 97 55 53 97 98 97 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 109 105 110 82 101 97 100 121 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 114 101 100 105 115 45 115 108 97 118 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 5686c4cfd5,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:5686c4cfd5] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005497fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 13:49:18.085: INFO: Pod "test-rollover-deployment-84f7f6f64b-thj84" is available:
&Pod{ObjectMeta:{test-rollover-deployment-84f7f6f64b-thj84 test-rollover-deployment-84f7f6f64b- deployment-4953 /api/v1/namespaces/deployment-4953/pods/test-rollover-deployment-84f7f6f64b-thj84 838f1155-16d0-467c-a93d-991de646b881 20139 0 2020-06-26 13:49:06 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:84f7f6f64b] map[] [{apps/v1 ReplicaSet test-rollover-deployment-84f7f6f64b 3da5a8cb-6251-4ba8-8de7-42ea503be385 0xc00545a687 0xc00545a688}] []  [{kube-controller-manager Update v1 2020-06-26 13:49:06 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 51 100 97 53 97 56 99 98 45 54 50 53 49 45 52 98 97 56 45 56 100 101 55 45 52 50 101 97 53 48 51 98 101 51 56 53 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 13:49:07 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 49 46 52 55 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-vr8zc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-vr8zc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-vr8zc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:49:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:49:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:49:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 13:49:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.47,StartTime:2020-06-26 13:49:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 13:49:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://31779b2d6b11d35a35e65677d892e792940dc1ede4ea79a5c22baff4be8e0de0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.1.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:49:18.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4953" for this suite.

• [SLOW TEST:18.148 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","total":276,"completed":181,"skipped":3014,"failed":0}
SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:49:18.092: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Jun 26 13:49:18.122: INFO: PodSpec: initContainers in spec.initContainers
Jun 26 13:49:59.090: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-575d59b0-df96-43fa-a54c-17a16e928247", GenerateName:"", Namespace:"init-container-6820", SelfLink:"/api/v1/namespaces/init-container-6820/pods/pod-init-575d59b0-df96-43fa-a54c-17a16e928247", UID:"efabbdfa-ec53-4520-a58d-5c01e69a982e", ResourceVersion:"20337", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63728776158, loc:(*time.Location)(0x7b52220)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"122352102"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0020be220), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0020be240)}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:(*v1.Time)(0xc0020be260), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0020be2a0)}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-fghdk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006561e00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fghdk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fghdk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.2", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-fghdk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0021d53f8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"docker-desktop", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002f50a80), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021d5490)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0021d54b0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0021d54b8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0021d54bc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776158, loc:(*time.Location)(0x7b52220)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776158, loc:(*time.Location)(0x7b52220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776158, loc:(*time.Location)(0x7b52220)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776158, loc:(*time.Location)(0x7b52220)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"192.168.65.3", PodIP:"10.1.1.48", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.1.1.48"}}, StartTime:(*v1.Time)(0xc0020be2e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f50b60)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002f50bd0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ce59816478ba8db2989582f8e18f74155f570234224db5bfba52f099993be610", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0020be3a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0020be320), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.2", ImageID:"", ContainerID:"", Started:(*bool)(0xc0021d553f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:49:59.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6820" for this suite.

• [SLOW TEST:41.007 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","total":276,"completed":182,"skipped":3021,"failed":0}
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:49:59.100: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:01.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2426" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","total":276,"completed":183,"skipped":3021,"failed":0}
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:01.148: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-b51d3c53-7673-466b-b7f3-e3dbc15c61bb
STEP: Creating a pod to test consume configMaps
Jun 26 13:50:01.181: INFO: Waiting up to 5m0s for pod "pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109" in namespace "configmap-3450" to be "Succeeded or Failed"
Jun 26 13:50:01.183: INFO: Pod "pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109": Phase="Pending", Reason="", readiness=false. Elapsed: 1.712987ms
Jun 26 13:50:03.186: INFO: Pod "pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00492953s
STEP: Saw pod success
Jun 26 13:50:03.187: INFO: Pod "pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109" satisfied condition "Succeeded or Failed"
Jun 26 13:50:03.189: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:50:03.206: INFO: Waiting for pod pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109 to disappear
Jun 26 13:50:03.209: INFO: Pod pod-configmaps-4c1165bb-0685-488f-8d9d-0e9281144109 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:03.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3450" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":184,"skipped":3022,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:03.218: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-521d94bb-a57a-45ce-ab3d-ed8b6c71b643
STEP: Creating a pod to test consume secrets
Jun 26 13:50:03.255: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5" in namespace "projected-3248" to be "Succeeded or Failed"
Jun 26 13:50:03.258: INFO: Pod "pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.965063ms
Jun 26 13:50:05.267: INFO: Pod "pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012179827s
STEP: Saw pod success
Jun 26 13:50:05.268: INFO: Pod "pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5" satisfied condition "Succeeded or Failed"
Jun 26 13:50:05.270: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 26 13:50:05.287: INFO: Waiting for pod pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5 to disappear
Jun 26 13:50:05.292: INFO: Pod pod-projected-secrets-117cf147-1c18-4761-aab7-d57dc46d1aa5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:05.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3248" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":185,"skipped":3042,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:05.301: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 26 13:50:05.333: INFO: Waiting up to 5m0s for pod "pod-1f033238-517e-44d1-ac9c-eb4fe488804c" in namespace "emptydir-9771" to be "Succeeded or Failed"
Jun 26 13:50:05.342: INFO: Pod "pod-1f033238-517e-44d1-ac9c-eb4fe488804c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.810689ms
Jun 26 13:50:07.344: INFO: Pod "pod-1f033238-517e-44d1-ac9c-eb4fe488804c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011670018s
STEP: Saw pod success
Jun 26 13:50:07.344: INFO: Pod "pod-1f033238-517e-44d1-ac9c-eb4fe488804c" satisfied condition "Succeeded or Failed"
Jun 26 13:50:07.347: INFO: Trying to get logs from node docker-desktop pod pod-1f033238-517e-44d1-ac9c-eb4fe488804c container test-container: <nil>
STEP: delete the pod
Jun 26 13:50:07.362: INFO: Waiting for pod pod-1f033238-517e-44d1-ac9c-eb4fe488804c to disappear
Jun 26 13:50:07.365: INFO: Pod pod-1f033238-517e-44d1-ac9c-eb4fe488804c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:07.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9771" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":186,"skipped":3043,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:07.374: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:50:09.431: INFO: Waiting up to 5m0s for pod "client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f" in namespace "pods-5179" to be "Succeeded or Failed"
Jun 26 13:50:09.434: INFO: Pod "client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.389854ms
Jun 26 13:50:11.438: INFO: Pod "client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007377044s
STEP: Saw pod success
Jun 26 13:50:11.438: INFO: Pod "client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f" satisfied condition "Succeeded or Failed"
Jun 26 13:50:11.442: INFO: Trying to get logs from node docker-desktop pod client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f container env3cont: <nil>
STEP: delete the pod
Jun 26 13:50:11.462: INFO: Waiting for pod client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f to disappear
Jun 26 13:50:11.464: INFO: Pod client-envvars-f1075fb3-5b6a-41df-97c6-7392de7cd42f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:11.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5179" for this suite.
•{"msg":"PASSED [k8s.io] Pods should contain environment variables for services [NodeConformance] [Conformance]","total":276,"completed":187,"skipped":3121,"failed":0}
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:11.470: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Jun 26 13:50:11.497: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:14.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2770" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","total":276,"completed":188,"skipped":3126,"failed":0}
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:14.620: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-6997/configmap-test-142c824c-ccb5-470f-9104-6abce189dd1b
STEP: Creating a pod to test consume configMaps
Jun 26 13:50:14.655: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca" in namespace "configmap-6997" to be "Succeeded or Failed"
Jun 26 13:50:14.661: INFO: Pod "pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.512356ms
Jun 26 13:50:16.673: INFO: Pod "pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017301099s
STEP: Saw pod success
Jun 26 13:50:16.673: INFO: Pod "pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca" satisfied condition "Succeeded or Failed"
Jun 26 13:50:16.678: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca container env-test: <nil>
STEP: delete the pod
Jun 26 13:50:16.704: INFO: Waiting for pod pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca to disappear
Jun 26 13:50:16.711: INFO: Pod pod-configmaps-ba3c0297-d52f-4a43-b930-cfc932da21ca no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:16.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6997" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","total":276,"completed":189,"skipped":3127,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:16.730: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:22.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3705" for this suite.

• [SLOW TEST:6.068 seconds]
[sig-apps] Job
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","total":276,"completed":190,"skipped":3139,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:22.799: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:50:22.832: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe" in namespace "downward-api-821" to be "Succeeded or Failed"
Jun 26 13:50:22.837: INFO: Pod "downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.759195ms
Jun 26 13:50:24.842: INFO: Pod "downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009622621s
STEP: Saw pod success
Jun 26 13:50:24.842: INFO: Pod "downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe" satisfied condition "Succeeded or Failed"
Jun 26 13:50:24.847: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe container client-container: <nil>
STEP: delete the pod
Jun 26 13:50:24.865: INFO: Waiting for pod downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe to disappear
Jun 26 13:50:24.870: INFO: Pod downwardapi-volume-d45a7a6d-da77-47c0-816c-87f5a5531abe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:24.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-821" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","total":276,"completed":191,"skipped":3170,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:24.878: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-8903e179-21c4-492c-8769-60f0e225f834
STEP: Creating a pod to test consume configMaps
Jun 26 13:50:24.911: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d" in namespace "projected-5170" to be "Succeeded or Failed"
Jun 26 13:50:24.914: INFO: Pod "pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.723737ms
Jun 26 13:50:26.918: INFO: Pod "pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006693675s
STEP: Saw pod success
Jun 26 13:50:26.918: INFO: Pod "pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d" satisfied condition "Succeeded or Failed"
Jun 26 13:50:26.921: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:50:26.937: INFO: Waiting for pod pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d to disappear
Jun 26 13:50:26.939: INFO: Pod pod-projected-configmaps-22fcb985-af2e-4cb9-a42f-53444a4f135d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:26.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5170" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","total":276,"completed":192,"skipped":3198,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:26.946: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:50:26.980: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 13:50:28.983: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:30.983: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:32.989: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:34.983: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:36.985: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:38.983: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:40.985: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:42.983: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:44.984: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = false)
Jun 26 13:50:46.984: INFO: The status of Pod test-webserver-21340675-72de-4229-8ef0-4c5d79e1f100 is Running (Ready = true)
Jun 26 13:50:46.986: INFO: Container started at 2020-06-26 13:50:27 +0000 UTC, pod became ready at 2020-06-26 13:50:45 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:46.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9863" for this suite.

• [SLOW TEST:20.045 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","total":276,"completed":193,"skipped":3209,"failed":0}
SS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:46.994: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:49.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1372" for this suite.
•{"msg":"PASSED [k8s.io] Docker Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","total":276,"completed":194,"skipped":3211,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:49.055: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 26 13:50:49.095: INFO: Waiting up to 5m0s for pod "pod-a4677ac9-aa2a-4f34-9028-d8386a69b259" in namespace "emptydir-1895" to be "Succeeded or Failed"
Jun 26 13:50:49.102: INFO: Pod "pod-a4677ac9-aa2a-4f34-9028-d8386a69b259": Phase="Pending", Reason="", readiness=false. Elapsed: 7.333169ms
Jun 26 13:50:51.105: INFO: Pod "pod-a4677ac9-aa2a-4f34-9028-d8386a69b259": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01036637s
STEP: Saw pod success
Jun 26 13:50:51.105: INFO: Pod "pod-a4677ac9-aa2a-4f34-9028-d8386a69b259" satisfied condition "Succeeded or Failed"
Jun 26 13:50:51.109: INFO: Trying to get logs from node docker-desktop pod pod-a4677ac9-aa2a-4f34-9028-d8386a69b259 container test-container: <nil>
STEP: delete the pod
Jun 26 13:50:51.130: INFO: Waiting for pod pod-a4677ac9-aa2a-4f34-9028-d8386a69b259 to disappear
Jun 26 13:50:51.134: INFO: Pod pod-a4677ac9-aa2a-4f34-9028-d8386a69b259 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:50:51.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1895" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":195,"skipped":3237,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:50:51.143: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:07.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7892" for this suite.

• [SLOW TEST:16.105 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","total":276,"completed":196,"skipped":3268,"failed":0}
S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:07.249: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 26 13:51:11.798: INFO: Successfully updated pod "pod-update-8ab254c0-06e5-4404-bd0a-9120f1e70434"
STEP: verifying the updated pod is in kubernetes
Jun 26 13:51:11.805: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:11.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6670" for this suite.
•{"msg":"PASSED [k8s.io] Pods should be updated [NodeConformance] [Conformance]","total":276,"completed":197,"skipped":3269,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:11.812: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-e614f35f-c651-4bc9-a05d-19f15777f822
STEP: Creating a pod to test consume secrets
Jun 26 13:51:11.844: INFO: Waiting up to 5m0s for pod "pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c" in namespace "secrets-2927" to be "Succeeded or Failed"
Jun 26 13:51:11.846: INFO: Pod "pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.491748ms
Jun 26 13:51:13.850: INFO: Pod "pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006347456s
STEP: Saw pod success
Jun 26 13:51:13.850: INFO: Pod "pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c" satisfied condition "Succeeded or Failed"
Jun 26 13:51:13.852: INFO: Trying to get logs from node docker-desktop pod pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c container secret-env-test: <nil>
STEP: delete the pod
Jun 26 13:51:13.868: INFO: Waiting for pod pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c to disappear
Jun 26 13:51:13.871: INFO: Pod pod-secrets-9c0718a1-3703-4637-9080-101fdcbb795c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:13.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2927" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","total":276,"completed":198,"skipped":3311,"failed":0}
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:13.877: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:51:14.538: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 26 13:51:16.546: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776274, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776274, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776274, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776274, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:51:19.561: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Jun 26 13:51:21.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 attach --namespace=webhook-7858 to-be-attached-pod -i -c=container1'
Jun 26 13:51:21.771: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:21.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7858" for this suite.
STEP: Destroying namespace "webhook-7858-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:7.949 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","total":276,"completed":199,"skipped":3332,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:21.828: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:51:22.210: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:51:25.230: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:51:25.234: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1084-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:26.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4902" for this suite.
STEP: Destroying namespace "webhook-4902-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","total":276,"completed":200,"skipped":3354,"failed":0}
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:26.460: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 26 13:51:26.506: INFO: Waiting up to 5m0s for pod "pod-f05471a8-f22b-4005-abdf-9bdd2241697b" in namespace "emptydir-9782" to be "Succeeded or Failed"
Jun 26 13:51:26.510: INFO: Pod "pod-f05471a8-f22b-4005-abdf-9bdd2241697b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.994231ms
Jun 26 13:51:28.514: INFO: Pod "pod-f05471a8-f22b-4005-abdf-9bdd2241697b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007384267s
STEP: Saw pod success
Jun 26 13:51:28.514: INFO: Pod "pod-f05471a8-f22b-4005-abdf-9bdd2241697b" satisfied condition "Succeeded or Failed"
Jun 26 13:51:28.516: INFO: Trying to get logs from node docker-desktop pod pod-f05471a8-f22b-4005-abdf-9bdd2241697b container test-container: <nil>
STEP: delete the pod
Jun 26 13:51:28.538: INFO: Waiting for pod pod-f05471a8-f22b-4005-abdf-9bdd2241697b to disappear
Jun 26 13:51:28.540: INFO: Pod pod-f05471a8-f22b-4005-abdf-9bdd2241697b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:28.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9782" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":201,"skipped":3359,"failed":0}
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:28.550: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:153
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
Jun 26 13:51:28.587: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:31.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1836" for this suite.
•{"msg":"PASSED [k8s.io] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","total":276,"completed":202,"skipped":3360,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:31.563: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 26 13:51:31.621: INFO: Waiting up to 5m0s for pod "pod-52f9cf91-8f1f-4928-91af-66e219e3266e" in namespace "emptydir-4695" to be "Succeeded or Failed"
Jun 26 13:51:31.635: INFO: Pod "pod-52f9cf91-8f1f-4928-91af-66e219e3266e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.557487ms
Jun 26 13:51:33.637: INFO: Pod "pod-52f9cf91-8f1f-4928-91af-66e219e3266e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015958034s
STEP: Saw pod success
Jun 26 13:51:33.637: INFO: Pod "pod-52f9cf91-8f1f-4928-91af-66e219e3266e" satisfied condition "Succeeded or Failed"
Jun 26 13:51:33.639: INFO: Trying to get logs from node docker-desktop pod pod-52f9cf91-8f1f-4928-91af-66e219e3266e container test-container: <nil>
STEP: delete the pod
Jun 26 13:51:33.657: INFO: Waiting for pod pod-52f9cf91-8f1f-4928-91af-66e219e3266e to disappear
Jun 26 13:51:33.659: INFO: Pod pod-52f9cf91-8f1f-4928-91af-66e219e3266e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:51:33.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4695" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":203,"skipped":3385,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:51:33.667: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:51:33.699: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Creating first CR 
Jun 26 13:51:34.274: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:34Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:51:34Z]] name:name1 resourceVersion:21341 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4b6d898f-fc71-4e67-aedd-ce880ed76df6] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Jun 26 13:51:44.279: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:44Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:51:44Z]] name:name2 resourceVersion:21395 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cb4cf8f8-76d3-4d81-885d-6f3247f46eb1] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Jun 26 13:51:54.286: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:51:54Z]] name:name1 resourceVersion:21420 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4b6d898f-fc71-4e67-aedd-ce880ed76df6] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Jun 26 13:52:04.291: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:52:04Z]] name:name2 resourceVersion:21443 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cb4cf8f8-76d3-4d81-885d-6f3247f46eb1] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Jun 26 13:52:14.305: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:34Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:51:54Z]] name:name1 resourceVersion:21466 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4b6d898f-fc71-4e67-aedd-ce880ed76df6] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Jun 26 13:52:24.315: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-26T13:51:44Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2020-06-26T13:52:04Z]] name:name2 resourceVersion:21489 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cb4cf8f8-76d3-4d81-885d-6f3247f46eb1] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:52:34.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-4574" for this suite.

• [SLOW TEST:61.162 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","total":276,"completed":204,"skipped":3398,"failed":0}
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:52:34.831: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:38
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:52:36.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7546" for this suite.
•{"msg":"PASSED [k8s.io] Kubelet when scheduling a busybox Pod with hostAliases should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":205,"skipped":3400,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:52:36.883: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Jun 26 13:52:36.907: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Jun 26 13:52:45.793: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:52:48.515: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:52:59.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6106" for this suite.

• [SLOW TEST:22.138 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","total":276,"completed":206,"skipped":3434,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:52:59.023: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-downwardapi-vc4q
STEP: Creating a pod to test atomic-volume-subpath
Jun 26 13:52:59.073: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-vc4q" in namespace "subpath-4720" to be "Succeeded or Failed"
Jun 26 13:52:59.078: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Pending", Reason="", readiness=false. Elapsed: 3.928656ms
Jun 26 13:53:01.081: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 2.00729586s
Jun 26 13:53:03.086: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 4.0123481s
Jun 26 13:53:05.089: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 6.015452317s
Jun 26 13:53:07.093: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 8.019053756s
Jun 26 13:53:09.096: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 10.022511759s
Jun 26 13:53:11.099: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 12.025443761s
Jun 26 13:53:13.103: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 14.029519612s
Jun 26 13:53:15.107: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 16.033864957s
Jun 26 13:53:17.111: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 18.03693368s
Jun 26 13:53:19.115: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Running", Reason="", readiness=true. Elapsed: 20.040269106s
Jun 26 13:53:21.118: INFO: Pod "pod-subpath-test-downwardapi-vc4q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.043256965s
STEP: Saw pod success
Jun 26 13:53:21.118: INFO: Pod "pod-subpath-test-downwardapi-vc4q" satisfied condition "Succeeded or Failed"
Jun 26 13:53:21.120: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-downwardapi-vc4q container test-container-subpath-downwardapi-vc4q: <nil>
STEP: delete the pod
Jun 26 13:53:21.139: INFO: Waiting for pod pod-subpath-test-downwardapi-vc4q to disappear
Jun 26 13:53:21.152: INFO: Pod pod-subpath-test-downwardapi-vc4q no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-vc4q
Jun 26 13:53:21.152: INFO: Deleting pod "pod-subpath-test-downwardapi-vc4q" in namespace "subpath-4720"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:21.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4720" for this suite.

• [SLOW TEST:22.137 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [LinuxOnly] [Conformance]","total":276,"completed":207,"skipped":3457,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:21.160: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:32.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-626" for this suite.

• [SLOW TEST:11.070 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","total":276,"completed":208,"skipped":3473,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:32.230: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 13:53:32.259: INFO: (0) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 4.856676ms)
Jun 26 13:53:32.262: INFO: (1) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.77508ms)
Jun 26 13:53:32.264: INFO: (2) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.551771ms)
Jun 26 13:53:32.267: INFO: (3) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.548117ms)
Jun 26 13:53:32.269: INFO: (4) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.107475ms)
Jun 26 13:53:32.271: INFO: (5) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.322352ms)
Jun 26 13:53:32.274: INFO: (6) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.669139ms)
Jun 26 13:53:32.276: INFO: (7) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.056138ms)
Jun 26 13:53:32.278: INFO: (8) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.862179ms)
Jun 26 13:53:32.280: INFO: (9) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.26044ms)
Jun 26 13:53:32.284: INFO: (10) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.19058ms)
Jun 26 13:53:32.286: INFO: (11) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.192978ms)
Jun 26 13:53:32.288: INFO: (12) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.162369ms)
Jun 26 13:53:32.290: INFO: (13) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.28572ms)
Jun 26 13:53:32.292: INFO: (14) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 1.881674ms)
Jun 26 13:53:32.295: INFO: (15) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.287274ms)
Jun 26 13:53:32.297: INFO: (16) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.175184ms)
Jun 26 13:53:32.300: INFO: (17) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 3.001395ms)
Jun 26 13:53:32.303: INFO: (18) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.753728ms)
Jun 26 13:53:32.305: INFO: (19) /api/v1/nodes/docker-desktop:10250/proxy/logs/: <pre>
<a href="containers/">containers/</a>
<a href="pods/">pods/</a>
</pre>
 (200; 2.6528ms)
[AfterEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:32.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2990" for this suite.
•{"msg":"PASSED [sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]","total":276,"completed":209,"skipped":3486,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:32.312: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:53:32.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d" in namespace "downward-api-2263" to be "Succeeded or Failed"
Jun 26 13:53:32.343: INFO: Pod "downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093295ms
Jun 26 13:53:34.347: INFO: Pod "downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007696736s
STEP: Saw pod success
Jun 26 13:53:34.347: INFO: Pod "downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d" satisfied condition "Succeeded or Failed"
Jun 26 13:53:34.349: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d container client-container: <nil>
STEP: delete the pod
Jun 26 13:53:34.368: INFO: Waiting for pod downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d to disappear
Jun 26 13:53:34.372: INFO: Pod downwardapi-volume-fe25520e-2df1-459c-9077-e02e6ea5684d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:34.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2263" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":210,"skipped":3546,"failed":0}
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:34.382: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 26 13:53:36.926: INFO: Successfully updated pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324"
Jun 26 13:53:36.926: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324" in namespace "pods-4185" to be "terminated due to deadline exceeded"
Jun 26 13:53:36.929: INFO: Pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324": Phase="Running", Reason="", readiness=true. Elapsed: 2.840875ms
Jun 26 13:53:38.933: INFO: Pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324": Phase="Running", Reason="", readiness=true. Elapsed: 2.006922268s
Jun 26 13:53:40.936: INFO: Pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009839044s
Jun 26 13:53:40.936: INFO: Pod "pod-update-activedeadlineseconds-06a8ea7a-e704-4f05-ab64-1c5e42d11324" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:40.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4185" for this suite.

• [SLOW TEST:6.560 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","total":276,"completed":211,"skipped":3564,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:40.943: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-632
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 26 13:53:40.973: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jun 26 13:53:40.992: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 13:53:42.995: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:44.995: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:46.997: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:48.999: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:50.995: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:52.995: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:54.996: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 13:53:56.996: INFO: The status of Pod netserver-0 is Running (Ready = true)
STEP: Creating test pods
Jun 26 13:53:59.043: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.1.1.84:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-632 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 13:53:59.043: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 13:53:59.164: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:53:59.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-632" for this suite.

• [SLOW TEST:18.230 seconds]
[sig-network] Networking
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":212,"skipped":3592,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:53:59.174: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-e3d0f667-ba3a-4e27-86f8-73354447c033
STEP: Creating a pod to test consume configMaps
Jun 26 13:53:59.214: INFO: Waiting up to 5m0s for pod "pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a" in namespace "configmap-1056" to be "Succeeded or Failed"
Jun 26 13:53:59.228: INFO: Pod "pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.554553ms
Jun 26 13:54:01.234: INFO: Pod "pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019778335s
STEP: Saw pod success
Jun 26 13:54:01.234: INFO: Pod "pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a" satisfied condition "Succeeded or Failed"
Jun 26 13:54:01.236: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:54:01.254: INFO: Waiting for pod pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a to disappear
Jun 26 13:54:01.257: INFO: Pod pod-configmaps-41109c02-75cf-4bbb-86b9-d56e2b8ebf5a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:01.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1056" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":276,"completed":213,"skipped":3602,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:01.268: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-a52d958d-c89e-45e8-85eb-5ec995312711
STEP: Creating a pod to test consume configMaps
Jun 26 13:54:01.353: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a" in namespace "projected-8898" to be "Succeeded or Failed"
Jun 26 13:54:01.362: INFO: Pod "pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.062134ms
Jun 26 13:54:03.365: INFO: Pod "pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012067553s
STEP: Saw pod success
Jun 26 13:54:03.365: INFO: Pod "pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a" satisfied condition "Succeeded or Failed"
Jun 26 13:54:03.367: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:54:03.383: INFO: Waiting for pod pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a to disappear
Jun 26 13:54:03.390: INFO: Pod pod-projected-configmaps-d5435d56-b081-4215-a1ab-1de77a44466a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:03.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8898" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","total":276,"completed":214,"skipped":3631,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:03.397: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:54:03.421: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c" in namespace "projected-6333" to be "Succeeded or Failed"
Jun 26 13:54:03.423: INFO: Pod "downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.59412ms
Jun 26 13:54:05.426: INFO: Pod "downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004522822s
Jun 26 13:54:07.429: INFO: Pod "downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007926403s
STEP: Saw pod success
Jun 26 13:54:07.429: INFO: Pod "downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c" satisfied condition "Succeeded or Failed"
Jun 26 13:54:07.431: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c container client-container: <nil>
STEP: delete the pod
Jun 26 13:54:07.448: INFO: Waiting for pod downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c to disappear
Jun 26 13:54:07.453: INFO: Pod downwardapi-volume-3ef898da-2817-4823-b950-541301e5aa4c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:07.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6333" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":215,"skipped":3677,"failed":0}
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:07.460: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward api env vars
Jun 26 13:54:07.495: INFO: Waiting up to 5m0s for pod "downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683" in namespace "downward-api-9400" to be "Succeeded or Failed"
Jun 26 13:54:07.498: INFO: Pod "downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683": Phase="Pending", Reason="", readiness=false. Elapsed: 3.238555ms
Jun 26 13:54:09.503: INFO: Pod "downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007792828s
STEP: Saw pod success
Jun 26 13:54:09.503: INFO: Pod "downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683" satisfied condition "Succeeded or Failed"
Jun 26 13:54:09.505: INFO: Trying to get logs from node docker-desktop pod downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683 container dapi-container: <nil>
STEP: delete the pod
Jun 26 13:54:09.530: INFO: Waiting for pod downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683 to disappear
Jun 26 13:54:09.534: INFO: Pod downward-api-dfbde81a-38b7-49a5-aef3-3435c7b71683 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:09.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9400" for this suite.
•{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","total":276,"completed":216,"skipped":3684,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:09.545: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service endpoint-test2 in namespace services-9384
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9384 to expose endpoints map[]
Jun 26 13:54:09.588: INFO: Get endpoints failed (3.500202ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun 26 13:54:10.592: INFO: successfully validated that service endpoint-test2 in namespace services-9384 exposes endpoints map[] (1.006897762s elapsed)
STEP: Creating pod pod1 in namespace services-9384
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9384 to expose endpoints map[pod1:[80]]
Jun 26 13:54:12.618: INFO: successfully validated that service endpoint-test2 in namespace services-9384 exposes endpoints map[pod1:[80]] (2.01949334s elapsed)
STEP: Creating pod pod2 in namespace services-9384
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9384 to expose endpoints map[pod1:[80] pod2:[80]]
Jun 26 13:54:16.672: INFO: Unexpected endpoints: found map[35bc4fcf-5619-484d-91fb-9a10e26817d1:[80]], expected map[pod1:[80] pod2:[80]] (4.048143934s elapsed, will retry)
Jun 26 13:54:17.680: INFO: successfully validated that service endpoint-test2 in namespace services-9384 exposes endpoints map[pod1:[80] pod2:[80]] (5.056174073s elapsed)
STEP: Deleting pod pod1 in namespace services-9384
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9384 to expose endpoints map[pod2:[80]]
Jun 26 13:54:18.699: INFO: successfully validated that service endpoint-test2 in namespace services-9384 exposes endpoints map[pod2:[80]] (1.015640542s elapsed)
STEP: Deleting pod pod2 in namespace services-9384
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9384 to expose endpoints map[]
Jun 26 13:54:18.709: INFO: successfully validated that service endpoint-test2 in namespace services-9384 exposes endpoints map[] (3.93933ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:18.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9384" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:9.189 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","total":276,"completed":217,"skipped":3710,"failed":0}
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:18.735: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-map-8d1e4c35-3380-4043-b10e-faa1d8dfd4a8
STEP: Creating a pod to test consume configMaps
Jun 26 13:54:18.764: INFO: Waiting up to 5m0s for pod "pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb" in namespace "configmap-7124" to be "Succeeded or Failed"
Jun 26 13:54:18.769: INFO: Pod "pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.993718ms
Jun 26 13:54:20.784: INFO: Pod "pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019368483s
STEP: Saw pod success
Jun 26 13:54:20.784: INFO: Pod "pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb" satisfied condition "Succeeded or Failed"
Jun 26 13:54:20.786: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:54:20.799: INFO: Waiting for pod pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb to disappear
Jun 26 13:54:20.804: INFO: Pod pod-configmaps-eef67226-c960-4cf8-8b46-7afd166330fb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:20.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7124" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":218,"skipped":3710,"failed":0}
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:20.813: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 13:54:20.838: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10" in namespace "downward-api-1539" to be "Succeeded or Failed"
Jun 26 13:54:20.842: INFO: Pod "downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10": Phase="Pending", Reason="", readiness=false. Elapsed: 3.752682ms
Jun 26 13:54:22.845: INFO: Pod "downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006999263s
STEP: Saw pod success
Jun 26 13:54:22.845: INFO: Pod "downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10" satisfied condition "Succeeded or Failed"
Jun 26 13:54:22.849: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10 container client-container: <nil>
STEP: delete the pod
Jun 26 13:54:22.866: INFO: Waiting for pod downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10 to disappear
Jun 26 13:54:22.870: INFO: Pod downwardapi-volume-bb17d430-8331-4c03-8fcc-ed84c1bb1b10 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:22.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1539" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","total":276,"completed":219,"skipped":3712,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:22.885: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:54:23.276: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:54:26.294: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:54:38.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5694" for this suite.
STEP: Destroying namespace "webhook-5694-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:15.557 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","total":276,"completed":220,"skipped":3738,"failed":0}
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:54:38.441: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:84
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:99
STEP: Creating service test in namespace statefulset-9017
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a new StatefulSet
Jun 26 13:54:38.488: INFO: Found 0 stateful pods, waiting for 3
Jun 26 13:54:48.492: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:54:48.492: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:54:48.492: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 26 13:54:48.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9017 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:54:48.668: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:54:48.668: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:54:48.668: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Jun 26 13:54:58.696: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 26 13:55:08.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9017 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:55:08.876: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:55:08.877: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:55:08.877: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:55:18.893: INFO: Waiting for StatefulSet statefulset-9017/ss2 to complete update
Jun 26 13:55:18.893: INFO: Waiting for Pod statefulset-9017/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:55:18.893: INFO: Waiting for Pod statefulset-9017/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:55:18.893: INFO: Waiting for Pod statefulset-9017/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:55:28.899: INFO: Waiting for StatefulSet statefulset-9017/ss2 to complete update
Jun 26 13:55:28.899: INFO: Waiting for Pod statefulset-9017/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 26 13:55:28.899: INFO: Waiting for Pod statefulset-9017/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Jun 26 13:55:38.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9017 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 26 13:55:39.117: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 26 13:55:39.117: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 26 13:55:39.117: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 26 13:55:49.147: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 26 13:55:59.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 exec --namespace=statefulset-9017 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 26 13:55:59.320: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 26 13:55:59.320: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 26 13:55:59.320: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 26 13:56:19.337: INFO: Waiting for StatefulSet statefulset-9017/ss2 to complete update
Jun 26 13:56:19.337: INFO: Waiting for Pod statefulset-9017/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:110
Jun 26 13:56:29.344: INFO: Deleting all statefulset in ns statefulset-9017
Jun 26 13:56:29.346: INFO: Scaling statefulset ss2 to 0
Jun 26 13:57:09.359: INFO: Waiting for statefulset status.replicas updated to 0
Jun 26 13:57:09.363: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:57:09.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9017" for this suite.

• [SLOW TEST:150.938 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","total":276,"completed":221,"skipped":3744,"failed":0}
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:57:09.384: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name s-test-opt-del-705376e0-12d7-4c39-9795-b49ce92afbd1
STEP: Creating secret with name s-test-opt-upd-e98a9643-eb7b-4a05-9220-bb9fb637e6cc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-705376e0-12d7-4c39-9795-b49ce92afbd1
STEP: Updating secret s-test-opt-upd-e98a9643-eb7b-4a05-9220-bb9fb637e6cc
STEP: Creating secret with name s-test-opt-create-c82699e3-f53d-4707-9fb1-0c4820262b76
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:58:39.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8425" for this suite.

• [SLOW TEST:90.527 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":222,"skipped":3754,"failed":0}
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:58:39.913: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-projected-kf7v
STEP: Creating a pod to test atomic-volume-subpath
Jun 26 13:58:39.944: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-kf7v" in namespace "subpath-1396" to be "Succeeded or Failed"
Jun 26 13:58:39.946: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Pending", Reason="", readiness=false. Elapsed: 1.716466ms
Jun 26 13:58:41.950: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 2.006276085s
Jun 26 13:58:43.953: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 4.009554729s
Jun 26 13:58:45.958: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 6.014617686s
Jun 26 13:58:47.964: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 8.019369389s
Jun 26 13:58:49.967: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 10.02262954s
Jun 26 13:58:51.971: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 12.026409249s
Jun 26 13:58:53.975: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 14.030613029s
Jun 26 13:58:55.981: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 16.036206444s
Jun 26 13:58:57.985: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 18.040526686s
Jun 26 13:58:59.990: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Running", Reason="", readiness=true. Elapsed: 20.045690511s
Jun 26 13:59:01.995: INFO: Pod "pod-subpath-test-projected-kf7v": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.050684843s
STEP: Saw pod success
Jun 26 13:59:01.995: INFO: Pod "pod-subpath-test-projected-kf7v" satisfied condition "Succeeded or Failed"
Jun 26 13:59:01.997: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-projected-kf7v container test-container-subpath-projected-kf7v: <nil>
STEP: delete the pod
Jun 26 13:59:02.013: INFO: Waiting for pod pod-subpath-test-projected-kf7v to disappear
Jun 26 13:59:02.017: INFO: Pod pod-subpath-test-projected-kf7v no longer exists
STEP: Deleting pod pod-subpath-test-projected-kf7v
Jun 26 13:59:02.017: INFO: Deleting pod "pod-subpath-test-projected-kf7v" in namespace "subpath-1396"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:02.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1396" for this suite.

• [SLOW TEST:22.112 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [LinuxOnly] [Conformance]","total":276,"completed":223,"skipped":3754,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:02.027: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:02.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3964" for this suite.
•{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","total":276,"completed":224,"skipped":3781,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:02.066: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: set up a multi version CRD
Jun 26 13:59:02.082: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:13.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2459" for this suite.

• [SLOW TEST:11.817 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","total":276,"completed":225,"skipped":3816,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:13.883: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-zmh28 in namespace proxy-24
I0626 13:59:13.912295      24 runners.go:190] Created replication controller with name: proxy-service-zmh28, namespace: proxy-24, replica count: 1
I0626 13:59:14.963109      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:15.963841      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:16.965165      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:17.965524      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:18.965827      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:19.966170      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0626 13:59:20.966731      24 runners.go:190] proxy-service-zmh28 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 26 13:59:20.968: INFO: setup took 7.068078138s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 26 13:59:20.972: INFO: (0) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 2.717239ms)
Jun 26 13:59:20.974: INFO: (0) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 5.002579ms)
Jun 26 13:59:20.975: INFO: (0) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 5.096227ms)
Jun 26 13:59:20.975: INFO: (0) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 5.224237ms)
Jun 26 13:59:20.977: INFO: (0) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 7.47599ms)
Jun 26 13:59:20.977: INFO: (0) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.402039ms)
Jun 26 13:59:20.978: INFO: (0) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.323311ms)
Jun 26 13:59:20.978: INFO: (0) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.965799ms)
Jun 26 13:59:20.978: INFO: (0) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.964096ms)
Jun 26 13:59:20.980: INFO: (0) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 10.761099ms)
Jun 26 13:59:20.981: INFO: (0) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 11.760177ms)
Jun 26 13:59:20.989: INFO: (0) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 19.247957ms)
Jun 26 13:59:20.989: INFO: (0) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 19.29265ms)
Jun 26 13:59:20.989: INFO: (0) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 19.254314ms)
Jun 26 13:59:20.989: INFO: (0) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 19.19372ms)
Jun 26 13:59:20.989: INFO: (0) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 19.31663ms)
Jun 26 13:59:20.994: INFO: (1) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 5.1676ms)
Jun 26 13:59:20.997: INFO: (1) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.712896ms)
Jun 26 13:59:20.997: INFO: (1) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.036569ms)
Jun 26 13:59:20.997: INFO: (1) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.158324ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 8.471586ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.633559ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 8.517336ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 8.612778ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 8.654435ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 8.897554ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.164149ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 9.163972ms)
Jun 26 13:59:20.998: INFO: (1) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 9.525211ms)
Jun 26 13:59:20.999: INFO: (1) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 10.152696ms)
Jun 26 13:59:20.999: INFO: (1) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 10.062116ms)
Jun 26 13:59:20.999: INFO: (1) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 10.256844ms)
Jun 26 13:59:21.004: INFO: (2) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 3.310448ms)
Jun 26 13:59:21.009: INFO: (2) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 8.110982ms)
Jun 26 13:59:21.010: INFO: (2) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 10.021973ms)
Jun 26 13:59:21.011: INFO: (2) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 10.22389ms)
Jun 26 13:59:21.011: INFO: (2) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 11.526966ms)
Jun 26 13:59:21.012: INFO: (2) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 11.229604ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 29.839226ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 29.871096ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 30.012362ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 29.774389ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 30.074916ms)
Jun 26 13:59:21.030: INFO: (2) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 30.062281ms)
Jun 26 13:59:21.031: INFO: (2) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 29.958214ms)
Jun 26 13:59:21.031: INFO: (2) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 30.049634ms)
Jun 26 13:59:21.031: INFO: (2) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 29.905856ms)
Jun 26 13:59:21.031: INFO: (2) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 30.086269ms)
Jun 26 13:59:21.043: INFO: (3) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 12.262078ms)
Jun 26 13:59:21.043: INFO: (3) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 12.423165ms)
Jun 26 13:59:21.044: INFO: (3) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 12.93385ms)
Jun 26 13:59:21.044: INFO: (3) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 13.061364ms)
Jun 26 13:59:21.044: INFO: (3) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 13.540894ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 13.73097ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 13.927242ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 13.910285ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 13.961312ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 14.067291ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 14.040813ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 14.020492ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 14.353083ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 14.488598ms)
Jun 26 13:59:21.045: INFO: (3) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 14.35012ms)
Jun 26 13:59:21.046: INFO: (3) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 14.967394ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 10.556647ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 11.248714ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 11.318799ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 11.222288ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 11.579581ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 11.833965ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 11.404558ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 10.816928ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 11.540255ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 11.048602ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 10.951214ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 10.905861ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 11.022683ms)
Jun 26 13:59:21.057: INFO: (4) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 11.194762ms)
Jun 26 13:59:21.058: INFO: (4) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 11.541486ms)
Jun 26 13:59:21.058: INFO: (4) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 11.222888ms)
Jun 26 13:59:21.063: INFO: (5) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 5.203998ms)
Jun 26 13:59:21.063: INFO: (5) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 5.502359ms)
Jun 26 13:59:21.063: INFO: (5) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 5.320543ms)
Jun 26 13:59:21.064: INFO: (5) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.1379ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.743961ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.344878ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 6.759326ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.535ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.010534ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.952509ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 4.558313ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.630314ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.430359ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 7.635146ms)
Jun 26 13:59:21.065: INFO: (5) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.373134ms)
Jun 26 13:59:21.067: INFO: (5) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 8.702985ms)
Jun 26 13:59:21.074: INFO: (6) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 5.892761ms)
Jun 26 13:59:21.074: INFO: (6) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.283149ms)
Jun 26 13:59:21.074: INFO: (6) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 7.350504ms)
Jun 26 13:59:21.074: INFO: (6) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 6.086989ms)
Jun 26 13:59:21.075: INFO: (6) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.084648ms)
Jun 26 13:59:21.075: INFO: (6) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.214166ms)
Jun 26 13:59:21.075: INFO: (6) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.160353ms)
Jun 26 13:59:21.075: INFO: (6) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.274185ms)
Jun 26 13:59:21.076: INFO: (6) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.662234ms)
Jun 26 13:59:21.076: INFO: (6) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 8.941216ms)
Jun 26 13:59:21.076: INFO: (6) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.608498ms)
Jun 26 13:59:21.076: INFO: (6) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 9.202479ms)
Jun 26 13:59:21.078: INFO: (6) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 9.786431ms)
Jun 26 13:59:21.078: INFO: (6) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 10.899965ms)
Jun 26 13:59:21.078: INFO: (6) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 10.141337ms)
Jun 26 13:59:21.078: INFO: (6) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 11.438132ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.897714ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.775795ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.958451ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.785552ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 7.88535ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 7.843872ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 7.879415ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 8.187133ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 7.957233ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.938039ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.021075ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 8.123874ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 7.924649ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.905914ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.951269ms)
Jun 26 13:59:21.087: INFO: (7) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.943862ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 6.744005ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.934406ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.131166ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.906393ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.15031ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.018593ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 7.022865ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.085003ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.957465ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 7.022791ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.063135ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.092465ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.078219ms)
Jun 26 13:59:21.094: INFO: (8) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.172106ms)
Jun 26 13:59:21.095: INFO: (8) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 8.523333ms)
Jun 26 13:59:21.096: INFO: (8) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 8.969203ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 6.609004ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 6.733002ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.030893ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 6.817463ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.00807ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.565297ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.722877ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.969984ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.934676ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.768586ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.959305ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 6.671189ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.741074ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 6.689022ms)
Jun 26 13:59:21.103: INFO: (9) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.419197ms)
Jun 26 13:59:21.104: INFO: (9) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.547936ms)
Jun 26 13:59:21.106: INFO: (10) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 2.34912ms)
Jun 26 13:59:21.106: INFO: (10) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 2.61995ms)
Jun 26 13:59:21.106: INFO: (10) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 2.376993ms)
Jun 26 13:59:21.109: INFO: (10) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 4.25347ms)
Jun 26 13:59:21.109: INFO: (10) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 4.704691ms)
Jun 26 13:59:21.109: INFO: (10) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 4.708258ms)
Jun 26 13:59:21.110: INFO: (10) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 5.174984ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.298451ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 6.261806ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.314786ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.961788ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.326152ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 6.522636ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 6.605195ms)
Jun 26 13:59:21.111: INFO: (10) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.798307ms)
Jun 26 13:59:21.112: INFO: (10) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.339315ms)
Jun 26 13:59:21.117: INFO: (11) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 4.617029ms)
Jun 26 13:59:21.117: INFO: (11) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 4.901145ms)
Jun 26 13:59:21.117: INFO: (11) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 4.831792ms)
Jun 26 13:59:21.117: INFO: (11) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 4.849851ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.767632ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.849996ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.839211ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 8.181397ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.299628ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 8.043422ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 7.914822ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.031047ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 8.285386ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.932457ms)
Jun 26 13:59:21.120: INFO: (11) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 8.279721ms)
Jun 26 13:59:21.122: INFO: (11) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 9.697774ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 6.271836ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.388355ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.505703ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 8.120429ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 8.043902ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.942538ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.316471ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.850451ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 6.591555ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 8.273539ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.79341ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 8.501186ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.889997ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 6.711956ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 6.628131ms)
Jun 26 13:59:21.130: INFO: (12) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 6.615813ms)
Jun 26 13:59:21.139: INFO: (13) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.571076ms)
Jun 26 13:59:21.139: INFO: (13) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 8.043257ms)
Jun 26 13:59:21.139: INFO: (13) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 8.028843ms)
Jun 26 13:59:21.139: INFO: (13) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 8.118343ms)
Jun 26 13:59:21.139: INFO: (13) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 8.530298ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 11.274976ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 11.235926ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 11.376166ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 11.305242ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 11.430965ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 11.379254ms)
Jun 26 13:59:21.143: INFO: (13) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 11.929062ms)
Jun 26 13:59:21.143: INFO: (13) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 12.02796ms)
Jun 26 13:59:21.143: INFO: (13) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 12.032846ms)
Jun 26 13:59:21.143: INFO: (13) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 12.081887ms)
Jun 26 13:59:21.142: INFO: (13) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 11.316048ms)
Jun 26 13:59:21.150: INFO: (14) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 6.563055ms)
Jun 26 13:59:21.150: INFO: (14) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 6.561794ms)
Jun 26 13:59:21.150: INFO: (14) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.529363ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 6.993506ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 5.258306ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 6.906259ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.075642ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.943032ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.900102ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.538831ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.078912ms)
Jun 26 13:59:21.150: INFO: (14) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.790862ms)
Jun 26 13:59:21.150: INFO: (14) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.654064ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.176767ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.550903ms)
Jun 26 13:59:21.151: INFO: (14) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 7.17562ms)
Jun 26 13:59:21.156: INFO: (15) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 4.745622ms)
Jun 26 13:59:21.156: INFO: (15) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 4.795134ms)
Jun 26 13:59:21.156: INFO: (15) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 4.665996ms)
Jun 26 13:59:21.156: INFO: (15) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 4.922188ms)
Jun 26 13:59:21.158: INFO: (15) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.676991ms)
Jun 26 13:59:21.158: INFO: (15) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 6.84485ms)
Jun 26 13:59:21.158: INFO: (15) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 6.943065ms)
Jun 26 13:59:21.158: INFO: (15) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.766304ms)
Jun 26 13:59:21.158: INFO: (15) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 6.998141ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 7.122625ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 7.128513ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.444145ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.255212ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.637502ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.493083ms)
Jun 26 13:59:21.159: INFO: (15) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.789566ms)
Jun 26 13:59:21.164: INFO: (16) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 4.557536ms)
Jun 26 13:59:21.164: INFO: (16) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 4.870011ms)
Jun 26 13:59:21.164: INFO: (16) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 5.159756ms)
Jun 26 13:59:21.165: INFO: (16) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 5.444549ms)
Jun 26 13:59:21.166: INFO: (16) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.211379ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 8.616335ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 8.718648ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 9.051246ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 8.704089ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 8.680934ms)
Jun 26 13:59:21.168: INFO: (16) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 8.723687ms)
Jun 26 13:59:21.169: INFO: (16) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 9.181215ms)
Jun 26 13:59:21.169: INFO: (16) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 9.244526ms)
Jun 26 13:59:21.169: INFO: (16) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 9.218857ms)
Jun 26 13:59:21.169: INFO: (16) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 9.131523ms)
Jun 26 13:59:21.169: INFO: (16) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 9.101303ms)
Jun 26 13:59:21.173: INFO: (17) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 4.267199ms)
Jun 26 13:59:21.173: INFO: (17) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 4.336991ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 6.508412ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 6.55833ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.862315ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.824626ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 6.575421ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.141521ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 6.889592ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 6.594477ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 7.052269ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.961594ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.212134ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.842796ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 6.753601ms)
Jun 26 13:59:21.176: INFO: (17) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 6.713263ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 5.966326ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 5.985849ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 5.962723ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 5.954693ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.016438ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 5.987849ms)
Jun 26 13:59:21.183: INFO: (18) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 6.534531ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 7.284268ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.425034ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.328971ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 7.413813ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.327508ms)
Jun 26 13:59:21.184: INFO: (18) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 7.531036ms)
Jun 26 13:59:21.185: INFO: (18) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 8.734206ms)
Jun 26 13:59:21.185: INFO: (18) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 8.753269ms)
Jun 26 13:59:21.185: INFO: (18) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 8.668244ms)
Jun 26 13:59:21.190: INFO: (19) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">te... (200; 4.434775ms)
Jun 26 13:59:21.192: INFO: (19) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 6.156603ms)
Jun 26 13:59:21.192: INFO: (19) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:460/proxy/: tls baz (200; 6.198947ms)
Jun 26 13:59:21.192: INFO: (19) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:443/proxy/tlsrewriteme"... (200; 6.212927ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/pods/https:proxy-service-zmh28-9gm8j:462/proxy/: tls qux (200; 6.740654ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j/proxy/rewriteme">test</a> (200; 7.071303ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 7.695945ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/pods/http:proxy-service-zmh28-9gm8j:160/proxy/: foo (200; 7.352548ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname2/proxy/: tls qux (200; 7.622451ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname1/proxy/: foo (200; 7.664907ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/: <a href="/api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:1080/proxy/rewriteme">test</a... (200; 7.624512ms)
Jun 26 13:59:21.194: INFO: (19) /api/v1/namespaces/proxy-24/services/proxy-service-zmh28:portname2/proxy/: bar (200; 7.818995ms)
Jun 26 13:59:21.193: INFO: (19) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname1/proxy/: foo (200; 7.647497ms)
Jun 26 13:59:21.194: INFO: (19) /api/v1/namespaces/proxy-24/pods/proxy-service-zmh28-9gm8j:162/proxy/: bar (200; 8.159092ms)
Jun 26 13:59:21.194: INFO: (19) /api/v1/namespaces/proxy-24/services/https:proxy-service-zmh28:tlsportname1/proxy/: tls baz (200; 8.219623ms)
Jun 26 13:59:21.196: INFO: (19) /api/v1/namespaces/proxy-24/services/http:proxy-service-zmh28:portname2/proxy/: bar (200; 9.754195ms)
STEP: deleting ReplicationController proxy-service-zmh28 in namespace proxy-24, will wait for the garbage collector to delete the pods
Jun 26 13:59:21.254: INFO: Deleting ReplicationController proxy-service-zmh28 took: 5.842196ms
Jun 26 13:59:21.755: INFO: Terminating ReplicationController proxy-service-zmh28 pods took: 500.372676ms
[AfterEach] version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:23.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-24" for this suite.

• [SLOW TEST:9.979 seconds]
[sig-network] Proxy
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:59
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","total":276,"completed":226,"skipped":3835,"failed":0}
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:23.863: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-f1e59dec-dc0d-42c3-beaa-bac23e065bf0
STEP: Creating a pod to test consume configMaps
Jun 26 13:59:23.890: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251" in namespace "projected-9157" to be "Succeeded or Failed"
Jun 26 13:59:23.892: INFO: Pod "pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251": Phase="Pending", Reason="", readiness=false. Elapsed: 1.789678ms
Jun 26 13:59:25.896: INFO: Pod "pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005903801s
STEP: Saw pod success
Jun 26 13:59:25.896: INFO: Pod "pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251" satisfied condition "Succeeded or Failed"
Jun 26 13:59:25.899: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 13:59:25.915: INFO: Waiting for pod pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251 to disappear
Jun 26 13:59:25.917: INFO: Pod pod-projected-configmaps-450fa97f-097f-4a76-89fd-f110091ad251 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:25.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9157" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":276,"completed":227,"skipped":3839,"failed":0}
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:25.926: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Starting the proxy
Jun 26 13:59:25.944: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-107382027 proxy --unix-socket=/tmp/kubectl-proxy-unix265819078/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:26.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4926" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","total":276,"completed":228,"skipped":3845,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:26.006: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 13:59:26.494: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 13:59:29.512: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 13:59:29.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1197" for this suite.
STEP: Destroying namespace "webhook-1197-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","total":276,"completed":229,"skipped":3877,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 13:59:29.617: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Jun 26 14:00:09.680: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:00:09.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0626 14:00:09.680490      24 metrics_grabber.go:84] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8604" for this suite.

• [SLOW TEST:40.068 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","total":276,"completed":230,"skipped":3921,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:00:09.686: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:00:14.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7788" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","total":276,"completed":231,"skipped":3952,"failed":0}
SSSSSSSS
------------------------------
[sig-network] DNS 
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:00:14.394: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3460 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3460;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3460 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3460;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3460.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3460.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3460.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3460.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3460.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3460.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3460.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 250.98.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.98.250_udp@PTR;check="$$(dig +tcp +noall +answer +search 250.98.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.98.250_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3460 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3460;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3460 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3460;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3460.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3460.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3460.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3460.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3460.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3460.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3460.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3460.svc;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3460.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 250.98.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.98.250_udp@PTR;check="$$(dig +tcp +noall +answer +search 250.98.97.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.97.98.250_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 26 14:00:18.455: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.459: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.461: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.464: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.466: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.469: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.472: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.475: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.492: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.493: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.498: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.500: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.502: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.504: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.506: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.510: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:18.532: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:23.536: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.540: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.543: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.546: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.548: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.551: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.552: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.555: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.570: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.573: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.575: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.577: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.579: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.581: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.583: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.586: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:23.598: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:28.536: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.538: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.543: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.547: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.550: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.552: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.572: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.574: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.578: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.581: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.583: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.585: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.588: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.590: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:28.604: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:33.536: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.539: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.541: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.543: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.547: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.550: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.552: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.568: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.570: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.572: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.574: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.575: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.577: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.579: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.581: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:33.591: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:38.539: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.542: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.547: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.550: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.553: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.555: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.557: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.571: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.574: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.578: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.581: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.583: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.585: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.587: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.590: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:38.610: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:43.536: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.539: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.546: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.549: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.551: INFO: Unable to read wheezy_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.553: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.557: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.559: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.573: INFO: Unable to read jessie_udp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.575: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.577: INFO: Unable to read jessie_udp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.578: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460 from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.581: INFO: Unable to read jessie_udp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.582: INFO: Unable to read jessie_tcp@dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.584: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.585: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc from pod dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806: the server could not find the requested resource (get pods dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806)
Jun 26 14:00:43.595: INFO: Lookups using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-3460 wheezy_tcp@dns-test-service.dns-3460 wheezy_udp@dns-test-service.dns-3460.svc wheezy_tcp@dns-test-service.dns-3460.svc wheezy_udp@_http._tcp.dns-test-service.dns-3460.svc wheezy_tcp@_http._tcp.dns-test-service.dns-3460.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-3460 jessie_tcp@dns-test-service.dns-3460 jessie_udp@dns-test-service.dns-3460.svc jessie_tcp@dns-test-service.dns-3460.svc jessie_udp@_http._tcp.dns-test-service.dns-3460.svc jessie_tcp@_http._tcp.dns-test-service.dns-3460.svc]

Jun 26 14:00:48.590: INFO: DNS probes using dns-3460/dns-test-e8310d59-0ee8-4a62-9b9d-4f395c5e8806 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:00:48.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3460" for this suite.

• [SLOW TEST:34.328 seconds]
[sig-network] DNS
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","total":276,"completed":232,"skipped":3960,"failed":0}
SSSSSSS
------------------------------
[sig-network] DNS 
  should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:00:48.724: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support configurable pod DNS nameservers [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig...
Jun 26 14:00:48.769: INFO: Created pod &Pod{ObjectMeta:{dns-4156  dns-4156 /api/v1/namespaces/dns-4156/pods/dns-4156 5a2df62e-f19a-4749-b042-6d2e54552e98 24168 0 2020-06-26 14:00:48 +0000 UTC <nil> <nil> map[] map[] [] []  [{e2e.test Update v1 2020-06-26 14:00:48 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 114 103 115 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 67 111 110 102 105 103 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 115 101 114 118 101 114 115 34 58 123 125 44 34 102 58 115 101 97 114 99 104 101 115 34 58 123 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-c9tm5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-c9tm5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-c9tm5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 26 14:00:48.789: INFO: The status of Pod dns-4156 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 14:00:50.791: INFO: The status of Pod dns-4156 is Running (Ready = true)
STEP: Verifying customized DNS suffix list is configured on pod...
Jun 26 14:00:50.792: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-4156 PodName:dns-4156 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 14:00:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Verifying customized DNS server is configured on pod...
Jun 26 14:00:50.898: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-4156 PodName:dns-4156 ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 14:00:50.898: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 14:00:50.992: INFO: Deleting pod dns-4156...
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:00:51.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4156" for this suite.
•{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","total":276,"completed":233,"skipped":3967,"failed":0}
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:00:51.010: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[BeforeEach] Update Demo
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:271
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a replication controller
Jun 26 14:00:51.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-4961'
Jun 26 14:00:51.247: INFO: stderr: ""
Jun 26 14:00:51.247: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 26 14:00:51.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:00:51.339: INFO: stderr: ""
Jun 26 14:00:51.339: INFO: stdout: "update-demo-nautilus-kdshc update-demo-nautilus-vmgpl "
Jun 26 14:00:51.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-kdshc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:00:51.400: INFO: stderr: ""
Jun 26 14:00:51.400: INFO: stdout: ""
Jun 26 14:00:51.400: INFO: update-demo-nautilus-kdshc is created but not running
Jun 26 14:00:56.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:00:56.482: INFO: stderr: ""
Jun 26 14:00:56.482: INFO: stdout: "update-demo-nautilus-kdshc update-demo-nautilus-vmgpl "
Jun 26 14:00:56.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-kdshc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:00:56.553: INFO: stderr: ""
Jun 26 14:00:56.553: INFO: stdout: "true"
Jun 26 14:00:56.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-kdshc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:00:56.618: INFO: stderr: ""
Jun 26 14:00:56.618: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 14:00:56.618: INFO: validating pod update-demo-nautilus-kdshc
Jun 26 14:00:56.622: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 14:00:56.622: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 14:00:56.622: INFO: update-demo-nautilus-kdshc is verified up and running
Jun 26 14:00:56.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:00:56.685: INFO: stderr: ""
Jun 26 14:00:56.685: INFO: stdout: "true"
Jun 26 14:00:56.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:00:56.754: INFO: stderr: ""
Jun 26 14:00:56.754: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 14:00:56.754: INFO: validating pod update-demo-nautilus-vmgpl
Jun 26 14:00:56.757: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 14:00:56.757: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 14:00:56.757: INFO: update-demo-nautilus-vmgpl is verified up and running
STEP: scaling down the replication controller
Jun 26 14:00:56.759: INFO: scanned /root for discovery docs: <nil>
Jun 26 14:00:56.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4961'
Jun 26 14:00:57.852: INFO: stderr: ""
Jun 26 14:00:57.852: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 26 14:00:57.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:00:57.928: INFO: stderr: ""
Jun 26 14:00:57.928: INFO: stdout: "update-demo-nautilus-kdshc update-demo-nautilus-vmgpl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 26 14:01:02.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:01:03.002: INFO: stderr: ""
Jun 26 14:01:03.002: INFO: stdout: "update-demo-nautilus-kdshc update-demo-nautilus-vmgpl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 26 14:01:08.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:01:08.081: INFO: stderr: ""
Jun 26 14:01:08.081: INFO: stdout: "update-demo-nautilus-kdshc update-demo-nautilus-vmgpl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 26 14:01:13.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:01:13.155: INFO: stderr: ""
Jun 26 14:01:13.156: INFO: stdout: "update-demo-nautilus-vmgpl "
Jun 26 14:01:13.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:13.226: INFO: stderr: ""
Jun 26 14:01:13.226: INFO: stdout: "true"
Jun 26 14:01:13.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:13.290: INFO: stderr: ""
Jun 26 14:01:13.290: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 14:01:13.290: INFO: validating pod update-demo-nautilus-vmgpl
Jun 26 14:01:13.293: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 14:01:13.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 14:01:13.293: INFO: update-demo-nautilus-vmgpl is verified up and running
STEP: scaling up the replication controller
Jun 26 14:01:13.294: INFO: scanned /root for discovery docs: <nil>
Jun 26 14:01:13.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4961'
Jun 26 14:01:13.388: INFO: stderr: ""
Jun 26 14:01:13.388: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 26 14:01:13.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:01:13.463: INFO: stderr: ""
Jun 26 14:01:13.463: INFO: stdout: "update-demo-nautilus-8c6zq update-demo-nautilus-vmgpl "
Jun 26 14:01:13.463: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-8c6zq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:13.522: INFO: stderr: ""
Jun 26 14:01:13.523: INFO: stdout: ""
Jun 26 14:01:13.523: INFO: update-demo-nautilus-8c6zq is created but not running
Jun 26 14:01:18.525: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4961'
Jun 26 14:01:18.601: INFO: stderr: ""
Jun 26 14:01:18.601: INFO: stdout: "update-demo-nautilus-8c6zq update-demo-nautilus-vmgpl "
Jun 26 14:01:18.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-8c6zq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:18.661: INFO: stderr: ""
Jun 26 14:01:18.661: INFO: stdout: "true"
Jun 26 14:01:18.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-8c6zq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:18.722: INFO: stderr: ""
Jun 26 14:01:18.722: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 14:01:18.722: INFO: validating pod update-demo-nautilus-8c6zq
Jun 26 14:01:18.726: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 14:01:18.726: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 14:01:18.726: INFO: update-demo-nautilus-8c6zq is verified up and running
Jun 26 14:01:18.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:18.791: INFO: stderr: ""
Jun 26 14:01:18.791: INFO: stdout: "true"
Jun 26 14:01:18.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods update-demo-nautilus-vmgpl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4961'
Jun 26 14:01:18.853: INFO: stderr: ""
Jun 26 14:01:18.853: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 26 14:01:18.853: INFO: validating pod update-demo-nautilus-vmgpl
Jun 26 14:01:18.857: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 26 14:01:18.857: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 26 14:01:18.857: INFO: update-demo-nautilus-vmgpl is verified up and running
STEP: using delete to clean up resources
Jun 26 14:01:18.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 delete --grace-period=0 --force -f - --namespace=kubectl-4961'
Jun 26 14:01:18.920: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 26 14:01:18.921: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 26 14:01:18.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4961'
Jun 26 14:01:18.995: INFO: stderr: "No resources found in kubectl-4961 namespace.\n"
Jun 26 14:01:18.995: INFO: stdout: ""
Jun 26 14:01:18.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -l name=update-demo --namespace=kubectl-4961 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 26 14:01:19.057: INFO: stderr: ""
Jun 26 14:01:19.057: INFO: stdout: "update-demo-nautilus-8c6zq\nupdate-demo-nautilus-vmgpl\n"
Jun 26 14:01:19.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4961'
Jun 26 14:01:19.641: INFO: stderr: "No resources found in kubectl-4961 namespace.\n"
Jun 26 14:01:19.641: INFO: stdout: ""
Jun 26 14:01:19.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 get pods -l name=update-demo --namespace=kubectl-4961 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 26 14:01:19.712: INFO: stderr: ""
Jun 26 14:01:19.712: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:19.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4961" for this suite.

• [SLOW TEST:28.707 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:269
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","total":276,"completed":234,"skipped":3968,"failed":0}
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:19.718: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 14:01:20.178: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 14:01:23.200: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:01:23.204: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:24.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9980" for this suite.
STEP: Destroying namespace "webhook-9980-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","total":276,"completed":235,"skipped":3971,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:24.350: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap configmap-5968/configmap-test-439c0377-ebf1-415a-a733-c390c15f3017
STEP: Creating a pod to test consume configMaps
Jun 26 14:01:24.394: INFO: Waiting up to 5m0s for pod "pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb" in namespace "configmap-5968" to be "Succeeded or Failed"
Jun 26 14:01:24.398: INFO: Pod "pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.401962ms
Jun 26 14:01:26.401: INFO: Pod "pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007622804s
STEP: Saw pod success
Jun 26 14:01:26.402: INFO: Pod "pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb" satisfied condition "Succeeded or Failed"
Jun 26 14:01:26.403: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb container env-test: <nil>
STEP: delete the pod
Jun 26 14:01:26.421: INFO: Waiting for pod pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb to disappear
Jun 26 14:01:26.423: INFO: Pod pod-configmaps-d458e853-3f69-46d6-81dd-d656bfa473cb no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:26.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5968" for this suite.
•{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","total":276,"completed":236,"skipped":4034,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:26.429: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 14:01:27.052: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 14:01:30.067: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:30.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3740" for this suite.
STEP: Destroying namespace "webhook-3740-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","total":276,"completed":237,"skipped":4057,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:30.109: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 14:01:30.558: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 14:01:33.576: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:33.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5056" for this suite.
STEP: Destroying namespace "webhook-5056-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102
•{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","total":276,"completed":238,"skipped":4090,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:33.654: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating the pod
Jun 26 14:01:36.223: INFO: Successfully updated pod "labelsupdatec93fe919-a994-4707-873e-7468330bc4c9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:38.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8553" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","total":276,"completed":239,"skipped":4115,"failed":0}
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:38.246: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 14:01:38.269: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5" in namespace "projected-4433" to be "Succeeded or Failed"
Jun 26 14:01:38.272: INFO: Pod "downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.418983ms
Jun 26 14:01:40.276: INFO: Pod "downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007275354s
STEP: Saw pod success
Jun 26 14:01:40.276: INFO: Pod "downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5" satisfied condition "Succeeded or Failed"
Jun 26 14:01:40.278: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5 container client-container: <nil>
STEP: delete the pod
Jun 26 14:01:40.291: INFO: Waiting for pod downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5 to disappear
Jun 26 14:01:40.295: INFO: Pod downwardapi-volume-3af9d639-2f97-4996-bc77-8b0bc5a499b5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:40.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4433" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","total":276,"completed":240,"skipped":4119,"failed":0}
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:40.303: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:87
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 26 14:01:40.865: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Jun 26 14:01:42.874: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776900, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776900, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776900, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728776900, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-779fdc84d9\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 26 14:01:45.890: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:01:45.894: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3606-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:01:46.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9515" for this suite.
STEP: Destroying namespace "webhook-9515-markers" for this suite.
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:102

• [SLOW TEST:6.708 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","total":276,"completed":241,"skipped":4138,"failed":0}
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:01:47.013: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:134
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:01:47.042: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 26 14:01:47.052: INFO: Number of nodes with available pods: 0
Jun 26 14:01:47.052: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 14:01:48.059: INFO: Number of nodes with available pods: 0
Jun 26 14:01:48.059: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 14:01:49.058: INFO: Number of nodes with available pods: 1
Jun 26 14:01:49.058: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 26 14:01:49.075: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:50.083: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:51.081: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:52.081: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:52.081: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:53.082: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:53.082: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:54.081: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:54.081: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:55.085: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:55.085: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:56.082: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:56.082: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:57.084: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:57.084: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:58.083: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:58.083: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:01:59.083: INFO: Wrong image for pod: daemon-set-zlftb. Expected: us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12, got: docker.io/library/httpd:2.4.38-alpine.
Jun 26 14:01:59.083: INFO: Pod daemon-set-zlftb is not available
Jun 26 14:02:00.084: INFO: Pod daemon-set-mz24d is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 26 14:02:00.091: INFO: Number of nodes with available pods: 0
Jun 26 14:02:00.091: INFO: Node docker-desktop is running more than one daemon pod
Jun 26 14:02:01.098: INFO: Number of nodes with available pods: 1
Jun 26 14:02:01.098: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:100
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9582, will wait for the garbage collector to delete the pods
Jun 26 14:02:01.166: INFO: Deleting DaemonSet.extensions daemon-set took: 6.444225ms
Jun 26 14:02:01.267: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.766783ms
Jun 26 14:02:09.570: INFO: Number of nodes with available pods: 0
Jun 26 14:02:09.570: INFO: Number of running nodes: 0, number of available pods: 0
Jun 26 14:02:09.572: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9582/daemonsets","resourceVersion":"24882"},"items":null}

Jun 26 14:02:09.574: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9582/pods","resourceVersion":"24882"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:02:09.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9582" for this suite.

• [SLOW TEST:22.570 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","total":276,"completed":242,"skipped":4150,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:02:09.584: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:02:25.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8137" for this suite.

• [SLOW TEST:16.116 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","total":276,"completed":243,"skipped":4161,"failed":0}
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:02:25.702: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Performing setup for networking test in namespace pod-network-test-7055
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 26 14:02:25.724: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Jun 26 14:02:25.735: INFO: The status of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Jun 26 14:02:27.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:29.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:31.738: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:33.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:35.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:37.740: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:39.739: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:41.738: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:43.741: INFO: The status of Pod netserver-0 is Running (Ready = false)
Jun 26 14:02:45.738: INFO: The status of Pod netserver-0 is Running (Ready = true)
STEP: Creating test pods
Jun 26 14:02:47.757: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.1.1.137:8080/dial?request=hostname&protocol=udp&host=10.1.1.136&port=8081&tries=1'] Namespace:pod-network-test-7055 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 26 14:02:47.757: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
Jun 26 14:02:47.845: INFO: Waiting for responses: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:02:47.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7055" for this suite.

• [SLOW TEST:22.150 seconds]
[sig-network] Networking
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:26
  Granular Checks: Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:29
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","total":276,"completed":244,"skipped":4169,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:02:47.852: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-424c1862-e9c3-43d4-a048-566146233b84
STEP: Creating a pod to test consume configMaps
Jun 26 14:02:47.878: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e" in namespace "projected-9800" to be "Succeeded or Failed"
Jun 26 14:02:47.881: INFO: Pod "pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.109528ms
Jun 26 14:02:49.884: INFO: Pod "pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006429225s
STEP: Saw pod success
Jun 26 14:02:49.884: INFO: Pod "pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e" satisfied condition "Succeeded or Failed"
Jun 26 14:02:49.886: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 14:02:49.903: INFO: Waiting for pod pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e to disappear
Jun 26 14:02:49.905: INFO: Pod pod-projected-configmaps-b4fc93a3-b1b0-4a5b-aecf-0e1942254e1e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:02:49.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9800" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","total":276,"completed":245,"skipped":4198,"failed":0}
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:02:49.913: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:38
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod pod-subpath-test-configmap-2tk5
STEP: Creating a pod to test atomic-volume-subpath
Jun 26 14:02:49.952: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2tk5" in namespace "subpath-9568" to be "Succeeded or Failed"
Jun 26 14:02:49.953: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.443336ms
Jun 26 14:02:51.956: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 2.003979348s
Jun 26 14:02:53.959: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 4.006986999s
Jun 26 14:02:55.962: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 6.010478617s
Jun 26 14:02:57.967: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 8.015634449s
Jun 26 14:02:59.970: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 10.018403639s
Jun 26 14:03:01.974: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 12.022004505s
Jun 26 14:03:03.977: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 14.025399708s
Jun 26 14:03:05.981: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 16.029076472s
Jun 26 14:03:07.985: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 18.033414441s
Jun 26 14:03:09.989: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Running", Reason="", readiness=true. Elapsed: 20.037056396s
Jun 26 14:03:11.992: INFO: Pod "pod-subpath-test-configmap-2tk5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.040651035s
STEP: Saw pod success
Jun 26 14:03:11.992: INFO: Pod "pod-subpath-test-configmap-2tk5" satisfied condition "Succeeded or Failed"
Jun 26 14:03:11.995: INFO: Trying to get logs from node docker-desktop pod pod-subpath-test-configmap-2tk5 container test-container-subpath-configmap-2tk5: <nil>
STEP: delete the pod
Jun 26 14:03:12.010: INFO: Waiting for pod pod-subpath-test-configmap-2tk5 to disappear
Jun 26 14:03:12.011: INFO: Pod pod-subpath-test-configmap-2tk5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2tk5
Jun 26 14:03:12.011: INFO: Deleting pod "pod-subpath-test-configmap-2tk5" in namespace "subpath-9568"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:12.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9568" for this suite.

• [SLOW TEST:22.107 seconds]
[sig-storage] Subpath
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:34
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [LinuxOnly] [Conformance]","total":276,"completed":246,"skipped":4220,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:12.020: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 26 14:03:16.072: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:16.075: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:18.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:18.079: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:20.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:20.080: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:22.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:22.079: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:24.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:24.078: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:26.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:26.080: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:28.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:28.079: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 26 14:03:30.076: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 26 14:03:30.079: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:30.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8580" for this suite.

• [SLOW TEST:18.073 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  when create a pod with lifecycle hook
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","total":276,"completed":247,"skipped":4285,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:30.094: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-map-89f168ce-6af1-493c-be2b-e676704e262f
STEP: Creating a pod to test consume configMaps
Jun 26 14:03:30.122: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033" in namespace "projected-9087" to be "Succeeded or Failed"
Jun 26 14:03:30.123: INFO: Pod "pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033": Phase="Pending", Reason="", readiness=false. Elapsed: 1.458034ms
Jun 26 14:03:32.128: INFO: Pod "pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006065165s
STEP: Saw pod success
Jun 26 14:03:32.128: INFO: Pod "pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033" satisfied condition "Succeeded or Failed"
Jun 26 14:03:32.130: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 14:03:32.145: INFO: Waiting for pod pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033 to disappear
Jun 26 14:03:32.146: INFO: Pod pod-projected-configmaps-5fa92d29-90f3-4dd9-ae54-815c81027033 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:32.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9087" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":248,"skipped":4296,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:32.153: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:03:32.174: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 26 14:03:34.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-333 create -f -'
Jun 26 14:03:35.188: INFO: stderr: ""
Jun 26 14:03:35.188: INFO: stdout: "e2e-test-crd-publish-openapi-5165-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jun 26 14:03:35.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-333 delete e2e-test-crd-publish-openapi-5165-crds test-cr'
Jun 26 14:03:35.344: INFO: stderr: ""
Jun 26 14:03:35.344: INFO: stdout: "e2e-test-crd-publish-openapi-5165-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jun 26 14:03:35.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-333 apply -f -'
Jun 26 14:03:35.514: INFO: stderr: ""
Jun 26 14:03:35.515: INFO: stdout: "e2e-test-crd-publish-openapi-5165-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jun 26 14:03:35.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 --namespace=crd-publish-openapi-333 delete e2e-test-crd-publish-openapi-5165-crds test-cr'
Jun 26 14:03:35.626: INFO: stderr: ""
Jun 26 14:03:35.626: INFO: stdout: "e2e-test-crd-publish-openapi-5165-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jun 26 14:03:35.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 explain e2e-test-crd-publish-openapi-5165-crds'
Jun 26 14:03:35.741: INFO: stderr: ""
Jun 26 14:03:35.741: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5165-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:38.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-333" for this suite.

• [SLOW TEST:6.323 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","total":276,"completed":249,"skipped":4303,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:38.476: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-volume-5472eb4c-c107-49b9-9b1e-88fd040889ec
STEP: Creating a pod to test consume configMaps
Jun 26 14:03:38.497: INFO: Waiting up to 5m0s for pod "pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841" in namespace "configmap-5902" to be "Succeeded or Failed"
Jun 26 14:03:38.498: INFO: Pod "pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841": Phase="Pending", Reason="", readiness=false. Elapsed: 1.78071ms
Jun 26 14:03:40.505: INFO: Pod "pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008197121s
STEP: Saw pod success
Jun 26 14:03:40.505: INFO: Pod "pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841" satisfied condition "Succeeded or Failed"
Jun 26 14:03:40.510: INFO: Trying to get logs from node docker-desktop pod pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 14:03:40.527: INFO: Waiting for pod pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841 to disappear
Jun 26 14:03:40.529: INFO: Pod pod-configmaps-d062dfb9-9251-4c98-8cec-81c54c92d841 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:40.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5902" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","total":276,"completed":250,"skipped":4339,"failed":0}
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:40.538: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:42
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 14:03:40.569: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7" in namespace "projected-9268" to be "Succeeded or Failed"
Jun 26 14:03:40.575: INFO: Pod "downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.30244ms
Jun 26 14:03:42.586: INFO: Pod "downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016357387s
STEP: Saw pod success
Jun 26 14:03:42.586: INFO: Pod "downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7" satisfied condition "Succeeded or Failed"
Jun 26 14:03:42.588: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7 container client-container: <nil>
STEP: delete the pod
Jun 26 14:03:42.603: INFO: Waiting for pod downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7 to disappear
Jun 26 14:03:42.607: INFO: Pod downwardapi-volume-d4212792-b9f7-47d3-901a-1488f6fb95f7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:42.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9268" for this suite.
•{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","total":276,"completed":251,"skipped":4352,"failed":0}
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:42.614: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a2c6dafc-c328-4084-8f2d-aeb3efa7750e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a2c6dafc-c328-4084-8f2d-aeb3efa7750e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:48.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8661" for this suite.

• [SLOW TEST:6.094 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:36
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":252,"skipped":4354,"failed":0}
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:48.709: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:42
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test downward API volume plugin
Jun 26 14:03:48.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6" in namespace "downward-api-8528" to be "Succeeded or Failed"
Jun 26 14:03:48.753: INFO: Pod "downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.10055ms
Jun 26 14:03:50.757: INFO: Pod "downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01980632s
STEP: Saw pod success
Jun 26 14:03:50.757: INFO: Pod "downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6" satisfied condition "Succeeded or Failed"
Jun 26 14:03:50.759: INFO: Trying to get logs from node docker-desktop pod downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6 container client-container: <nil>
STEP: delete the pod
Jun 26 14:03:50.777: INFO: Waiting for pod downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6 to disappear
Jun 26 14:03:50.780: INFO: Pod downwardapi-volume-31f75de3-802c-4634-82a1-e869a30164e6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:50.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8528" for this suite.
•{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","total":276,"completed":253,"skipped":4357,"failed":0}
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:50.786: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 26 14:03:50.830: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8724 /api/v1/namespaces/watch-8724/configmaps/e2e-watch-test-resource-version a1ca6920-de99-48f7-a637-efb23d38fbaf 25464 0 2020-06-26 14:03:50 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-06-26 14:03:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Jun 26 14:03:50.831: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-8724 /api/v1/namespaces/watch-8724/configmaps/e2e-watch-test-resource-version a1ca6920-de99-48f7-a637-efb23d38fbaf 25465 0 2020-06-26 14:03:50 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  [{e2e.test Update v1 2020-06-26 14:03:50 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 100 97 116 97 34 58 123 34 46 34 58 123 125 44 34 102 58 109 117 116 97 116 105 111 110 34 58 123 125 125 44 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 119 97 116 99 104 45 116 104 105 115 45 99 111 110 102 105 103 109 97 112 34 58 123 125 125 125 125],}}]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:50.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8724" for this suite.
•{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","total":276,"completed":254,"skipped":4364,"failed":0}
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:50.838: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:03:56.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-1337" for this suite.
STEP: Destroying namespace "nsdeletetest-5859" for this suite.
Jun 26 14:03:56.934: INFO: Namespace nsdeletetest-5859 was already deleted
STEP: Destroying namespace "nsdeletetest-2388" for this suite.

• [SLOW TEST:6.100 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","total":276,"completed":255,"skipped":4366,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:03:56.939: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Jun 26 14:03:56.962: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Registering the sample API server.
Jun 26 14:03:57.317: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jun 26 14:03:59.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 14:04:01.368: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 14:04:03.369: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63728777037, loc:(*time.Location)(0x7b52220)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7996d54f97\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 26 14:04:06.001: INFO: Waited 619.897183ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:06.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1050" for this suite.

• [SLOW TEST:9.766 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","total":276,"completed":256,"skipped":4400,"failed":0}
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:06.705: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name configmap-test-upd-84c127e4-9b22-4a96-a89b-268dd8ca1df8
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:08.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1053" for this suite.
•{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","total":276,"completed":257,"skipped":4407,"failed":0}
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:08.777: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Jun 26 14:04:11.324: INFO: Successfully updated pod "adopt-release-wmvdw"
STEP: Checking that the Job readopts the Pod
Jun 26 14:04:11.324: INFO: Waiting up to 15m0s for pod "adopt-release-wmvdw" in namespace "job-3852" to be "adopted"
Jun 26 14:04:11.333: INFO: Pod "adopt-release-wmvdw": Phase="Running", Reason="", readiness=true. Elapsed: 9.447909ms
Jun 26 14:04:13.336: INFO: Pod "adopt-release-wmvdw": Phase="Running", Reason="", readiness=true. Elapsed: 2.012255882s
Jun 26 14:04:13.336: INFO: Pod "adopt-release-wmvdw" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Jun 26 14:04:13.852: INFO: Successfully updated pod "adopt-release-wmvdw"
STEP: Checking that the Job releases the Pod
Jun 26 14:04:13.852: INFO: Waiting up to 15m0s for pod "adopt-release-wmvdw" in namespace "job-3852" to be "released"
Jun 26 14:04:13.856: INFO: Pod "adopt-release-wmvdw": Phase="Running", Reason="", readiness=true. Elapsed: 3.932341ms
Jun 26 14:04:15.858: INFO: Pod "adopt-release-wmvdw": Phase="Running", Reason="", readiness=true. Elapsed: 2.006159655s
Jun 26 14:04:15.858: INFO: Pod "adopt-release-wmvdw" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:15.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3852" for this suite.

• [SLOW TEST:7.086 seconds]
[sig-apps] Job
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","total":276,"completed":258,"skipped":4421,"failed":0}
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:15.864: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:74
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:04:15.891: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun 26 14:04:15.897: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun 26 14:04:20.907: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 26 14:04:20.909: INFO: Creating deployment "test-rolling-update-deployment"
Jun 26 14:04:20.917: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun 26 14:04:20.930: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun 26 14:04:22.947: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun 26 14:04:22.951: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
Jun 26 14:04:22.961: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4006 /apis/apps/v1/namespaces/deployment-4006/deployments/test-rolling-update-deployment 539e7b41-2ded-4d40-b336-d5b893f447c8 25826 1 2020-06-26 14:04:20 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  [{e2e.test Update apps/v1 2020-06-26 14:04:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 112 114 111 103 114 101 115 115 68 101 97 100 108 105 110 101 83 101 99 111 110 100 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 118 105 115 105 111 110 72 105 115 116 111 114 121 76 105 109 105 116 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 116 114 97 116 101 103 121 34 58 123 34 102 58 114 111 108 108 105 110 103 85 112 100 97 116 101 34 58 123 34 46 34 58 123 125 44 34 102 58 109 97 120 83 117 114 103 101 34 58 123 125 44 34 102 58 109 97 120 85 110 97 118 97 105 108 97 98 108 101 34 58 123 125 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 14:04:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 65 118 97 105 108 97 98 108 101 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 80 114 111 103 114 101 115 115 105 110 103 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 85 112 100 97 116 101 84 105 109 101 34 58 123 125 44 34 102 58 109 101 115 115 97 103 101 34 58 123 125 44 34 102 58 114 101 97 115 111 110 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 117 112 100 97 116 101 100 82 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0055e4ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-26 14:04:20 +0000 UTC,LastTransitionTime:2020-06-26 14:04:20 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-59d5cb45c7" has successfully progressed.,LastUpdateTime:2020-06-26 14:04:21 +0000 UTC,LastTransitionTime:2020-06-26 14:04:20 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jun 26 14:04:22.963: INFO: New ReplicaSet "test-rolling-update-deployment-59d5cb45c7" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7  deployment-4006 /apis/apps/v1/namespaces/deployment-4006/replicasets/test-rolling-update-deployment-59d5cb45c7 c2fde532-5627-4c36-94dc-b031efaf710c 25816 1 2020-06-26 14:04:20 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 539e7b41-2ded-4d40-b336-d5b893f447c8 0xc0055e5057 0xc0055e5058}] []  [{kube-controller-manager Update apps/v1 2020-06-26 14:04:21 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 51 57 101 55 98 52 49 45 50 100 101 100 45 52 100 52 48 45 98 51 51 54 45 100 53 98 56 57 51 102 52 52 55 99 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 97 118 97 105 108 97 98 108 101 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 102 117 108 108 121 76 97 98 101 108 101 100 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 97 100 121 82 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 59d5cb45c7,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [] []  []} {[] [] [{agnhost us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0055e50e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 26 14:04:22.963: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun 26 14:04:22.963: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4006 /apis/apps/v1/namespaces/deployment-4006/replicasets/test-rolling-update-controller 7459b39e-09c6-4b2a-9f2e-2cdb0caae8b2 25825 2 2020-06-26 14:04:15 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 539e7b41-2ded-4d40-b336-d5b893f447c8 0xc0055e4f47 0xc0055e4f48}] []  [{e2e.test Update apps/v1 2020-06-26 14:04:15 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 46 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 114 101 118 105 115 105 111 110 34 58 123 125 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 115 101 108 101 99 116 111 114 34 58 123 34 102 58 109 97 116 99 104 76 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 116 101 109 112 108 97 116 101 34 58 123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 34 58 123 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 104 116 116 112 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125 125 125],}} {kube-controller-manager Update apps/v1 2020-06-26 14:04:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 97 110 110 111 116 97 116 105 111 110 115 34 58 123 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 100 101 115 105 114 101 100 45 114 101 112 108 105 99 97 115 34 58 123 125 44 34 102 58 100 101 112 108 111 121 109 101 110 116 46 107 117 98 101 114 110 101 116 101 115 46 105 111 47 109 97 120 45 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 53 51 57 101 55 98 52 49 45 50 100 101 100 45 52 100 52 48 45 98 51 51 54 45 100 53 98 56 57 51 102 52 52 55 99 56 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 44 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 111 98 115 101 114 118 101 100 71 101 110 101 114 97 116 105 111 110 34 58 123 125 44 34 102 58 114 101 112 108 105 99 97 115 34 58 123 125 125 125],}}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0055e4fe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 26 14:04:22.966: INFO: Pod "test-rolling-update-deployment-59d5cb45c7-lbf7z" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-59d5cb45c7-lbf7z test-rolling-update-deployment-59d5cb45c7- deployment-4006 /api/v1/namespaces/deployment-4006/pods/test-rolling-update-deployment-59d5cb45c7-lbf7z bfcb0258-4a09-422d-9436-42aa5f2dbe4d 25815 0 2020-06-26 14:04:20 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:59d5cb45c7] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-59d5cb45c7 c2fde532-5627-4c36-94dc-b031efaf710c 0xc0055e55e7 0xc0055e55e8}] []  [{kube-controller-manager Update v1 2020-06-26 14:04:20 +0000 UTC FieldsV1 FieldsV1{Raw:*[123 34 102 58 109 101 116 97 100 97 116 97 34 58 123 34 102 58 103 101 110 101 114 97 116 101 78 97 109 101 34 58 123 125 44 34 102 58 108 97 98 101 108 115 34 58 123 34 46 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 112 111 100 45 116 101 109 112 108 97 116 101 45 104 97 115 104 34 58 123 125 125 44 34 102 58 111 119 110 101 114 82 101 102 101 114 101 110 99 101 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 117 105 100 92 34 58 92 34 99 50 102 100 101 53 51 50 45 53 54 50 55 45 52 99 51 54 45 57 52 100 99 45 98 48 51 49 101 102 97 102 55 49 48 99 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 97 112 105 86 101 114 115 105 111 110 34 58 123 125 44 34 102 58 98 108 111 99 107 79 119 110 101 114 68 101 108 101 116 105 111 110 34 58 123 125 44 34 102 58 99 111 110 116 114 111 108 108 101 114 34 58 123 125 44 34 102 58 107 105 110 100 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 117 105 100 34 58 123 125 125 125 125 44 34 102 58 115 112 101 99 34 58 123 34 102 58 99 111 110 116 97 105 110 101 114 115 34 58 123 34 107 58 123 92 34 110 97 109 101 92 34 58 92 34 97 103 110 104 111 115 116 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 109 97 103 101 34 58 123 125 44 34 102 58 105 109 97 103 101 80 117 108 108 80 111 108 105 99 121 34 58 123 125 44 34 102 58 110 97 109 101 34 58 123 125 44 34 102 58 114 101 115 111 117 114 99 101 115 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 97 116 104 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 77 101 115 115 97 103 101 80 111 108 105 99 121 34 58 123 125 125 125 44 34 102 58 100 110 115 80 111 108 105 99 121 34 58 123 125 44 34 102 58 101 110 97 98 108 101 83 101 114 118 105 99 101 76 105 110 107 115 34 58 123 125 44 34 102 58 114 101 115 116 97 114 116 80 111 108 105 99 121 34 58 123 125 44 34 102 58 115 99 104 101 100 117 108 101 114 78 97 109 101 34 58 123 125 44 34 102 58 115 101 99 117 114 105 116 121 67 111 110 116 101 120 116 34 58 123 125 44 34 102 58 116 101 114 109 105 110 97 116 105 111 110 71 114 97 99 101 80 101 114 105 111 100 83 101 99 111 110 100 115 34 58 123 125 125 125],}} {kubelet Update v1 2020-06-26 14:04:21 +0000 UTC FieldsV1 &FieldsV1{Raw:*[123 34 102 58 115 116 97 116 117 115 34 58 123 34 102 58 99 111 110 100 105 116 105 111 110 115 34 58 123 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 67 111 110 116 97 105 110 101 114 115 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 73 110 105 116 105 97 108 105 122 101 100 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 44 34 107 58 123 92 34 116 121 112 101 92 34 58 92 34 82 101 97 100 121 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 108 97 115 116 80 114 111 98 101 84 105 109 101 34 58 123 125 44 34 102 58 108 97 115 116 84 114 97 110 115 105 116 105 111 110 84 105 109 101 34 58 123 125 44 34 102 58 115 116 97 116 117 115 34 58 123 125 44 34 102 58 116 121 112 101 34 58 123 125 125 125 44 34 102 58 99 111 110 116 97 105 110 101 114 83 116 97 116 117 115 101 115 34 58 123 125 44 34 102 58 104 111 115 116 73 80 34 58 123 125 44 34 102 58 112 104 97 115 101 34 58 123 125 44 34 102 58 112 111 100 73 80 34 58 123 125 44 34 102 58 112 111 100 73 80 115 34 58 123 34 46 34 58 123 125 44 34 107 58 123 92 34 105 112 92 34 58 92 34 49 48 46 49 46 49 46 49 53 51 92 34 125 34 58 123 34 46 34 58 123 125 44 34 102 58 105 112 34 58 123 125 125 125 44 34 102 58 115 116 97 114 116 84 105 109 101 34 58 123 125 125 125],}}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-88sch,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-88sch,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-88sch,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:docker-desktop,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 14:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 14:04:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 14:04:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-26 14:04:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:192.168.65.3,PodIP:10.1.1.153,StartTime:2020-06-26 14:04:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-26 14:04:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12,ImageID:docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c,ContainerID:docker://37324e08793fd4e3467334379bd488d5d6202f0faff44947afe18b7e1b14874b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.1.1.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:22.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4006" for this suite.

• [SLOW TEST:7.109 seconds]
[sig-apps] Deployment
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","total":276,"completed":259,"skipped":4425,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:22.982: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-cb2da608-8c6c-44cb-bd3c-2114c9e8ef7e in namespace container-probe-2944
Jun 26 14:04:25.016: INFO: Started pod liveness-cb2da608-8c6c-44cb-bd3c-2114c9e8ef7e in namespace container-probe-2944
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 14:04:25.019: INFO: Initial restart count of pod liveness-cb2da608-8c6c-44cb-bd3c-2114c9e8ef7e is 0
Jun 26 14:04:47.070: INFO: Restart count of pod container-probe-2944/liveness-cb2da608-8c6c-44cb-bd3c-2114c9e8ef7e is now 1 (22.050833414s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:47.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2944" for this suite.

• [SLOW TEST:24.119 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","total":276,"completed":260,"skipped":4448,"failed":0}
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:47.101: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 26 14:04:47.136: INFO: Waiting up to 5m0s for pod "pod-42add932-27cc-4316-9082-07ed0693f351" in namespace "emptydir-4117" to be "Succeeded or Failed"
Jun 26 14:04:47.139: INFO: Pod "pod-42add932-27cc-4316-9082-07ed0693f351": Phase="Pending", Reason="", readiness=false. Elapsed: 2.657796ms
Jun 26 14:04:49.144: INFO: Pod "pod-42add932-27cc-4316-9082-07ed0693f351": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007749818s
STEP: Saw pod success
Jun 26 14:04:49.144: INFO: Pod "pod-42add932-27cc-4316-9082-07ed0693f351" satisfied condition "Succeeded or Failed"
Jun 26 14:04:49.147: INFO: Trying to get logs from node docker-desktop pod pod-42add932-27cc-4316-9082-07ed0693f351 container test-container: <nil>
STEP: delete the pod
Jun 26 14:04:49.163: INFO: Waiting for pod pod-42add932-27cc-4316-9082-07ed0693f351 to disappear
Jun 26 14:04:49.165: INFO: Pod pod-42add932-27cc-4316-9082-07ed0693f351 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:49.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4117" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":261,"skipped":4449,"failed":0}
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:49.182: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 26 14:04:51.227: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:51.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8505" for this suite.
•{"msg":"PASSED [k8s.io] Container Runtime blackbox test on terminated container should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","total":276,"completed":262,"skipped":4464,"failed":0}
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:51.257: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating secret with name secret-test-7d3d3f0c-0d6d-4f33-8e86-a8f7fb62c44a
STEP: Creating a pod to test consume secrets
Jun 26 14:04:51.298: INFO: Waiting up to 5m0s for pod "pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f" in namespace "secrets-870" to be "Succeeded or Failed"
Jun 26 14:04:51.300: INFO: Pod "pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.497917ms
Jun 26 14:04:53.304: INFO: Pod "pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006302446s
STEP: Saw pod success
Jun 26 14:04:53.304: INFO: Pod "pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f" satisfied condition "Succeeded or Failed"
Jun 26 14:04:53.307: INFO: Trying to get logs from node docker-desktop pod pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f container secret-volume-test: <nil>
STEP: delete the pod
Jun 26 14:04:53.322: INFO: Waiting for pod pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f to disappear
Jun 26 14:04:53.325: INFO: Pod pod-secrets-350145cb-53a7-4dfe-87d8-7be22589d83f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:53.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-870" for this suite.
•{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":263,"skipped":4475,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:53.335: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 26 14:04:53.366: INFO: Waiting up to 5m0s for pod "pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01" in namespace "emptydir-1598" to be "Succeeded or Failed"
Jun 26 14:04:53.368: INFO: Pod "pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01": Phase="Pending", Reason="", readiness=false. Elapsed: 1.915828ms
Jun 26 14:04:55.372: INFO: Pod "pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00607327s
STEP: Saw pod success
Jun 26 14:04:55.372: INFO: Pod "pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01" satisfied condition "Succeeded or Failed"
Jun 26 14:04:55.375: INFO: Trying to get logs from node docker-desktop pod pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01 container test-container: <nil>
STEP: delete the pod
Jun 26 14:04:55.388: INFO: Waiting for pod pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01 to disappear
Jun 26 14:04:55.391: INFO: Pod pod-5d67f67a-2ee5-4c03-9d25-25a877b02f01 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:04:55.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1598" for this suite.
•{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":264,"skipped":4499,"failed":0}
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:04:55.400: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:54
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating pod liveness-f866f4fc-8a0b-4e4e-a753-6d2f98264523 in namespace container-probe-9875
Jun 26 14:04:57.442: INFO: Started pod liveness-f866f4fc-8a0b-4e4e-a753-6d2f98264523 in namespace container-probe-9875
STEP: checking the pod's current state and verifying that restartCount is present
Jun 26 14:04:57.446: INFO: Initial restart count of pod liveness-f866f4fc-8a0b-4e4e-a753-6d2f98264523 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:08:57.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9875" for this suite.

• [SLOW TEST:242.624 seconds]
[k8s.io] Probing container
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","total":276,"completed":265,"skipped":4510,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:08:57.998: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:178
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jun 26 14:08:58.037: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:09.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4132" for this suite.

• [SLOW TEST:11.528 seconds]
[k8s.io] Pods
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [k8s.io] Pods should be submitted and removed [NodeConformance] [Conformance]","total":276,"completed":266,"skipped":4534,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:09.527: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name secret-emptykey-test-85eb82df-2f55-42e4-b601-5795e12115fe
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:09.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8576" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance]","total":276,"completed":267,"skipped":4567,"failed":0}
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:09.555: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:20.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1652" for this suite.

• [SLOW TEST:11.057 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","total":276,"completed":268,"skipped":4587,"failed":0}
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should patch a secret [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:20.615: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should patch a secret [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating a secret
STEP: listing secrets in all namespaces to ensure that there are more than zero
STEP: patching the secret
STEP: deleting the secret using a LabelSelector
STEP: listing secrets in all namespaces, searching for label name and value in patch
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:20.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6857" for this suite.
•{"msg":"PASSED [sig-api-machinery] Secrets should patch a secret [Conformance]","total":276,"completed":269,"skipped":4603,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:20.661: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:09:20.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8056'
Jun 26 14:09:20.862: INFO: stderr: ""
Jun 26 14:09:20.862: INFO: stdout: "replicationcontroller/agnhost-master created\n"
Jun 26 14:09:20.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 create -f - --namespace=kubectl-8056'
Jun 26 14:09:21.030: INFO: stderr: ""
Jun 26 14:09:21.030: INFO: stdout: "service/agnhost-master created\n"
STEP: Waiting for Agnhost master to start.
Jun 26 14:09:22.037: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:22.037: INFO: Found 0 / 1
Jun 26 14:09:23.034: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:23.034: INFO: Found 0 / 1
Jun 26 14:09:24.036: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:24.036: INFO: Found 0 / 1
Jun 26 14:09:25.032: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:25.032: INFO: Found 0 / 1
Jun 26 14:09:26.035: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:26.035: INFO: Found 1 / 1
Jun 26 14:09:26.035: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 26 14:09:26.037: INFO: Selector matched 1 pods for map[app:agnhost]
Jun 26 14:09:26.037: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 26 14:09:26.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 describe pod agnhost-master-2x6wb --namespace=kubectl-8056'
Jun 26 14:09:26.132: INFO: stderr: ""
Jun 26 14:09:26.132: INFO: stdout: "Name:         agnhost-master-2x6wb\nNamespace:    kubectl-8056\nPriority:     0\nNode:         docker-desktop/192.168.65.3\nStart Time:   Fri, 26 Jun 2020 14:09:20 +0000\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.1.1.161\nIPs:\n  IP:           10.1.1.161\nControlled By:  ReplicationController/agnhost-master\nContainers:\n  agnhost-master:\n    Container ID:   docker://6ee1c849fe7b67e571afd72c1c882ebb72670f571843e4d6eb6a3316abfeb03f\n    Image:          us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Image ID:       docker-pullable://us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost@sha256:1d7f0d77a6f07fd507f147a38d06a7c8269ebabd4f923bfe46d4fb8b396a520c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 26 Jun 2020 14:09:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jg7kv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jg7kv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jg7kv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                     Message\n  ----    ------     ----  ----                     -------\n  Normal  Scheduled  6s    default-scheduler        Successfully assigned kubectl-8056/agnhost-master-2x6wb to docker-desktop\n  Normal  Pulled     2s    kubelet, docker-desktop  Container image \"us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\" already present on machine\n  Normal  Created    2s    kubelet, docker-desktop  Created container agnhost-master\n  Normal  Started    1s    kubelet, docker-desktop  Started container agnhost-master\n"
Jun 26 14:09:26.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 describe rc agnhost-master --namespace=kubectl-8056'
Jun 26 14:09:26.211: INFO: stderr: ""
Jun 26 14:09:26.211: INFO: stdout: "Name:         agnhost-master\nNamespace:    kubectl-8056\nSelector:     app=agnhost,role=master\nLabels:       app=agnhost\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=master\n  Containers:\n   agnhost-master:\n    Image:        us.gcr.io/k8s-artifacts-prod/e2e-test-images/agnhost:2.12\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: agnhost-master-2x6wb\n"
Jun 26 14:09:26.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 describe service agnhost-master --namespace=kubectl-8056'
Jun 26 14:09:26.282: INFO: stderr: ""
Jun 26 14:09:26.283: INFO: stdout: "Name:              agnhost-master\nNamespace:         kubectl-8056\nLabels:            app=agnhost\n                   role=master\nAnnotations:       <none>\nSelector:          app=agnhost,role=master\nType:              ClusterIP\nIP:                10.111.221.100\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         10.1.1.161:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun 26 14:09:26.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 describe node docker-desktop'
Jun 26 14:09:26.366: INFO: stderr: ""
Jun 26 14:09:26.366: INFO: stdout: "Name:               docker-desktop\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=docker-desktop\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 26 Jun 2020 12:48:34 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  docker-desktop\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 26 Jun 2020 14:09:17 +0000\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 26 Jun 2020 14:04:33 +0000   Fri, 26 Jun 2020 12:48:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 26 Jun 2020 14:04:33 +0000   Fri, 26 Jun 2020 12:48:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 26 Jun 2020 14:04:33 +0000   Fri, 26 Jun 2020 12:48:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 26 Jun 2020 14:04:33 +0000   Fri, 26 Jun 2020 12:48:34 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  192.168.65.3\n  Hostname:    docker-desktop\nCapacity:\n  cpu:                6\n  ephemeral-storage:  61255492Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             2038544Ki\n  pods:               110\nAllocatable:\n  cpu:                6\n  ephemeral-storage:  56453061334\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             1936144Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 aa4a6b67-b026-4f19-8231-90361e6247bc\n  System UUID:                a592459d-0000-0000-8f62-375a108b88a4\n  Boot ID:                    747dddf8-0e04-46f0-9c99-1d7e88d0096f\n  Kernel Version:             4.19.76-linuxkit\n  OS Image:                   Docker Desktop\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  docker://19.3.12\n  Kubelet Version:            v1.18.3\n  Kube-Proxy Version:         v1.18.3\nNon-terminated Pods:          (13 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------  ---\n  docker                      compose-858b8f86cc-tx2ld                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  docker                      compose-api-767cd94f6-wd2l9                                0 (0%)        0 (0%)      0 (0%)           0 (0%)         57m\n  kube-system                 coredns-66bff467f8-dfrnp                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     57m\n  kube-system                 coredns-66bff467f8-rcx2v                                   100m (1%)     0 (0%)      70Mi (3%)        170Mi (8%)     57m\n  kube-system                 etcd-docker-desktop                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         79m\n  kube-system                 kube-apiserver-docker-desktop                              250m (4%)     0 (0%)      0 (0%)           0 (0%)         79m\n  kube-system                 kube-controller-manager-docker-desktop                     200m (3%)     0 (0%)      0 (0%)           0 (0%)         79m\n  kube-system                 kube-proxy-tzb5b                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         80m\n  kube-system                 kube-scheduler-docker-desktop                              100m (1%)     0 (0%)      0 (0%)           0 (0%)         79m\n  kubectl-8056                agnhost-master-2x6wb                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         6s\n  sonobuoy                    sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  sonobuoy                    sonobuoy-e2e-job-ad77c8f3bad64e56                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-d3fbe960354442de-cz22k    0 (0%)        0 (0%)      0 (0%)           0 (0%)         68m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (12%)  0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none>\n"
Jun 26 14:09:26.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-107382027 describe namespace kubectl-8056'
Jun 26 14:09:26.441: INFO: stderr: ""
Jun 26 14:09:26.441: INFO: stdout: "Name:         kubectl-8056\nLabels:       e2e-framework=kubectl\n              e2e-run=d19e42d1-cbd6-46a4-9d55-dd4b50a27e47\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:26.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8056" for this suite.

• [SLOW TEST:5.785 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:978
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","total":276,"completed":270,"skipped":4613,"failed":0}
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:26.447: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
Jun 26 14:09:26.464: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Jun 26 14:09:28.484: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:29.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9204" for this suite.
•{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","total":276,"completed":271,"skipped":4618,"failed":0}

------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:29.497: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating configMap with name projected-configmap-test-volume-300be7a3-5acd-4d19-b647-70dc7c524ea9
STEP: Creating a pod to test consume configMaps
Jun 26 14:09:29.532: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a" in namespace "projected-7697" to be "Succeeded or Failed"
Jun 26 14:09:29.535: INFO: Pod "pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.176078ms
Jun 26 14:09:31.539: INFO: Pod "pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00670666s
STEP: Saw pod success
Jun 26 14:09:31.539: INFO: Pod "pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a" satisfied condition "Succeeded or Failed"
Jun 26 14:09:31.541: INFO: Trying to get logs from node docker-desktop pod pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 26 14:09:31.568: INFO: Waiting for pod pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a to disappear
Jun 26 14:09:31.573: INFO: Pod pod-projected-configmaps-59157df7-cc42-46b6-b21b-26f347df8b1a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:31.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7697" for this suite.
•{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","total":276,"completed":272,"skipped":4618,"failed":0}
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:31.583: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8984" for this suite.

• [SLOW TEST:17.080 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","total":276,"completed":273,"skipped":4635,"failed":0}
SSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:48.664: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:698
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: creating service multi-endpoint-test in namespace services-5932
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5932 to expose endpoints map[]
Jun 26 14:09:48.694: INFO: Get endpoints failed (2.08742ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 26 14:09:49.700: INFO: successfully validated that service multi-endpoint-test in namespace services-5932 exposes endpoints map[] (1.007526508s elapsed)
STEP: Creating pod pod1 in namespace services-5932
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5932 to expose endpoints map[pod1:[100]]
Jun 26 14:09:51.727: INFO: successfully validated that service multi-endpoint-test in namespace services-5932 exposes endpoints map[pod1:[100]] (2.021701039s elapsed)
STEP: Creating pod pod2 in namespace services-5932
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5932 to expose endpoints map[pod1:[100] pod2:[101]]
Jun 26 14:09:53.764: INFO: successfully validated that service multi-endpoint-test in namespace services-5932 exposes endpoints map[pod1:[100] pod2:[101]] (2.033327537s elapsed)
STEP: Deleting pod pod1 in namespace services-5932
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5932 to expose endpoints map[pod2:[101]]
Jun 26 14:09:53.784: INFO: successfully validated that service multi-endpoint-test in namespace services-5932 exposes endpoints map[pod2:[101]] (13.642639ms elapsed)
STEP: Deleting pod pod2 in namespace services-5932
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5932 to expose endpoints map[]
Jun 26 14:09:54.801: INFO: successfully validated that service multi-endpoint-test in namespace services-5932 exposes endpoints map[] (1.007696487s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:54.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5932" for this suite.
[AfterEach] [sig-network] Services
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:702

• [SLOW TEST:6.164 seconds]
[sig-network] Services
/workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
------------------------------
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","total":276,"completed":274,"skipped":4644,"failed":0}
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:54.829: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: Creating projection with secret that has name projected-secret-test-d4a70fce-4ffd-4f06-be92-c08f9ebee7e5
STEP: Creating a pod to test consume secrets
Jun 26 14:09:54.863: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298" in namespace "projected-7689" to be "Succeeded or Failed"
Jun 26 14:09:54.865: INFO: Pod "pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298": Phase="Pending", Reason="", readiness=false. Elapsed: 1.762714ms
Jun 26 14:09:56.874: INFO: Pod "pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010608364s
STEP: Saw pod success
Jun 26 14:09:56.874: INFO: Pod "pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298" satisfied condition "Succeeded or Failed"
Jun 26 14:09:56.876: INFO: Trying to get logs from node docker-desktop pod pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 26 14:09:56.893: INFO: Waiting for pod pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298 to disappear
Jun 26 14:09:56.897: INFO: Pod pod-projected-secrets-97f10121-6ea6-44c4-8460-f2c88685e298 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:56.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7689" for this suite.
•{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","total":276,"completed":275,"skipped":4700,"failed":0}
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:178
STEP: Creating a kubernetes client
Jun 26 14:09:56.902: INFO: >>> kubeConfig: /tmp/kubeconfig-107382027
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:219
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:703
STEP: starting the proxy server
Jun 26 14:09:56.922: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-107382027 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.18.3-beta.0.58+d6e40f410ca91c/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:179
Jun 26 14:09:56.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5815" for this suite.
•{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","total":276,"completed":276,"skipped":4710,"failed":0}
SSSSSSJun 26 14:09:56.987: INFO: Running AfterSuite actions on all nodes
Jun 26 14:09:56.990: INFO: Running AfterSuite actions on node 1
Jun 26 14:09:56.990: INFO: Skipping dumping logs from cluster

JUnit report was created: /tmp/results/junit_01.xml
{"msg":"Test Suite completed","total":276,"completed":276,"skipped":4716,"failed":0}

Ran 276 of 4992 Specs in 4135.567 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4716 Skipped
PASS

Ginkgo ran 1 suite in 1h8m56.928680262s
Test Suite Passed
